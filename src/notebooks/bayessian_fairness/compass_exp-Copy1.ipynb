{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"exp_compass\"\n",
    "exp_number = \"exp_1\"\n",
    "base_path = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/\"\n",
    "data_path = base_path + \"/my_code/Bayesian-fairness/data\"\n",
    "save_path = base_path + f\"/my_code/Bayesian-fairness/results/{exp_name}/{exp_number}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set atributes\n",
    "Z_atr = [\"sex\", \"race\"]\n",
    "X_atr = ['age_cat', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree']\n",
    "Y_atr = ['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compas_dataset(path, clip_features, clip_value):\n",
    "    raw_data = pd.read_csv(path + \"/compas.csv\")\n",
    "    raw_data[raw_data[clip_features] > 2] = 2\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_features = [\"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\"]\n",
    "data = load_compas_dataset(path = data_path, clip_features = clip_features, clip_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct values\n",
    "unique_z = np.unique(data[Z_atr].values, axis=0)\n",
    "n_z = len(unique_z)\n",
    "\n",
    "unique_x = np.unique(data[X_atr].values, axis=0)\n",
    "n_x = len(unique_x)\n",
    "\n",
    "unique_y = np.unique(data[Y_atr].values, axis=0)\n",
    "n_y = len(unique_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Z values: 12\n",
      "Unique X values: 141\n",
      "Unique Y values: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Z values:\", n_z)\n",
    "print(\"Unique X values:\", n_x)\n",
    "print(\"Unique Y values:\", n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data,unique_values):\n",
    "    encoded_value = np.array([])\n",
    "    for i, d in data.iterrows():\n",
    "        # encode feature to an index represents the unique value.\n",
    "        index = np.argmax((d.values == unique_values).all(axis=1))\n",
    "        encoded_value = np.append(encoded_value, index)\n",
    "    return encoded_value.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compact_dataset():\n",
    "    # encode z\n",
    "    encoded_z = encode_data(data[Z_atr], unique_z)\n",
    "    assert (int(max(encoded_z))+1) == len(unique_z)\n",
    "    \n",
    "    # encode x\n",
    "    encoded_x = encode_data(data[X_atr], unique_x)\n",
    "    assert (int(max(encoded_x))+1) == len(unique_x)\n",
    "    \n",
    "    # encode y\n",
    "    encoded_y = encode_data(data[Y_atr], unique_y)\n",
    "    assert (int(max(encoded_y))+1) == len(unique_y)\n",
    "\n",
    "    return np.stack([encoded_x, encoded_z, encoded_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_compact_dataset()\n",
    "dataset = pd.DataFrame(dataset,columns = [\"x\",\"z\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>z</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  z  y\n",
       "0  124  0  0\n",
       "1   64  1  1\n",
       "2   11  1  1\n",
       "3   20  1  0\n",
       "4   68  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.iloc[0:6000]\n",
    "test_data = dataset.iloc[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (6000, 3)\n",
      "testing size: (1214, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"training size:\", train_data.shape)\n",
    "print(\"testing size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirichletModel:\n",
    "    def __init__(self, n_x, n_z, n_y, prior):\n",
    "        self.X = n_x\n",
    "        self.Y = n_y\n",
    "        self.Z = n_z\n",
    "        \n",
    "        # why we have this fractoriazation?\n",
    "        self.N_x = prior + np.zeros(shape = (n_x, 1) )\n",
    "        self.N_y_x = prior + np.zeros(shape = (n_y, n_x) )\n",
    "        self.N_z_yx = prior + np.zeros(shape = (n_z, n_y, n_x) )\n",
    "        \n",
    "        # prop\n",
    "        self.Px = np.zeros(shape = (n_x, 1) )\n",
    "        self.Py_x = np.zeros(shape = (n_y, n_x) )\n",
    "        self.Pz_yx = np.zeros(shape = (n_z, n_y, n_x) )\n",
    "    \n",
    "    def update_posterior_belief(self, data):\n",
    "        for i , datum in data.iterrows():\n",
    "            self.N_x[datum[\"x\"]] += 1\n",
    "            self.N_y_x[datum[\"y\"], datum[\"x\"]] += 1\n",
    "            self.N_z_yx[datum[\"z\"], datum[\"y\"], datum[\"x\"]] += 1\n",
    "        \n",
    "    def calculate_marginal_propabilities(self):\n",
    "        # calculate Prop\n",
    "        self.Pxyz =  np.zeros(shape = (self.X, self.Y, self.Z) )\n",
    "        self.Pxy = np.zeros(shape = (self.X, self.Y) )\n",
    "        self.Pyz = np.zeros(shape = (self.Y, self.Z) )\n",
    "        self.Px_yz = np.zeros(shape = (self.X, self.Y, self.Z) )\n",
    "        \n",
    "        # calculate Pxyz\n",
    "        for x in range(self.X):\n",
    "            for y in range(self.Y):\n",
    "                for z in range(self.Z):\n",
    "                    # calculate Pxyz\n",
    "                    self.Pxyz[x, y, z] = self.Pz_yx[z, y, x] * self.Py_x[y, x] * self.Px[x]\n",
    "        \n",
    "        # calculate Px_yz \n",
    "        for y in range(self.Y):\n",
    "            for z in range(self.Z):\n",
    "                self.Pyz[y, z] = np.sum(self.Pxyz[:, y, z])    \n",
    "                for x in range(self.X):\n",
    "                    self.Pxy[x, y] = np.sum(self.Pxyz[x, y, :])\n",
    "                    self.Px_yz[x, y, z] = self.Pxyz[x, y, z] / self.Pyz[y, z]\n",
    "        \n",
    "        # calculate Px_y\n",
    "        self.Py = np.zeros(shape = (self.Y, 1) )\n",
    "        self.Px_y = np.zeros(shape = (self.X, self.Y) )\n",
    "        for y in range(self.Y):\n",
    "            self.Py[y] = np.sum(self.Pxyz[:, y, :])\n",
    "            for x in range(self.X):\n",
    "                self.Px_y[x,y] = self.Pxy[x,y] / self.Py[y]\n",
    "        \n",
    "        # calculate Pz_y\n",
    "        self.Pz_y = np.zeros(shape = (self.Z, self.Y) )\n",
    "        for y in range(self.Y):\n",
    "            self.Pz_y[:,y] = self.Pyz[y,:] / self.Py[y]\n",
    "                \n",
    "    def get_marginal_model(self):\n",
    "        self.Px = self.N_x / np.sum(self.N_x)\n",
    "        self.Py_x = self.N_y_x / np.sum(self.N_y_x, axis=0)\n",
    "        self.Pz_yx = self.N_z_yx / np.sum(self.N_z_yx, axis=0)\n",
    "        self.calculate_marginal_propabilities()\n",
    "        \n",
    "    def sample_model(self):\n",
    "        self.Px = np.random.dirichlet( np.ravel(dirichlet_model.N_x) ).reshape((-1,1))\n",
    "        \n",
    "        for y in range(self.Y):\n",
    "            self.Py_x[y, :] = np.random.dirichlet(self.N_y_x[y,:])\n",
    "        \n",
    "        for y in range(self.Y):\n",
    "            for z in range(self.Z):\n",
    "                self.Pz_yx[z, y, :] = np.random.dirichlet(self.N_z_yx[z, y, :])\n",
    "        \n",
    "        self.calculate_marginal_propabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_prior = 0.5\n",
    "true_dirichlet_model = DirichletModel(n_x = n_x, n_z = n_z, n_y = n_y, prior = dirichlet_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dirichlet_model.update_posterior_belief(data=test_data)\n",
    "true_dirichlet_model.get_marginal_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_policy(size):\n",
    "    a = np.ones(shape=size[0])\n",
    "    policy = np.random.dirichlet(a, size= size[1])\n",
    "    return np.transpose(policy)\n",
    "\n",
    "def get_random_policy_2(size):\n",
    "    policy = np.random.random(size = size)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = get_random_policy(size = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normilize_policy(policy):\n",
    "    policy[policy < 0] = 0\n",
    "    policy[policy > 1] = 1\n",
    "    for x in range(policy.shape[-1]):\n",
    "        policy[:, x] /= np.sum(policy[:, x])\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(Px_y, Px_yz):\n",
    "    delta = np.zeros(Px_yz.shape)\n",
    "    for z in range(Px_yz.shape[-1]):\n",
    "        delta[:, :, z] = Px_y - Px_yz[:,:,z]\n",
    "    return delta\n",
    "\n",
    "def get_delta(Px_y, Px_yz, Pz_y):\n",
    "    delta = np.zeros(Px_yz.shape)\n",
    "    for z in range(Px_yz.shape[-1]):\n",
    "        delta[:, :, z] = (Px_y - Px_yz[:,:,z]) * Pz_y[z,:]\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_1 = get_delta(true_dirichlet_model.Px_y, true_dirichlet_model.Px_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_2 = get_delta2(true_dirichlet_model.Px_y, true_dirichlet_model.Px_yz, true_dirichlet_model.Pz_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_utility(size):\n",
    "    return np.eye(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- data parameters\n",
    "horizon = train_data.shape[0]\n",
    "\n",
    "num_X = n_x # number of features\n",
    "num_Y = n_y # number of outcomes\n",
    "num_Z = n_z # number of sensitive features\n",
    "num_A = 2 # number of actions\n",
    "\n",
    "# --- SGD parameters\n",
    "n_iter = 400 # number of itteration for SGD\n",
    "lr = 1.0 # learning rate\n",
    "\n",
    "# --- Algorithm parameters\n",
    "update_policy_period = 100 # period to update policy\n",
    "l = 0.5 # lambda\n",
    "n_samples = 16 # number of sample for bayssian policy\n",
    "\n",
    "# --- Utility\n",
    "utility = get_eye_utility(size=num_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. initializition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize belief\n",
    "belief = DirichletModel(n_x = num_X, n_y=num_Y, n_z=num_Z, prior = 0.5)\n",
    "\n",
    "# initialize policy\n",
    "policy = get_random_policy(size = (num_A, num_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true model delta to avoid computations\n",
    "true_model_delta = get_delta(true_dirichlet_model.Px_y,\n",
    "                             true_dirichlet_model.Px_yz,\n",
    "                             true_dirichlet_model.Pz_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fairness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness(policy, model_delta):\n",
    "    (X, Y, Z) = model_delta.shape\n",
    "    fairness = 0\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            delta = np.matmul(policy, model_delta[:, y , z ])\n",
    "            fairness += np.linalg.norm(delta, 1)\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_gradient(policy, model_delta):\n",
    "    \"\"\"\n",
    "    Todo: vectorize operation\n",
    "    \"\"\"\n",
    "    fairness_gradient = np.zeros(policy.shape)\n",
    "    \n",
    "    (X, Y, Z) = model_delta.shape\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            dyz = model_delta[:,y,z].reshape((-1,1))\n",
    "            c = np.matmul(policy, dyz)\n",
    "            fairness_gradient -= np.matmul(c, dyz.T)\n",
    "    \n",
    "    return fairness_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Calculate expected utility\n",
    "    Todo: vectorize operation - minor\n",
    "    \"\"\"\n",
    "    A, X = policy.shape\n",
    "    Y = A\n",
    "    Eu = 0\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            for a in range(A):\n",
    "                Eu += utility[a,y] * policy[a,x] * model.Pxy[x,y]\n",
    "                \n",
    "    return Eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_gradient(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Todo: vectorize operation\n",
    "    \"\"\"\n",
    "    utility_gradient = np.matmul(utility, model.Pxy.T )\n",
    "    \n",
    "    \n",
    "    return utility_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_gradient(grad):\n",
    "    proj_grad = grad - np.mean(grad,axis=0)\n",
    "    return proj_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### opt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_model, true_model_delta, policy, utility, l):\n",
    "    \"\"\"\n",
    "    Evaluate policy on true model\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    results[\"fairness\"] = np.round(get_fairness(policy, true_model_delta),4)\n",
    "    results[\"utility\"] = get_utility(policy, true_model, utility)\n",
    "    results[\"total\"] = (1 - l) * results[\"utility\"] - l * results[\"fairness\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, model, utility, l, lr, n_iter):\n",
    "    \"\"\"\n",
    "    Marginal Policy Dirichlet\n",
    "    \"\"\"\n",
    "    model.get_marginal_model()\n",
    "    model_delta = get_delta(model.Px_y, model.Px_yz, model.Pz_y)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        fairness_gradient = get_fairness_gradient(policy, model_delta)\n",
    "        utility_gradient = get_utility_gradient(policy, model, utility)\n",
    "        gradient = (1 - l) * utility_gradient + l * fairness_gradient # minus on the gradient calc.\n",
    "        gradient = project_gradient(gradient)\n",
    "        policy = policy + lr * gradient # maximize Utility & minimize fairness constrain.\n",
    "        policy = normilize_policy(policy)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# reproduce results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "# reproduce results\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_org_policy(org_path_results):\n",
    "    file = pd.read_csv(org_path_results + \"/policy.csv\")\n",
    "    p_1 = file.iloc[4].values\n",
    "    p_2 = file.iloc[5].values\n",
    "    p_1 = [float(x) for x in p_1[0].split(\" \")[1:]]\n",
    "    p_2 = [float(x) for x in p_2[0].split(\" \")[1:]]\n",
    "    return np.array([p_1, p_2])\n",
    "# [float(x) for x in p_1[0].split(\" \")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 141)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_path_results = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/org_code/bayesian-fairness/src/octave\"\n",
    "policy = load_org_policy(org_path_results)\n",
    "policy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Calculate expected utility\n",
    "    Todo: vectorize operation - minor\n",
    "    \"\"\"\n",
    "    A, X = policy.shape\n",
    "    Y = A\n",
    "    Eu = 0\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            for a in range(A):\n",
    "                Eu += utility[a,y] * policy[a,x] * model.Pxy[x,y]\n",
    "                \n",
    "    return Eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.637832923125326"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_utility(policy, true_dirichlet_model, utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000000000001"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.mean(m,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.matmul(policy,true_dirichlet_model.Pxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6378329231253261"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(utility * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(141, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(range(141), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1 \n",
      "  ------- {'fairness': 0.1384, 'utility': 0.4804503987963803, 'total': -0.07651496012036199}\n",
      "--- Step : 101 \n",
      "  ------- {'fairness': 0.1845, 'utility': 0.5518809227813718, 'total': -0.11086190772186283}\n",
      "--- Step : 201 \n",
      "  ------- {'fairness': 0.2297, 'utility': 0.5796560575888795, 'total': -0.14876439424111207}\n",
      "--- Step : 301 \n",
      "  ------- {'fairness': 0.2704, 'utility': 0.608810747225974, 'total': -0.18247892527740261}\n",
      "--- Step : 401 \n",
      "  ------- {'fairness': 0.263, 'utility': 0.6187054138137963, 'total': -0.1748294586186204}\n",
      "--- Step : 501 \n",
      "  ------- {'fairness': 0.2485, 'utility': 0.6228421039832859, 'total': -0.16136578960167144}\n",
      "--- Step : 601 \n",
      "  ------- {'fairness': 0.2559, 'utility': 0.6280360529013993, 'total': -0.16750639470986012}\n",
      "--- Step : 701 \n",
      "  ------- {'fairness': 0.2679, 'utility': 0.6339927125354835, 'total': -0.17771072874645166}\n",
      "--- Step : 801 \n",
      "  ------- {'fairness': 0.2676, 'utility': 0.63539189184272, 'total': -0.17730081081572802}\n",
      "--- Step : 901 \n",
      "  ------- {'fairness': 0.2559, 'utility': 0.6346186786979807, 'total': -0.16684813213020194}\n",
      "--- Step : 1001 \n",
      "  ------- {'fairness': 0.2489, 'utility': 0.634646116368414, 'total': -0.16054538836315863}\n",
      "--- Step : 1101 \n",
      "  ------- {'fairness': 0.2486, 'utility': 0.6350228619397149, 'total': -0.16023771380602853}\n",
      "--- Step : 1201 \n",
      "  ------- {'fairness': 0.2508, 'utility': 0.635660804557318, 'total': -0.16215391954426825}\n",
      "--- Step : 1301 \n",
      "  ------- {'fairness': 0.2566, 'utility': 0.6368601527624554, 'total': -0.16725398472375447}\n",
      "--- Step : 1401 \n",
      "  ------- {'fairness': 0.2545, 'utility': 0.6368912950491912, 'total': -0.1653608704950809}\n",
      "--- Step : 1501 \n",
      "  ------- {'fairness': 0.2441, 'utility': 0.6352794203838399, 'total': -0.15616205796161603}\n",
      "--- Step : 1601 \n",
      "  ------- {'fairness': 0.2377, 'utility': 0.6347396212975089, 'total': -0.15045603787024914}\n",
      "--- Step : 1701 \n",
      "  ------- {'fairness': 0.2412, 'utility': 0.6360123405508151, 'total': -0.1534787659449185}\n",
      "--- Step : 1801 \n",
      "  ------- {'fairness': 0.2407, 'utility': 0.6365440395797155, 'total': -0.15297559604202846}\n",
      "--- Step : 1901 \n",
      "  ------- {'fairness': 0.2371, 'utility': 0.6362638565315706, 'total': -0.14976361434684293}\n",
      "--- Step : 2001 \n",
      "  ------- {'fairness': 0.2324, 'utility': 0.635995483224567, 'total': -0.14556045167754333}\n",
      "--- Step : 2101 \n",
      "  ------- {'fairness': 0.2279, 'utility': 0.6356230637667102, 'total': -0.14154769362332897}\n",
      "--- Step : 2201 \n",
      "  ------- {'fairness': 0.2265, 'utility': 0.6353931709501691, 'total': -0.1403106829049831}\n",
      "--- Step : 2301 \n",
      "  ------- {'fairness': 0.2259, 'utility': 0.6352438327656781, 'total': -0.1397856167234322}\n",
      "--- Step : 2401 \n",
      "  ------- {'fairness': 0.2255, 'utility': 0.6350316892425432, 'total': -0.13944683107574574}\n",
      "--- Step : 2501 \n",
      "  ------- {'fairness': 0.227, 'utility': 0.6349247616079616, 'total': -0.14080752383920386}\n",
      "--- Step : 2601 \n",
      "  ------- {'fairness': 0.2288, 'utility': 0.6349094619071137, 'total': -0.14242905380928866}\n",
      "--- Step : 2701 \n",
      "  ------- {'fairness': 0.2293, 'utility': 0.6349786014796027, 'total': -0.14287213985203973}\n",
      "--- Step : 2801 \n",
      "  ------- {'fairness': 0.2293, 'utility': 0.6350901473196234, 'total': -0.14286098526803767}\n",
      "--- Step : 2901 \n",
      "  ------- {'fairness': 0.2294, 'utility': 0.6352285887584488, 'total': -0.14293714112415512}\n",
      "--- Step : 3001 \n",
      "  ------- {'fairness': 0.2296, 'utility': 0.6354325641563805, 'total': -0.14309674358436197}\n",
      "--- Step : 3101 \n",
      "  ------- {'fairness': 0.2298, 'utility': 0.63563183830872, 'total': -0.143256816169128}\n",
      "--- Step : 3201 \n",
      "  ------- {'fairness': 0.2299, 'utility': 0.6356945690031318, 'total': -0.14334054309968686}\n",
      "--- Step : 3301 \n",
      "  ------- {'fairness': 0.2301, 'utility': 0.6357143678739954, 'total': -0.14351856321260048}\n",
      "--- Step : 3401 \n",
      "  ------- {'fairness': 0.2305, 'utility': 0.6358337933861646, 'total': -0.14386662066138356}\n",
      "--- Step : 3501 \n",
      "  ------- {'fairness': 0.2308, 'utility': 0.63593309288203, 'total': -0.144126690711797}\n",
      "--- Step : 3601 \n",
      "  ------- {'fairness': 0.2309, 'utility': 0.6359232784514315, 'total': -0.14421767215485687}\n",
      "--- Step : 3701 \n",
      "  ------- {'fairness': 0.2312, 'utility': 0.6359647786420827, 'total': -0.14448352213579174}\n",
      "--- Step : 3801 \n",
      "  ------- {'fairness': 0.2314, 'utility': 0.6360196997406626, 'total': -0.14465803002593375}\n",
      "--- Step : 3901 \n",
      "  ------- {'fairness': 0.2316, 'utility': 0.6360490755084101, 'total': -0.14483509244915904}\n",
      "--- Step : 4001 \n",
      "  ------- {'fairness': 0.2318, 'utility': 0.6360899020554613, 'total': -0.14501100979445386}\n",
      "--- Step : 4101 \n",
      "  ------- {'fairness': 0.232, 'utility': 0.6361595160696966, 'total': -0.14518404839303037}\n",
      "--- Step : 4201 \n",
      "  ------- {'fairness': 0.2323, 'utility': 0.63623843134307, 'total': -0.145446156865693}\n",
      "--- Step : 4301 \n",
      "  ------- {'fairness': 0.2328, 'utility': 0.636364049318561, 'total': -0.1458835950681439}\n",
      "--- Step : 4401 \n",
      "  ------- {'fairness': 0.2331, 'utility': 0.636506947474264, 'total': -0.14613930525257363}\n",
      "--- Step : 4501 \n",
      "  ------- {'fairness': 0.2336, 'utility': 0.636650403496457, 'total': -0.14657495965035433}\n",
      "--- Step : 4601 \n",
      "  ------- {'fairness': 0.234, 'utility': 0.6368140971573972, 'total': -0.1469185902842603}\n",
      "--- Step : 4701 \n",
      "  ------- {'fairness': 0.2343, 'utility': 0.6369052685097162, 'total': -0.1471794731490284}\n",
      "--- Step : 4801 \n",
      "  ------- {'fairness': 0.2347, 'utility': 0.637048243762444, 'total': -0.1475251756237556}\n",
      "--- Step : 4901 \n",
      "  ------- {'fairness': 0.235, 'utility': 0.6371528156338726, 'total': -0.14778471843661273}\n",
      "--- Step : 5001 \n",
      "  ------- {'fairness': 0.2354, 'utility': 0.6372362087677124, 'total': -0.14813637912322877}\n",
      "--- Step : 5101 \n",
      "  ------- {'fairness': 0.2359, 'utility': 0.6373358277032748, 'total': -0.14857641722967252}\n",
      "--- Step : 5201 \n",
      "  ------- {'fairness': 0.2364, 'utility': 0.6374288471270194, 'total': -0.14901711528729808}\n",
      "--- Step : 5301 \n",
      "  ------- {'fairness': 0.237, 'utility': 0.6375273314321301, 'total': -0.149547266856787}\n",
      "--- Step : 5401 \n",
      "  ------- {'fairness': 0.2375, 'utility': 0.6376002062658033, 'total': -0.14998997937341968}\n",
      "--- Step : 5501 \n",
      "  ------- {'fairness': 0.238, 'utility': 0.6377090730942572, 'total': -0.1504290926905743}\n",
      "--- Step : 5601 \n",
      "  ------- {'fairness': 0.2384, 'utility': 0.63774642056534, 'total': -0.150785357943466}\n",
      "--- Step : 5701 \n",
      "  ------- {'fairness': 0.2389, 'utility': 0.6377671264470566, 'total': -0.15123328735529434}\n",
      "--- Step : 5801 \n",
      "  ------- {'fairness': 0.2393, 'utility': 0.6377988345112953, 'total': -0.1515901165488705}\n",
      "--- Step : 5901 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.637832923125326, 'total': -0.15194670768746743}\n"
     ]
    }
   ],
   "source": [
    "steps = horizon // update_policy_period\n",
    "\n",
    "results = []\n",
    "for step in range(steps):    \n",
    "    # update policy step\n",
    "    policy = update_policy(policy, belief, utility, l, lr, n_iter) # SDG to update policy\n",
    "    \n",
    "    # evaluation step\n",
    "    step_results = evaluate(true_dirichlet_model, true_model_delta, policy, utility, l)\n",
    "    results += [step_results]\n",
    "    \n",
    "    # update belief step\n",
    "    data_start_index = step * update_policy_period\n",
    "    data_stop_index = min(data_start_index + update_policy_period, horizon)\n",
    "    belief.update_posterior_belief(train_data.iloc[data_start_index : data_stop_index])\n",
    "    \n",
    "    print(f\"--- Step : {data_start_index + 1} \\n  ------- {step_results}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5108256237659907"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6094379124341003"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(true_dirichlet_model, \u001b[43md_2\u001b[49m, policy, utility, l)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_2' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate(true_dirichlet_model, d_2, policy, utility, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[data_start_index : data_stop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls[[\"utility\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load org resutls\n",
    "org = np.loadtxt(org_path_results + \"/results.csv\")\n",
    "org = org[:,1][1:].reshape((4,-1))\n",
    "\n",
    "org_pd = pd.DataFrame( columns= [\"utility\",\"fairness\",\"total\"])\n",
    "org_pd[\"utility\"] = org[0]\n",
    "org_pd[\"fairness\"] = org[2]\n",
    "org_pd[\"total\"] = org[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"utility\"].plot()\n",
    "pd_resutls[\"utility\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(org_pd[\"utility\"], label = \"original code results\")\n",
    "plt.plot(pd_resutls[\"utility\"], label = \"new code results\")\n",
    "plt.title(\"Utility\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(org_pd[\"fairness\"], label = \"original code results\")\n",
    "plt.plot(pd_resutls[\"fairness\"], label = \"new code results\")\n",
    "plt.title(\"Fairness\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"fairness\"].plot()\n",
    "pd_resutls[\"fairness\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. ProjectPolicyGradient ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
