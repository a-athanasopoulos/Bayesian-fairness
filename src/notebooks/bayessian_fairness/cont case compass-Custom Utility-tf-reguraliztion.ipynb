{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"exp_compass\"\n",
    "exp_number = \"exp_debug\"\n",
    "base_path = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/\"\n",
    "data_path = base_path + \"/my_code/Bayesian-fairness/data\"\n",
    "save_path = base_path + f\"/my_code/Bayesian-fairness/results/continuous/{exp_name}/{exp_number}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data,unique_values):\n",
    "    encoded_value = np.array([])\n",
    "    for i, d in data.iterrows():\n",
    "        # encode feature to an index represents the unique value.\n",
    "        index = np.argmax((d.values == unique_values).all(axis=1))\n",
    "        encoded_value = np.append(encoded_value, index)\n",
    "    return encoded_value.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set atributes\n",
    "Z_atr = [\"sex\", \"race\"]\n",
    "X_atr = ['age_cat', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree']\n",
    "Y_atr = 'two_year_recid'\n",
    "\n",
    "# clip_features = [\"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_path + \"/compas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct values\n",
    "unique_z = np.unique(dataset[Z_atr].values, axis=0)\n",
    "n_z = len(unique_z)\n",
    "\n",
    "unique_y = np.unique(dataset[Y_atr].values, axis=0)\n",
    "n_y = len(unique_y)\n",
    "\n",
    "unique_x = np.unique(dataset[X_atr].values, axis=0)\n",
    "n_x = len(unique_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Z values: 12\n",
      "Unique X values: 604\n",
      "Unique Y values: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Z values:\", n_z)\n",
    "print(\"Unique X values:\", n_x)\n",
    "print(\"Unique Y values:\", n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode z for convenience\n",
    "dataset[\"z\"] = encode_data(dataset[Z_atr], unique_values=unique_z)\n",
    "Z_atr = \"z\"\n",
    "# # # drop under represented index\n",
    "# n_z = n_z - 1\n",
    "# mask = np.logical_not(dataset[Z_atr] == 10)\n",
    "# dataset = dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maks_11 = dataset[Z_atr] == 11\n",
    "# dataset.loc[maks_11,Z_atr] = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_z = dataset[\"z\"].unique()\n",
    "# unique_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# train_size = 6000/dataset.shape[0]\n",
    "# spliter = StratifiedShuffleSplit(n_splits=1, test_size=1-train_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.sample(frac=1,replace=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.iloc[0:6000]\n",
    "test_data = dataset.iloc[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = train_data.copy()\n",
    "# train_data = test_data.copy()\n",
    "# test_data = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (6000, 10)\n",
      "testing size: (1214, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"training size:\", train_data.shape)\n",
    "print(\"testing size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq(data, n):\n",
    "    \"\"\" calculate frequency of 1D array\"\"\"\n",
    "    P = np.zeros(n)\n",
    "    for value in range(n):\n",
    "        mask =  data == value\n",
    "        P[value] = mask.mean()\n",
    "    return P\n",
    "\n",
    "def get_models(data):\n",
    "    # Py, Pz_y\n",
    "    N_y = np.zeros(n_y) + 0.5# 0.5\n",
    "    N_z_y = np.zeros((n_z,n_y)) + 0.5#0.5\n",
    "    for i, datum in data.iterrows():\n",
    "        N_y[int(datum[Y_atr])] += 1\n",
    "        N_z_y[int(datum[Z_atr]),int(datum[Y_atr])] += 1\n",
    "    Py = N_y / np.sum(N_y)\n",
    "    Pz_y = N_z_y/ np.sum(N_z_y, axis=0)\n",
    "    \n",
    "    # Py_x\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model_y_x = LogisticRegression(max_iter=1000)\n",
    "    model_y_x.fit(X = data[X_atr], y = data[Y_atr])\n",
    "    \n",
    "    #Pz_yx\n",
    "    unique_z_values = data[Z_atr].unique()\n",
    "    missing_z = [z for z in range(12) if z not in unique_z_values]\n",
    "\n",
    "    if missing_z:\n",
    "        random_data = np.random.randint(low= 0 , high=2, size = (1, len(data.columns)))\n",
    "        fake_df = pd.DataFrame(random_data,columns = data.columns)\n",
    "        fake_df[Z_atr] = missing_z\n",
    "        data = pd.concat([data, fake_df])\n",
    "        print(missing_z)\n",
    "    input_features = [Y_atr] + X_atr\n",
    "    model_z_yx = LogisticRegression(max_iter=1000)\n",
    "    model_z_yx.fit(X = data[input_features], y = data[Z_atr])\n",
    "    \n",
    "    return Py, Pz_y, model_y_x, model_z_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  2.,  3.,  8.,  7.,  9.,  5.,  6., 11.,  4.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[Z_atr].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    }
   ],
   "source": [
    "test_model = get_models(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54115226, 0.45884774])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04600302, 0.34615385, 0.29487179, 0.08069382, 0.00226244,\n",
       "       0.00075415, 0.0173454 , 0.09577677, 0.09125189, 0.02337858,\n",
       "       0.00075415, 0.00075415])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model[1][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_X = n_x # number of features\n",
    "num_Y = n_y # number of outcomes\n",
    "num_Z = n_z # number of sensitive features\n",
    "num_A = 2 # number of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_iter = 400 # number of itteration for SGD\n",
    "lr = 1.0 # learning rate\n",
    "l = 0.5 # lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_utility(size):\n",
    "    return np.eye(size)\n",
    "\n",
    "utility = get_eye_utility(size=2)"
   ]
  },
  {
   "attachments": {
    "Screenshot%202023-01-20%20at%203.01.34%20PM.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABKgAAAG+CAYAAAC3ajwEAAAMPmlDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnluSkEAIEEBASuhNEKkBpITQAkjvNkISIJQYA0HFjiwquBZULGBDV0UUO82O2FkUe18sqCjrYsGuvEkBXfeV753vm3v/+8+Z/5w5d24ZAGjHuWJxLqoBQJ6oQBIbEsBITkllkJ4CBGgBGhgJzLi8fDErOjoCQBs8/93eXYfe0K44yLT+2f9fTZMvyOcBgERDnM7P5+VBfAAAvJonlhQAQJTx5lMKxDIMG9CWwAQhXiDDmQpcLcPpCrxH7hMfy4a4DQAVNS5XkgmA+iXIMwp5mVBDvQ9iJxFfKAKAxoDYNy9vEh/iNIhtoI8YYpk+M/0Hncy/aaYPaXK5mUNYMRe5qQQK88W53Gn/Zzn+t+XlSgdjWMGmliUJjZXNGdbtZs6kcBlWg7hXlB4ZBbEWxB+EfLk/xCglSxqaoPBHDXn5bFgzoAuxE58bGA6xIcTBotzICCWfniEM5kAMVwg6VVjAiYdYD+IFgvygOKXPRsmkWGUstCFDwmYp+bNciTyuLNZ9aU4CS6n/OkvAUepj6kVZ8UkQUyC2KBQmRkKsDrFjfk5cuNJndFEWO3LQRyKNleVvAXGsQBQSoNDHCjMkwbFK/7K8/MH5YhuzhJxIJd5XkBUfqqgP1sbjyvOHc8EuCUSshEEdQX5yxOBc+ILAIMXcsWcCUUKcUueDuCAgVjEWp4hzo5X+uJkgN0TGm0Hsml8YpxyLJxbABanQxzPEBdHxijzxomxuWLQiH3wpiABsEAgYQApbOpgEsoGwo7exF14peoIBF0hAJhAAByUzOCJJ3iOCxzhQBP6ESADyh8YFyHsFoBDyX4dYxdEBZMh7C+UjcsATiPNAOMiF11L5KNFQtETwGDLCf0TnwsaD+ebCJuv/9/wg+51hQSZCyUgHIzJog57EIGIgMZQYTLTFDXBf3BuPgEd/2JxxJu45OI/v/oQnhE7CQ8I1Qhfh1kRhseSnLMeALqgfrKxF+o+1wK2gphsegPtAdaiM6+IGwAF3hXFYuB+M7AZZtjJvWVUYP2n/bQY/3A2lH9mJjJKHkf3JNj+PVLdTdxtSkdX6x/oock0fqjd7qOfn+Owfqs+H5/CfPbEF2H7sDHYCO4cdxhoBAzuGNWHt2BEZHlpdj+WrazBarDyfHKgj/Ee8wTsrq2S+U51Tj9MXRV+BYKrsHQ3Yk8TTJMLMrAIGC34RBAyOiOc4guHs5OwCgOz7onh9vYmRfzcQ3fbv3Lw/APA5NjAwcOg7F3YMgL0e8PFv/s7ZMOGnQxWAs808qaRQweGyAwG+JWjwSdMHxsAc2MD5OAN34A38QRAIA1EgHqSACTD7LLjOJWAKmAHmglJQDpaClWAt2AA2g+1gF9gHGsFhcAKcBhfAJXAN3IGrpxu8AH3gHfiMIAgJoSJ0RB8xQSwRe8QZYSK+SBASgcQiKUgakomIECkyA5mHlCMVyFpkE1KL7EWakRPIOaQTuYU8QHqQ18gnFEPVUG3UCLVCR6JMlIWGo/HoeDQTnYwWoSXoYnQ1WoPuRBvQE+gF9Brahb5A+zGAqWK6mCnmgDExNhaFpWIZmASbhZVhlVgNVo+1wPt8BevCerGPOBGn4wzcAa7gUDwB5+GT8Vn4Inwtvh1vwNvwK/gDvA//RqASDAn2BC8Ch5BMyCRMIZQSKglbCQcJp+Cz1E14RyQSdYnWRA/4LKYQs4nTiYuI64i7iceJncRHxH4SiaRPsif5kKJIXFIBqZS0hrSTdIx0mdRN+qCiqmKi4qwSrJKqIlIpVqlU2aFyVOWyylOVz2QNsiXZixxF5pOnkZeQt5BbyBfJ3eTPFE2KNcWHEk/JpsylrKbUU05R7lLeqKqqmql6qsaoClXnqK5W3aN6VvWB6kc1LTU7NbbaODWp2mK1bWrH1W6pvaFSqVZUf2oqtYC6mFpLPUm9T/2gTld3VOeo89Vnq1epN6hfVn9JI9MsaSzaBFoRrZK2n3aR1qtB1rDSYGtwNWZpVGk0a9zQ6Neka47SjNLM01ykuUPznOYzLZKWlVaQFl+rRGuz1kmtR3SMbk5n03n0efQt9FP0bm2itrU2Rztbu1x7l3aHdp+Olo6rTqLOVJ0qnSM6XbqYrpUuRzdXd4nuPt3rup+GGQ1jDRMMWzisftjlYe/1huv56wn0yvR2613T+6TP0A/Sz9Ffpt+of88AN7AziDGYYrDe4JRB73Dt4d7DecPLhu8bftsQNbQzjDWcbrjZsN2w38jYKMRIbLTG6KRRr7Gusb9xtvEK46PGPSZ0E18TockKk2Mmzxk6DBYjl7Ga0cboMzU0DTWVmm4y7TD9bGZtlmBWbLbb7J45xZxpnmG+wrzVvM/CxGKMxQyLOovblmRLpmWW5SrLM5bvraytkqzmWzVaPbPWs+ZYF1nXWd+1odr42Uy2qbG5aku0Zdrm2K6zvWSH2rnZZdlV2V20R+3d7YX26+w7RxBGeI4QjagZccNBzYHlUOhQ5/DAUdcxwrHYsdHx5UiLkakjl408M/Kbk5tTrtMWpzujtEaFjSoe1TLqtbOdM8+5yvmqC9Ul2GW2S5PLK1d7V4HretebbnS3MW7z3Vrdvrp7uEvc6917PCw80jyqPW4wtZnRzEXMs54EzwDP2Z6HPT96uXsVeO3z+svbwTvHe4f3s9HWowWjt4x+5GPmw/XZ5NPly/BN893o2+Vn6sf1q/F76G/uz/ff6v+UZcvKZu1kvQxwCpAEHAx4z/Ziz2QfD8QCQwLLAjuCtIISgtYG3Q82C84MrgvuC3ELmR5yPJQQGh66LPQGx4jD49Ry+sI8wmaGtYWrhceFrw1/GGEXIYloGYOOCRuzfMzdSMtIUWRjFIjiRC2PuhdtHT05+lAMMSY6pirmSeyo2BmxZ+LocRPjdsS9iw+IXxJ/J8EmQZrQmkhLHJdYm/g+KTCpIqkreWTyzOQLKQYpwpSmVFJqYurW1P6xQWNXju0e5zaudNz18dbjp44/N8FgQu6EIxNpE7kT96cR0pLSdqR94UZxa7j96Zz06vQ+Hpu3iveC789fwe8R+AgqBE8zfDIqMp5l+mQuz+zJ8suqzOoVsoVrha+yQ7M3ZL/PicrZljOQm5S7O08lLy2vWaQlyhG1TTKeNHVSp9heXCrumuw1eeXkPkm4ZGs+kj8+v6lAG/7It0ttpL9IHxT6FlYVfpiSOGX/VM2poqnt0+ymLZz2tCi46Lfp+HTe9NYZpjPmzngwkzVz0yxkVvqs1tnms0tmd88JmbN9LmVuztzfi52KK4rfzkua11JiVDKn5NEvIb/UlaqXSkpvzPeev2EBvkC4oGOhy8I1C7+V8cvOlzuVV5Z/WcRbdP7XUb+u/nVgccbijiXuS9YvJS4VLb2+zG/Z9grNiqKKR8vHLG9YwVhRtuLtyokrz1W6Vm5YRVklXdW1OmJ10xqLNUvXfFmbtfZaVUDV7mrD6oXV79fx111e77++foPRhvINnzYKN97cFLKpocaqpnIzcXPh5idbErec+Y35W+1Wg63lW79uE23r2h67va3Wo7Z2h+GOJXVonbSuZ+e4nZd2Be5qqneo37Rbd3f5HrBHuuf53rS91/eF72vdz9xff8DyQPVB+sGyBqRhWkNfY1ZjV1NKU2dzWHNri3fLwUOOh7YdNj1cdUTnyJKjlKMlRweOFR3rPy4+3nsi88Sj1omtd04mn7zaFtPWcSr81NnTwadPnmGdOXbW5+zhc17nms8zzzdecL/Q0O7WfvB3t98Pdrh3NFz0uNh0yfNSS+fozqOX/S6fuBJ45fRVztUL1yKvdV5PuH7zxrgbXTf5N5/dyr316nbh7c935twl3C27p3Gv8r7h/Zo/bP/Y3eXedeRB4IP2h3EP7zziPXrxOP/xl+6SJ9QnlU9NntY+c352uCe459Lzsc+7X4hffO4t/VPzz+qXNi8P/OX/V3tfcl/3K8mrgdeL3ui/2fbW9W1rf3T//Xd57z6/L/ug/2H7R+bHM5+SPj39POUL6cvqr7ZfW76Ff7s7kDcwIOZKuPJfAQw2NCMDgNfbAKCmAECH+zPKWMX+T26IYs8qR+A/YcUeUW7uANTD//eYXvh3cwOAPVvg9gvq08YBEE0FIN4ToC4uQ21wrybfV8qMCPcBGzlf0/PSwb8xxZ7zh7x/PgOZqiv4+fwvdnV8dq4TJnAAAACKZVhJZk1NACoAAAAIAAQBGgAFAAAAAQAAAD4BGwAFAAAAAQAAAEYBKAADAAAAAQACAACHaQAEAAAAAQAAAE4AAAAAAAAAkAAAAAEAAACQAAAAAQADkoYABwAAABIAAAB4oAIABAAAAAEAAASooAMABAAAAAEAAAG+AAAAAEFTQ0lJAAAAU2NyZWVuc2hvdMabbeIAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAHXaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA2LjAuMCI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOmV4aWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vZXhpZi8xLjAvIj4KICAgICAgICAgPGV4aWY6UGl4ZWxZRGltZW5zaW9uPjQ0NjwvZXhpZjpQaXhlbFlEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlBpeGVsWERpbWVuc2lvbj4xMTkyPC9leGlmOlBpeGVsWERpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6VXNlckNvbW1lbnQ+U2NyZWVuc2hvdDwvZXhpZjpVc2VyQ29tbWVudD4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CqMfWloAAAAcaURPVAAAAAIAAAAAAAAA3wAAACgAAADfAAAA3wAAc2Mdps8WAABAAElEQVR4AeydBbjlxPn/Z6EUihRYtjgsLA7FpTgUdyvutktxihYvLFBkobgs7lZkoYs7izsUWFhgcXcolCL5z3f+v8mTm5uck5Pk3OTe85nnufecExn5zGSS+eadd/oFNhgCBCAAAQhAAAIQgAAEIAABCEAAAhCAAAQqItAPgaoi8iQLAQhAAAIQgAAEIAABCEAAAhCAAAQg4AggUNEQIAABCEAAAhCAAAQgAAEIQAACEIAABColgEBVKX4ShwAEIAABCEAAAhCAAAQgAAEIQAACEECgog1AAAIQgAAEIAABCEAAAhCAAAQgAAEIVEoAgapS/CQOAQhAAAIQgAAEIAABCEAAAhCAAAQggEBFG4AABCAAAQhAAAIQgAAEIAABCEAAAhColAACVaX4SRwCEIAABCAAAQhAAAIQgAAEIAABCEAAgYo2AAEIQAACEIAABCAAAQhAAAIQgAAEIFApAQSqSvGTOAQgAAEIQAACEIAABCAAAQhAAAIQgAACFW0AAhCAAAQgAAEIQAACEIAABCAAAQhAoFICCFSV4idxCEAAAhCAAAQgAAEIQAACEIAABCAAAQQq2gAEIAABCEAAAhCAAAQgAAEIQAACEIBApQQQqCrFT+IQgAAEIAABCEAAAhCAAAQgAAEIQAACCFS0AQhAAAIQgAAEIAABCEAAAhCAAAQgAIFKCSBQVYqfxCEAAQhAAAIQgAAEIAABCEAAAhCAAAQQqGgDEIAABCAAAQhAAAIQgAAEIAABCEAAApUSQKCqFD+JQwACEIAABCAAAQhAAAIQgAAEIAABCCBQ0QYgAAEIQAACEIAABCAAAQhAAAIQgAAEKiWAQFUpfhKHAAQgAAEIQAACEIAABCAAAQhAAAIQQKCiDUAAAhCAAAQgAAEIQAACEIAABCAAAQhUSgCBqlL8JA4BCEAAAhCAAAQgAAEIQAACEIAABCCAQEUbgAAEIAABCEAAAhCAAAQgAAEIQAACEKiUAAJVpfhJHAIQgAAEIAABCEAAAhCAAAQgAAEIQACBijYAAQhAAAIQgAAEIAABCEAAAhCAAAQgUCkBBKpK8ZM4BCAAAQhAAAIQgAAEIAABCEAAAhCAAAIVbQACEIAABCAAAQhAAAIQgAAEIAABCECgUgIIVJXiJ3EIQAACEIAABCAAAQhAAAIQgAAEIAABBCraAAQgAAEIQAACEIAABCAAAQhAAAIQgEClBBCoKsVP4hCAAAQgAAEIQAACEIAABCAAAQhAAAIIVLQBCEAAAhCAAAQgAAEIQAACEIAABCAAgUoJIFBVip/EIQABCEAAAhCAAAQgAAEIQAACEIAABBCoaAMQgAAEIAABCEAAAhCAAAQgAAEIQAAClRJAoKoUP4lDAAIQgAAEIAABCEAAAhCAAAQgAAEIIFDRBiAAAQhAAAIQgAAEIAABCEAAAhCAAAQqJYBAVSl+EocABCAAAQhAAAIQgAAEIAABCEAAAhBAoKINQAACEIAABCAAAQhAAAIQgAAEIAABCFRKAIGqUvwkDgEIQAACEIAABCAAAQhAAAIQgAAEIIBARRuAAAQgAAEIQAACEIAABCAAAQhAAAIQqJQAAlWl+EkcAhCAAAQgAAEIQAACEIAABCAAAQhAAIGKNgABCEAAAhCAAAQgAAEIQAACEIAABCBQKQEEqkrxkzgEIAABCEAAAhCAAAQgAAEIQAACEIAAAhVtAAIQgAAEIAABCEAAAhCAAAQgAAEIQKBSAghUleIncQhAAAIQgAAEIAABCEAAAhCAAAQgAAEEKtoABCAAAQhAAAIQgAAEIAABCEAAAhCAQKUEEKgqxU/iEIAABCAAAQhAAAIQgAAEIAABCEAAAghUtAEIQAACEIAABCAAAQhAAAIQgAAEIACBSgkgUFWKn8QhAAEIQAACEIAABCAAAQhAAAIQgAAEEKhoAxCAAAQgAAEIQAACEIAABCAAAQhAAAKVEkCgqhQ/iUMAAhCAAAQgAAEIQAACEIAABCAAAQggUNEGIAABCEAAAhCAAAQgAAEIQAACEIAABColgEBVKX4ShwAEIAABCEAAAhCAAAQgAAEIQAACEECgog1AAAIQgAAEIAABCEAAAhCAAAQgAAEIVEoAgapS/CQOAQhAAAIQgAAEIAABCEAAAhCAAAQggEBFG4AABCAAAQhAAAIQgAAEIAABCEAAAhColAACVaX4SRwCEIAABCAAAQhAAAIQgAAEIAABCEAAgYo2AAEIQAACEIAABCAAAQhAAAIQgAAEIFApAQSqSvGTOAQgAAEIQAACEIAABCAAAQhAAAIQgAACFW0AAhCAAAQgAAEIQAACEIAABCAAAQhAoFICCFSV4idxCEAAAhCAAAQgAAEIQAACEIAABCAAAQQq2gAEIAABCEAAAhCAAAQgAAEIQAACEIBApQQQqCrFT+IQgAAEIAABCEAAAhCAAAQgAAEIQAACCFS0AQhAAAIQgAAEIAABCEAAAhCAAAQgAIFKCSBQVYqfxCEAAQhAAAIQgAAEIAABCEAAAhCAAAQQqGrUBv73v/+Zl19+2XzyySfm008/dX8DBw40a6+9do1yWU1WfvrpJ/Piiy+GXMTn97//vVluueWqyVDNU6UtVVNBH3zwgXnzzTfDdvrVV1+ZP//5z2aCCSZoS4aCIDB33nmnueWWW8wbb7xhPvroIzPttNOa5Zdf3gwePNhMOOGEbUm3XZG2m9/dd99trrrqKteXzDnnnGbDDTc0a6yxRruK02Pxcr33GGoSggAEIAABCEAAAhBoIwEEqhxwv//+ezPZZJPlODP5lAMOOMAceeSR5qWXXjLzzDNPl4O23nprc/HFF3fZ1ok/NPieZZZZuhR94403NldffXWXbT314+effzZjx441s846a08l2VI6tKWWcJV28DbbbGMuueSSLvH9+9//7nZddzkg54/777/fiV+jR482K664otlyyy2NBO2nnnrKHH300Wa22WYz9957r5looolyptDzp7WT35AhQ8y5555rFl10UbPbbrsZpaVwww03mPXWW6/nC1tiilzvJcIsOaq63ytKLi7RQQACEIAABCAAgUIEEKhy4HvnnXfMjDPO6M6cZJJJzHbbbWfmnntuM+mkk5rxxhvPWTEcdNBBRtYTChtttJF7Uz/OOOMYiVvvvfeeGTlypBk1apTbL0uH4cOHmx9++MFZUGlAu8MOOxi9FUegcojMjz/+6KweNBjffvvtHceqBKovv/zSzD///Obtt982q6yyirn99tv/fyZr9J+2VE1lvPvuu65dnHjiieb66693mWiHQCWrqXXXXdf897//NZdddpnZfPPNwwK/+uqrZo455nC/zzzzTLPzzjuH++r+pV38xGHXXXd1Ap4sMR9//HGzwgorOByHHHKIGTp0aN3RNMwf13tDPJXt7A33isrgkDAEIAABCEAAAhBIImCniBBaJGAtFALLMlhmmWWCDz/8MPFsa9HgjtFx99xzT+Ix1tLCHWPf3nfbv/jii7t9VqDqtq/TN9jpS46NFagqQWGttsK6HXfccQM7OOzxfOyxxx7BwQcfnCld2lImTKUeZK2bwjZiBapS41ZkViB38Vvry25xn3/++WHae+65Z7f9vWFD2fw8r5NOOskV304ZDuz04MBamQWPPfZY7ZFwvdenij7++OPATtkN7Mumppmqw72iaSY5AAIQgAAEIAABCNSIgKlRXnpNVqzFjBsAWn8mqXlebbXVwkHigw8+mHrckksuGSy99NLd9v/xj3905yNQdUMTrL766o5NVQLVF198EVhrOZcHa4XRPYM9sMX6JQv233//TCnRljJhKvUga6ETXv9lC1TWAiiM+8knn+yWb+sDK7DTYYNpppkmeOKJJ7rt7w0byuRnffqFvBr1xXXmwvVen9rxL6i+++67ppmqw72iaSY5AAIQgAAEIAABCNSIAAJVjsqwU2qC6aabruGZWQWqs846K7DTcbrFhajQDUm4oWqBShnRoPehhx4KfvnllzBfPfVFaVpfQwhUPQU8RzplCizx5L3l5fjjjx/Yqa/x3X3id5n8onG99dZbvY4P13u9quyCCy5wgmcWgUo5r/JeUS9y5AYCEIAABCAAAQg0J4BA1ZxRtyP+8Y9/BJpm1ihkFahkhdW/f/9uUSFQdUMSbqiDQBVmpoIvDzzwgBsgYUFVAfyMSUZFkbItqC666CJX/7Li66uhTH6awqep1vp7//33ex0yrvd6VZmsZtWWsgpU9co9uYEABCAAAQhAAAL1JoBAlaN+5Ptn2223bXhmVoHq9ddfD/r16xfIJ0o0IFBFaXT93skClfxdyXeOBkgIVF3bRZ1+lSmwxMuFQBUn0vh3bxaouN4b121P773lllvc/RqBqqfJkx4EIAABCEAAAp1CgFX87JNmq8EOeMw333xjVlpppdRTrYhibrvtNrff+j0x1s9U4rFane64444zWvVPq/z5oBWmtES8X8XPTvMwL7zwgnnuuefcyl1zzTWXWWKJJcyvfvUrf0rip5a41jkPP/yw0epedmqiWWeddYzOzxvslAVjncMbferPXixm0003dZ/PPPOMefrpp80f/vAHM++887oktJLRBx98YD799FP3p99adcxOUQqzoNW7/H59qrzRlcnCA+2XNdZYw9x6662m2Sp+ypvKrfrSameqAyscmgknnDAaXUvftYKj4lUe9Tn77LO7Zevjkah9qP7EXOdMOeWUZtlllzULL7ywOf74482+++5rJp544vhpDX9rKXmtOHbDDTe443bZZRdjxdIu50w77bRdfutHWW1JcWVlqjq21iohK61IudlmmykK8/XXXxvrO8m88sorZvLJJzdWcDPWX5Lbl+ef4vb1ovzpzy5gYKwDbPP5558bu0iBsSKwW3FRq27GQ5FrRG3/tddeM9bXk4tW9as2ofIttthibluzVfyyMhW3b7/91lx77bVmr732MiqLVrX0QdeMdeDsymx93xj9zTPPPGappZbyh5h21EvV/MLCxb5YCxdXXl3/G2ywgdurvmmqqaZy33/961+bAQMGxM4yri09+uijrk5/85vfmDnnnNOstdZajnf8YNVdK31h/PxGv3vT9d6oHM32qe9/5JFHHG/1zeK95pprJvL2cWnVQtWlztO1P/PMMxvrz9Esssgi/pDwU+1Tx/g+W3Wma1Pp6PpVH63rV+0l7b76n//8x9x8881mxx13NPquYF8uGessPUxH/flvf/vb8Lfvk3y68XtF0WtR5YrfN63vOWMXxQjzoLxq1WDlwf/pPqi8pAXlO2v7LzsPelZRvY4ZM8at3DvrrLO6Zwv1p+rPNtxww7RsZ97eantTu1Dda/VPPUeojahPbcTQZyZvebLeE3w6+tS9Qe2x2TNh9By+QwACEIAABGpJoFOUuJ4uZ1YLqrR8RS2o7CA0sIKPc3osZ7n2AclZ0NgHpED70oId4ARzzz23O9YO0IJDDz00sCKJ+60VCO3gPe3UhtvtIMDFYRu0+5QPLfvwGyy66KKBfUAP92kqpMJGG20UbvPnyNFsNPjt/tM+mEZ3d/nezILKPjQHf/vb3wIr+DlfYVrpbLfddnN5swPOQD588gRN6fD5859JjtpvvPFGV1d2ABT89a9/DU488cRgq622CqxIFUwxxRQujjfeeKOlLPzlL3/plrbPQ/TTPkB3i7eMttQq06Q6t4OlQKuoTTTRRIFWFtQ1YgekziLh8MMPz+3P61//+lc3NldeeWUgXzH2Yd1NoRUjOQ1XHqKhyDVyzjnnhHFbMTbQtfm73/0usMKxa2O+XtKm+LXKVGn4OLN+2gFdtLiJ12KReqmSX5eCJfzQtdmIU3xxCisYBOKlc9Tf7r333sEWW2wRTD311MFkk00WnHLKKd1SabUv7BZByobedr2nFKPhZjugDrbZZhvHW6ss7rDDDoF90RFYsSmwwmFw8cUXJ54/YsQId92pL9Xx++yzj1tRV5bIsi59++23u5wXXVTAtwdZn8p6Oct9VSv1atU+f27ap/p6H7LcK4r2kUnlUh8UDepX4/mVD82kkKf9l5WHr776ytXleOONF2y55ZaBfWkX2Jd2rl517Wm13KILxuRpb/ZFWGBf+jg/oUOGDAnsi4HACtwuP1pZU/lOCnnL0+o9wad98sknuzaq+48V4PxmPiEAAQhAAAK9koDeIBLaQKAsgWrllVcOpp9+evdgpOkeCpoOuOqqq7oHzwUWWCAx99Z6ywkBEmk0LSEaBg8e7M79/e9/n8uPhrWSCq6//vpg/vnnd/FIoFpxxRUDa1EWSCDxIoyENIWXX37Z5UGimH9YjgtUWlZewpE/N69AJafRnr3YWUumsOj2TXkoiKQNfsKDE77o4VH5HD58eCAH1SpLXKBSGhLBJAjGHVjbN9Nu8KXzWhWoNOgSd/15Rppm6rf5TzlUjgcvUOVtS3mYqs4lHPm0VWZNjZ1pppkCTbnyQauq+TYhYS9PkNAqX24SJX1cO++8c2AtZAJdB6eddlq4Xcu++5D3GtFAx1p4uDh1/Y0dO9ZHGUQHQT4vSQJVHqYSg1TPRx55ZFgea23QpQ3ourIWVq7sSj8uUJVZL1XyC4E3+KJrTLwuvfTSkNd1110X8tK16oPYqm1K5Bg2bJjf7D7Vvrywf8YZZ3TZp/hb6Qu7nNzgR2+73hsUJXGX+kIJ+GqjEpmi/bTub3vuuafbpxVzo0HCks7Ri5e4EHXFFVe4dq/7jl6Y+CCxyFqzun5AgrXO32677ZzwIMGh2X3VWmiGbUZ9mM7Xn7XeCrerHUT9m2W5VxS9FlWu++67z5VL7VZ5igtUWhRADCW0+nwnCVR5239ZeZA4KXHKWm75ags/jzrqKJf3IgJVnvaml396mSJhSvXpg9rWfPPN5/KkZxq1j3jIU5489wSfrvouX7/WQttv5hMCEIAABCDQKwkgULWp2rxIooeGPEubRwf2f/rTn7rl8rzzzgsfSOzUvy77NUiWqKW07VSyLvv0Q2/39FZQ+08//fRu+7NuOPPMM8M86K2if5u4ySabBHa6Q6A3jNGggZx/iIoLVP44iS46xk5V8Ju6fTayoNKbRJ2vt65JbxI1+NR+ld8PTLolkGGD3tQrnrhAdcQRR7jtGrwnhWuuucbtb1WgisYliw6l3aoPKp3TaltSukWYShxVuv5PA7l48G01KW/xY5v9lpWaT0tv4RXs9B1n2SSrDDt1xG0rco3IGk9p2CmEiVaIGmDbaahhPpIEqiJMvQ8q5SFJkFQBvWVPXKByhbf/itZL1fx8ObJ8ShD1bUID8XjQ4FOWNDrGTqGN73a/JbwPHDjQWWXqGo6HVvvC+PmNfvem671ROaL71l13Xcd70KBB3fphO5XLWVCpPuy04PC0kSNHunNkpZtm/Xv22We7Y1SfaqPxYKf2uf2KO6m/aXRfVVw+fp0vcSZLSLtX+HOLXouKxwsmcYHKp/Hmm2+G5ZZgGw1ltH/FlzcPEnj0MkFWtWlBgmQRgSpPezvssMMcM1n3RcVH5VHipNqA/mStGw15y1PknuAtP5UfibEECEAAAhCAQG8mgEDVptorU6CKWmj47GrQ7R+QrE8iv9l9yjRe+/S2WA/7SWHXXXd1x+jBL2+IDpQ1zSIakt4qysrF5zlNoPL5yiNQWf87gVY2Uxrx/Pi86Rifh6SBpj+u2WeaSKY384pfFgBJQYMm7a9KoGq1LRVlKoszz1vTeZKCt0aSRV7REH2THLWi0CAs+hY87zUisdlbK5x77rmp2Y1OO4wLVEWZRq+7NIHKC2RpAlXReqmSXyr0lB3NBCovLqleZXGSFg488EDXlmUhGRdIonUS73uS+sK0NJK2FxGoevp6T8p/fJv15xP2CZdffnl8d2D99oT7tWKegqah+mt7++2373aO36Bpan46XnTKnd8fffHTKhvFkUegSrtX+DwVvRYVj7dOThOorE+jkGlcoCqj/RfJg6453SNkrZT0Uklx77fffrkFqjztTWlaH5ghM8URDep3rQ9Atz/+oihPeYreE77//ntnsWz9OkazyXcIQAACEIBArySAQNWmaitLoJLfnKQQFVo0tSEa5JtKD3x6W5wWdI6OkYgVn4qWdk58e3RQpqXQm4Xog3g7BCpfJpUrPq0xmjfPR1PC8oa0QcfQoUPDh1q9ob/pppvctMdoOko36e1+9JhG3/MOWPO0paJMo3Uun01JwTp7d8xUL0WDH8T6gW1afL4NtHqNSGTz100jC4o77rgjbAdxgaoo0+h1V4ZAladequSXVqdp25sJVNaxvasr6/g4LQq3/dlnnw3rNG55Gq2TLH1hw4RiO3vT9R7LeuJPWdjqGtJfVET2B8sCUSKUdXoe6DpSiIoMd955pz808XO99dZzcYub4ooGL1Dl6QsVT7sFqjzXovLly5VHoCqj/RfJgwRcib5qD7JsPuaYYwK78ISiDINd7MRNpQ03tPAlT3tT9HqGkGW4+oXoFFSf9EILLeTyHBdM85Sn6D3B54lPCEAAAhCAQF8ggEDVplosS6BKG2hH34hGfUpo0Cy/U3rYW3DBBZ2jWflbiv95UUDHyfw/T4gOyhpZHvi4o2JFM4Eqjw8qb+GgMslPT7zM/rccieoYTSfMG9IEKrtaoXOGrvj9n6YvaBAgy4q435Q86ecdsLbalpS3okyjdZ42cPdWc43qPCsnL1DJki0tFLlGvKNyTUtsFBoJVEWZRq+7MgSqVuulan6NuCftayRQSZz3FjdyztwoyBrVX9Py6RMN0TrJ0hdGz232vTdd783Kov3e95SsXbOGqPAfFy/icXj/VaorP6XXH+OFnDx9oeJot0DV6rUYL1cWgSr6vFBW+1c+PNtW86BztYCLv7b8p8QqiY0Sb9L6OZ3bLORpb0lxyrpLPr/OP/98d1+UeKW8xqf569xWy1P0npCUX7ZBAAIQgAAEeiuBfsq4vckSSiZgBQxj/RC5WO20IKOlnVsJ9gHaWF8Cxj7sGWuF0+1U++bZWKHFbbcPnMYOmNx36+PH2Dd77rt9wDN2qk+3c6MbtNS69dVjtER2q8EKPsaKPO40+9bQWCenDaOwD9/G+uNwx1iBKsxn9CTr38dYR8TGihVuqenoPv9dZbKr6xj7YGis02u/2Vg/EyEr63i3aZmso/ncy1an5UGZ0XLUVnQxVpwJ8+a/aBn1v//978b65/KbWv60b//d0vZ2aoGru2YR5G1Lirco07LqvFkZ/X4tN28FV2OnoJmjjz7ab+7ymfcaUfvWdWKtMoxdsdI8/vjjXeKN/rBWHmaVVVZxm6wFlZlnnnnC3UWZRq87O3AzdmpaGLf/YqdNGmsB4Nq3dZruN4efReqlan5hITJ+UT1Zn0TuaOuDyi0T70/VtWoXi3A///znP5uzzjrL7+r2aaeIhku4L7/88q5/9gdF6yRLX+jPy/LZm673ZuWxvrzcNSSW9gWKsU7+m53i9quv9+3YrqpnrDiQep71u2jsyqluvxUUwnuONhTpC3W+tXAyaicKVqg11vLHfW/0r9G9QucVuRZ9unnLVVb7Vz7y5kHnqh874YQTXJ9trZW0qUuw1nTmqquuMjPMMEOX7c1+5G1vPl719Wp31vG4sRaUxoqqxi4I4/oTu0qxuw/Hn0N0bqvlKXpP8PnlEwIQgAAEINAnCPRWZa3u+S7LgqrVt5GaTmQbpvvTSjLtDFGrgSxvOKPWNO2woIo6CtWqPe0MaRZU0TTlSNWKUcFaa60Vrrzn66bZNJVoPPHvaRYV8osjy7p4KPJmuyjTsuo8Xqa0396CSg5u00Lea0SOsr3/KU0/ahSiFlRaij0aijLNct3ZQbHrA7L4oGr1WqyaX5Rllu+NLKjktN9fk/GpOvG45efFH2vFxy67s9RJlxNa+NGbrvdmxYpeQ1a0bXZ4uN9P2xP/ZlaoBxxwQFhPmhoWDUX6QsXTyIJKll1RP3c+3Wb3ijL6yLzlKqv9q6x58+A56VP3L1lMWRHQWYB7a3DVu/xstRrytjelIzcK8tGptLXoi3wORqeMyqm79iVZUPl8Zi1P0XuCT49PCEAAAhCAQF8gwBS/NtViVQKVd8KtB6d11lmnTaX7/9G2OijL8iAuUU15bzTdK+2BXysW6lz92TfzbS17Wh7kX0pc4kEDFzmnnXzyyV3+5IA1b0gbsB5++OHdVk5UGkUGDkWZZqnzdkzxayRQFblG5LtG7WuOOeZoWH1RgUqCTjQUZZrlumunQFU1vyjLLN8bCVTRaXtJq7pF49f0Xd+/xB2hZ6mTaFytfO9N13uWcmnqljhqamWWFxuKMzptL75qbTzNnXbaycUvMdmvLOuPKdIXKo5GApXKFHeer3PS7hXap1BGH9msXHph49tudIpfWe1f5cibBwlBEnuS2oLEyKg4+eqrryqplkKe9ian/H4lVK3emTStNE2gylOeoveEloBwMAQgAAEIQKDmBBCo2lRBVQlUKs4SSyzhHkblI6FZGD58eDcn3s3O8ftbHZQ9+uij4UNymtWGnSbgjsmzit/tt98exq+ViRoFLTdfxIopbdCx1VZbBSuvvHJq0iNGjHB5lC+jvCFtwCq/F/EVhZRGs4FDmj8znVuUaRmDL+Uja8hiQaW48l4jG220kas/LS6Q5DjX57ORQFWUaZbrrp0CVdX8POOsn40EKsUx33zzuTqV+Jg0SPbpaNXPpEG+9mepEx9Pq5+96XrPUjY7/Trk2Mz/ofz9yE/S9ddfH55jp2E2TMZbvSS95CjSFyrRNIFKLyDGHXfcxD4h7V7hC1FGH+mfN9Isru00wpBffBW/Mtq/ypI3D6+//rrL20MPPeSRdPlU/dsp1e6Y6667rsu+LD/ytLcbb7wx5JW00qTSnW222dwx3oJKTtW1Im2e8hS9J2ThwDEQgAAEIACB3kIAgapNNeUf1jSg0dL0rYYiD9J6Q+oHUlpFLi3ogSrtoTrtnOj2Vgdl0alBEqviQW8t+/fv7/KeR6DSIMGvLqYH2qTpFj5N65Mm0FSQvCFt0CGBSuJF0upUSksP25q2IKfpeYN3+rrzzjt3iUKWA4ccckiXbfpRpC0VZVrG4KtbgRpsyCpQ5b1GosLTP//5z9ScRK+NuAVVUabRuNMElXYLVFXyS4WesqOZQBUVHUaNGpUSS+CWuVe/OuOMM3YTIrLUSWrETXb0puu9SVHc7nvuuSe8P8lyJC2o3rTAhKZpqd+0/ofceSuttFLaKcEbb7wRxn3KKad0O65IX6jIrrzyyjD+jz76KIxf1nXq17WCWzyk3Sv8cWX0kX6KmJ47ksKxxx4b5jsuUJXR/pVm3jx4QWevvfZKyrrbJotYXXtazbHVkKe9yULSP0ONHTu2W5Jff/11ON3bC1QjR44M9FyRpzxF7wmyalUfpDwQIAABCEAAAr2dAAJVm2rQPwjrIeeuu+5qORX5uNG5cV8nPiKtKOMfoC644AK/OfzUw572a7UxPUzFg6w/FlhggUIr2WlJbJ+HH374IZ5Et9+aTuBXzJI1QjycdNJJYXyNrL+8lVXSFEZNAZhyyildPIovKWhwrXyMHj06aXembT4P66+/fpfjJVCJyZAhQ7ps9z+UZqP9/rhGn3pLrjj0MBwNWrUxqS0UbUtFmEYFnbg/GJ/3HXfc0ZVHA/+iwU/B06pIzULea8QvWz7//PMHSe1e02n8tBLVk3yRxUMRptHrTn6RkoJ15OuYpllUlFEvVfJLKnPatqj1iHV0nHiY/E+pruwiDoEGe/FgF6wI7AIH7hi7QEN8dxCtk6Q20e2EFjb0pus9a7F8Pzn++OMnTp+SIKU+dvDgwWGUzz33XDDZZJO5lyqycIkHiUPW2bSrI/V5SS8oivaFsvxVO9FftB3IMjat/0q7V/j8l3Eter9bsh6LB734GTBgQJjvJAu0ou1faebNgxd0JppooiBtCp+soCQA6rknT2i1vcl3pK9n9R/xYB26h/u9YCqBSAJh3vIUuSfoOcTnV4IcAQIQgAAEINCbCSBQlVR7skbSQ7PEj/322889RPsHBgkHp59+eiBRRm8A5aMgKUg00oOujvVCjpxz6oFS2zUYfeWVV9x0B++rSWnI2kjChJZA9kGWFf6hbLHFFuvik0n+mWRhZFevSvSZ4eNI+9QDm94kSyDxZdQDrl1lJ0h6mIvG4/0NaaAQ9Q9yySWXOEekdnWsME4NgO0KOo6XHrLFQFP39CCrdLVMuaYoykosOijUIOK3v/1toMGPlifXG3gFxaEHS72V11vjVkNSHqaYYgqXBz9d0DNX/uSPKpov+bEQdw2y8j5oK89qQ567XcXQFUP1oQG0RECFMtuS4muV6ZNPPunqzlvyKL/yJSKrIy8SqN4uvPDCLmKO6lxlSbtGlJd4kCWD2oZdtS98qy1rC7WVG264IbCrfsVPcb/zXiNqt76dqnx+mpIGxLKWlM+SSSaZJKwjHat+QQPsaGiVadJ1Z1eDdGX88ssvA7uqmOOg/kL9hr9GJJ74a6TMeqmaX5Rl0nc5gFb/4UUL8VB9qS7UX0etz+T82Pu6sSuuBm+99ZaLUtevphXp2lJ/Ylfu6pJUUp1k7Qu7RNTgR2+43htkP3GX+ie7iqpro3qhYFe8DY+TxYpEOYktUSslHaDry66c56xUJQj4/lWisF5YqI51v/PXpM4puy/0vonkg0h9geLXtqgonuVeUea1qPuJ7msqv9q8D5q+rfYcteiW/7zzzjvP+b7yx+Vt//58febNgxd0lHfVua5bH9Snnnbaaa5f13NV3tBqexszZoy7TytPmgLpHfOrz9C0U72A8NZ04q4+Re1B9/wi5Wn1nuB5eMth5deuYOk38wkBCEAAAhDolQQQqEqqNln8SFTSwFDiiMQTCRH603cNWCWs2KXq3UNMUrJa7UtvCTUY8nHoU7/1p4fNw60jbMWhdBSv/rwYo8FXNOgt9HHHHRfIh4kcxg4aNMiJWcqLBlFJlgLR89O+S2TRYE3x+HIqDyqf8u8FoaTzZc11xBFHuKl8OkeDCbGTyKY30gcffLB7yNaDlv/T4EUPfWlsxCIqdildPeRqkKNyK58S45Sepst4MSkpf422JeVBcYuFmChss802gfxLaSClMknAWmqppYK55prLDaokVjz//PONksm0b9iwYa5NiJH46SFZAqEPZbclxdsKU/lqUp58G/HXgLb5aT2qGw02VS++LasNaYpk0hRQX7b4p3yX6BydG43L10104Bg/N+81ImsNiZ+/+93vXP1rcKK6Vh6Untqyb7/+Mz4lU3lpham/7qJlVNtX2SVqS4gTz2j/Ia76reMkYpVdL1Xzi9dn9PfWW2/dpQ2qLxY738a8UOrPUb91zDHHhBaYsj4VO7XZZZddNvG69XXi23k0jWZ9oU83y2fdr/csZYgfI1FE5ZpuuunctaJrSVO0tZCErBTVXpPC448/7oRGXVe658pySd8lGkggUJuMhrL7QomXqnefvupcfXz0HpTlXlH2tSixVJaT6lflH0kvxnRv0r1eLH0/5D/VZ0VDnvYfPV/f8+RBgqTyJOFH9wY932iFR/kJlOWXrq3jjz8+cfpkPP1Gv1ttb3qRpxV4dR2rX9ULObU1PUdpWqbEKj2vyE2C8i9LOQmTRcvTyj3Bl1cvY9TXq116Mc3v4xMCEIAABCDQ2wj0U4btzZXQhwnYBzNjrXeMfWg2djBgrIBi7ENVpSW2bzSNfRAz1uLHWL9Txj4sG/tgauwg29hVmtw2O+B3n3ZQmTuv1heUsVZnxopxxr7lNoqzncEOhlye7VQzYx9gjbWaMfaB0djBl7GDL2MfuEtL3g6IHCuxtA/PLt3SIm8QUU8zbZCV0nblvUasUOXalx20GmsJYqwFgLFikNF2O9XC2MFr2Jb1Pe266+1Mq+ZXWkOwEaks6iv1pzq1FhTGilRlJpErrr56vYu3tVgx1n+UsSKT4512nUTB+WvGvvQwdrqtOze6v93fX375ZWPFCKO+3k6XN1YYaneSmeJXvtQf6f6j/sha17jzrHhkrNgS9ke67+qeGw9ltP9W8iBu9iWDsdNrXVbsSojmiSeeMNZ6ytiXPMYKQon5jOc76+9W25t9Meja52effWasQGWseGbsS4EwOWvl5/p7a7Xrtin+Msrj23dPPbuEBeILBCAAAQhAoGICCFQVVwDJQwACEIAABCAAAQhAAAIQgAAEIACBTieAQNXpLYDyQwACEIAABCAAAQhAAAIQgAAEIACBigkgUFVcASQPAQhAAAIQgAAEIAABCEAAAhCAAAQ6nQACVae3AMoPAQhAAAIQgAAEIAABCEAAAhCAAAQqJoBAVXEFkDwEIAABCEAAAhCAAAQgAAEIQAACEOh0AghUnd4CKD8EIAABCEAAAhCAAAQgAAEIQAACEKiYAAJVxRVA8hCAAAQgAAEIQAACEIAABCAAAQhAoNMJIFB1egug/BCAAAQgAAEIQAACEIAABCAAAQhAoGICCFQVVwDJQwACEIAABCAAAQhAAAIQgAAEIACBTieAQNXpLYDyQwACEIAABCAAAQhAAAIQgAAEIACBigkgUFVcASQPAQhAAAIQgAAEIAABCEAAAhCAAAQ6nQACVae3AMoPAQhAAAIQgAAEIAABCEAAAhCAAAQqJoBAVXEFkDwEIAABCEAAAhCAAAQgAAEIQAACEOh0AghUnd4CKD8EIAABCEAAAhCAAAQgAAEIQAACEKiYAAJVxRVA8hCAAAQgAAEIQAACEIAABCAAAQhAoNMJIFB1egug/BCAAAQgAAEIQAACEIAABCAAAQhAoGICCFQVVwDJQwACEIAABCAAAQhAAAIQgAAEIACBTieAQNXpLYDyQwACEIAABCAAAQhAAAIQgAAEIACBigkgUFVcASQPAQhAAAIQgAAEIAABCEAAAhCAAAQ6nQACVae3AMoPAQhAAAIQgAAEIAABCEAAAhCAAAQqJoBAVXEFkDwEIAABCEAAAhCAAAQgAAEIQAACEOh0AghUnd4CKD8EIAABCEAAAhCAAAQgAAEIQAACEKiYAAJVxRVA8hCAAAQgAAEIQAACEIAABCAAAQhAoNMJIFB1egug/BCAAAQgAAEIQAACEIAABCAAAQhAoGICCFQVVwDJQwACEIAABCAAAQhAAAIQgAAEIACBTieAQNXpLYDyQwACEIAABCAAAQhAAAIQgAAEIACBigkgUFVcASQPAQhAAAIQgAAEIAABCEAAAhCAAAQ6nQACVae3AMoPAQj0agI//vijGTVqlJl33nnNgAEDenVZyDwEIAABCEAAAhCAAAQg0LkEEKg6t+4pOQQg0MsJPPPMM2bVVVc1/fv3N/369TOzzDKLufLKK80kk0zSy0tG9iEAAQhAAAIQgAAEIACBTiOAQNVpNU55IQCBPkHg888/NwsttJD56aefzIsvvmgWX3xxM3r0aHPIIYeYoUOH9okyUggIQAACEIAABCAAAQhAoHMIIFB1Tl1TUghAoA8ROPTQQ81RRx1lhg0bZtZcc00z11xzudINGTLEnHPOOX2opBQFAhCAAAQgAAEIQAACEOgEAghUnVDLlBECEOhTBL7//nszwwwzGFlRvfPOO2aaaaYxu+++uxkzZow57rjjzIILLtinykthIAABCEAAAhCAAAQgAIG+TwCBqu/XMSWEAAT6GIELLrjA7LDDDm6K31NPPdXHSkdxIAABCEAAAhCAAAQgAIFOJIBA1Ym1TpkhAIFeTWCttdYyI0eONPvuu6854YQTenVZyDwEIAABCEAAAhCAAAQgAAERQKCiHUAAAhDoRQS+/fZbM2DAAPPDDz+YESNGmHXWWacX5Z6sQgACEIAABCAAAQhAAAIQSCaAQJXMha0QgAAEaknguuuuMxtuuKHp16+f+fTTT03//v1rmU8yBQEIQAACEIAABCAAAQhAoBUCCFSt0OJYCEAAAhUT2HHHHc3555/vVu176aWXKs4NyUMAAhCAAAQgAAEIQAACECiHAAJVORyJBQIQgECPEJh55pnNm2++abbeemtz8cUX90iaJAIBCEAAAhCAAAQgAAEIQKDdBBCo2k2Y+CEAAQiUREDClAQqhVNPPdXsvvvuJcVMNBCAAAQgAAEIQAACEIAABKolgEBVLX9ShwAEIJCZwEUXXWS22247d/wjjzxiFl988cznciAEIAABCEAAAhCAAAQgAIE6E0CgqnPtkDcIQAACEQISpyRSjTPOOOabb74xE044YWQvXyEAAQhAAAIQgAAEIAABCPReAghUvbfuyDkEINBhBAYNGmTGjh1r5pxzTvPyyy/3idJ/9NFH5r///a8ZOHBgJeXRtEkJfVNOOWUl6StRrcb43XffmRlnnLFH86C29Prrr3dJc8kll6yN8Pn444+bxRZbrEv+OuHHL7/8Yp555hmz8MILV1LcqtpjJYXtgUTr0I6r7ufUnueff373cqUHkBdOour7kgrQW+osCAJz9913d2E+7bTTmrnnnrvLNn5AAAIQyEoAgSorKY6DAAQgUCGB9957z0w//fQuB5tuuqm58sorK8xNOUk/9NBDZq211jInnHCC0eqEVYTZZ5/dzDbbbGbkyJFVJO/S/Ne//mU23nhjc9VVV5l11lmnx/IxdOhQc9hhh3VJ79VXX3U8umzs4R8//fST2WabbYzahwS0cccdt4dzUG1yV1xxhdliiy2MhI1FF120xzNTVXvs8YK2OcE6teOq+7lFFlnE9O/f39xwww1mookmajP5YtHX4b6kEvSWOvv555/Nr371qy7Qt912W3PhhRd22cYPCEAAAlkJIFBlJcVxEIAABCokcPXVVxsJUwrHHnusOeCAAyrMTfGkn3jiCbP88subVVdd1Vx//fXFI8wZg0Q/CVT33ntvzhjKOW2fffZxju9vuukms/rqq5cS6RdffGFeeeUV88knn5gPP/zQfPbZZ2bLLbcMhU4vUF133XXhoHGZZZZJtaDSgFtCqQYkzYKmoU499dRmggkmaHZol/16G692fuONN5pRo0ZVItB0yVAFP8477zwzePBgc99995nllluughwY0472WElBEhLtxHZcdT/31ltvmQUXXNBZUd1xxx1mvPHGS6iZxpvUf3311VeND/q/vRNPPLH53e9+Z/r165fpeH9QXe5Lyk9vqrNHH300rJvVVlvNIFD5FsUnBCCQi4B9GCRAAAIQqCWBd999NzjzzDOD/fffPzj00EMDK2QE//vf/2qZ13Znatdddw1sJ+/+brnllnYn19b433///WC66aYLZpllluDLL79sa1rNIlc+rFDW7LC271e7ttPrgkknnTSwolIp6S299NJhm/Ft58EHHwzjPvLII91+O+gLtzX6ctZZZ3WLz8eb9jnVVFMFQ4YMCV588cVGUYf7jjjiCJfG6aefHm7rtC/nnnuuY2AFqsqK3o72WFlhYgl3YjuuQz938803B1YwCnbeeedYjWT7qb4krZ9J2m7F8cBaIAZW8A1++OGHponU6b6kzPbWOrOWcoEVqJry5gAIQAACaQRM2g62QwACEKiKwI8//hjsueeegTUbD+aYY45gv/32cw88448/fmB9GwTW30FVWass3QUWWCB8OH/nnXcqy0cZCdtpfYEGD9YvSRnRFYqjDoMAXwDV6xRTTBFY30OBtVLym3N/Wqup4KmnngqsFY5rO2Ju/X2F8bUqUFk/WU5oksilfPpBoQaAEqCsXzT399xzzwV33nlnoPhnmGEGd9xvfvObwFqphWknfXnssccCa3kVbLLJJkm7O2ZbHQQqwS67PdalAjuxHdeln7OWv64/GDFiRMvN4e2333b3jL322ivse+xKtq6P833PSy+9FNgVbgM7BT5Yf/31w+Ps1OmmL7fqdF8SnN5aZwhULTdtToAABGIEEKhiQPgJAQhUT2CDDTZwD5Z21bpAYpUPsiyxzqwD65MmsNME/OY+/2lX7HNlliAw+eST9+ry2qlbrm532WWXWpSjLoMAD+OYY45xfIYPH+43Ff5cdtllXZxxS7FWBSqfEVnXWMfyLk4JUI2CRLJZZ53VHWt9zwSjR49OPFyCnIQ5O/UnsNMIE4/plI11EajEux3tsS712EntuC793LfffuvuYXbBj+D777/P1RSOPvpo15/ofnj++ec3jGPYsGHhsdbPYeqxdbsvKaO9tc4QqFKbGTsgAIGMBBCoMoLiMAhAoGcI6M2nHjz1ABsVp3zq/kHS+mcIsk5N8uf21k9ZjHlrFYkNvTnMM888bpqHdcZdi2LUZRDgYVg/K4GEnAEDBpTSvmUtIstDtR9Nn4uGvAKVdSIctsett946GmXi9+iA0vpPSzzm2muvdXFaH1mJ+ztpY50EqrLbY53qsZPacZ36uQMPPNBd6xI/84SVV1457H/eeOONhlHoGcKL6ZNMMkniM4UiqNt9SXnqrXWGQKXaI0AAAkUIIFAVoce5EIBA6QTsUtTu4VOD2qRgHdwG00wzjTvmsssuSzqkz2076qijwgfy3XffvdeWT1P6JJRoukVdQp0GAZ7Jbrvt5jidffbZflPuz6i4ef/993eJJ69AFRWcmlkwKEFNAfQC65/+9KcuefA/1l13XXfM008/7Td17GedBCpVQpntsU6V2kntuE79nCwkf/3rXzsBRvfzVkIrVm8+Xr3M8v3PCy+84DeHn3W8LylzvbXOEKjCpsUXCEAgJwEEqpzgOA0CECifgHye+AfJkSNHpibgfUtsvvnmqcf0pR1rrrlmyCWLIFDXsu+7776uHHWanlmnQYCvt+eff95xkoPfokGLC+iakg+oqP8pxZtXoIpaMLz++utNs3jQQQeF7VfTd+NBVjoasMpJPCEI6iZQldke61S/ndSO69bP+Wn8je7zSW0lavW21VZbJR3SZdt//vMf58vSP1eoLcdDHe9LymNvrTMEqngL4zcEINAqAQSqVolxPAQg0DYCshjxD5KNpoDtscce7jg5ai7DmXTbClRSxHa57JDLk08+WVKsPRuN6kkP3PIxpGlndQl1GwSIyy+//BLoIV/XQtEV/ZZZZhkXzworrNANeR6BKo8Fg3xL+es6aYrfOeec4/YffPDB3fLYiRvqJlCV2R7rUp+d1o7r1s+dfPLJ7prfbLPNWmoSUWviLC9rtHKg73smm2yybiJ9Xe9LgtJb6wyBqqUmzcEQgEACAQSqBChsggAEqiEg/zN6mNRKXhpApIWo41OtUtaXg3xs+AdsrWoYt4LpibJ/+eWXznG1pmY0+9NS3Ul156ea5bEK0jSQ++67L5Dj8H/9619OwCmr3GUOAr744ovgqquuCi666KJAVkE+aICvN//Kv9qrfjcLa6+9tqt3iTdZQhIjCYGyTFL7kRgVD3kEqlGjRoXtMYu/qMcffzw8XoLyp59+Gs9G4EW0Vq0pxPKss84KHnjggS5xyjG76kF+rT7//PMu+8r8oXZ+zz33BBdffHHw0UcfdYtabf6tt97qtr3ZhrIEKuVN7UerIzYKX3/9dfDDDz80OiRotT02jKwGOzutHZfRz6lvv/TSS4Orr766S/8Wr071b9H+L75fv3Xtql/SdP1WwkorrRT2J6+99lrTU9dYY43w+MMPP7zb8XnvS2X29d0y9X8byqgzRVVWP5C1zhCo0mqU7RCAQFYCCFRZSXEcBCDQdgLLLbece5jUdKRG4YILLggfOm+55ZZGh/b6fRoMeIFKjlx7Msh3kB6SffpZP5McZ3vHuHvuuWdLRZAgNeOMM7opaquvvrr7vsACCwTyVbTqqqsGQ4YMaSm++MFlDAIkVGy77baBnPDKv9bss88eTDDBBE4c0KpVyufUU08dbLzxxo7ltNNOG7z44ovxrHT5fdxxx7ljs0xjSWOkwaSvs7iIo8TyCFRRCwa1j0ZBYuq8887r8iBHxY8++mi3w7WSV79+/dxfs0GtP1ll0eqBuh60NLyEWwmfEr+uv/56Vw/qS3x/Ih9KZYcxY8a4hRw8X1lnPPHEE2Ey9957r7MWlH+bVkNRgUpipQQlDf6XWmopxz9pcK58Pfzww47fEkss0TCbrbTHhhHVZGenteOi/ZyEHPVvWglUCzioT37zzTcTa9NPSb/99tsT92uj2ujEE0/s2maWacI6RyKqd3guv1LNwuWXXx72fxtttFGitXWr96V29PVp5ShaZ2X3A1nrDIEqrUbZDgEIZCWAQJWVFMdBAAJtJ/D73//ePVD+9re/bZjWJZdcEj54atW/vhz22WefsKxbbLFFjxX1b3/7W5iuBuHjjjuu+y0xQd/9b7/Pb9MKdKecckq3fEq00rEaNGQNmvKpeOeaa67Avy3XQ/Jqq60W5m3SSSfNGl3icWUMAuTgW6LZ22+/7dL45ptv3FLqms4okWS++eZzFgVyUu65yS9To+Df7DcTJbMwkuCbZCGTR6DKasGgQacGs6pzDSrThGRvITjbbLM1whHuE0MNbE877bTQEs07u1566aWdMCiBR8H7GBLzvEvahwlHvsivzUwzzRS2QZVRfxKpbrvttuCf//xnMNVUUwV5FzQoKlDtv//+gRab+OSTTwJZkylvsqRLmlrrRVP1vY1C1vbYKI467eu0dlykn5MVoEQpf13ppYDalPzbxcNLL70UXhe6DhoFbzkpS8csIavVm6btqV/USwLlUy8Ikvo/pdnKfUn3nnb09WllL1JnirMd/UCWOkOgSqtRtkMAAlkJIFBlJcVxEIBA2wlokKoHSj3gNApXXHFF+BCcdQqUj08m/xpclvUn8UFTZNoV/AOhuJxwwgntSqZLvLfeequzaJHAIKsXPZjroV+DlJtuuik8Vs5l9WY6S1hxxRVdnWmgmyWorCqzpoXJeX40RAdBEiGKhKKDAE0xk0XUBx980CUbvrwqw4gRI9y+U089NWy3svRpFLTalM6VGJMWsjJSXpJCqwJV1IJBotOdd97Z5e+aa64JTjrpJGfVJEFElk0azGpqUFp48MEHXTnVzpsFiUy6bpXvaPBxiNdCCy0U7lI/om26RssMxx9/vLs+xF9WX2qPEszE2Q+KF1988dRBcbO8FBGoJAxKGPWWW5reJwb6S/JnJiFN+3beeeeG2crSHhtGUKOdndiOi/Rzsg7VwiQ+yJJVbSbJf9SZZ54ZtjeJo42CVvRUPJqynyVErd522mmnLn2PBHD5pNI9aeaZZ3bxypK1mfjl++ks96V29fVpZS9SZ+3qB7LUGQJVWo2yHQIQyEoAgSorKY6DAATaTmDgwIHuwVJCSKNw4YUXhg/BZ5xxRqNDu+3TVBc9ZJX1t8022wSaxtWOIFHIT4PQg3xPrH731VdfueloG264YWihorJJBJAlivxR+aBB+DHHHON/NvyUFZTKoKl5zYKsasYff3x3fJIAKUsQWXIpvqFDhzaLruH+IoOAH3/8MZAD+xNPPLFbGrKoUv40xc37nFI72W+//ZyFjeq2UZCvL52vvyQ/Sq0w0sAuKbQqUEWFIE33GTRoULc/rcQnUUqCTaOFDnx+/BRWTY1sFmSZN+WUU3azhrrxxhtDVlGrDTlIlpWHt2xrFn/W/eImK854kJC7ySabBHPMMUfw8ccfx3dn/l1EoNIAPSra+hXK1I/ErUg0zdS3MdVDo9CsPTY6t277OrEd5+3nNG1WfbF86ClIkPV+7ZL6fr2wUJtSf98sDB482B2rRU+yBC8mKX5NMYz3P3POOWew3nrruWteLwDUPzcLWe9L7ezr0/KYt84UX7v6gSx1hkCVVqNshwAEshJAoMpKiuMgAIG2E/APi5NPPnnDtKK+JWSx0VfD6NGjwwGkHsqLDHqzMpLfEE1/iYtuGkREHZzLv5AGKs0sgXy6moqnMowdO9ZvSv30b2ll3ZE0yLjrrrtCLpryVSQUGQTI55AsvOIWhHtmeQAAMyNJREFUdJri56fyafpZniBrIfHSX5Kvl1YYaWpMUmhVoJIY6PNUljXfP/7xDxenhN5mQb5tkgbFBxxwgItD00uTHPQ3i7eM/RKn5DRe1htFBbEiAtUiiywSXHbZZa5IEkFl3ac6S/ILJ3Hf12eSk/col2btMXps3b93YjvO28/Jv110+m10pd0k31ESkNWmmlnkqY3461YWWs1C1OpN9xJdb2WErPeldvb1aeXIW2eKr139QJY6Q6BKq1G2QwACWQkgUGUlxXEQgEDbCchRrx5um/mg0qpZfmDVqgVV2wtRYgLRqYwaaFYVNNCVw2U9nPrgV2d78skn/abUT1k8+fpKsgaKnqiBgD82zYfPIYcc4o7RdKqiqxoWGQTIMkoWZ/Egkc+X4ZFHHonvzvxbvqMUT1zUa4WRpuKliTatClRRC4Ys9Z6loPKTojJmsaKQ9Z63RovG7fsN+ZqpIki8kW8aDeSLilPKfxGBSquLeUZavcu3wyQfYN7aZe65586ELa09NjtZYoKsWyRoF/2TNc+uu+7aLMmG+zuxHeft51R30T5u2WWXdW1qscUW68Y4apGn6b7Ngne8n0Wcjlq9aWGEMkIr96V29/VJ5clbZ4qrXf1AljpDoEqqTbZBAAKtEECgaoUWx0IAAm0l4H1bSHhoFIYPHx4OvLScfF8NfnqOBpliU1WQTyrlIboqk/x9aFtcPEnKo95++4FyMyswb1Gj4+VwOinIGbb2ywF50VBkEJCWtl8ZStPgkizA0s6Lb5cvIZVTToqjoRVG0ele0Tj0vRWBSnXoBYoyLRg8q1122SWevUy/ZennOWnw1NNBopnaoQbszdp21rwVEaiiaXhn1howxkVKDbg1PVXtKyt7zzneHqNppn2XEKlpw0X/JKpdaKd45w2d2o7L6OfefffdcGp10rTm008/Peznm1nkqf784gbbbbdd0+qMWr1l9VnVLNJW7ktpcfn+q2hfnxR/GXWmeMvsB7LUGQJVUm2yDQIQaIUAAlUrtDgWAhBoKwE5XdWASX/Rt7bxRP3AWsfpzWpfDSussELIQw/CVQVNJ9PgNDrtzw8Ysg5WtcKZ6kvTFhuFrbbayh0nB9tJq45pm/eBIn9iRUNZg4BoPuSHSWXVlLS8QSvFKQ752tJAKhpaYdRoiqG/jhpdaz7ddlgwKO6TTz7ZlXPTTTf1SbX0Kb9s4qQ/WZb1ZNCAXT7GZNGh+iorlCVQ+el98hsTD//+979DblmsXRq1x3jcdf7dqe24jH5O/gB9nxRfuEJ1LvFR+7Na5Mkfn44/+OCDmzaZdli9KdGs96W0DJbR16fFXUadKe4y+4EsdYZAlVajbIcABLISQKDKSorjIACBthPQm1E9sOqvkZChN/7+uKjT7iwZlGNvve0s608PkTKnb0eQLy5fziyDyHbkQSsxSZyS1VI0+Drwq4VF9yV9l+NoleXhhx9O2h1u03L3Om7BBRcMt0W/RP1PPfDAA26XfEAlDZii56V9L2sQ4OPXQN5bmiT5adIURzkebhYkfoiDfLrEQyuMvHPjJEatCFT+WOWpLAsGlevKK6905VxllVXixcz0+6CDDnLna1pwkl+aMWPGZIqn1YPkAF6LOmh6UpKVnOo4KT9Z0ilDoIqudCmfffHQqrVLo/YYj7vOvzu1HZfRz2288cbuWov6pPJ1nccib8cdd3TxaeW/RiFu9dZsgYlGccX3Zb0vxc/T77L6+qS4ta2MOiu7H8hSZwhUaTXKdghAICsBBKqspDgOAhBoO4HXXnvNPbBqEKwl7NOCLFN0zDzzzJN2SOp2WWzIoqCsv7333jvR0ic1Axl3yJeNyuj/8gowGZNLPeywww5zedBqaNGgZceVN/kDyxK87xI53W0UtDqT4t18880TD/P+p6IOsWVdlsWHUVKEZQwCovFqWqKvs8ceeyy6y31ffvnlnY+hbjtiG1544QUXj1YDjIeyGPnBehYLqqg1X1n+p1Qu7ydJTn3zBAnO4p00Bfbee+8Npp9++jzRNjxH4vnUU08d7LbbbqG/p+gJEs1ltfDss89GN2f+XoZApdUMfTt87rnnuqXtnexn7UMbtcdukdd4Q6e24zL6OS+Mq++PB98+1Oauvfba+O7E374NahXORkEvInxbLsv/lE8v633JHx/9LKuvj8YZ/V5GnZXdD2SpMwSqaC3yHQIQyEMAgSoPNc6BAATaRmC++eZzD6MSfpKCpnhJnNADa6PpS0nn9qZtEnL8Q3k7BtlZWMj5s/dTo8F+NGilP+Vvp512im5O/e4dMmsVqEbBDxi23377bofJj87ss8/u0tVA04dZZ501uOCCC/zPlj6LDAJuuOGGQFPToo7Q/TQXreIX9/ujKWiaupi0+lU80zfffLMrZ9I0wayMVEc+JDHKKlC104LBO1aW4NMoyJJvn332cX/+uOigOC6g6hixS/NvI+sH+TK66aabfHSZPj/55BO3Up8GakmWU7LukFWVLN/i9Z8pAXtQGQLVpZde6trPOOOM022KqCy7tPqkrt+sDscbtces5ar6uL7YjrMyLdLP+TRmmWUW12aSpuT5qbqakpzVF9vCCy/s4ms2Ndf3U2qvZVpvqlxZ70vt7Os93/hnGXVWdj+Qpc4QqOI1yW8IQKBVAghUrRLjeAhAoK0E/DQ/WYkkDfCuvvpq91Ar0Sbrg3BbM9ymyP/+97+7cuqhXA/RVQTvjF5OseN1sd5667n8yQdPluCdqyYtdx8931tI6W19NGhQHfVRttdee7ndTz/9tBN9skybi8bnv+cdBLz33nsuXdXPGmus4aKLWr1ptbEoM4l9iy66aGZBwDvflZVOPGRl9Je//MWdmsbID/yaWVCNGDEibItrr712PDuFfouRVhoUxzfeeCM1Lj+lVMdpBUkF7/xX24444ogu58qKQ/GmraonSwydp7+sVoBaMXKppZYKz9M0YVn66XxNdZWPHu/A/7zzzuuSn1Z+lCFQSVD25YtPg/bXovZntXZp1B5bKVuVx/bFdpyVZ95+Lhq/FgNQm/H9it/3/vvvB96qM6tFngRiifUStCT6NgoLLbRQ2JafeuqpRoe2vM9fC43uS+3u69MyXUadldkPZK0zBKq0GmU7BCCQlQACVVZSHAcBCPQIAVkl+Gk7cescDTZlmaDBvx+k9kimKkhEA18/wNSqbVWEueaay+Uh6eFdgxTlTwMMPcA3C6NGjXLHDxo0qOGhspSR7y3FKwsZBa0IJUFMS9XvvPPOLh5vGbPOOusEG2ywQcM4G+3MOwi4//77XT7EQD5UJEBJ9FB+vENfTa9Q+OCDD4LVVlvNtetmYpDPq6YCKm5NgYuHshg1EqjefPPNQAN6CS3eT4vyI5FNIvEtt9zSRYCL57GV394a75JLLkk97Y9//KPjISsO+dPSFGD5nZKfL+VLq+h5p/ryuaR9V1xxRWp8M800U1h/W2yxRepx0R0SxAYMGOBWl9SCAdtuu20Yh/Lg/3TtyidP3lCGQKX2OM0007g8KT4FibzHHntsmM9WrF0atce85eyJ8/p6O87KMG8/F43/lFNOcW1H/YFfMEPT8tUv+7af1SLvvvvuc+fIGjQpyNeg/C7qRYSPW59qv5oSKN9KZYQs96V29/Vp5SijzsrsB5rVmS8HApUnwScEIJCXAAJVXnKcBwEItI2AnI7LUkMPpLJYOO2009xKPxIuZLXQaODZtkz1cMTe34cYPProoz2ceuCmL8lySg6/9YAeD3ozqwHuxBNPnMlJvKbXSDRQeZoJWvLdJCFLUznlm0iWMBKoZCUla5AllljCxSOxUo6qi1jS5R0EyPLHT+dTG5VwIfFGTtDlmNtPhdCKVnpgl4NhCStZgkRalVl5S3MIXAajRgKVxBdNU1QdaKUr/6c61CqK2idH4WUEL5pIAEoLt956q5uWJpZyoC8+3kpJVhC/+c1vHGcJWJrOeN1116VF5bafccYZrmwzzDCDW4mv4cF2pyw3JphggsA7ndfxfjqf2rT+dL1oGmJanTVLw+8vQ6BSXC+//HIg6xNN85MvM1mdqj16cS5upejTj39maY/xc+ryu6+346yc8/Zz0fjVrmXZq3uCpn6rb9Y1EbVG9KJ89Lyk78ccc4y7ZpKmfMuSUvcWvYjSNeX7Hn3quld71kqmZYQs96V29vWNylBGnSn+svqBRnUWLQcCVZQG3yEAgTwEEKjyUOMcCECgRwiMHTvWLUO/ySabBJriI6Gq2XSAHslYmxPRQ7NfCU4DAP2uIsjJ8yuvvJKatKzYNL0ja/jzn//sBiUXXXRR01Nk7aEl4UeOHBnICiIaZJ2iN9+yLkryAxQ9ttn3ooOAb775JrjjjjucRV9UmFAetWKhHOl6a4NmefH7FZ8ED4kdjUJRRo0Eqkbplr1PK8RJ8JIo2czySJYTst6SFVk0yEpNbUU+rVoJ8h+WZVqSxNEkp/dKS07TJdhGp3S2kof4sWUJVIpX14ecpMvX1vPPP+9WHpOorPYVnxYZz4f/nbU9+uM79bPKdtyMedF+Lhq/LFrV98qKUfdjL1xIvFZ/mCUsueSSTuj+7LPPshze1mOy3pfa0dc3KliZdVZGP5C1zhCoGtUq+yAAgSwEEKiyUOIYCEAAAj1IQANKb5Whh8K+EmSFonLJqqMuocxBQFllkk8rcZLvqHaGughUKqO3mGzVaXlRPvIflbQqWdF4i5xfVKCSYCan8ZqSEw/er5ys4OIiX/xY/7un2qNPrzd/VtWOmzEr0s9J3NBLhb/97W/dRFi9PJl55pldf5V1JVW92FD/punQdQh1vC+JS5E60/ll9gOt1BkClegTIACBIgQQqIrQ41wIQAACbSBw2WWXuQd4PcTvu+++bUihuihXWWUVVzZZnNQhFB0ElF0GWQhpesv8889fdtTd4quTQKWpcyr3ctYRc08GTb087LDDejLJpmkVEagkJmi6qfoOTXWMBvnoUnvXvrh/v+hx0e892R6j6fbW71W142a8ivRzfoU+tRvdm6LB+6XS1Dv5o8oStPKp4rr++uuzHN4jx9TtvqRCF6mzsvuBVuoMgapHmiyJQKBPE0Cg6tPVS+EgAIHeSOCAAw5wD/B6iG/mS6e3lU/+MDR9UX5L6hCKDALakf/Bgwe7uu8JAa9OApVYyq+M2nyzZefL4i4LA/mueuutt8qKspR4ighUr7/+eth3bL/99mF+NHVyxx13dPvkUF7Ok7OEnmyPWfLTG47p6XachUmRfs6XR1Z3URFKU0b9ghZZfU9purZW75PT/TqFut2XxKZInZXZD7RaZwhUdWrZ5AUCvZMAAlXvrDdyDQEI9GECfkqNBuut+HjqLUj++te/uoHyVVddVXmWiwwCys68fP2U6QC4Wf7qJlDJj5QGvHLonVVAaVbGtP2amqSpphJt6haKCFSynFC/oVUuvT8vbZMPP22Xvy1xzhJ6uj1myVNvOKYn23FWHkX6ueOOO861HfmE9EH+CeUoXWJT1lVm5TNPwpScn5e1Cp/PTxmfdbovqTxF6qysfiBPnSFQldEaiQMCnU0Agaqz65/SQwACNSSglcU0mNQKdX0x6OH5j3/8o1sBUFYsVYYig4Ay8y0HyxrwaWW1rI6Gi6ZfN4FK5bn99tudw3RZ7rQznHrqqW71vp5i3UpZighUSkerG0o42GijjQI5gJbzeVktaipj1gUXqmiPrTCq+7E91Y6zcijSz2llUonGmjK6++67O99RWtRA2+S/KWs48MAD3X0tyyIZWeMs87g63ZdUriJ1pvPL6Afy1BkClegTIACBIgT66WQ7ECJAAAIQgEANCHz55ZfGWpG4nGy22WbmiiuuqEGuys+CXRXNLLPMMsYOpI1dSc3YlcXKTyRDjNNPP72Zd955za233prh6PYcYt9SG2tZYOxUM/PAAw8Y63S4PQnFYh06dKixooWxVkTGTt9xew8//HAz5ZRTxo7s2Z+nn366sQNhYweyZptttmlL4nZlRWOt1Yz1ndOW+ItEageWxgp05tFHHzV/+MMfckVlHaCbu+66y1gLTLPIIouYRRdd1EwyySSZ4qqqPWbKXC86qCfacVYcRfs5tQnrKNvY1VPN1FNP7drl7LPPbqzfuExZsCtsGutA3ljBwxx99NGZzqnioLrcl1T2onWmOIr0A1nrzFpquv5a6Smcf/75Rs8uF1544f/fwH8IQAACrRIoom5xLgQgAAEIlEtAK2/Zftz9nXnmmeVGXrPYtET5sssuG8jRblVB0ymzrj7Vrjxecsklzil6dApNu9KKxqupORNMMEGXvzFjxkQPqez7BRdcEMw444yVpV9lwvfff38wzTTTBPIjU0Woqj1WUdZ2p1mXdlx1PzfnnHMGxx57bLtxlxJ/He5LKkhvqbOff/45mHTSSbvcR6q+p5bSEIgEAhCojAAWVK0qehwPAQhAoI0ETjzxRGNX7nMpWMetxj7YN0xNb3zPOussY6daGCs2mL333ttYJ8hdzrF3GHPaaaeZW265xVnMLLnkkl328wMCEIAABCAAAQhAAAIQgEDVBBCoqq4B0ocABCAQIbDJJpuYa665xlgLCjc9J7Kr21e7ipJZYYUV3PS49957z2gahvU3Y6zlRZdjNYXOWiq5/VtuuaW59NJLu+znBwQgAAEIQAACEIAABCAAgaoJIFBVXQOkDwEIQCBCQAKTneplNt98c3P55ZdH9nT/Onz4cPPZZ5+ZAw44wPl9GDJkiDvo1VdfNbPNNluXE+TTRz5RTj75ZLPnnnt22ccPCEAAAhCAAAQgAAEIQAACVRNAoKq6BkgfAhCAwP8R0HQ9u5Kb+yVHyTvssENmNl9//bWZbLLJtDKrkXNT678iPFcWVOuuu65zUmtXCHPOocOdfIEABCAAAQhAAAIQgAAEIFADAghUNagEsgABCEBABG677Taz+uqrOxhvvvmmGThwYEtgrFNp884775gzzjjD7LLLLua7774zRx55pDnnnHPMsGHDWhK8WkqYgyEAAQhAAAIQgAAEIAABCBQkgEBVECCnQwACECiLwGGHHWaGDh3qloTXkt6thuWXX97YFcCco/QllljC7LPPPmaBBRZwU/tmmGGGVqPjeAhAAAIQgAAEIAABCEAAAj1GAIGqx1CTEAQgAIHGBJZaainz8MMPG63kp9X4Wg3bbrutufjii90UPq3+d9JJJ5lVV1211Wg4HgIQgAAEIAABCEAAAhCAQI8TQKDqceQkCAEIQKA7gY8//thMO+205pdffjFvv/22mX766bsf1GCLpvZpBUD5m5pjjjnMv//9b/OrX/2qwRnsggAEIAABCEAAAhCAAAQgUB8CCFT1qQtyAgEIdAgBOTL/6quvnFNzX2T5jdptt93MMsssYx544AG/uenn999/b44//ni3Op+Eqccee8w5WpfgRYAABCAAAQhAAAIQgAAEINBbCCBQ9ZaaIp8QgECfICBxaqGFFjLPPvusE5X23HNPt/LewgsvbJ555hlz4403uhX3shT26quvNvvvv79ZbLHFnEj11ltvmT/+8Y/u1G+//dZMNNFEWaLhGAhAAAIQgAAEIAABCEAAApUTQKCqvArIAAQg0EkExo4dawYNGuSKvNFGG5lrrrnG+Y2S/6ill17aPPjgg01xvPvuu2b77bc3Wunv7LPPNiussII754033jCzzDKL+64pfvPMM0/TuDgAAhCAAAQgAAEIQAACEIBAHQggUNWhFsgDBCDQMQRkQaWpeGPGjDF333236d+/v3NkPs4445gnn3zSTDfddA1Z6JyNN97YbLbZZmbYsGFmggkmCI//8ccf3W/5sbr22mvNhhtuGO7jCwQgAAEIQAACEIAABCAAgToTQKCqc+2QNwhAoE8SeP31180ee+xhRo0aZcYff3xnAaUV9+QkvVEYPXq0WWSRRcyiiy5q7r333sRDZ555ZmdZNXjwYDN8+HDncF2i1nbbbZd4PBshAAEIQAACEIAABCAAAQjUgQACVR1qgTxAAAIQyEDguOOOM3/961/NpJNO6qYGrrLKKt3O2mabbcwll1ziVvCTSKUphH/605/MOeec0+1YNkAAAhCAAAQgAAEIQAACEKgLAQSqutQE+YAABCDQhMAjjzxiVl99dbPAAgs4v1UDBw7sdoasrLbaaisjH1SaSrjDDjuYXXbZxYw77rjdjmUDBCAAAQhAAAIQgAAEIACBuhBAoKpLTZAPCEAAAhCAAAQgAAEIQAACEIAABCDQoQQQqDq04ik2BCAAAQhAAAIQgAAEIAABCEAAAhCoCwEEqrrUBPmAAAQgAAEIQAACEIAABCAAAQhAAAIdSgCBqkMrnmJDAAIQgAAEIAABCEAAAhCAAAQgAIG6EECgqktNkA8IQAACEIAABCAAAQhAAAIQgAAEINChBBCoOrTiKTYEIAABCEAAAhCAAAQgAAEIQAACEKgLAQSqutQE+YAABCAAAQhAAAIQgAAEIAABCEAAAh1KAIGqQyueYkMAAhCAAAQgAAEIQAACEIAABCAAgboQQKCqS02QDwhAAAIQgAAEIAABCEAAAhCAAAQg0KEEEKg6tOIpNgQg0DcI/Pjjj2bUqFFm3nnnNQMGDOgbhaIUEIAABCAAAQhAAAIQgEDHEUCg6rgqp8AQgEBfIfDMM8+YVVdd1fTv39/069fPzDLLLObKK680k0wySV8pIuWAAAQgAAEIQAACEIAABDqEAAJVh1Q0xYQABPoWgc8//9wstNBC5qeffjIvvviiWXzxxc3o0aPNIYccYoYOHdq3CktpIAABCEAAAhCAAAQgAIE+TwCBqs9XMQWEAAT6IoFDDz3UHHXUUWbYsGFmzTXXNHPNNZcr5pAhQ8w555zTF4tMmSAAAQhAAAIQgAAEIACBPkwAgaoPVy5FgwAE+iaB77//3swwwwxGVlTvvPOOmWaaaczuu+9uxowZY4477jiz4IIL9s2CUyoIQAACEIAABCAAAQhAoM8SQKDqs1VLwSAAgb5K4IILLjA77LCDm+L31FNP9dViUi4IQAACEIAABCAAAQhAoIMIIFB1UGVTVAhAoG8QWGuttczIkSPNvvvua0444YS+UShKAQEIQAACEIAABCAAAQh0NAEEqo6ufgoPAQj0NgLffvutGTBggPnhhx/MiBEjzDrrrNPbikB+IQABCEAAAhCAAAQgAAEIdCOAQNUNCRsgAAEI1JfAddddZzbccEPTr18/8+mnn5r+/fvXN7PkDAIQgAAEIAABCEAAAhCAQEYCCFQZQXEYBCAAgToQ2HHHHc3555/vVu176aWX6pAl8gABCEAAAhCAAAQgAAEIQKAwAQSqwgiJAAIQgEDPEZh55pnNm2++abbeemtz8cUX91zCpAQBCEAAAhCAAAQgAAEIQKCNBBCo2giXqCEAAQiUSUDClAQqhVNPPdXsvvvuZUZPXBCAAAQgAAEIQAACEIAABCojgEBVGXoShgAEINAagYsuushst9127qRHHnnELL744q1FwNEQgAAEIAABCEAAAhCAAARqSgCBqqYVQ7YgAAEIxAlInJJINc4445hvvvnGTDjhhPFD+A0BCEAAAhCAAAQgAAEIQKBXEkCg6pXVRqYhAIFOJDBo0CAzduxYM+ecc5qXX365TyD46KOPzH//+18zcODASsqjaZMS+qaccspK0leiWo3xu+++MzPOOGNLeVBbeP3117ucs+SSS9ZCuKyyXn/55RfzzDPPmIUXXrgLm075kbc9dQqfVsv5+OOPm8UWW6zV0wofX4d2rOto/vnndy9FGhUoCAJz9913dzlk2mmnNXPPPXeXbX3hR1XtIcqu6vtW1nYRzTPfIQABCGQmYG8qBAhAAAIQqDmBd999N7Adu/vbdNNNa57bbNkbNWpUMNlkkwXnnntuthPacNRss80WrLHGGm2IOXuUN998c/Cb3/wmGDFiRPaT7JFHHnlk2CZ823j11VdbiqMdB1ddr5dffrnjYgeS7She7ePM255qX7AezuCPP/4YbL755oEVz4Offvqph1MPgjq0YyvyBiuvvHLw7bffNiy/+Pg+yH9uu+22Dc/pbTurbg9RXlXft7K2i2ie+Q4BCEAgKwEsqOydlAABCECg7gSuvvpqY4Upl81jjz3WHHDAAXXPcsP8PfHEE2b55Zc3q666qrn++usbHtvOndNPP72xD/vm3nvvbWcyTePeZ599nOP7m266yay++upNj9cBQ4cONYcddpi57rrrzEQTTeTOWWaZZVItqOwg0rz33nvm559/bhq/ppFOPfXUZoIJJmh6bPSAOtTreeedZwYPHmzuu+8+s9xyy0Wz1zHf87Sn3gKnJ9qxfYh2/e2NN95orOBqFl100R7HU4d2/NZbb5kFF1zQWVHdcccdZrzxxkvl8Oijj5qvvvrK7V9ttdWMFajMhRdemHp8ox1ffPGFeeWVV8wnn3xiPvzwQ/PZZ5+ZLbfc0qi/Tgra79NO2h/dNvHEE5vf/e53pl+/ftHNDb/XoT1EM1j1fauVdhHNN98hAAEIZCKQVcniOAhAAAIQqI7ArrvuGr6hvuWWW6rLSAkpv//++8F0000XzDLLLMGXX35ZQoz5o1A+rFCWP4KSzvzf//4X2Ol5waSTThrYgVmmWL0FlR2YZTr+rLPOCtuQfUDI9H2qqaYKhgwZErz44otN06hLvcoiT+WzAlXTPPfVA/K0p97Cot3tWByOOOII14ZOP/30yrDUpR3LIs+KOcHOO++cmUX//v2DIhZUSy+9dLf+6cEHH0xNX/1U1j5Nx1nhPbCiY2BFwOCHH35IjdfvqEN78HnRZx3uW3naRbQMfIcABCCQRsCk7WA7BCAAAQjUh8ACCywQPoC/88479clYjpystdZaboBg/VjkOLvcU+rwoO9LpHqdYoopAk2fsFZOfnPqZ6sClfVz5YQmDfSUjh/QaZAmAcr6NXN/zz33XHDnnXe6KYQzzDCDO05TEK2VWWpetKMu9VqXgX1DWD2ws9X21ANZKiWJdrfjxx57LLAWhMEmm2xSSn7zRlKndmwtdl0/kHUaclGBylpNBU899VRgLSBduhKUrK/CVJRvv/12oPvJXnvtFfZrdpVbF4fv11566aXArn4bXHnllcH6668fHrfOOusEEnTTQl3aQzR/dblvtdouomXgOwQgAIE0AghUaWTYDgEIQKAmBOyKfcG4447rHqgnn3zymuQqXzbslBlXjl122SVfBCWfVZcHfV+sY445xvEZPny435T62apA5SPSYMw6hnfpSIBqFDRQnHXWWd2xdhphMHr06MTD61SvdRrYJ8LqwY2ttKcezFYpSbWjHUsYlkBsp7IFdjpsKfnMG0md2rF8UOneYxfqCL7//vumRSoqUPkEll12Wdf3ZLVyPfroo93xEt/PP/98H03i57Bhw8Jjd9xxx8Rj6tQeohmsy32r1XYRLQPfIQABCKQRQKBKI8N2CEAAAjUhYFdHCh+k9cDem8M888zjpovUwZm3ONblQd/XqfWlEkgIGjBgQNBs6l5egeqhhx4K29PWW2/tk079jA76rP+zxOPqVK91GtgnwurBja20px7MVilJtaMdX3vtte7asP6OSsljkUjq1o4PPPBAx0aiZ7NQhkAlS7nxxx/fpakpdlmCHLp7y9A33nij4Slyeu6F+kkmmSTQ73ioU3uI5q1O961W2kW0DHyHAAQgkEYAgSqNDNshAAEI1ITAUUcdFT5077777jXJVevZ0BQMDR40paIuoU4P+p7Jbrvt5jidffbZflPiZ16BKio4NbMyUMKaAugHfX/605+65aVu9Vq3gX03YD28IWt76uFsFU6u7HasDK277rqurT/99NOF81c0grq1Y1mU/frXv3aifrNVDcsQqKIvZu6///6mOFuxqPORWWfjYd/2wgsv+M3hZ53aQ5gp+6VO961W2kW0DHyHAAQgkEYAgSqNDNshAAEI1ITAmmuuGT5EZxEUapLtbtnYd999XTnsalDd9lW1oU4P+p7B888/7zjJiW+jkFegiloZvP76642ScPsOOuigsP1tsMEG3Y6vW73WbWDfDVgPb8janno4W4WTK7sdy9pMAowWK6hDqGM71vUvsXrkyJENEZUhUB166KEuLfm/a+R/ymckalG31VZb+c2pn//5z3+CX/3qV2HfpuskGurWHqJ5q9t9K2u7iJaB7xCAAATSCCBQpZFhOwQgAIGaELBLYocP0U8++WRNctVaNuTLQw/V8u2iqRt1CXV70BeXX375JdAATwPBRiv65RGo8lgZyCePt6CKT/GrY73WcWBfZXvP2p6qzGOraZfdjpX+Oeec49r5wQcf3Gp22nJ8HdvxySef7BhtttlmDctchkC1zDLLuLRWWGGFhmn5nVFL4ywvcrQKne/XJptssm4iWN3agy+nPut238raLqJl4DsEIACBNAIIVGlk2A4BCECgBgTkR8M/ROttb5Y3yWVn+8svv3QOg2XK3+zv/fffT1wRyU/XaGYVlJR3TSe57777AjkO/9e//uUEnKTj8mwr80H/iy++CK666qrgoosuCvT23QcJBHq7r/xrZSr9bhbWXnttV+8aJKWFPALVqFGjwvaUxc/O448/Hh6vlf8+/fTTLtkpUq8SGe65557g4osvDj766KMu8eqH4n7rrbe6bW+2oayBvdrypZdeGlx99dVd6jOevuozWt/x/Xl/93R7ypvPKs4rux2rDF4QaWYdFC9vJ7Vj9V+6H00zzTRxDF1+tyJQJfXveokhazalpX4uS1hppZXCvuq1115resoaa6wRHn/44Yd3Oz5veyjzuu2Wqf/bUMZ9q8z+LWu7SCsP2yEAAQhECSBQRWnwHQIQgEDNCGhw7AUqOaLuySDfQ3oQ9uln/UxyvO0dqe65554tFUGC1Iwzzhhomsfqq6/uvi+wwAKBfMSsuuqqwZAhQ1qKL35wGQ/6GqBuu+22gRztyr/W7LPPHmhZdIlLWuVI+Zx66qmDjTfe2LGcdtppgxdffDGelS6/jzvuOHdso6kqeQSqqJWB6rdRkBg677zzunzImfCjjz7a7fC89TpmzBi3IphvU7JgeOKJJ8L47733XmdtJ/9WrYYyBCqJY6pPrR4mh/Vqg2+++WZiVvwU3Ntvvz1xf6sbq2pPreazyuPLbsdama5fv37urxWxsdPascSkiSee2PUJjaYHZxWo0vp3CcO+b3jggQeaNrUffvghdHguv1LNwuWXXx7Gv9FGGwWyBI2GPO2hHddtNE/R70XvW2X3b1nbRbQMfIcABCCQRgCBKo0M2yEAAQjUgMA+++wTPkhvscUWPZajv/3tb2G6GiiMO+647rcGcfruf/t9fptWoDvllFO65VOilY7VwCBrkJNwxTvXXHMF/o24HoRXW221MG+TTjpp1ugSjyv6oK/8yJGuRLO3337bpfHNN9+4Jdk1nXG55ZYL5ptvPmdhI0e/npv8OjUK3jKpkSiZR6DKamWgwafEGdWZxKlbbrklMbt56lW+X2aaaaawDpWG/iRS3XbbbcE///nPYKqppgryLghQVKCS1ZZEKcWjIBFU+ZNPnHh46aWXwnIo30VDle2paN578vyy27G3VJ1tttkyF6NT27G3LNIKd2khi0CVpX/XiwmJT81CVos6CVFKVy8QdE3r5UFS/K22h3Zdt2nlLnLfalf/lqVdpJWH7RCAAASiBBCoojT4DgEI9HkCMuvX4LisP4kPX3/9ddu4+Yc+PUyfcMIJbUsnGvGtt97qLAkkUMhqRg/ferDXoP2mm24KD5VzbL19zhJWXHFFNyCQ8JIlqKwqs6aVvfPOO11OiYoCcpRcJBR50Fe6Z511ViCLqA8++KBLNnx5VYYRI0a4faeeemooZlx//fVdjo//0IpSOlfWCmmhVYEqamUg0enOO+/s8nfNNdcEJ510UrDWWmu56TWaUipxRlNB0oIvZ9Z6VTzHH3+8a1+qY1mrqD5PO+20QHH5gePiiy+eOHBMy0d0e1GBStZw66+/fhilLPdUF0l+d84888ywTj/88MPwnLxfqmxPefPc0+e1ox0/+OCDrh7V32YNndqOtZKnrodhw4alomomUGXt39UnZAlRi7qddtqpS78mcV0+qXS/mnnmmV3eZeXaSGBrtT2067pNK3uR+1a7+rcs7SKtPGyHAAQgECWAQBWlwXcIQKDPE5CvCT1IlfW3zTbbuGlc7QAnUchPp9CAoCdWv/vqq6/cdLQNN9ywi68kPbDL+kf+qHyQiHDMMcf4nw0/ZQWlMmRZvl1vr8cff3x3fJIPJvknkSWX4hs6dGjDdJvtLPKg/+OPPwZyYH/iiSd2S0YWVcqfpsh5n1Oa7rfffvs5C6H4lJJ4BPL1pfP19/nnn8d3u9+tClR+0KU4NX1t0KBB3f60gplEKQlGr776amK60Y2t1Ks/T/m+5JJL/M/wU0LoJptsEswxxxzBxx9/HG5v9UsRgUo+ttT25DNMQQKa94WT1NYl0IqnOBQNVbenovnvqfPb0Y79VGpN0c0aOrUdDx482LX5PfbYIxVVI4Gqlf5dwlOW4IVyXYuajhvv2+acc85gvfXWc1aQejmga61RaKU9tPO6Tctj3vtWO/u3LO0irTxshwAEIBAlgEAVpcF3CEAAAjUiMHr06FCk0IN3kUF71mLJj46mz0hMiQYNRqIOzuWfSAP3ZpZAPg5NxVMZxo4d6zelfvo3sZrmlTSQuOuuu0IumjZXJOR90Fea8pkkC6+4BZ2m+PmpfEcffXSu7MkHinjpL833UasClcQ8H2dZ1nit1GsjEBKn5LRdFg5+qmSj4xvtKyJQySdOdJqXpgN5Zkk+d6acckq3f+edd26UpUz7qm5PmTJZg4Pa0Y7/8Y9/uHrUC4cioRPa8QEHHOBYyRInLTQSqFrp3zV1r1mIWtSpP1IdFA2ttId2Xrdp5ch732pn/5alXaSVh+0QgAAEogQQqKI0+A4BCECgRgSuuOKKcHCsaWRVBVn7aNUmPYD64Fd3e/LJJ/2m1E9ZPPlBfpo1kD9ZD/v+2DQfRIcccog7RtPBiq5qmPdBX/mVZZQszuJBIp8vwyOPPBLfnfm3/K8onjRRr1WBKmplkKXemmW0lXptFJfEOPnxkjBUVJxSOkUEKg1uo3W67LLLujpYbLHFuhVBju59PWt6ZNFQdXtKy7+mR2lKqATpon/yM5bWntPSj28vux0r/v3339/VZSOroHg+4r87pR37BRwaiXlpAlUr/bvanByPNwtRizpNTy4jtNIe2n3dJpUn732rnf1blnaRVBa2QQACEIgTQKCKE+E3BCAAgZoQkM8MPwCWH5yqgnxSKR/RVco0aG0knkTzqjfcvhzNrMD8m2sdL4fZSWHppZd28ckBedGQ90G/Ubp+ZTtNo0uyAGt0bnSfnKyLg5zaJoVWBCrVgRe8yrIyaKVek/KvbZoyqnqUANSsbaTFEd9eRKCKxvXuu++GU0mTpnGefvrpYbv+6KOPoqeW+r2n2lNapuWHTlMvNe236J9WpdQ0o7yhHe1YefGMd9lll1xZ66R2LKtQ9UvbbbddKqs0gaqV/j2rf8GoRV0jv1ipmU3YUbQ9KEofR9H7QEL23Oq68hFZJJTdv2VpF0Xyy7kQgEDnEECg6py6pqQQgEAvI7DCCiuEA2A97FYVNCVDYkl02p8fFKSJJ/G8ynJCgxpNW2wUNIDVcXLQLQudeNA27xNI/sSKhnYIVPLjpDKsueaaubOnFcIUh3xtaVCeFFoRqNphZaA8Za3XpPxrgCQfXbJ6UHnLCmUJVPJ/5usg7qhfeZVYo/1zzz13WVlPjKen2lNi4jXb2K52fPLJJ7u63HTTTVsucae1Y/nRU7s/+OCDU1mlCVSt9O9Zp0e3w6KuSHvwUMq4bn1c8c8y7ltl929Z2kW8HPyGAAQgkEQAgSqJCtsgAIE+S0COvfVGs6w/PSh+8cUXbeE1+eSTu4GABgNlTCHKk0mtTCZxSlZL0SBLA+XrmWeeiW5O/S7H1zr+4YcfTj1GO37/+9+74xZccMHE46L+px544AF3jHxAJQkIiRHENpbxoB+NUkKLt3xK8vOkKY5ZLEg06BUv+ThKC60IVP5YxVmWlYHylbVe42WQA/aBAwcGmiaUZGUmRnl9yZQlUG288cauDqI+qXw5NK1HDvLFM6/VjY+r0WdPtqdG+ajLvna14yuvvNLV5SqrrNJSUTuxHe+4446OlVawTAtpAlUr/btfqKBR/x63qGu2+ERafuPb87YHH09Z162PL/5Zxn2r7P4tS7uIl4PfEIAABJIIIFAlUWEbBCDQZwnozahWmynrb++990609CkKUL54NPj1f3kFmKL5OOyww1weDj300C5Rrb/++m77xRdf3GV72g/vy0dOWhsFrcCkMm+++eaJh3n/UxNNNFHon0TWZXl9x5TxoB/NqKYl+jp77LHHorvcd03LkIDSLLzwwgsuHq0GmBb8YD3qMynt2Kg1Xhn+p3w6WevVH69PWdFNPfXUwW677RaucBjdr+lS8rn27LPPRjdn/l6WQOUH02rr8eDrR3XdaLn6+Hmt/u7J9tRq3qo4vl3t+J577nHX2yKLLJK5WJ3ajr2T8xtvvDGVVZpAVXb/rpcUvr8ty/+UCpWnPURhlHXdRuOMfi/jvlV2/5alXUTLwHcIQAACaQQQqNLIsB0CEIBAhQQk5PgH7+mnn76SnMjpr7cSuffee7vkQSv9KX877bRTl+1pPzbaaCN3vFZFaxS84LH99tt3O0wOc2effXYXjwaqPsw666zBBRdc4H+29FnkQf+GG24INCUo6gjdT/vSKn5xB79yEKypi0mrwcUzffPNN7tyNpommFWgapeVgfKctV59+T755BO3Up8GM0mWU7KAkFWVLMfi/HwczT7LEqhmmWUWVwdJU5n8FCBNwUzznfX0008H8lOVVVyuuj0141r1/na2Y+/wXsJpltBJ7TjOY+GFF3bXhfqztJAmUGXt33V/8aFR/+77QN2LyrQMbaU9tPO69Qzin0XuWz6uov2bj8d/ZmkX/lg+IQABCDQigEDViA77IAABCFRE4O9//7sbBOjBWyJAFWH48OEuD3KqHRcL1ltvPbdPPoSyBO9Adeutt254uLeQ0tvdaNB0r8022yxkstdee7ndEgEk+mSZNheNz3/P+6D/3nvvuXRVP2ussYaLLmr1Nv7443dhJrFv0UUXDXbddVefdMNP72BXVkZpwQ/OmllQjRgxIuS29tprp0WXa3vWelXkWnFxqaWWCvOiabaylJMVnqaKyieKd4B/3nnn5cqPTipLoJLzdtXvX/7yly55ef/99wNvCTLPPPN02ed/yEpN5+pv0KBBiZZi/lh91qE9RfNTx+/tbMfq37RqnOrrjTfeaFj8TmrHcRCauqb+VsKsRLq0kCZQZe3f/TXXrH9faKGFwuvsqaeeSstOy9uztod2X7dpGc9734rGV6R/i8aj71nbRfw8fkMAAhBIIvD/AAAA//+CuSwEAABAAElEQVTsnQn8TNX//9+WUIRUkixRRKXskV1FKtpEkqgQKkuUrUUpUpRKlqRCyhJFdtnXyJKQFiIiSpak+lbu/7zO43fmPzOfuTN39jszr/N4fD4z955zz/I8Z+7yvu9FLCYSIAESIAHXEbjnnnssEdF/r776alL6V758ed3+fffdl6X9Hj166Lxs2bJZP/30U5Z8/x2rVq3S5UuXLu2f5bP9888/W+ecc46Fer/66iudd+jQIeu2226zypUrZ3Xu3FnXc//99+u8Zs2aWXfccYdPHeFsXHTRRVb9+vXDOUSXXb58ue4H5mjkyJHWn3/+ad1yyy0W+nPdddfpvI8++kiXPXjwoHXjjTdaNWrUsI4fP+6oLfQJdS9ZssS2/HPPPafLBKpzz5491syZM623337buuyyyzx9rVatmjVlyhRr7ty51v/+9z/bup1mOJ1X1NexY0frvPPOs+bPn2+dPHnSateunadfZq3jE2v/9OnTTruQpdzYsWN1vcuWLcuSF86O1157TdcDfugv0vfff6/Xoenvww8/HLDK9957z2ds3333XcByZqcb1pPpi5s+E7WOMebrr79ez9mECROCIsikdewPAr8prP26dev6Z/lsFypUSP++fXaqjVic3z/77DNr6tSpVvfu3X1+Yy+++KL1ySefWDt27PBvNqJtJ+sh3r9bu45Het3yri+a85t3PfjudF34H8dtEiABEghEQALt5D4SIAESIIHkErjyyis9N9/r1q1LeGf++ecfq0CBAtYZZ5xh4SbcPy1dulQLkfLly2cdPXrUPzvL9t9//23lz59fjymUQOvzzz+3IMjKmzevVbVqVeuss87SAqpff/3VOnbsmFWzZk1dT+HCha2SJUtahw8fztKe0x2R3uhDuNO8eXPdj1q1amnBC4Q/v/32mwVhRJUqVXTe5ZdfbuFhrUWLFtaJEyccdQvsMWb07b///rM9JpiACsKfHDlyaIYFCxa0zB/mIFeuXDrv22+/ta3baYbTed24caOVJ08ea/Xq1Z6qMba2bdtqTnjoxXrr2bNn0DF7Dg7yJVYCKvRv8ODB+jdw/vnn67WIMUAQaQRURgjp3x2sVaxd/D4wLjw4B0tuWE/B+pesvEStY4wPAg7MKwRQdinT1rE/h0GDBmlGo0eP9s/y2bYTUKFQNOf33bt36+tO7ty59e/KnNfwiXNm9uzZrTZt2vj0JdINJ+shnr/bYP2O9LrlXWc05zfvevDd6brwP47bJEACJBCIAAVUgahwHwmQAAkkkQAe+iEYwsMSHoixnYy0ZcsW65tvvrFtev369daBAwds8/0zOnXqpMcE7ZJQ6d9//7VWrlxpzZkzx4IWhXeCdg00d6BdBGFONCnaG/3ff//dWrhwoQUW3sIk9HHNmjUebaFw+oj6MPcQ1gRLwQRUwY6LdZ6TeYXABg+mgdLOnTutpUrgGQuNLtQfKwGV6Ss0+LDWFi1aZP3yyy+ehzEI+zD/oVLjxo2tadOmhSqm85O5nhx1MI0L7d+/XwtuIRy30+DL5HWMqb/22mu1gPvIkSNBV0IwARUOTNT5PWgnQ2Q6WQ+minj8bk3dgT6jvW551xnt+Q11OV0X3u3yOwmQAAnYEaCAyo4M95MACZBAkgh8+eWXWkABIQVu/NIlQfsAY6pcubJrhhTLG/1YDeqmm27SnDZt2hS0SrcIqNw2r9EKqCD0hBB1wIABWYRmEBaXKlVKz0/Xrl2Dzo/JRHn8ppOVnK6nZPXPTe02bdpUz+2sWbOS3i23rWMI4XH+hhlzqBRKQBXqeLfku2k9eDOJ5roV6/NbOOvCewz8TgIkQAJ2BCigsiPD/SRAAiSQJALvv/++fhDAw0CvXr2S1Iv4NNuoUSM9NmjMuCFFc6Mfj/7Dfwr8b1199dUhq3eLgAodddO8RvtgP3z4cM/vD79F72T8tsCcCP6oQqXt27drLUj4KEtGCmc9JaN/bmsTJqj4/dWrVy/pXXPTOgaMu+++W/8uZsyYEZJNugio3LQevKFHc92K5fkt3HXhPQZ+JwESIAE7AhRQ2ZHhfhIgARJIEoHevXt7HpCnT5+epF7Ep9mvv/5amy/Cj48bUjQ3+vHof4cOHRwL8NwkoHLTvEb7YA8fNhAOw1eXtxBq69atHgf+dr6n/NfEvffea2FOk5XCWU/J6qPb2jXzv2HDhqR2zU3rGGbWOXPmdBxQIl0EVFgAblkP3osxmuuWGU8szm/hrgvvMfA7CZAACdgRoIDKjgz3kwAJkECSCBiTHDwkh+PjKUndDbvZPn36aAHA5MmTwz421gdEc6Mf677A91Q4Tn7dJKACC7fMa7QP9kOGDNHr84cffvBMMfyxwVE6HtKdRtWEEOvMM8/UTvM9FSXwS7jrKYFdc3VTiLqJSKIVK1bU0TmT1Vm3rGP4i0JUUTgmdxohL50EVG5ZD97rMJrrVqzOb5GsC+8x8DsJkAAJ2BGggMqODPeTAAmQQJIIFC9eXD8gI0JdOib4wGjQoIGOcAYH2clM0dzox7LfcMgLAQiiNzpxvI223Sagcsu8Rvtgj0iMEE5ceuml1qOPPqp97iAiIvbB35bTdO6551rvvvuu0+IxLRfJeoppB1K8sgULFmiH6cnUfnPLOu7bt6++HjkJbmGmPZ0EVBiTG9aDYYvPaK5bsTq/RbIuvMfA7yRAAiRgRyAbMtRbeiYSIAESIAEXEDh27Jiot/e6J61atZIPPvjABb2KfRdUNCypU6eOKI0UWbt2reTLly/2jTiosVixYlKhQgWZN2+eg9LxKaLeRIvSUJC9e/fKihUrRDnVdtTQwIED5emnn5b27duLMtfQxzzzzDNSuHBhR8fHo5Ab5vXtt98WJViQdevWyTXXXBPRMDEnyvmvqGiRUqRIEV1P2bJlRfknclyfio4lF1xwgePysSoY6XqKVfvpUs+IESNECShFCWakbdu2CR+WG9axiqIqylG4KGGEvPDCC7YMVNRDzcoUGDdunOD6pQS0ZlfKfyZ7PXgDjPa6Fe35zem68O4zv5MACZCAYwJ2kivuJwESIAESSDyBZcuW6bfV6iRujRw5MvEdSGCLv/zyi1W3bl0LjqeTlWBO6TQaW7z6OGHCBO0U3dukzElbMDXLkyePz993333n5NC4lkn2vC5fvty68MILrV27dsV1nG6tPNL15NbxJLNf77zzjlWiRImkdMEN67hcuXLWiy++GHL8//33n1WgQAGfc1Gyz6shOx1BgWSuB+/uJvu65XRdePeZ30mABEjAKQFqUDkW5bEgCZAACcSfwLBhw0RF7tMNKcfTom4EgzYKjZVRo0aJMj0SJayQxx57TKpXr+5zjLogyBtvvCFz587VGjfXXnutTz43SIAESIAESIAESIAESIAESCDZBCigSvYMsH0SIAES8CLQsmVLmTp1qigNEFEO0r1ysn5VUcWkYcOG2jzup59+Eqjtly5dWpTmiE9hmNApTSWdr6KKycSJE33yuUECJEACJEACJEACJEACJEACySZAAVWyZ4DtkwAJkIAXAQiYlKmX3HPPPTJp0iSvnKxf33rrLTly5Ij07t1b4POjY8eOutC3334rZcqU8TkAvlTgQ2P48OHSrVs3nzxukAAJkAAJkAAJkAAJkAAJkECyCVBAlewZYPskQAIk8H8EYK6nIrnpLTjIffDBBx2zOXHihBQsWBCRWQUOTJWPCs+x0KC69dZbtbNbFRlKsmfP7snjFxIgARIgARIgARIgARIgARJwAwEKqNwwC+wDCZAACSgC8+fPlyZNmmgWe/bskZIlS4bFRTnzlX379smbb74pXbp0kVOnTslzzz0nY8aMkaFDh4Yl8AqrYRYmARIgARIgARIgARIgARIggSgJUEAVJUAeTgIkQAKxIvD000/LwIEDpVq1ajrEfbj11q9fX1TkJ+0ovWbNmtKzZ0+pWLGiNu0rXrx4uNWxPAmQAAmQAAmQAAmQAAmQAAkkjAAFVAlDzYZIgARIIDiBWrVqyZo1awSR/BCNL9zUrl07GT9+vDbhQ/S/V155RRo3bhxuNSxPAiRAAiRAAiRAAiRAAiRAAgknQAFVwpGzQRIgARLISuDw4cNStGhROX36tPz4449SrFixrIWC7IFpHyIAwt/UZZddJtu2bZOcOXMGOYJZJEACJEACJEACJEACJEACJOAeAhRQuWcu2BMSIIEMIQBH5sePH9dOzc2Q4TfqkUcekTp16siKFSvM7pCff/75p7z00ks6Oh8EU59//rl2tA6BFxMJkAAJkAAJkAAJkAAJkAAJpAoBCqhSZabYTxIggbQgAOFU5cqVZcuWLVqo1K1bNx15r0qVKrJ582b55JNPdMQ9J4OdMmWKPPHEE1K9enUtpNq7d680aNBAH3ry5EnJmzevk2pYhgRIgARIgARIgARIgARIgASSToACqqRPATtAAiSQSQR++OEHKV26tB7yXXfdJVOnTtV+o+A/qnbt2rJy5cqQOPbv3y8PPPCAINLf6NGjpWHDhvqY3bt3yyWXXKK/w8TviiuuCFkXC5AACZAACZAACZAACZAACZCAGwhQQOWGWWAfSIAEMoYANKhgivfdd9/J4sWLpVChQtqRefbs2eWLL76Qiy66KCgLHNOiRQtp1aqVDB06VPLkyeMp/88//+ht+LGaNm2aNG/e3JPHLyRAAiRAAiRAAiRAAiRAAiTgZgIUULl5dtg3EiCBtCSwa9cu6dq1q6xatUpy586tNaAQcQ9O0oOlnTt3StWqVaVatWqydOnSgEVLlSqlNas6dOggb731lna4DqHW/fffH7A8d5IACZAACZAACZAACZAACZCAGwhQQOWGWWAfSIAESMABgSFDhkifPn2kQIEC2jSwUaNGWY5q27atTJgwQUfwg5AKJoR33nmnjBkzJktZ7iABEiABEiABEiABEiABEiABtxCggMotM8F+kAAJkEAIAmvXrpUmTZpIxYoVtd+qkiVLZjkCWlZt2rQR+KCCKeGDDz4oXbp0kRw5cmQpyx0kQAIkQAIkQAIkQAIkQAIk4BYCFFC5ZSbYDxIgARIgARIgARIgARIgARIgARIgARLIUAIUUGXoxHPYJEACJEACJEACJEACJEACJEACJEACJOAWAhRQuWUm2A8SIAESIAESIAESIAESIAESIAESIAESyFACFFBl6MRz2CRAAiRAAiRAAiRAAiRAAiRAAiRAAiTgFgIUULllJtgPEiABEiABEiABEiABEiABEiABEiABEshQAhRQZejEc9gkQAIkQAIkQAIkQAIkQAIkQAIkQAIk4BYCFFC5ZSbYDxIgARIgARIgARIgARIgARIgARIgARLIUAIUUGXoxHPYJEACJEACJEACJEACJEACJEACJEACJOAWAhRQuWUm2A8SIAESIAESIAESIAESIAESIAESIAESyFACFFBl6MRz2CRAAiRAAiRAAiRAAiSQqQTWr18v1atXT8rwT58+LZs3b5YqVaokpX3TKPpw9dVXS/bs2c0ufpIACZBAUglQQJVU/GycBEiABEiABEiABEiABEggUQT+/fdfadu2raxevVp27dolOXLkSFTTnnY++OADad26tUBIVq1aNc/+RH+pWrWqFCpUSD7++GPJmzdvoptneyRAAiSQhQAFVFmQcAcJkAAJkAAJkAAJkAAJkECiCRw5ckSOHz/uqNl8+fLJ+eefL9myZXNUHoUsy5K7775bPvnkE1m1alXShENvv/22dOjQQZYtWyb16tVz3P9YF9y7d69UqlRJa1EtXLhQzjjjjFg3wfpIgARIICwCFFCFhYuFSYAESIAESIAESIAESIAE4kGgSJEicujQIcdV58mTRypUqCAPPfSQtGnTRnLlyhX02Oeee06eeeYZGTFihDz88MNBy8Yz0y0CKoxx9uzZ0qxZM+nUqZOMHDkynsNm3SRAAiQQkgAFVCERsQAJkAAJkAAJkAAJkAAJkEC8Cezbt0+gRTV+/HgZPny4bq5GjRry5ptvyllnnaW3oQUFLas9e/bI1KlTtXkaMiBk+eijj2y1gGBOV7NmTbnrrrtk8uTJuq5k/XOTgAoM+vTpI0OGDJGZM2dqjsniwnZJgARIgAIqrgESIAESIAESIAESIAESIAHXEBg0aJD0799f92fcuHHywAMP2PZt2LBh0qtXL53fvn17GTt2bJaycEoOh+hbt27Vgq2iRYtmKZPIHW4TUP3xxx9SvHhxOeecc2T79u0CzTQmEiABEkgGAQqokkGdbZIACZAACZAACZAACZAACQQk0KhRI1m0aJHO2717t5QqVSpgOeyE0/MCBQrIqVOn5Oyzz5bffvtNcubM6VMemlXQnLr33ntl4sSJPnnJ2HCbgAoM+vXrJ4MHDxYIB/v27ZsMLGyTBEiABIQCKi4CEiABEiABEiABEiABEiABVxD4559/pGDBglrgBK2eH3/8MWS/UG7//v263FdffSVXXnmlzzG33XabNl/btGmTdgruk5mEDTcKqA4cOKAFgXA8D+fpyYhumISpYJMkQAIuI0ABlcsmhN0hARIggXAI4EYekYjgJPa8884L51CWJQESIAESIAHXEVizZo3UqlVL9wuOzydMmBC0j9CcggYVNKmQYMaHa6JJ0Ki68MILpWrVqrJ69WqzO6mfbhRQAcidd94pM2bMkDlz5shNN92UVEZsnARIIDMJUECVmfPOUZMACaQBgc2bN0vjxo2lUKFCOsz2JZdcIh9++KE2cUiD4XEIJEACJEACGUjghRdekCeffFKPPJT/KRRCFLqmTZvq8tC8+vnnnyV37tx6G//eeustHeUPPq2ef/55z/5kfnGrgOq1116T7t27S6tWreSDDz5IJiK2TQIkkKEEKKDK0InnsEmABFKbAN4IV65cWb8xhkNTRDnauXOnvqkfOHBgag+OvScBEiABEshYAjfccIN89tlnevzff/+94OVLsHTzzTfL3LlzdZFnnnlGBgwY4FO8bt26snLlSsdaQQcPHpTFixdLrly55Prrr9cvgXwq/L8NRBM8evSobX6gY8y+WAuoYLqIKIVXXHGF1KlTxzQjhw4dkmXLlmlzveuuu047QfdkBviCeqpUqaI1zmDyx0QCJEACiSZAAVWiibM9EiABEogBgaeeekq/CR46dKjg5rx8+fK61o4dO8qYMWNi0AKrIAESIAESIIHEEvjf//6nhSgw2ytWrJjs27cvaAeg5dO6dWtdBk7QJ0+eLNmzZ/cc89dff8lZZ52lt3/99deQwqQlS5YI/FVBSLNt2zZ97IoVK6RkyZKeOs2XW265RQu9FixYIHDqHk6KlYAKgjeMP3/+/Np/1Pz587WPrXnz5gn63bZtW/0yC31bvny5PPLII/LGG2/YdvW///7T/r9Onjwpu3btktKlS9uWZQYJkAAJxIWAkv4zkQAJkAAJpBABdeNunXvuuVa2bNks5RTWUjeUVpcuXSz11tlSbz9TaCTsKgmQAAmQAAn8fwLKp6KlHnj0n4q49/8z/L7hujd69GgrT548uqwyd7f+/vtvv1KWpSIA6vwyZcpkyfPfoRyDW8qXozV27FidpV746GPVCyH/otaOHTt0HvqqIgRmyQ+1A23gWKXdFKqobb4SOFn58uWzlMDJOn36tC6nzCN1vbVr19ZszFhwf4D2lONz688//7StExlKA0uXnTZtWtByzCQBEiCBeBCgBpU6WzORAAmQQCoReOedd+TBBx/Ub0U3btyYSl1nX0mABEiABEjAloC3/6mHHnpImjdv7imLoCAwv/v6669l+vTp8sMPP0jZsmUFx3iX8xygviCICEze8AeNomDp/vvvl+PHj2sn4SgHJ+HQRArkj2nUqFGiXgzp6uDz6oILLghWdZa8aDWooBkGzekHHnhAoFFtkhkvtuEGwNwjqJdaAtcAV111lXz55ZemeMBPsARfaGj37NkzYBnuJAESIIF4EaCAKl5kWS8JkAAJxImAMSvo1auXvPzyy3FqhdWSAAmQAAmQQGIJwOcT/D8hlShRQnLmzOnTAfiFKleunI7SV6lSJe0c3b+M9wFTp06Vli1bSrNmzWTmzJneWT7fjxw5IhdddJHAxO/aa6/VwhxE/oPJ4aBBg6Rv374+5Vu0aCFKw0gLiZQ2lU+ek41oBVSvv/66FswprS9RWmSeJjFGmCgiKc0uHZUP3+FIHj6qOnToIMWLF8cu2wRXAUrzSrp27Spwms5EAiRAAokkQAFVImmzLRIgARKIkgD8QigTBFGmDPpmGzfdTCRAAiRAAiSQ6gS8/U8VKFBAIDRSJmlRDWv48OHSo0cP7Yvpvffes61rzpw5uty3336ry8CXY6dOnfT3QL6YoDF1+PBh6dy5s4wcOdK2XruMaAVUeFFVq1atLIKzPn36yJAhQyRv3rzagfsZZ5xh1wXb/aaOdu3aybvvvmtbjhkkQAIkEA8CFFDFgyrrJAESIIE4EYDaPdTvlf8pceLwNU7dYLUkQAIkQAIkEFMC3uZpEMB8+umnUdffu3dveemll0JqA8E5+B9//KGdjaPRevXqaZPA6tWry+eff+7TD2hMIVoeEjS04Jw93BStgAqmiHCMjnsB7wTtr7Vr14ryySVwmB5JAi9wg4P1YEK9SOrmMSRAAiQQigAFVKEIMZ8ESIAEXESgffv2Mm7cuIjNClw0FHaFBEiABEiABDwEnn/+eY8/pVj5P+rXr58MHjxY+4t68803PW0F+/LTTz9pMzjl/FeGDRsmjz32mE9x1INoeEiHDh2SwoUL++Q72YhWQBWoDQjYzjnnHIGvLmhRPfHEE4GKhdwHk8b+/fsLfHLB5yUTCZAACSSSAAVUiaTNtkiABEggSgKlSpWSPXv2yH333Sfjx4+PsjYeTgIkQAIkQALuIODtf+qLL76QKlWqRN0x+FDq3r273H333fLhhx86qu+tt94SOGiHdtKPP/4oxYoV8zkOGlPw73T55ZfL9u3bffKcbsRDQLVo0SJp1KiR7sKGDRukatWqTrvjUw6CLfi3hJAKQkMmEiABEkgkAQqoEkmbbZEACZBAFAQgmIKACgkOUh999NEoauOhJEACJEACJOAOAvA/VbBgQfnzzz8F/qcQcS579uxRd27y5Mk6Ch8ENwsWLHBUH5yqw3SvTJkyYnxSmQOhVQX/U7/88ktYWlnmePMZDwEVBErQfoLpH/j5++/6/vvv5dJLLzVdsP2EI3X0D7614GOLiQRIgAQSSYACqkTSZlskQAIkEAUB+IKAyj0SfEzUqFEjitp4KAmQAAmQAAm4g8DKlSulbt26ujOx8j+FypYuXSoNGzbU2kTQKnKSKlSoINu2bZPbb79dZsyY4XMI9iMfCVH84BMykhQPAVXNmjVl3bp10qRJE5k7d65Pt5YtWyZt2rSRffv2+ewPtIExwd/lJ598IrfeemugItxHAiRAAnEjQAFV3NCyYhIgARKILQEIpyCkwlvl33//Xc4666zYNsDaSIAESIAESCAJBAYOHChPP/20bjlW/qdQmXFoXqRIETl48KCjkUHLCJH7Apm4GZNBmP/B/9T555/vqE7/QtEIqNAuTPCQwArJW3D21FNPyXPPPaf3m38Q+sFXlhOfUjAN3Lhxo0RjJmja5ScJkAAJhEuAAqpwibE8CZAACSSJQOnSpeWHH36QcuXKyddff52kXsS2Wdxo//XXX1KyZMnYVuywNphNQtAXiZNbh02ELIZojKdOnZISJUqELOtdAGsBD1HeCRGc3CC4TOa8nj59WjZv3hwT/zXebFPle6TrKVXGl+h+rl+/XhDJLdHJDesYv6Orr746pKkdzN4WL17sg6ho0aLaR5PPziAb8De1adMmXQLCkcqVKwcp7TwLDsNhOohz7O7duz1m8sFqqF+/vixfvlx69Oghr7zyiqcoBFzQXIZfKkTxg1Ao0hSNgOrhhx/W5ndoG+uzWrVq2mcWfGchPfvssx5hH7bhLwsR+Xbu3Kmdv2OfXQInmFgiquHhw4flvPPOsyuaFvvj8fvmOTgtlgYHkUwC6qLCRAIkQAIk4HIC+/fvt9S1Qv8pZ68u762z7qmQ4pZ6cLDGjh3r7IA4lFI+RqybbropDjU7r1KFUrfOPPNMa+bMmc4PUiXVG3LPmjBrQ/lLCauOeBRO9rxOmjRJc1EPHvEYnuvrjHQ9uX5gCe6gEmxY99xzj6WE59a///6b4NYtyw3rWAmNrBtuuME6efJk0PGDjzkHmc927doFPQaZn332maV8PVnKibnP8S+++KKlzMsspf0Usg4nBZTzdV3/hAkTnBS3lJaULn/ZZZd5xq78N1nq5ZCnn0pI5Kguu0K47oGVMr2zK2K7v0GDBvrYSy65xDpx4oSlnKNbyu+UpbSq9H4lULWUoEkfj3WEvA8++MC2Pu8M9Af9UuaW3rvT7ns8f988B6fdcuGAEkxAEtwemyMBEiABEoiAgHL0qm8aceOIm/dUTxAeKE0fS/n4SOpQLrroIku9LU9qH9C4CmNu5cyZ01J+Qxz3xQiolK8Qa/78+fpPhRm3PR435EpjzFJaVyH/lHaWpZwV29Zll+GGeY3mwc9uXKm2P5L1lCpjTMQ6VtpLVosWLaxcuXJZyRJ0umEd43xxzjnn6HOkcmIedIkov4ie8xCuU6EEVEqbyVJmclbu3LktpbGjX1bghQX+cG1QpuyW8pkUtE2nmbhmok8dO3Z0dIjSHrIGDx5snXHGGZYy4bOUyZuVJ08eS5nJea7DSivJUV12haKZ33nz5lnnnnuuVahQIatSpUqal9LI0k298MIL+oUH8iDAUuaKFq4RTpNysq7HOHr0aKeHhCynHLZbWB+zZs2ylJaXZqt8YQU8Ll1+3+l8Dg44cdxJAjEkQAFVDGGyKhIgARKIFwG8rcUNNv7CEWLEqz/R1HvgwAELgiHcPB87diyaqqI+1i0CKjz8KfM8/aD2zTffOBqXEVAdP37cUflRo0Z51pBZS6E+VbQq/VCnQqmHbMMt8xrNg1/IQaZIgUjWU4oMzYr3OgYHZSKlfysjRoxIGha3rGNog0CQpKK5OWYB4UgoAZXjymJQEBrIKqKdpczkLQgfnSZlqmwtWbJEayipqH2WEd5AI0n5gXRaTcBysZhfaJjhfuDnn3/2aUOZIlpz5syxnJy3fQ5UG7gOQTB75MgR/6yIt2vXrp3l2qOc4gesL11+3+l8Dg44cdxJAjEkQAFVDGGyKhIgARKIF4GKFSt6bvDs3jzGq+1Y14u30HgbrfybxLrqsOtzi4AKHce84q04zGrwBj9UCldABZMPPLDgwQDtGOEU3rxjv/Jrpv++/PJL/UCG+osXL67LwQRRRcMK2iW3zGssHvyCDjRFMsNdTykyLG26FM91/Pnnn2vtnZYtWyYViZvWce/evfV5wKkZstsEVJjIpk2b6jFAi8cuQXtHBSKxBgwYYPlrjP39999WqVKldB1du3a1q8LxfjfNr+k0tAVxXWjWrJnZFZNPCNCUXzGrXr16un5c/5XvyYB1x/s6lcjfd7qegwNOHHeSQAwJUEAVQ5isigRIgATiQQBvavH2FzeOMLdI5QS/IhhHly5dXDEMNwmoAMS8oYcZRKgUroDK1IcHL5jQYB4ggAqW8GABExGUzZs3r6Wc7AYs7qZ5deODX0BoCdgZznpKQHdi2kQ81jEEwxAQw7Trp59+iml/w63MTesYPqhw7YEGkhPTXzcKqFavXq01wSAksUvDhw/X5zqc795//32fYsYvFc6d8EcVbXLT/JqxwL8lxj5jxgyzK6af8GuF+p2Y1afL7zudz8ExXRysjAS8CFBA5QWDX0mABEjAjQRUdCTPTXOqOy5VkY/0Q4IbnHljrt0moIJZBQRBKnKSFcp0L1IBFR7U8JCAv/vuuy/kkodPE1Pezv+Zm+bVjQ9+ISHHqUA46ylOXYhbtfFYx9OmTdNr/d57741bv51W7LZ13LdvX80GD9yhkhsFVOgzfFrhXLZhw4aAQzD5MHHzFkJt3bpVC+hg6hit7ynTsNvmF/7G4AfRifDIjCGcT2hGwd8Y+MOENlRKl993Op+DQ80h80kgUgIUUEVKjseRAAmQQIIIPP/88/qmDjd2jz76aIJajX0zMOnDGGJtPhBNT90moMJYHnnkEc0plJPaSAVU3gKncePGhcQHE0DMG/7uvPPOLOXdNq9ue/DLAizBO5yupwR3K+rmYr2O0aFbb71Vr/NNmzZF3b9oK3DbOoZGGQQ3OGeGimroVgEVfDNBEwwm84E0wYYMGaLnH0EiTNqyZYt2lA7hzauvvmp2R/3ppvnFfEIwBQFSrCIn+gPyftG2fPly/+ws2+n0+07Xc3CWSeMOEogRAQqoYgSS1ZAACZBAvAjcfPPNHgGBE4FCvPoRbb29evXS41i4cGG0VcXseDcKqPC2HsKgatWqBR1npAIqhI03AidE9AuV+vXr5yl/xx13ZCnutnl104NfFlhJ2OF0PSWha1E1Get1DE0HCGDgJNoNyY3rGL9/nDvggDtYcquACn1esGCBNpnv0KFDliEg2hyEVzBrxssgvEyBeT32wYdSLJOb5tdox8H/VrzSU089pdcO/Bna+Z/ybjudft/peg72ni9+J4FYEqCAKpY0WRcJkAAJxIEAwlwbgcIXX3wRhxbiXyV8u0AYBN8uUPV3S3KjgApRpvCAhzkPFtEvEgFVOH49zBzBJ49Zf/4mfm6cVzc9+BmGyfx0up6S2cdw2471Okb7Y8aM0eu8f//+4XYnLuXduI6Nj6ZWrVoFHbObBVTo+BtvvKHnOpBABo7SYV4Gbarx48drv3vhRP4LCsYr08zvunXrvPYm/uvs2bO12T1eRMQz1alTRzNv2LBhyGbS7fedjufgkJPIAiQQBQEKqKKAx0NJgARIIN4Edu/e7REOwMTAyZvHWPfp2LFj2mEwTDxC/R04cCBL9CP0x6j3h9IKCtR3mB8sW7bMguNw3EzH8mEhlgKqo0ePWpMnT9ZRoKCNYRL6iwce9B9v4Z3030ScwkOzXYpEQLVq1SrPenLiZ8dEdYKACpH/fv31V5/uRDOveAhBCHc8BCKcu39C3Xv37vXfHXLbPPhhzUSTsJYnTpxoTZkyJWjIdcyn93xH06b3sYleT95tu/17rNcxxmseoENpB/mzyaR1jPMXzgUXXnihPwafbbcLqNDZd955xypRooRPvxO5ATM3cHSixRrPfpUrV87yf/EQTXuBrtd4KQXtRKwdXLdCJTf9vrHmR40aZa1YscKn2wgggus9/NZB8y5UcnJND1UH80kgUwhQQJUpM81xkgAJpCQBPBwb7RU4ok5kgu8hCHBM+04/AzneNiYE3bp1C2sIEEjhIQJmAU2aNNHfYW4BHzGNGze2OnbsGFZ9/oVjIaDCA2q7du2ss88+W5uElC1b1kIYbQiXEP0K/SxSpIjVokULzbJo0aLW9u3b/bvis218ocBpr12KREDl7c8M8xssQRhaoUIF3WdErgr0pj/Sef3uu+90RDCzpgoWLOjjuHjp0qVa2w7+rcJNsRBQQTiG+YRfFjisxxqEE+FAyZjgwnQoFilZ6ykWfU9UHbFex/BHBAfY+AtH2Jhp6xjCh3z58ulzQjDBSioIqBK1VjOpHbvrNQT95lzvL+gJxMcNv2/0E1Fucd91yy23aAfyeMGGlzSIcojrAyJC4g9jg5+pYMnJNT3Y8cwjgUwiQAFVJs02x0oCJJByBHr27Om5sWvdunXC+j9gwABPu7j5gh8OfOIBDt/Ntskz+xCBDuG4/ROEVig7adIk/yzbbTgJR73ly5f3RFTCA9KNN97o6VuBAgVsj3eSEa2ACv2BY2UIzX788Ufd5O+//64d8cKcETevV111lX7oxRtzwy2UOYXRTAomlIxEQHX99dd72HlHqfJnhYdPCGcwZxBOzZ0717+I3o5kXv/44w/r4osv9vQDbeAPQqr58+frKFkXXHBBxAEBohVQQWsLQinUgwQhKPoHHyr+CQ6FTf9jEd0rmevJf2xu3o71OjaaqmXKlHE87Exdx0bTDJojdokCKjsy6bvfyfUaL5r+/vvvkBCS/fvGtRqCWJiCGo1n47S9du3a+gWUuT4YX1m4tgdyvG8G6+SabsrykwQynQAFVJm+Ajh+EsgwAjfddJN+OMYDciz+IHw4ceJE3CiahwE8BL/88stxa8e74nnz5mlBFAQU0JrBQzN8DeGhfdasWZ6icI591113ebaDfbnuuuv0gzxu0pwkjBVjhlnZvn37fA7xFgrg5jCaFK2ACqr/0IhCdCjvZMaLMcycOVNnvf766x5hBt7ABktfffWVLoubZLsUroAKDwYQNqFP+Fy0aJHP39SpU61XXnlFvy2GOQZMSiGcgambXTLjdDqvqOell17S6wtzDG0VzCceBFAXNM/Qvxo1ajh6kAnUr2gFVNCGu/322z1VQ3MPfQrkd2fkyJE6D/kw+Yg2JXM9Rdv3RB0fj3W8cuVKPY843zpNmbqOEckT633o0KG2qCigskWTlhlOr9c4x4dKyf59Q8iEe0N/U0RzjsDar1y5smcYWOvYh3vBYMnJNT3Y8cwjgUwiQAFVJs02x0oCJGA988wzFm6wY/XXtm1bbcYVD7QQChlzCtwAJSL63fHjx7U5WvPmzT1vDjE23JzhDSH8UZkEIcKgQYPMZtBPaEFhDE7Ct0ObAeGuUT6QDyb4s4AmF/IHDhwYtN1QmdEIqOBMFw7shw0blqUZaFShfzCRM29gYe73+OOPaw0hzG2wBF9fOB5/dv4twhVQed9gwzyhdOnSWf4QwQxCKQiMvv3222Bd1HnhzKupDP2eMGGC2fR8QhDasmVL67LLLrMOHz7s2R/ul2gEVDDfwNqDzzAkCNCM75RAax0CWswROESbkr2eou1/oo6Pxzo2ptSI2uY0Zeo6RvQ7rPmuXbvaoqKAyhZN2mWEc72G6V6olOzfNzTACxcunEUb6pNPPvFck721ZT/99FOtXWs0qO3G5+Sabncs95NAphHIhgGrCw0TCZAACZCAywioCG6iHJh6eqUe2kUJRDzb8fiihGCi3oaKuhkTZa7naUL5jpK1a9eKcpqt96m3nJI/f35RTkJFaZt4ytl9UeZbooRf8sMPP4h6O2lXTO9XwjGZPn26KDMv2b9/vyhNHp/ySltHlAmA3qdU8aVu3bo++eFsFCtWTJRZjyifR+EcpsuqiIqizA31mJTAx3O8EkQJxquEUKLMAkSZ83nynH5R/p9EmUPo4sr3kZQsWTLLoUo4J08//bTmirkIldTDgSgzNV0Mc6w04EIdEjI/nHkNVhlYKc0lUYIhwZwq3x/BigfNU761RD1Ei3KSLsrEMmhZ/0zlIFt69OghSjins5SAVDp16qS/K7NHUUI9n0OwRvG77Ny5syhtKp+8cDeSvZ7C7W+yysdjHavodHre1QsHUZHdIh5aJqzjPn36iPKno3+v7777bkBWSvNVlLBP7PLxWzK/sYAVcKfrCOAaU6tWrSz9Cud6rZyfB6zDu9Jk/76VvyndR+Vf0btbYtY97otUAAtRJvw++aE2nFzTQ9XBfBLIFAIUUGXKTHOcJEACKUfgww8/lHvuuUf3W5mRiXoDl5QxKA0ggSBH+RsSFe1H92HDhg1SvXp1wUN1lSpVgvZLqcyLMinTZZQ2kJxzzjm25VGfckSq8x999FFRZnFZykLIgptYZQ4mSqNLlMZLljJOd0QjoML7HeVvSgvqvNuDkE85Rte7INRTmmbe2Y6/gxnY2Qn1whVQQagH4R6Sk3kL1dFw5jVYXbhxv/vuu0WZ+un+RSOcQjvRCKggYFC+hTxzCgGXcpar1/rnn3/uMwz0V/kI0/uUeaQobSqf/HA3kr2e7Pqrop0JfotKw82uiOP9WNPK8X1IIXWwCmO9jtFW7969RZnsidIKEqVBEax527xMWcfgBF7BhHmhBFQQXKmoprYsmeE+ApdeeqkoZ+c+HQvneo3fPq7XoQQ7yf5940UahHFKS9tnrEq7WL+kw7Vd+Ur0yXO6Eeqa7rQeliOBtCcADSomEiABEiAB9xGAjyd1EdJ/8IOTrASfVOiHd5SycePG6X1KeBKyW/ApYcYRynTr1Vdf9ZSFw+xACU5KUZ8SHgTKDmtfNCZ+dg2ZyHYwo4PZVqQJTtYxTjjtDpTCMfHDHMBBLeqDY3mY00WbwplXu7ZgMop5VMLOqMz6vOuPxsTPux6lvecxJQ1kxjlixAjPWj106JD3oTH9nqj1ZNdp+KGD6SXMfqP9Q1RKmFFGmuKxjtEXw7hLly4RdS2T1rFxFn3//ffbsqKJny2atMoI53rtxF+kW3/fMM8312NE44s0mTrsrumR1svjSCDdCNAHVbrNKMdDAiSQNgQaNmzoeQDGA1SyEvx14cYKN2kmwfdTMOGJKWc+EaEN5Xfu3Gl2BfzEAyzKwUE3fE35J+wzPoHgTyzaFA8BFfw4YQw333xzxN1DhDDUAV9buGkPlMIRUHn79UDI7Fglp/MaqD0IgOCjC/3BeGOVYiWggv8zMwf+jvrRVwhrkH/55ZfHqusB60nUegrYuMt2xmsdKxM/PZdKky/sEWfaOoYfPaz7/v3727KigMoWTVplhHO9hmAzVHLj7xt9hv9PrHn8Ke3xUMMImO/kmh7wQO4kgQwkQAFVBk46h0wCmUwAjr2h2RKrPwg4lD+CuCBVpnCemyJEWEtGQmQyCKegteSdoGmAmzVlruO92/Y7HF+j/Jo1a2zLIOPKK6/U5SpVqhSw3GeffeZhokyvdBlEUQwkQAhYgd/OWAuocBNq3pIispF/gsNzJxokeOgFLzhrtUvhCKhMWdQZLPqWXVt2+53Oq//xcMCu/GpZCDIQSMsMjCLV8oqVgKpFixZ6DpSPMv/ua8f3cJAPnpFq3WSpNMCORK6nAM27ble81rEyp9Zz2ahRo7DGnInruH379poVIljaJQqo7Mik1/5wrtcm8ESw67Xbft9mtpQfSb3mlelfwOvSd999Z4rafjq5ptsezAwSyDACFFBl2IRzuCSQ6QTwphxRiGL199hjjwXU9ImWMyLC4OHX/EUqgIm2H8oJt+6D8vvkU5VyjK73jx8/3me/3YZyZK7Lz549266I3l+iRAldTvneCljuySef1PnKUan1v//9T5eBdlmwiFIBK/q/nbEWUMEs0cyZ8lmUpen69etbEKCESiYkNaIB2iVzM4/Ii6GStzae8hsSqrjjfKfz6l0htOiKFCliPfLII54Ih975MJdSPtesLVu2eO92/D1WAirz8IW17p/M/GCup02b5p8ds+1ErqeYdTqOFcVrHS9ZskT/bqtWreq495m6jqFRi3WPqGZ2iQIqOzLptT/W12s3/b69ZwovNrHmA7laUAFWLOXL0rt4wO/mmhHsmh7wQO4kgQwkQAFVBk46h0wCJOB+AhDkGEGHk5ufeIxIOcG2jJYIbsK8k3Jkqvv30EMPee+2/a4cSOvyo0ePti2DDCPweOCBB7KUg0CqbNmyuh7cyJqknLdaypGz2QzrMxoB1ccff2zBJEg5Qve0acy+cuTI4RGgmUyYBsB0UUWwMrtsPxG6GvMfzEzQqYDK36+HcgRu2264GU7n1dT7yy+/WKVKlbLwkBtIcwp9g1YVNMeMANIc6/QzVgKqSy65RM9BIFMmYxIGE0w7v2qbNm2y4KfKqXA52evJKd9klYvnOt6+fbueawhOnaRMWsf+PFRQDM0qmKkTBVT+1NJz2+n1GvcLJtldr93w+4bGeM+ePfWf6a8RLOF67P+iDmVwjQ7mj83U4+SabsrykwQynQAFVJm+Ajh+EiABVxIYPHiwfgjATRGEAMlIKsqS7gOcavsLC2677TadBx9CTpJxrKsiAQYtbjSkoL3inWDu1apVKw+T7t2762wIASD0cWI2512f+R6pgEpFVNTtYn5uuukmXZ231puKLOjDDMI+FZ3Qevjhh03TQT+N02ZoGdklpwKqmTNnerg1bdrUrrqI9judV1SuopxZKky5py8ws4WmHLTwYCoKn0/GAb6KxBdRf3BQrARUcN6O+e3Ro4dPXw4cOGAZzQEVxc8nz2xASw3H4q906dIBNcVMWXy6YT1598eN3+O5jnF+UxG29Hzt3r076PAzaR37g4DJKc63EMxCSGeXMl1ABUHHnj177PBEtB/Xuli+XIioE34HOb1em3NosOu1G37fxnUBztvr16/Xo+3YsaPnXP7ss8/6EID2LM4buPaHSk6u6aHqYD4JZAoBCqgyZaY5ThIggZQigAd384CLSDnJSOXLl9d9CCRUwg0n+ocHFTxch0qrVq3S5fGwHizhxh6+t1Av3lwiIUIaBGLlypWzOnfurOsxbyybNWtm3XHHHcGqDJoXqYBq+fLluh9gAF8sEEDB2Tf6c9111+m8jz76SLd98OBB68Ybb7RgJuDEHA8HwRQQdcP0yC4FE1Dh4Qg3/BD0GD9RqA9CsilTplhz5871EaDZtRFqv9N5RT240T/vvPMsmK3B4X67du08DNE384e1f/r06VBN2+bHSkD12muv6T6BnwkQ8P333+t1aPpqJ3B87733PONB2VA+StywnmyBJjEjUesYQzRaoRMmTAg64kxax/4gli1bptc1NGeCpUwWUOGciOAROA/FMkFzDZHwzLkolnVHWle012u3/b4bNGig1ze0Z+Era9GiRRb8TsGfJM7jiDZrgrdMmjRJ533wwQeO8Dm5pjuqiIVIIAMIUECVAZPMIZIACaQeAeP/BjdFCPOe6ATzK2hOweE3Hp79E0z+IETKly+fIyfxUN/HjR7GE0qgBd9NEGTBzxR8wuANJQRU0JKCf6KaNWvqemAGBkfbdiZW/n0OtB2pgAoaF8acD1pBELxA+AMn6BBGGDMYRHjDwxocbuOG10kCe4wZfQv2xjyYgArCH5gZgiEelswf5gBREJEHB8/RJqfzunHjRitPnjyWcZSLdo05H9YE/rDeYF4RbMxO+hsrARX6AU1G/AZg6oq1iDFAEGn6bISQ/v3CWkV5/D4wrmD+enCsG9aT/xjcsJ2odYyxvvjii3peIYCyS5m2jv05DBo0SDMKZartRgEVfpMwr3byh5cikQjJoXWDc3cgv3X+LMPdhjAHL28g6PDXaA63rliWj+Z67bbf97x586xzzz1XX7MRqAVzabR5oS185pln6jwIsGCqOH36dEconV7THVXGQiSQAQQooMqASeYQSYAEUosAHvpNJDg8EGM7GQlOqr/55hvbpnEzDnMnp6lTp0764QbaJaESTPoQcnrOnDlZTCXw4IC31NAuCuTHKFTd3vmRCqhMHb///rsOQQ0W3oIV9BERC422kCnv5NOEtIawJlgKJqAKdlys85zMKx4OAzmNR1/gbBoCz1g9dMVKQGU44WEVaw1v02HWZB7SIezD/IdKjRs3duxIPZnrKdQ40j0fUbYguA1mkpnJ6xjzf+2112oB95EjR4IuBzcKqC644AKPYNkImIN94tqLlw4QUDi5BuNaiOsJhBd4kRKPBD9GeDEETWI3pURdr6MZs5Pft6l/x44dWssYGmLeCdrQuCeBz7pwktNrejh1siwJpDMBCqjSeXY5NhIggZQk8OWXX3pupPFAkC4J2gd4IKhcubJrhhStgCoeA4FPK3CCv45gyS0CKrfNa7QCKgg9IUQdMGBAFqEZHlTh5B3z4zRyJMrjN52s5HQ9Jat/bmoXPtowt7NmzUp6t9y2jiGEBxuYMYdKbhRQwU8QfN3BfyHGgT+YXeP89fXXX+s/CCYQ9OLDDz/UWlCmHMYcSoAOzUoItdBGPFPv3r1132HCzRQegWT9vnkODm+eWJoEKKDiGiABEiABlxF4//33PTfQvXr1clnvoutOo0aN9NigMeOG5DYBFR6Q8Ib86quvDonHLQIqdNRN8xrtg72J0IeHU/wWvZPxSwXTD/ijCpXwph0PrfBRlowUznpKRv/c1iZMUPH7q6cc5Cc7uWkdgwUiluI3MWPGjJBo3CigMp02gR0wlnHjxpndAT+HDh3quRa3b98+YBnshAkv6oOT7Xgn+KCCqR80/ZJ1Xon3GONVfzJ+3zwHx2s2WW86E6CAKp1nl2MjARJISQLmDSlueJ36OEiVgeJNNcwX8bbZDcltAqoOHTo4FuC5SUDlpnmN9sG+TZs2eg7gq8tbCLV161aPA38731P+a/ree++1MKfJSuGsp2T10W3tmvnfsGFDUrvmpnUM/0eI3gf/R06SmwVUcDSOayv+QkVsNL6DUBZRR+1MyhHNE4LNWPj1c8LXRISDuTFTeAQS/fvmOTi8+WFpEgABCqi4DkiABEjAZQSMOjhuisPx8eSyYdh2p0+fPvrhYPLkybZlEpXhJgEV/FRkz57dwg20k+QmARX665Z5jfbBfsiQIXp9/vDDD55pgD82OErHQ7rTqJoQYsGpbqgIfp5GYvwl3PUU4+ZTtjr4mYGGSsWKFZOqoeKWdQz/QhBM5c6d24I2iJPkVgEVzPSg/Yhra/HixZ0MxSpWrJguj2NMZFnvA2HShzwnpo/ex0XzHYFGIEDH9Qvzw+ScQCJ/3zwHO58XliQBbwIUUHnT4HcSIAEScAEB3DjjhhcR6tIx4S00wjkjwhkcZCczuUVABQeuEIAgeqMTx9tg5jYBlVvmNdoHe0RihHACUZoeffRR/eAJ59nYB381ThOiQb377rtOi8e0XCTrKaYdSPHKFixYoB2mJ1P7zS3r2GjrOAluYabdrQIqmHjh2oo/Jy8C/vjjDy2UNsdAi9I/wQwf+RBGJDLdcccdul047WYKj0Aift88B4c3JyxNAt4EKKDypsHvJEACJJBkAkePHvXcQLdq1SrJvYlf84iGVq5cubAEMvHoDQRUN954YzyqdlwnBDu1atXSb+pDmZx4V2oEVPCNAt8n+EPEuWQmN8yrebBft25dxCgwJ3iYhTbV+PHjtSA13LDz/hGgIu5MmAdGup7CbCbti7/xxhv6XByOYCaWUNywjmfPnq1N1/r16xd0aIhgas5B+IS2Vbt27YIek4zM559/3nN9DeV/Cv1D1DwjnCpYsKD1119/+XQb48Y1BGbrp06d8smL94bxlZfO9wnxZBjP3zfPwfGcOdadCQQooMqEWeYYSYAEUobAsmXLPDfEI0eOTJl+R9JRCDPq1q1rwfF0shLMKZ1GY4tXHydMmKCdonublDlpC6ZmcMDt/ZcsczLv/iZ7XpcvX25deOGF1q5du7y7lTHfI11PGQMojIG+8847VokSJcI4InZF3bCO8RLhxRdfDDkoCGoKFCjgcy5K9nk1UKevv/56z/XV279coLLY521u/8wzz2QptnjxYl1ftWrVsuQF2gGT/YkTJ1pTpkyxjhw5EqiI3gdheLB8FDLRU3GuY4qMQLx+3zwHRzYfPIoEDIFs+KLeDjCRAAmQAAm4gMCwYcNEmQzonijH06IeEIL26tdff5VRo0aJulkVJaiQxx57TKpXr+5zDE7z6m2hzJ07V55++mm59tprffK5QQIkQAIkQALpTED5nxLlW0yUppMov1Kyb9++oMP94IMPpHXr1rrMXXfdJcpnoigfgT7HKM0yGTx4sHTr1k2URpNPnv/GkiVL5LbbbpMqVarItm3bRPnCkhUrVogy5fcvKiqIiCjTPVGmaKIipGbJxw4lFBSl1SUqqp8oYbyoqH4By3EnCZAACaQaAQqoUm3G2F8SIIG0JtCyZUuZOnWqqLeiot62Bh2r8ochDRs2FOXLSZTTVFHOUvVNKm5WvdPatWtFaSrpfBVVTNQbXO9sficBEiABEiCBtCagTHaldu3aeozBroNKe0mUeaV0795dlEmfNG7cWGbNmiXKKXkWPm3bthWlLSOTJk2Se+65J0u+2fHjTOpdwQAAQABJREFUjz9qwRSEWcokWx566CF566235KmnnhJlqm2K6U+8mLr88sv1dxVoQe68806ffO8NXNdXrlwp06ZNk+bNm3tn8TsJkAAJpCwBCqhSdurYcRIggXQkgLegytRL3+zipjdYwg2uMgOQ3r17i/KnIR07dtTFVahrKVOmjM+hytmzjBgxQr/lxdteJhIgARIgARLIFAIvvPCCPPnkk3q4EBB5C3SUzyBR0d0EwqHp06fra3DZsmUFx3iX82elTAZFmfnpP7wsskv333+/HD9+XGbMmKGLKNNBmTdvnij/UQJNLe8EjWjlx0vvUn7s5IILLvDO9vmOvqG/Q4cOlZ49e/rkcYMESIAEUpUABVSpOnPsNwmQQNoRgLmeiuSmx/X222/Lgw8+6HiMJ06c0Or+MOeDaQBugE2CBtWtt94qTZs21W+G/c0UTDl+kgAJkAAJkEA6EjDCJIxN+RWTnDlz+gwTGlIwqa9QoYJUqlRJXy/9y/gcoDag6QSh1qZNm/Qx/vnYxksk5UhdYOIH83oVJVRrSMPkcNCgQaKiJPoc1qJFC60RVb58edmxY4dPnv8GXkpB20v5+xLly9E/m9skQAIkkJIEKKBKyWljp0mABNKRwPz586VJkyZ6aHv27AnomyLYuHHTDb8ab775pn4DC18bMB8YM2aMfsMajsArWDvMIwESIAESIIFUIeDtf0o5c9dCoxw5ckTdffiAgmYUtJ4vvvjigPXhhVGPHj0Ems1IuB536tRJfw/kOwoaU4cPH5bOnTuLCpSiy9n969Onj6hIo6IiJsq7775rV4z7SYAESCClCFBAlVLTxc6SAAmkMwE4MB84cKCoiECyfv36sIdav359UZGftKP0mjVrapX/ihUratO+4sWLh10fDyABEiABEiCBVCewatUqqVOnjh4GHJB/+umnUQ/pzz//1I7OURG0ouCAPVCCM/M//vhD8ufPr7Pr1aunnaMjmMnnn3/ucwg0pq644gq9D74o4Zw9WHrppZe0iT98Yb333nvBijKPBEiABFKGAAVUKTNV7CgJkEC6E6hVq5asWbNGEMkP0fjCTXiLOn78eB1pCKYKr7zyinbwGm49LE8CJEACJEAC6ULg+eef1w7JMZ5Y+WuCVlbu3Lk1Img8GfP8YMwQzAQvi2CKH+g6D+3nRx55RFdx6NAhKVy4cLDqtIlg//79BT6u3nnnnaBlmUkCJEACqUKAAqpUmSn2kwRIIK0J4Aa3aNGigghCiPiDMNjhJJj2IQIg/E1ddtllOox1KP8Z4dTPsiRAAiRAAiSQigS8/U998cUXOqJeLMYBraljx47Jzp079XU3VJ0IbAIH7dmyZQt4nYfGFCL3wbfV9u3bQ1UnTzzxhLz88ssCIRWEcEwkQAIkkA4EKKBKh1nkGEiABFKKAN6ewm8F/FeYZN6cwgxhxYoVZnfIT5gZQM1/+PDh+gYZJgN4kwuBFxMJkAAJkAAJZDIBaDrhWotrJfxPwRwvVoFCoKn8zTffaM1nmNWHSniJBNM9RNk1PqnMMbgvgP+pX375RfuQxD1BqNShQwdBQBX4qoLPKiYSIAESSAcCFFClwyxyDCRAAilDADehlStXli1btmihUrdu3bS6f5UqVWTz5s3yySef6Ih7TgY0ZcoU/QYVviwgpNq7d680aNBAH3ry5EnJmzevk2pYhgRIgARIgATSksDKlSulbt26emyx8j9lQBl/UrNnz5abb77Z7Lb9RITAbdu2ye233y4zZszwKYf9yEeaNm2aNG/e3Cc/0AbKTJ8+Paz7hkD1cB8JkAAJuIkABVRumg32hQRIIO0JINpP6dKl9Tihzo+3qfAbBf9RtWvXFtxMh0r79++XBx54QBDpb/To0dKwYUN9yO7du+WSSy7R33Gza5ythqqP+SRAAiRAAiSQjgQQeAQBSJBi5X/KcGrRooUWJuE6DNO9UOnSSy8VRO4LZJL32muvSffu3bX5H/xPOfFpVbVqVdm4caNs2LBB8J2JBEiABNKBAAVU6TCLHAMJkEDKEIAGFXxEfffdd7J48WIpVKiQdmQOkwP4xrjooouCjgXH4Ka4VatW+mY7T548nvL//POPYBt+rJy+gfUczC8kQAIkQAIkkGYEoJ28adMmPSoIc6DBHKs0aNAgLWy677779IumUPWaSLs9evTQQUxM+YMHD0qNGjW0Xyq8WMILplDp1KlT2mQRUQJh0n/eeeeFOoT5JEACJJASBCigSolpYidJgATSiQDeoHbt2lUQ+hpRgKABhYh7cJIeLMERK96SVqtWTZYuXRqwaKlSpbRmFXxTwCErHK5DqIUoP0wkQAIkQAIkkO4EcM2DrylExYV/RpNefPFFgd+osmXLSvny5c3uiD9Xr16tNZ+hFY3reqj0+uuvC8z68ZIKwjKY4eM4mB7i+o708MMPy4gRI0JVJcuXLxcIvGC+iO9MJEACJJAuBCigSpeZ5DhIgATSnsCQIUOkT58++q0pTAMbNWqUZcxt27aVCRMmCCL4QUiFcnfeeaeMGTMmS1nuIAESIAESIIF0IgAzepi658qVS2sUI2KeSXCY/tdff0nr1q31ddLsj/QT9cEU78SJE/LTTz+FfMkE7Wb4i4TJIRy3lyxZUmtLIcog/FghIYofrtmh0uDBg6Vfv37azN+JeWGo+phPAiRAAm4hQAGVW2aC/SABEiCBEATWrl0rTZo0kYoVK2pzAtzc+ie8hW3Tpo2+6cVb2gcffFBHBMqRI4d/UW6TAAmQAAmQAAlEQQDR8+CD6r333hO8IHKSYJK3fft2gXkerudjx47Vwqb8+fNrQVe+fPlCVlOrVi3tFgDmgXAVwEQCJEAC6UKAAqp0mUmOgwRIgARIgARIgARIgARIIGEE4N8Kfq7g2wpme4HSv//+K5MmTdLm99B6OuOMMzzFoIUFs0NofsH0H87SQyU4RUf03mbNmsnMmTNDFWc+CZAACaQUAQqoUmq62FkSIAESIAESIAESIAESIAG3EGjcuLEsXLhQ+4aEXyj/ZCL0Yf/777+vTQxNGeOX6qyzzpKtW7d6IvGa/ECfCJIyefJkmTFjhtx+++2BinAfCZAACaQsAQqoUnbq2HESIAESIAESIAESIAESIIFkEoBp/VVXXaUj8n766adZuoIofxMnTtR+sXbs2OERQn311VdSr149OXbsmI6868T31N69e+XSSy/VztntgqVk6QB3kAAJkEAKEaCAKoUmi10lARIgARIgARIgARIgARJwF4G+ffsKogRCs6lly5Y+nYNj9N69e2szvosvvljnffnll3LDDTfI0aNH5eWXX5bu3bv7HBNoAz6r4FAd/ig3b94ck0iEgdrhPhIgARJIJgEKqJJJn22TAAmQAAmQAAmQAAmQAAmkNAH4mUJkXfiH+uKLLwRBSkyCEKphw4Zy8uRJHegEWlBz5syRChUqyLhx47T/KlM22Cf8VyF6XzgO2YPVxzwSIAEScCMBCqjcOCvsEwmQAAmQAAmQAAmQAAmQQMoQ+PXXX6VOnTqSM2dOreXkHY0PAqz169fLqlWrpEiRInLNNddI2bJlJVu2bI7GB4FW06ZNBZpaL7zwgqNjWIgESIAEUpEABVSpOGvsMwmQAAmQAAmQAAmQAAmQgKsIQEgFX1L4Q1S+WKXy5ctLu3bttKlgrOpkPSRAAiTgRgIUULlxVtgnEiABEiABEiABEiABEiABEiABEiABEsggAhRQZdBkc6gkQAIkQAIkQAIkQAIkQAIkQAIkQAIk4EYCFFC5cVbYJxIgARIgARIgARIgARIgARIgARIgARLIIAIUUGXQZHOoJEACJEACJEACJEACJEACJEACJEACJOBGAhRQuXFW2CcSIAESIAESIAESIAESIAESIAESIAESyCACFFBl0GRzqCRAAiRAAiRAAiRAAiRAAiRAAiRAAiTgRgIUULlxVtgnEiABEiABEiABEiABEiABEiABEiABEsggAhRQZdBkc6gkQAIkQAIkQAIkQAIkQAIkQAIkQAIk4EYCFFC5cVbYJxIgARIgARIgARIgARIgARIgARIgARLIIAIUUGXQZHOoJEACJEACJEACJEACJEAC6UXg0KFD8tdff0nJkiWTMrA9e/bIWWedJYULF05K+2j0119/lVOnTkmJEiWS1gc2TAIkED0BCqiiZ8gaSIAESIAESIAESIAESIAESCDhBFavXi233HKLvPzyy9K+ffuEt48Gy5YtK2XKlJE5c+YkpX00Onv2bGnRooVMnjxZmjVrlrR+sGESIIHoCFBAFR0/Hk0CJEACJEACJEACJEACJEACPgSOHDkix48f99lnt5EvXz45//zzJVu2bHZFAu7fsGGD1K9fXxo3biwzZswIWCYRO4sVK6YFVEuXLk1Ec7Zt9OzZU15//XWZNWuWNGnSxLYcM0iABNxLgAIq984Ne0YCJEACJEACJEACJEACJJCCBIoUKSIwvXOa8uTJIxUqVJCHHnpI2rRpI7ly5Qp66MGDB6VatWqC4zZu3CgFChQIWj6emW4RUP3zzz9aYLd9+3ZZv3691uyK57hZNwmQQOwJUEAVe6askQRIgARIgARIgARIgARIIIMJ7Nu3T6BFNX78eBk+fLgmUaNGDXnzzTe1vybssCxLa1nBh9PUqVPl448/1uVgovbRRx/JGWecobcD/WvatKl89tlnsnbtWqlYsWKgIgnb5xYBFQa8f/9+zePiiy/WQqrs2bMnjAMbIgESiJ4ABVTRM2QNJEACJEACJEACJEACJEACJJCFwKBBg6R///56/7hx4+SBBx7IUsbsGDZsmPTq1Utvwp/U2LFjTZbP58yZM+W2226TLl26aIGXT2YSNtwkoMLwBw8eLP369ZO33npLOnTokAQibJIESCBSAhRQRUqOx5EACZAACZAACZAACZAACZBAEAKNGjWSRYsW6RK7d++WUqVK2Zb+999/takeotGdffbZ8ttvv0nOnDmzlL/yyitlx44d8s0332jfT1kKJHiH2wRU4IZofmeeeabs2rVL8ufPn2AibI4ESCBSAhRQRUqOx5EACZAACZAACZAACZAACZCADQH4RCpYsKBA4FS8eHH58ccfbUr+/90oBzM1pK+++kogjPJOW7ZskUqVKulIddCkckNym4AKTB599FEZMWKEjB49Wvv1cgMn9oEESCA0AQqoQjNiCRIgARIgARIgARIgARIgARIIi8CaNWukVq1a+hg4Pp8wYULQ4yHIgrNzaFIhbd26VTtO9z7o8ccfl6FDh8rChQvlhhtu8M5K2nc3Cqgg3Lvqqqu0I3k4TGciARJIDQIUUKXGPLGXJEACJEACJEACJEACJEACKUTghRdekCeffFL3OJT/KRSaPXu2wPk5EjSvfv75Z8mdO7fexr/Tp09r07XDhw9r5+owYXNDcqOACg7ozzvvPG0mCVPIsmXLugEV+0ACJBCCAAVUIQAxmwRIgARIgARIgARIgARIgATCJQANJ0TaQ/r+++/lkksuCVrFzTffLHPnztVlnnnmGRkwYIBP+SVLlsh1113nWCvo4MGDsnjxYsmVK5dcf/31UqhQIZ/6zAaEOUePHrXNN+XsPmMpoDp27JgsWLBA/vrrLy2sM31GHxGxcPv27VKlShVt5pgtWza7Lun9iIb46aefypgxY6Rjx45ByzKTBEjAHQQooHLHPLAXJEACJEACJEACJEACJEACaULgf//7n5xzzjna/xQEOPv27Qs6sg8++EBat26ty9x1110yefJkyZ49u88xiEyHCHXdunWT4cOH++T5b0CYhUh/EOZs27ZNzjrrLFmxYoWULFnSv6jccsstMmfOHC0YglP3cFMsBFTw1wUh0vTp06VBgwayc+dO7bPrtdde01zuvPNO+fLLL6Vu3boydepUKVq0qHY+f/nll9t296WXXpLevXuLE/NK20qYQQIkkFACFFAlFDcbIwESIAESIAESIAESIAESSHcCq1evltq1a+th3nvvvTJx4sSAQ4bZ3tixY6V79+5aa6hx48Yya9YsrfXkf0Dbtm21H6tJkybJPffc45/t2YYzdgimIMxq3769dhL+1ltvyVNPPSXPPfecpxy+fP3112KEPB999JFAEBRuilZA9d9//+l29+7dq8cOR/EnT57U5oz4vPbaa7WG19KlS7WwrWHDhoJjILCDGaVdMhpnV1xxhT7Orhz3kwAJuIcABVTumQv2hARIgARIgARIgARIgARIIA0IePufeuihh6R58+aeUUFbCOZ3EA5BY+iHH37QPpJwjHc5zwH/9wVmejDZwx+ENHbp/vvv1z6qZsyYoYvcdNNNMm/ePGnVqpVAU8s7jRo1Srp06aJ3wefVBRdc4J3t6Hu0AipE2hs4cKBs3LhRihQp4mnTjBc7ELEQJntvvPGGdO3aVZfB+G6//XZPef8v0ByrUKGC5MuXT37//Xf/bG6TAAm4kAAFVC6cFHaJBEiABEiABEiABEiABEggdQl4C1dKlCghOXPm9BkM/EKVK1dOC1AqVaqk/S35l/E5QG1A0wlCrU2bNmkfTP752D5y5IhcdNFFAu0haB799ttvcuGFFwpMDgcNGiR9+/b1OaxFixYybdo0KV++vOzYscMnz+lGNAIqRCyEuV6fPn3kscce82kSXLZs2aIZwbwPPqf++OMPefbZZ+Waa67Rwil/M0jvCg4cOKBZYB84wOSSiQRIwN0EKKBy9/ywdyRAAiRAAiRAAiRAAiRAAilEwNv/VIECBbTQKEeOHFGPAJH9jh8/rjWuLr744oD1wZdUjx495Ntvv9X5cBDeqVMn/X3Xrl1SunRpn+OgMYWogJ07d5aRI0f65DndiEZA9cUXX8iNN96ox3T22Wd7moRpH8YLUz5olsGcL9wER+sm0uGePXsC+t8Kt06WJwESiC8BCqjiy5e1kwAJkAAJkAAJkAAJkAAJZBCBVatWSZ06dfSI4YAckeSiTX/++ad2dI56gmkDQaADLaP8+fPrJuvVq6edo1evXl0+//xzn25AYwr+mZDgeBzO2SNJ0QioEJ0P5nemv6b9hQsXCvxxISF6X40aNUxWWJ9wDg92MKO0E+qFVSELkwAJxJUABVRxxcvKSYAESIAESIAESIAESIAEMonA888/rx2SY8xDhw6Vnj17Rj18aGXlzp1b1wONp/PPPz9knT/99JPA4TiEQMOGDctiQvfmm2/KI488ous5dOiQFC5cOGSdgQpEI6AKVB/2mYiF0KqCQC6U+aNdPTClhM8vOGCHqSUTCZCAuwlQQOXu+WHvSIAESIAESIAESIAESIAEUoiAt/8pmLAhol4sEnwoHTt2THbu3CmXXXZZyCoRuQ8O2uG7CZH9IEjyTtCYQuQ++Lbavn27d1ZY3+MhoKpVq5asWbNGbr75Zpk9e3ZY/TGFT506JXnz5tXjh7kfhFVMJEAC7iZAAZW754e9IwESIIGwCeAmE34mkpXwtrNBgwbJap7tkgAJkAAJkEDSCEDTCb6TYFYG/1PQ/gnmyDucjsKp+jfffKMFNzVr1gx5aMuWLbXpXpkyZTw+qcxB0KqC/6lffvlFR/GDNlWkKdYCKgiWwBCaTy+//LL06tXLp2tHjx6V06dPy7nnnuuz338DGmToGzTDoCHGRAIk4H4CFFC5f47YQxIgARIIi4CJyBPWQTEsDEewu3fvpip9DJmyKhIgARIggdQgsHLlSqlbt67ubKz8T5mRG39S0CiCZlGoVKFCBdm2bZuOdjdjxgyf4tiPfCRE8WvevLlPfjgbsRZQLViwQDtORx/gNwv+s7wTXoK1bt1a2rdv7707y3czxooVK8rmzZuz5HMHCZCA+whQQOW+OWGPSIAESCAqApMnT5ZWrVr51JEvXz6txg81/3AT3mD+/fff2ukq3gT//PPPgmg4CPkMMwO8hfVPTzzxhAwZMsR/N7dJgARIgARIIK0JDBw4UJ5++mk9xlj5nzLAzAuo0aNHa9M9s9/u89JLL9Ua1f379xf4xfJOr732mnTv3l2bv0G7yIlPK+/jvb9HI6D65JNPZMqUKdKtWzePI3RjeogXXtBEO+OMMzzNwWQS2mPQJPOPSOgp9H9fIMhr2rRpVGaC/nVymwRIIL4EKKCKL1/WTgIkQAJJIfDggw/KO++849P2Sy+9JI8//rjPvmg3jhw5InhbDD8X8+bN81RXqFAh2b9/vye8sycjzb+sX78+y5veRA0ZQkNEK4rUyW0s+vnrr78KTDPCdUSL6Er+ZqnXXnutJ2JVLPoWTR2ZPq/RsIvm2EjXUzRtpvOxmbyOoT1z9dVXhzS1wwuXxYsX+yyDokWLah9NPjuDbMDf1KZNm3SJjRs3SuXKlYOUDi9r0KBBAmHTfffdJ+PHjw95cP369WX58uXSo0cPeeWVVzzlDx48qIVB8EuFKH7QNIomRSqgOnDggJQsWVL+/fdfuemmm2TOnDmyb98+zzUETuER4c8IqOBHCtpp0KgaMWJEyC4bR+twBP/GG2+ELM8CJEACLiCgTsRMJEACJEACaUbg5MmTlvJVAdUmz5+6wbOUqnzcRrp161brnnvu8bSnhFZxa8ttFSstMz12daNtqRvtpHRP+Rix1A1+Uto2japQ6taZZ55pzZw50+xy9Pncc8951o1Zs99++62jY+NZiPMaT7qh6450PYWuObNKcB1blhIaWTfccIOFa2OwhPO3OQeZz3bt2gU7ROd99tln1tSpUy2lkeRz/IsvvmgpDSFrx44dIetwUmDVqlW6fqU55KS4pbSkdHnlUN0z9u+//97n/uDhhx92VFewQhdddJGlhGHBigTMU8IzD6+RI0daSlvKUmaRVrNmzazrrrtO5ykn7vpYJVSzbrzxRqtGjRrW8ePHA9bnvxN9wjwuWbLEP4vbJEACLiVADSp11mIiARIggXQkABO8a665RpvnmfFBHR5vkvPnz292xfxz4sSJ2i9E2bJl5auvvop5/W6rUF3f5e677xaYKaiHB6lWrVpSuhjpG+xYdxbh1F9//XWZNWuWNGnSxFH1xiRm+vTpOuISDqpTp46tBhXetsP57X///ReyfjgnLlKkiOTJkydkWe8CnFdvGsn7Hsl6Sl5vw2uZ6zg8XtGU3rt3r1SqVElrUS1cuNCjkROoznXr1okSgOgsJRARJaCSd999N1BRvQ8aoJdccomOEIfzjLcpPRymQ+sH/pImTJhgW4fTDNQHU7wTJ07ocyC0u4IlOBKH9jRMDuF0HNpK0JZClEETGQ9R/O68885g1YTMi/T6AxcC6sWWdkGAqH0w2ytVqpTABxU0tHFthRYaogzCvQD6/fbbbwuCsYRK+H3BST0iH0JTLFaO6kO1y3wSIIEoCbhUcMZukQAJkAAJxICAEhR43k6qy4X+rm74YlBz8Co+/vhj3ZYylQheMA1yn332WT1WZW6Q1NFE+gY71p1WD1CWMs+z1IOBpR42HFVvNKicvhUfNWpUlnVt1rfdp4pWZXXs2NFSUS4d9Ynz6ghT3AtFsp7i3qkYNcB1HCOQDquBRp4SHlmdO3d2eIRlKXN1y4kGleMKY1CwU6dO+vz33nvvOa5N+ZjSWkSLFi2yVNQ+S5kK6jrUyypLmdA5rseuYLTXH/RBCQ4tZYZqqRcPnmaUgM1as2aNNX/+fI8GmCczxBfUh+uBEnKHKMlsEiABNxGAc1smEiABEiCBNCYAVXn/h/Zx48bFfcT33nuvdeutt8a9nWQ2AJNJ9VbWUqG8k9kN3Xa0DwixHIDyIWKp8N/arMb7YcOujXAFVMrPlRY0Kf9nuh2zvtWbdb3/66+/tvCntAgtPJCh/uLFi+vfAUwQly5datcVvZ/zGhRPwjPDXU8J72CEDXIdRwguisN69+6tzwNOzZDdKKBSGkV6DMq3lS0JmHVCgDVgwAALQl7vpIKeWEpLSdfRtWtX76yIv7vp+mMGAZN3XBuUPzCzi58kQAIpQIACqhSYJHaRBEiABKIhoBwNW0r9Xt+omQd55UxbP8BHU2+oY5V6vqWcsoYqlrL5ELzArwl8eylzs6SPw20PCOYNvRNfZOEKqAxsPHhhLWNdQwAVLCnzEEtFtNJl8+bNa6kIlAGLc14DYkn6znDWU9I7G2YHuI7DBBZFcfigUiZfFnw4wd9RqORGARX63KhRI30usxO2Dx8+3HPNf//9932GafxS4dwJf1SxSG67/sDnF7TllGP8WAyPdZAACSSQAAVUCYTNpkiABEggWQSWLVumNX2MgAqfV111laV8YySrSynf7rRp0/QDADTF3JDc9oAAASUEQeedd15Ih7aRCqhWr17teQhTUa1CTsMLL7zgKQ/nxYES5zUQleTvC2c9Jb+34fWA6zg8XtGW7tu3rz4PQOgZKrlVQAUNUbwcgUPxQKlNmzZ6jLly5fIRQiGYCQR0EN4Y5+OBjg93n9uuPx06dNDjtxPghTs+licBEkgcAQqoEseaLZEACZBAUgkoJ6meh3MjqIpF9J6kDiqJjcN8ERzdYj7gtgcETI0K7a0ZjR49OuhMRSqg8hY4OTFbhQmgWfvKKXDAPnFeA2JxxU6n68kVnQ2jE1zHYcCKQVFovEJwg3MmovYFS24VUKHPffr00eezyZMnZxnCkCFDdJ5y4O7J27Jli6UcrFs5c+a0Xn31Vc/+WHxx0/UHvqdgeg8hHRMJkEDqEaCAKvXmjD0mARIggYgI4EZcRUbzPKCbB3WEwGYKjwC0OfCAA2fgbkluekAwTPC2HutMRTY0uwJ+RiqgQth4s4537doVsG7vnf369fOUv+OOO7yz9HfOaxYkrtrhdD25qtMOOsN17ABSjIvg949zx5w5c4LW7GYBFfxMNWjQwMqXL18Wk+XffvvNqlixojZrfvTRRy34osyRI4feBx9WsU5uuf7s379fC+GuvPLKmDh/jzUn1kcCJBCaAAVUoRmxBAmQQBoSwI2dChttIRoObvDuuusuCyY/KhRxWKOFOdDEiRPDOiaZhTE+3HCbh3p8YhtOiJmcExgzZoxm2L9/f+cHxbmkWx4QvIeJCExmvQWL6BeJgCocvz2mT/AZZtZ+IBM/zqsh5c5Pp+vJnb0P3Cuu48Bc4r3X+Ghq1apV0KbcLKBCxxGRr1y5clYggQzuc2A+Cm2q8ePHayEWfkPxSLj+3HjjjfGo2nGdGG+tWrW0z83du3c7Po4FSYAE3EWAAip3zQd7QwIkkAACCDOPN4vmQdX7E1oxjz/+uHXixAlHPcGb74ceeshRWbcUmjFjRpaxQ7MqlKmDW/ofTT8wxgMHDmin5jDzCPWHt9CBktFEC/X2PdCxe/futaZOnWohxHwsnavHWkCFt+zo44oVK3yGAWfjMCmBcNaOj/cBTZs21esNwh+7FImAatWqVZ517MQPGMKXm986IgwieIB/inReIWRYsmSJfghEOHf/tHjxYgvzHkmKxbxizUOQPmXKFAtaYnYJD6/B8u2Oc7I/kevJSX/cUsZN6xhM8LICL2/wu/cXZhw/ftyaPn16ROhisY7RMH5nOJcg0mawhGs4otXZJRMJ78ILL7Qrove7XUCFTkJIVbduXQvOz5OVEDEvVhEBIx3DhAkTtFN0b7PGSOvicSRAAskjQAFV8tizZRIggSQQ+OOPP6yyZcvqB9UCBQpYHTt2tJ5//nmrefPmVuHChT0PsEWKFAmpGYUbeTgpHTx4cBJGEl2TXbp08YzVPLQ/88wz0VXq4qMhCIKJA+bLjNfJJ0wivv32W5+RIfITHMziL5yHeUSPgiAFdV5++eVacy9//vw60uGbb75pVa9e3YIQJdIUqwdAPJgiIt4VV1yhHfDCXwlM9CDQgXDz7LPPturVq6f/wBB+gYIl4wslmD+QSARU+N2aOYRvqWAJwQAqVKigyyNy1bp167IUj3Rev/vuOx0RzPSlYMGC1oYNGzz1w0kv1t3mzZs9+8L5Eu28QjiGOatfv752WF+iRAlrz549Abtw8803a0YLFiwImB/JzmSsp0j6maxj3LKOMf6nnnrK85vCekbgAUS1RMInXsjcdtttejvcf9GuY7xcgLAbAiVoyaB/dtesNWvWaD9LNWvWtO0m6oNpHOoJZh6cCgIq20EygwRIgARSkAAFVCk4aewyCZBA5ASMM1rc6AbSkkJUm2LFinlu0vFQB40r/4QHPAgZcHPrr2HiX9aN23gYNw/sGAP+4FQU0f7SLcGsEQIX73Ga7xAWmT/DwGzjs3z58taxY8d8kMB0AGXLlCnjsz/YBrSOjHkZBJrmoQ+8c+fO7elbNI5ro30ARP+XL1+uH9reeOMNj/aE+c3Url3bypMnjzV27Fg9VOM3B5yChWuHgAS8IPCyS5EIqK6//noPt2Ch0vHwid8x+gDh1Ny5cwN2I5J5hcD74osv9vQDbeAPQqr58+frKFkXXHCBBR8wkaZo5hVaW4iiaOYMAnn0D4II/4Sw7Kb/sYrulaz15D82N2+7YR2DD4TkZv69P9u2bWtB2+j++++3IFCPVDslmnWM/j3xxBNaOwbaQjifoo/QeD516hSyfVKLFi10PszegiWjMQltULtEAZUdGe4nARIggfgQoIAqPlxZKwmQgEsJNGnSRGtQBVP9//3337WZn9G2gaYMhDnQFHnppZes1q1bezRxWrZs6dKRhu4WBG94YPd+GMFDRCDTp9C1ubME3pJDsJI3b14dtejw4cO6ozCFqFy5sqfTMF2BgC6QMNJT6P++rFy5UjPDw42ThDZLlSqlj8FDln/CGjJzAH8hkaZoHwAhZIKwBcIi72TGiz56M8ODG/ZdddVV3sWzfP/qq690OWgr2KVwBVT4/Zq1i89Fixb5/MGE8pVXXtEaYHiIhRYYhDMwdbNLZpxO5xX14HyA88PLL7+stekg5IFw77rrrtPCPPCpUaNGUFMju/6Y/dHMa7t27azbb7/dVGXh/Ic+BfK7M3LkSM86hAAg2pTM9RRt3xN1vFvWMfoBoSquc4j0BqE8zJchWPUWwEYTUCOadQwhs7cWIsz7sI7xF8i3HYTCyOvcuXPQqUQkT5QbOnSobTkKqGzRMIMESIAE4kKAAqq4YGWlJEACbiUA85a+ffs66t7OnTu1009zI+z/CS0sJz54HDWWpELQrPAfF0zh0iVBgACtH3/TOQgQevXq5RkmtF3OPPNMR3644McHzJxyMlorpUuXDqhp1Lt3b10f2g8mOPV01uZLNA+AqBJCO5i5+mtD4aHUrBFvzZpPP/1Ua+KECiwA80pzvN3vJVwBlREmoV6Yr4Gt/x8iLII9BEb+ZpqBEIY7r6gD/YbfE/8EwSgEj5dddpllhKL+ZZxuRzqvEDRDO88IPU2EQjAbNGhQluYRKAJ50BqMRUrmeopF/xNRh1vWMQS3MN0L9PuEuRx+Y9H6N4p0HWMecK6GxqZJ2MZahdDb/5yJlwzIwx9+08FShw4ddLlgvpMooApGkHkkQAIkEHsC2VClOokzkQAJkEBGEFA3oqIeWkWp/jser7pBF3WjK19//bUoZ8iiNEZEmWWIElA4rsPNBdWDtCiNE58uvv7666LenvvsS8UN5bhVlBaJKJMPT/eViYgoPyYya9YsQT7SgAED5OOPP5Yvv/zSU87ui4r+JD169BBl+iLvvfeeXTG9H/UprSNRzoZFCUpEaeFlKa80dkQ5ShYVTVKUA+As+U53KNNUUWaHonweOT3Ep9wtt9wiyreLKAGuz/4+ffqI8iMlSgtNjh49KkqTwSc/1Iby/yRK+KaLKdNYKVmyZJZDBg4cKE8//bQoTTZRZkRZ8v13KL89oszU9G6lvSTqgdW/SNjb4cxrsMqV+aZec0owJMrETZR5abDiIfMinVelAaPXqRLO6TaUY2lRUUv1d6WRIkqg59O20joRJUwTpXUiSpvKJy+SjWSup0j6m4xj3LyOwUNpKknjxo317+vJJ5+MClGk6xiNKh940r17d1Hay/pcit+UEqqJ8pElKjqdT7+wdh9++GG9TwUsECV098n33jDnNlwj3n33Xe8sz3cVUEFf6+3ylbaZvnZ4DuCXlCCg/I6KErymRF/ZSRLINAIUUGXajHO8JEACHgJ4kFTmAfpP+WkRZd4gyszBk+/ky8GDB0WFNhalmeWkuCvLQCigohoKhAcmQYCnTLPMZlp9jh49WgvfIGxRb+D12JRzaFGmWjJ79uyQY1UaT6I0swTCTqVVELS80rLTdSrzQcHDEtaZd1LaSnrNQfAJIZly+uudHdb3aB4A0ZARDoGDd1KaSLJ27Vr9oKo0zbyzHH9XZniCsSr/NaJMhrIcF66ACgJi5dtK1/PFF1+I8u+Vpc5wd4Qzr3Z1Qxh39913izL10/2LVjiFdiKdV5zflI8sj8BPObYX5S9PlDN+LXjwHgP6q3yE6V0QVittKu/siL4ncz3ZdRhMcG5T/sbsijjej99J+/btZcSIEY6P8S/o1nWMfiqzWbnjjjukf//+AkFOtCnSdYx2IQRSQU30ORoC+IYNG+ruKH9yosxWfbqGlxHKp5QoH5GitKl88vw3cB7H7z7Yy4ZQAiqlQSrdunXzr5rbLieA+wAI5ZlIgARcSCD2SlmskQRIgATcTQChs0eNGmUhip86LXv+4KsGZi6IyuU0wcdFqChmTutKZjklgNB+esADvj7g2Dpd0zXXXGP5R3eCE3U4A3aSYCIKToiEGCrBrwvKwg9RoPTZZ5951p968ApUxPG+aExo7BpB5EHjiw3R+CJNpg447Q6UwjHxg0kPzCHBFb9hmNPFIoUzr4Hag98eJQTS0RijNevzrj8W87p//37tKwvMhg0b5l29/q6ELJ51qASpWfJjtSNR6ylYf+EHDlFbo/3DtUJp1QRrKmieW9cxOg3TOPh2CxUdM+gA/TJjsY5RpTGZhumdEuz7tIJr+/nnn6/XspPzswkAAQfwdokmfnZkuJ8ESIAE4kOAPqjiw5W1kgAJuJgAhEp4UMMfnCcXKVLEs419EFTBLxAepkIlpQ1iKXOvUMVcnw8fPcbpdCwfStw28K1bt+q57tevn6dreKiBACXYQ4qnsPqiTMF0HUpTxnt3lu9w7GvWmXd73gWV2YwuAz9Z/r6fvMs5+R6rB0DvthYuXOgZw4YNG7yzHH9HpDtwgDNxf38xppJwBFTefnuUGZmpIupPp/MaqCEIgOBgGv3BeGOZYjGvyrzPMwf79u3L0j0IazBHiEwaz5So9RTPMcSqbjeuY4wNkUThc2revHmxGqquJxbrGBUVLVpUr1X4j/JP27Zt03lYywiUECo9/vjjurzSErMtSgGVLRpmkAAJkEBcCFBAFResrJQESMCtBBYsWKBvSKF5gbDaRgilTPWsyZMne8LR4wZXmSToMPF2Y1HmWLqu999/365ISuyH82Tlu0iPBYK5dE6ISoW5heaSSdB2wb5bb73V7Ar6+eGHH+ryjRo1CloODsVRL/5mzpwZsCwiDCJfmax48uGcH0KzcFOsHgC924VgDf1DePlAmkpOtA0hvEEdcMBul8IRUJmyqDNY9C27tuz2O51X/+Mh3FV+tbQGnjL39c/WUTEDsctS0GZHLOZVmT3pOcDv3D+Fq3Xif3w424laT+H0KVll3baOwQFahBDIrFu3LgsWrJNotOtisY4RJRO/e/xNmjQpSx/D1QRUJpq6LkSwtEsUUNmR4X4SIAESiA8BCqjiw5W1kgAJuJQAzLigKeQf1c27uxMnTrRMmGrcCCPiGzQQEM761KlT+uZd+ebQN7YwDVO+VrwPT6nv0GiBWRLGiZDbkQhGUmXAmCdoBkBDDvNoknJkrsdfqlQpsyvop3JkrstXrVo1aLl33nlHlwPbQFHkoGmDviAfpiZI6CO0qQJF0wramMqMxQOgfxswTUT/lJ8X/ywLJokQ4oZKypeZrkP5ObMtah7WnfyWIMxDn/Cn/E/9v/bOBVqqqozjnxjdltpDA5+R5FUBSxHzEaKEpmIJmAYUL3nkKzWw0HyAuEwE0pWVhQ9AK1TyEfgAikgTxWBhiOCLNI3KIFJBUHNhD6f938s968z73LlzmTMzv70WzMzZ++yz92+fO3POd77v/xXss6UVcdc12q+MifLAVJhvvr8dhf3J42P16tXR3Vr0vhLr6nSXPK/TTjst59hhfcTTaffk1Fdyw/Y6nyo55rbqK0nnseboRMi9EVlZ8PIVZUTNd/7ka5tvWyXO46jRX9/b2UW/YTqPnZ5adlXez6G9MpUWKhioCpFhOwQgAIG2IYCBqm240isEIJBQArpRU/r3UkU3lrpgVwhguBnOfpUOTq1rNclgp3m5LEkZRptSfGqxXt42mqsMctHiMuil11iedKVKSGMuw0SxEgweOqYT0s1p6jIApo/rxKt9vYyjTnA/p22cDa25Ady4cWNq/Pjx/l84VtRw4TLmhc3pVycsHysscv78+X6eal+oxDVQZev2ONHrQl22eHvcdQ0du2yQKRk1dZObz3NKY9PflzzHsrVyQh9xXluzrqH/5uZmvwb5QplCaKNCMAtpZ8mYKr0ll/kydFn0tdrnU9HBJaAySeexcFx//fXeMO4yT+alIwOry+KZckkh8tbH2ViJ81jfj/o+dUkncsKF5aXoBM19vcviF2dIKZdcwbcvFr7c6AYq/S27BCqxeMZttGrVqlQlv7vjHpd2EIBAbRDAQFUb68QoIQCBChHo0qVL3tCAQt0rpGDIkCFpUWZdHDc1NaVOPPFE71FVaL9a2O5SnPuLcxlE4hhmamFOhcYoA4LmqfWTJ0C06OZL2/Vv7ty50aq872VsCHpdLhtY3jbaKCOnyxLo+9WT/2hZtmyZvyEMx1VblQEDBpStadaaG0AJCoexBO/CIEas7VdddVV0+N7TRgzyGd4yGroPQXy8WDKBuAYqhUqGcboMidmHatXnuOuqg7hsfalevXqlxyLPvKFDh6ZcyvvUU0895T0uQ/hmazXdWrOuAUjwkszWy9uwYUP676KY14m0tQJ3zbFUqfb5VGp81a5PynksDjI6hrXVqzwdXUbR1KOPPuofwMhwLeOUjJw678stlTiP5bUZxhq+M8N4guC56uN4AsroqgdQMszK2FyoNLKBSg9vlOhj5syZhfCUtV2GQV1DBYmFsjphJwhAoG4JYKCq26VlYhCAQD4C69evzxuKk69tdJsuzBXiJ5Ht1nhDRPus5nvpbenCXDfWmlO9F2WlCjc2Ei+PljfeeCOd4eycc86JVhV879LD+/5mz55dsI0qgnFGGb9CCJiMVeI+adIkr/eicSm73YoVK7zxUwaOckprbgCPO+44Px/dhL755pspl2Le605dd911fvuRRx6Z9rCT9os0qebMmRNrmH369PF9yKOsUClmoNLTe93Qy9AjA3NYR3n9aV1dqvmK/U3GXVcZ7zp06JBatGiRv8kaNWpUelxhfHqV0Sqse6G5l9remnUNfcvzReMRv3BT+NJLL6W6du2aHncxrxMlgwjzGjZsWOi24Gu1z6eCA6tiRRLPY4Uey/h0xhlneK00Gc533XXX9FqHNZdmo76fWlMqcR4rkcRee+3lxxeMJvKcmjZtWnrMxTwBo+NfsmSJ36d3797RzTnvk2igev3111P6HYvzT7ph5XwH6UGFHkK0JqwzB+b7G/S3oPNMvw31cD1VaJ5shwAEyiOAgao8buwFAQhAoGYJBO+dHXfc0d/c1+xEWjDwYGjp27dv3r3CDbWy6sUp4YZIhopiRWEM8iYRaxkHZACSvlkQ+FWYn24CZPCR9pT6Lbe05gZQGbsUHqObsR49evgxBc8feSYonFV1Gv/+++8fy9NM85DnmuansRUL6ShmoJLxR/x0I62n+eGfmEnDS3X5NL7K4RhnXZ988smccKgQzhe9oZfnSbE5xx1fa9Y1HEPjmDp1qs9W2bFjx5T003S+RT2jsr38wr56VUIJ8ZfmnrIVlirVPp9Kja8a9Uk7j8VAXohKDhE9T2WYiBqp9H2gkKzWlkqcxxrD2rVrU4cddpgP85O3l3TwlH0yGFEVxh+nTJkyxRuobr755qLNk2igimpkhu+cYq/6W5dBX9/phTKpRiHIs1Lrpe/7bE+1aLvWvFfot4yJyqpMgQAEIBAlgIEqSoP3EIAABOqcgELSpImji1llPGqUonAOebvk0woSg7feeiulJ+pxnzQrM50MI/vtt1+sfRQKt2DBgtTy5ctT8gKIFt0MqE5eVK0plbgBVEirPJKkOxItCgFduHBhqpCAcrRt9P3ixYv9uSZjTbFSzEBVbL9K18VZV3kvFPImkWi6wpAq6RVQiXUNnORNIU82ecgprCncpMvYp7+BUkXnb7FQwOz9q3U+ZY+j0T7HOY/FRCFc8pjMLkoioYy3rf1OivZbyfNY3+MSSVd4ojyA9f0ewqmzw5GjY4i+P/roo72BW1lsi5UkGqj0eyJPW+lkBsOUEhDIeC4Dnv7pb09/r8pOKi+o0E5h5KW+n2S4llGrXG/eYjyjdcoarHEVynIbbct7CECgcQhgoGqctWamEIBAgxPQk1A9adYF4dixY9uchi6izz333DY/TrUOIO8DsYwrHN3W46zkDWClxvqlL33JMyrlgZEUA5XmXU/rqht5eelJUyj7plSeFBJ5b8n3gfSn2iLkJ+75Fvd8ittfPberp/NY6yTjr5I16EFCdpkxY4Y/j+VRmW1cz26rz/IS03kvY02pkkQDVRhzVHfr1ltvDZvzvoYkIZr3mWeembeNNiqjodrI87eti8KN5a2nBz3ZD27a+tj0DwEIJJcABqrkrg0jgwAEIFAxArpRlSipLjyVTU26HW1dJC4fJ2NiW4+jrfpXxiuFKGRnBWyr45XqN2kGKj3BF5/u3buXGnoqSQaqelrXkKFPf/d33HFHxjoEXSqFYEqPKk4ZPHiw106L07bSbVpyPlX62LXYXz2dx/r9kuabzmOFGEeLvL303ae6uBqCX/va13z7efPmRbvK+z7JBqrwm665F0vYoYmJof7W1VYaiPqcr8hDUt/blQqbzneM6Lag0yhvTgoEIAABEcBAxXkAAQhAoAEIhIxsMhbECeVpLRLdDOtCWFo09VxGjBjh51ksTfn2mn/SDFRnnXWWZ6OQt1IlSQYqjbVe1jXMQ54lUSOUwqLkuaAb0WLaU9F1kweLtMgqGfYV7b/U+5acT6X6apT6sP61/v0kMXD9nujfmDFj0sunkGx5A2m7EjnE8cKRQLey90mgO05JqoFKHpHB4CRtuDhFel2B4zPPPJOzi0L6VB/Hsyxn5zI3KHGNvp/0+7U9HpyVOUx2gwAEtiMBDFTbETaHggAEIFANAsG1X9mPFHbXlkU3DNK2ateuXUlh7LYcx/bqW9pMutGXWG+cm6O2HFeSDFTSntI5oBvkOCVpBqp6Wdfvfe97/oZz3bp16WVYvXp1SkLpukn/wQ9+kN5e7I3CASVMXSw0qNj+ra1r6fnU2uPVy/71ch7L20eGk9GjR6c1/7RNYWjaLq8fzbVUkQFEhqmmpiav0VSqveqTaqCSh1wwNsX5npVOl/7mwz75svdedNFFvl5/b9uznH766f640jmkQAACEMBAxTkAAQhAoI4J3Hfffd5QoCetK1eubLOZ6mnuT3/607TGlS6C5brfCEViwhJMl4dHNUtSDFQSaJYBRNm04nrrJc1ApXWsh3XdvHmzN54qLOqb3/ym94zQuSqDqgSV45YbbrjBZ++Lu55x+43TrpzzKU6/jdKmHs5jrZUy0MnAMmjQIK9tKN2i9u3b+5DTOJnp1EcIJ5MuW9ySVAPV5MmT08amUvpTmquy5gXjlDKhbtu2LQOBMjnqN0RMFTa5PUsIRZYsAAUCEIAABirOAQhAAAJ1SkAGKRmm5MkSR2ujHAzSvZCHli5sw8VveH3hhRfK6bIm9/nxj3/s59+SG59KT1RrcPLJJ1e62xb1J6+GXr16+dTvpTRRoh0HA5U8dOQVoX/KOFftUg/rqjWRt4W8qSRyrlC9uNkqA38ZpuSBsb1LuefT9h5n0o9XD+exGMtL6vbbb/fn8sMPP5w3A2GhtVCmVIW0Xn755YWa+O0y1ITvIL3K22rUqFFF96lG5QknnJD+zY2G7xYaS0gwoN/nK6+8MqeZeKruiCOOyKkrtEEZQW+55ZaCWU3DfsoUWcyIKGO5ji0vbwoEIACBHYTAfSlQIAABCECgjgi88sordtRRR5m7oLd9993Xxo0bV/bs3E2iufA1c09czV1o2oYNG8zpRpgzQPnP+Tp2KbzN3RTnq6rbbc6DzFy2NHMaPVWZoxO/N+cpY078uirH10HdzaN9//vfN5cJyjp37hx7HO4Jujnvhoz2TiPFzydjYxU+sK5VgP7+Ics9n6o34uQeudHP427dupkzNNkll1xSdJGc8dac15Q5g0q6ndNwrOr3anog779xHsvmQsvNeTqZ05Uy/d4XK3PmzLFhw4b5Js4Dze666y5zD64ydnGGO5s6daq/VtD3cbHijHjmsnmaewhmzpPN/9Y7o5f//cveb/ny5da7d29zhi9btmxZdrX/rP6cV5e5rH7m9MZ8n3kbshECEGgIAhioGmKZmSQEINBIBHSRd8wxx9iaNWuqNu2ZM2ea84ap2vE5MAQgAAEIQKAeCejhj37jVYYPH+4fDOSbp4xt+i2+8MIL/QOmvn372oMPPmhOlDyn+ciRI2327Nl255132tChQ3Pqoxtk5HOho/bQQw+ZjEt77rmn73PLli3mEilEm5rL5Gv33HOPuZBv00OHQkVGrKVLl9q9995rAwcOLNSM7RCAQAMQwEDVAIvMFCEAgcYi8J3vfMeuu+66qk3ahRXaxo0bzaWyrtoYODAEIAABCECgHglcc801NnHiRD+1c845J8OgI49neU6vXbvW5s6day5Bgh144IGmfYoZflzIoLkwP//v+OOPL4jNhW5b165d7YknnjCnZedf5a2tIq9qHStaZLxy4dr2jW98w2688cZoVcZ7jU3jdZIBNn78+Iw6PkAAAo1FAANVY603s4UABBqAwKZNm3wYXrWmKgNVc3NztQ7PcSEAAQhAAAJ1SyAYkzTBT37yk+bE4zPmKg8pGZEOPvhg69Gjh/Xv3z+nTcYO7sNBBx3kjVqrVq3y+2TXh88XX3yx9852mf78Jn2WUWmXXXYxXXtEvbOef/55cxkWfbu7777bBg8eHLrJeVUYpby9xo4dm6hwypyBsgECEGhzAhio2hwxB4AABCAAAQhAAAIQgAAEINA6AlH9qY9+9KPeKOQyc7auU7e3NKC2bt3qPa6K6QdKS0ohg9K0Ughhp06d/AOxM844w1wShoxxyGPq/PPP99vkRbX77rtn1Ec/XHrppeYSOXidMOmlUSAAgcYlgIGqcdeemUMAAhCAAAQgAAEIQAACNULg8ccft2OPPdaPtl+/fjZ//vxWj1xJUOT5rLJ582YvwF6oU+lMyTDmMiLaI488YiEc8Fe/+pV98YtfzNhNHlPSlJJ31nPPPZdRl/3h2muv9QL20sJy2XCzq/kMAQg0EAEMVA202EwVAhCAAAQgAAEIQAACEKhNApMnT7YrrrjCD75Sek3yympqavJ9vvrqq9axY8dYcKR/NWPGDJ/1ULqT7du3T++nJPF77LGHvfbaa3beeefZ9OnT03X53kyZMsUmTJhgo0ePtttuuy1fE7ZBAAINQgADVYMsNNOEAAQgAAEIQAACEIAABGqXQFR/auXKlfbZz362IpPZddddTd5Rf/zjH61Lly6x+txnn318eN9ZZ53lDVXRneQxpcx9KsriN2jQoGh1zvuQ3EVGKhnhKBCAQOMSwEDVuGvPzCEAAQhAAAIQgAAEIACBGiAgTydpRSkkT2F2Csdr165dRUYuUXVl4Vu2bJn17NmzZJ/KEqjQPZU77xXZ8vYAAA+tSURBVLzThg4dmrGPPKYuuOACv62U/pQaycg1a9Ysn+lPGf8oEIBA4xLAQNW4a8/MIQABCGw3Akp9/cYbbxQVSS02mHfffdf07yMf+UixZtRBAAIQgAAE6pLA0qVLrXfv3n5uldKfCqA+//nP22OPPWYLFiywU045JWwu+Dp37lwbOHCgr1+zZo0dcsghGW1VpzbK4vfss89m1OX7ENrff//9duqpp+ZrwjYIQKBBCGCgapCFZpoQgAAEqkXg9ddf9+Kpw4cPt3HjxpU1jCeffNKnypYQ66GHHlpWH+wEAQhAAAIQqFUCV199tU2aNMkPv1L6U4FFEDS/+eabTdpSpcodd9xhI0aM8B5c8uj64Ac/mN7lf//7n9ef2rRpk8/i95Of/CRdV+jN4Ycfbvqd/8Mf/mB6T4EABBqXAAaqxl17Zg4BCDQwAXkj9e/f33slFcIgTYr999/flD46++looX2yt//3v//1T3y7d+9uN910U3Z1iz4ry4/SUOspcggtaFEHNIYABCAAAQjUKAHpTa1atcqPXsacww47rGIzCSLl+r3/+c9/XrLfJUuW2HHHHefbhcx+YafQlz4ri1/wtAr12a/vvPOOD1mUYUsi7R06dMhuwmcIQKCBCGCgaqDFZqoQgAAEogSeeeYZW7RokUmcVE8/H3jgAf/UU22UkUdPMqUt8eKLL3rDkNq1tFx66aUml/2nn3464wlrS/sJ7b/61a/68axYsaIi/YV+eYUABCAAAQgkjcDDDz/staakDfXDH/4wPbxp06aZdKMOPPBA69atW3p7uW9+//vf2zHHHGP77befvfzyyyW72bZtm2/7j3/8w2bOnGlnnnmmycAkzy797qvssMMOJv2pUlkBH330UevTp49/mKX3FAhAoLEJYKBq7PVn9hCAQIMT0AXvt771LVNmoN/+9rc5NNavX2+dOnUypYyWKKouiOMWXVDrgnfx4sW+/7j7FWuncEGN5/LLL0+n2i7WnjoIQAACEIBALRJYt26dNTc3+4cxH/rQh7zBJ8xDgukyEg0bNsxmz54dNpf9qv5kSHrzzTdNv/t77713yb6U8U/HX716tfey1u+zdCLlEfWXv/zFZ/HTg7BSZerUqf43PW54Yan+qIcABGqbAAaq2l4/Rg8BCECgVQS+/OUve8+pa665xl8g5uts55139hect99+u0lHKm75yle+Yko1rYvYShZl+/nNb35jf/3rXzMu2Ct5DPqCAAQgAAEINBIBZc+TkehnP/uZjRw5MtbUFcb//PPP+9/jzp07e4PaHnvsYW+//bZdddVVac2sYp316tXLVq5cafLG2m233Yo1pQ4CEGgAAhioGmCRmSIEIACBfATee+89r/Wg7Hpy7z/66KNzmintdPCa0lNSaUnFKa+88op96lOfsgkTJviL1Dj7xG3z1FNPee2NRx55xIcFxN2PdhCAAAQgAAEI5CcgfSvpXEnbShpXhYquCxT+/4UvfMGU/S9aFO539tlne6+vv/3tb2nZgGib6HtJCRx55JE2YMAA/7AsWsd7CECgMQlgoGrMdWfWEIBAAgjIC0hhddJ/+vrXv+6fPC5cuNCHxH3mM5+xQYMG2cc+9rE2G6kMTj169LCddtrJJHLavn37nGOdf/75duONN5a8YM3eUU9h9TRW2lMHH3xwdnX6czkMFG4oAXd5aN16663pvngDAQhAAAIQgED5BPr27euvQQo9AJLH1F577WUK51MSlT/96U/pgymb3wEHHOBDBJUJUNcBpcqQIUPsrrvusnnz5tlpp51Wqjn1EIBAAxDAQNUAi8wUIQCBZBGQ55IMUvIECuFqjz32mEkAXG7uyqJz4YUXegPVPffckzN4udPLSPPpT386py57gy4im5qa7MMf/nB2lf3oRz/yxznxxBP9BWm0gcao+vHjx3sPKmXs2X333aNNir4fPXq0zwQkjYxo+umwU2sZaMx6iqsntBQIQAACEIAABFpPQCH5ytorQ9X8+fNzOvzzn//sH6apYsyYMemHRLomkefUrFmzvEeUxM6lm1WsKExfRi5pVcogRoEABCDgCbgvFAoEIAABCGxHAs7wk3IeUiknSuqP6sTEU+4LOeU8mVJOgyHlPJb8Z2ewyhiVM2il9t13X1+n9i7bTmrGjBkZbbI/uMx7qV/84hfZm/1npz/l+3Jhe6mJEyf6fxdddFHq5JNPTjkNidTHP/7xlBMvTb311lsZ+zvjUspdTKac91PqP//5T0Zd+OBCBFJOcDV8zHktl0Ho6IILLkg5j6+UxkKBAAQgAAEIQKAyBFwWPn9t4DybcjrUb76uP9xDqPTvr7add955frt7cOavY3J2zNrgPLFSLnNfyj1AS7mHblm1fIQABBqZAB5U3kzHfxCAAAS2HwGFvOkp41FHHeUPKi8peU8pTbP0G7Zu3Wpz5szx7u577rmnb7N582b/pFEhf+5C0Le57777vAj5ueeeazfccEPeED3pQyjjnZ6GRov74fP6U+pX9UpVHYqy8Bx00EH+KekHPvCBsNm/yutLYx08eLDP3KNQO4mnZxeJpWqsCiPMV8phEO3niiuusMmTJ/sU1i3x7Ir2wXsIQAACEIAABDIJKIzvpJNOMulDyau7S5cuGQ0UWq/rDoXkuQdZ3gNbupOXXXaZ153M5zWd0YH7oOsOZe9riSB7dh98hgAE6pMABqr6XFdmBQEIJJiAwu46dOiQHqHzBrLp06d7o5T0GPKV7373u16UVMKlu+yyi28iI5Oy5KhOWXB++ctfZgiSSt+qX79+pgvHbCPOmjVr7NBDDzUZoCSSHvrMd+ywTWmje/bsaVdeeaW/OH355Zf9hav2zw4h1PwktiqNqXylHAbRfkJa6rVr16ZF3KP1vIcABCAAAQhAoDwC+o0+9thj/TXC8uXLc64RNm7caA899JBt2LDBDj/8cDviiCNyrgMKHVlam/379/cGLWUQpkAAAhCIEsBAFaXBewhAAAJVICBvomeffdYLi+699955R6BsOdKtGjp0aE79gw8+aMOHD7edd97ZRowYYb179zZl45ERR59dGGDOPkF/StlzVqxYkVOfb4N0It5991174oknbIcddrB33nnHH3PRokU5Hlp64irvL+lQxClxGET7kTbW9ddfb9LDULZACgQgAAEIQAAClSMgI5WSkejf2LFjK9Zxt27dbNSoUXbJJZdUrE86ggAE6ocABqr6WUtmAgEI1CABXQDKu6m5uTkjG87999/vn0p+4hOf8LPq2rWr/frXvy5ojHnuueds2LBhJs+oUJyWlM2dO9dn6Qvbwuvpp59uChG8+OKL7dprrw2bC74+/vjj/mmqQhNlKFOR95JCARWWqPDEaDn++ONt06ZNGeOJ1kffx2UQ3Sdk/pH3VltmOowek/cQgAAEIAABCEAAAhCAQNsRwEDVdmzpGQIQgEAOgVdffdU/OezRo4fJtf22227zBp+RI0d6LQbtsG7dOh9+p2x9++yzj+9DWf7kGVWqKOWz3PGdSLk5Ifa8zaP6UwsWLLBTTjklb7voRhm05KmlcEHpTqkoNbSy9eVLRy3PrQceeMC2bNli7dq1i3Zl5TKIdiJtrZdeesl7nUW38x4CEIAABCAAAQhAAAIQqE0CGKhqc90YNQQgUKMEJAgqo468m1x2PW9IkrbTqaee6j2a/vWvf5nLruf1m6ZNm9Yms5ThSMdQkfeSRE5LFYXrbdu2LUNMXR5Ub7/9dl6hcom2jxs3zocuuqw+Gd1XgoEMdxKZnzdvXkbffIAABCAAAQhAAAIQgAAEapMABqraXDdGDQEI1CgBhaRJnLxjx45eXFQC6dJQUmY+eTz985//9HoPU6ZM8TpPlZymjEaTJk1KdylPqvfee88byYppRWnMu+22m02cONGuvvpqv7/2U/ihNLOU5Se7SDi1U6dOdtNNN9nZZ5+dUd1aBtLM+tznPme33HJLTt8ZB+IDBCAAAQhAAAIQgAAEIFAzBDBQ1cxSMVAIQKCeCCg8TV5JIXueBMdfeOEFr+nU1NSUqKk+/fTT1r17d7v33ntt4MCBfmxLly71IYd33323DR48OO94+/Tp44XUJaqer5TL4Nvf/rYPjVy/fr0Xac/XN9sgAAEIQAACEIAABCAAgdoigIGqttaL0UIAAhDY7gT+/e9/eyFyaVCdcMIJ/vgKUfz73//uRdB33HHHvGNavHixz+4ngfVevXrlbdPSjQopPOCAA3x2wjji7i3tn/YQgAAEIAABCEAAAhCAQHUIYKCqDneOCgEIQKCmCCgrn4TSFZIoYfcJEyZ4MfbOnTsXncfw4cO96PuSJUusffv2RdvGqVTWwYULF/qwwp122inOLrSBAAQgAAEIQAACEIAABGqAAAaqGlgkhggBCECg2gR+97vf2ZgxY7xelTyqpJF1yCGHlBzWa6+9Zj179vSeVNOnTy/ZvlgDGbkGDBhgy5YtK5ihsNj+1EEAAhCAAAQgAAEIQAACySWAgSq5a8PIIAABCCSKgAxTW7du9QLvLRnYxo0b7aSTTrLLLrvMhgwZ0pJd021ffPFFr3k1a9Ys69evX3o7byAAAQhAAAIQgAAEIACB+iCAgao+1pFZQAACEEg0AWXu27x5szU3N5c1TnlibdmyxetPldUBO0EAAhCAAAQgAAEIQAACiSaAgSrRy8PgIAABCEAAAhCAAAQgAAEIQAACEIBA/RPAQFX/a8wMIQABCEAAAhCAAAQgAAEIQAACEIBAoglgoEr08jA4CEAAAhCAAAQgAAEIQAACEIAABCBQ/wQwUNX/GjNDCEAAAhCAAAQgAAEIQAACEIAABCCQaAIYqBK9PAwOAhCAAAQgAAEIQAACEIAABCAAAQjUPwEMVPW/xswQAhCAAAQgAAEIQAACEIAABCAAAQgkmgAGqkQvD4ODAAQgAAEIQAACEIAABCAAAQhAAAL1TwADVf2vMTOEAAQgAAEIQAACEIAABCAAAQhAAAKJJoCBKtHLw+AgAAEIQAACEIAABCAAAQhAAAIQgED9E8BAVf9rzAwhAAEIQAACEIAABCAAAQhAAAIQgECiCWCgSvTyMDgIQAACEIAABCAAAQhAAAIQgAAEIFD/BDBQ1f8aM0MIQAACEIAABCAAAQhAAAIQgAAEIJBoAhioEr08DA4CEIAABCAAAQhAAAIQgAAEIAABCNQ/AQxU9b/GzBACEIAABCAAAQhAAAIQgAAEIAABCCSaAAaqRC8Pg4MABCAAAQhAAAIQgAAEIAABCEAAAvVPAANV/a8xM4QABCAAAQhAAAIQgAAEIAABCEAAAokmgIEq0cvD4CAAAQhAAAIQgAAEIAABCEAAAhCAQP0T+D/cMoJ0KJKLQgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "![Screenshot%202023-01-20%20at%203.01.34%20PM.png](attachment:Screenshot%202023-01-20%20at%203.01.34%20PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_loss(Pa_x, Py, Pz_y, Py_x, Pz_yx):\n",
    "    # compute delta\n",
    "    term_1 = Pz_yx/tf.expand_dims(Pz_y, axis=-1)  - 1 # ok\n",
    "    term_2 = Py_x / tf.expand_dims(Py,axis=-1) # ok\n",
    "    delta = term_1 * tf.expand_dims(term_2, axis=0) # ok\n",
    "    \n",
    "    # compute c\n",
    "    exp_Pa_x = tf.expand_dims(tf.expand_dims(Pa_x, axis=0),axis=0)\n",
    "    exp_delta = tf.expand_dims(delta, axis=-1)\n",
    "    c = tf.linalg.matmul(exp_Pa_x,\n",
    "                         exp_delta)\n",
    "    \n",
    "    # compute fairness\n",
    "    fairness = tf.norm(c, ord=1) / Py_x.shape[1]\n",
    "    return fairness\n",
    "\n",
    "# def get_fairness_loss(Pa_x, Py, Pz_y, Py_x, Pz_yx):\n",
    "#     # compute delta\n",
    "#     term_1 = Pz_yx  - tf.expand_dims(Pz_y, axis=-1) # ok\n",
    "#     term_2 = Py_x / tf.expand_dims(Py,axis=-1) # ok\n",
    "#     delta = term_1 * tf.expand_dims(term_2, axis=0) # ok\n",
    "    \n",
    "#     # compute c\n",
    "#     exp_Pa_x = tf.expand_dims(tf.expand_dims(Pa_x, axis=0),axis=0)\n",
    "#     exp_delta = tf.expand_dims(delta, axis=-1)\n",
    "#     c = tf.linalg.matmul(exp_Pa_x,\n",
    "#                          exp_delta)\n",
    "    \n",
    "#     # compute fairness\n",
    "#     fairness = tf.norm(c, ord=1) / Py_x.shape[1]\n",
    "#     return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_loss(y_true, y_pred):\n",
    "    utility = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "    neg_utility = - utility\n",
    "    return tf.math.reduce_mean(neg_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_metric(y_true, y_pred):\n",
    "    utility = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "    return tf.math.reduce_mean(utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "utility_tracker = tf.keras.metrics.Mean(name=\"utility\")\n",
    "fairness_tracker = tf.keras.metrics.Mean(name=\"fairness\")\n",
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "eval_utility_tracker = tf.keras.metrics.Mean(name=\"eval_utility\")\n",
    "eval_fairness_tracker = tf.keras.metrics.Mean(name=\"eval_fairness\")\n",
    "eval_loss_tracker = tf.keras.metrics.Mean(name=\"eval_loss\")\n",
    "\n",
    "\n",
    "class LogisticRegresionTF(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    logistic regresion model , tensorflow\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, l):\n",
    "        super(LogisticRegresionTF, self).__init__()\n",
    "        self.l = l\n",
    "        \n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, 1), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(), dtype=\"float32\"),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.sigmoid(tf.matmul(inputs,self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_from_data(data):\n",
    "    # get Py, Pz_y and models for Py_x & Pz_yx\n",
    "    Py, Pz_y, model_y_x, model_z_yx = get_models(data)\n",
    "    \n",
    "    # get Py_x from data\n",
    "    Py_x = model_y_x.predict_proba(data[X_atr]).T\n",
    "    \n",
    "    # get Pz_yx from data\n",
    "    Pz_yx = np.zeros((n_z, n_y, data.shape[0]))\n",
    "    for y in range(n_y):\n",
    "        tmp_data = data[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx[:,y,:] = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "    return Py, Pz_y, Py_x, Pz_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = LogisticRegresionTF(input_dim=len(X_atr), l = 0.0)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = get_models_from_data(train_data)\n",
    "Py, Pz_y, Py_x, Pz_yx = train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(policy, data, lamba_parameter, optimizer):\n",
    "    x, y, Py, Pz_y, Py_x, Pz_yx = data\n",
    "    # Run forward pass.\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = policy(x, training=True)\n",
    "        utility = get_utility_loss(y_true = y, y_pred = y_pred)\n",
    "        Pa_x = tf.stack([1 - y_pred, y_pred])\n",
    "        Pa_x = tf.squeeze(Pa_x, axis=-1, name=None)\n",
    "        fairness = get_fairness_loss(Pa_x, Py, Pz_y, Py_x, Pz_yx)\n",
    "        loss = utility + lamba_parameter * fairness \n",
    "\n",
    "    # Run backwards pass.\n",
    "    optimizer.minimize(loss, policy.trainable_variables, tape=tape)\n",
    "    # update metrics\n",
    "    loss_tracker.update_state(loss)\n",
    "    utility_tracker.update_state(get_utility_metric(y_true = y, y_pred = y_pred))\n",
    "    fairness_tracker.update_state(fairness)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"fairness_loss\"] = fairness_tracker.result()\n",
    "    metrics[\"utility\"] = utility_tracker.result()\n",
    "    metrics[\"loss\"] = loss_tracker.result()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(policy, data, lamba_parameter):\n",
    "    x, y, Py, Pz_y, Py_x, Pz_yx = data\n",
    "    \n",
    "    y_pred = policy(x, training=False)\n",
    "    utility = get_utility_metric(y_true = y, y_pred = y_pred)\n",
    "    Pa_x = tf.stack([1 - y_pred, y_pred])\n",
    "    Pa_x = tf.squeeze(Pa_x, axis=-1, name=None)\n",
    "    fairness = get_fairness_loss(Pa_x, Py, Pz_y, Py_x, Pz_yx)\n",
    "    loss = utility - lamba_parameter * fairness \n",
    "\n",
    "    # update metrics\n",
    "    eval_loss_tracker.update_state(loss)\n",
    "    eval_utility_tracker.update_state(get_utility_metric(y_true = y, y_pred = y_pred))\n",
    "    eval_fairness_tracker.update_state(fairness)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"fairness_loss\"] = eval_fairness_tracker.result()\n",
    "    metrics[\"utility\"] = eval_utility_tracker.result()\n",
    "    metrics[\"loss\"] = eval_loss_tracker.result()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_trackers(trackers):\n",
    "    for tracker in trackers:\n",
    "        tracker.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03262693],\n",
       "        [ 0.07397023],\n",
       "        [ 0.02534937],\n",
       "        [-0.05676214],\n",
       "        [ 0.0054805 ],\n",
       "        [ 0.04888055]], dtype=float32),\n",
       " 0.0]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "--- Step : 1 \n",
      "  ------- {'fairness_loss': 1.4591445, 'utility': 0.49973616, 'loss': -0.45596182}\n",
      "--- Step : 2 \n",
      "  ------- {'fairness_loss': 1.4669333, 'utility': 0.50009227, 'loss': -0.45608428}\n",
      "--- Step : 3 \n",
      "  ------- {'fairness_loss': 1.4732944, 'utility': 0.5003802, 'loss': -0.45618138}\n",
      "--- Step : 4 \n",
      "  ------- {'fairness_loss': 1.4787965, 'utility': 0.5006396, 'loss': -0.45627573}\n",
      "--- Step : 5 \n",
      "  ------- {'fairness_loss': 1.4824325, 'utility': 0.5008402, 'loss': -0.45636722}\n",
      "--- Step : 6 \n",
      "  ------- {'fairness_loss': 1.4846245, 'utility': 0.5009986, 'loss': -0.45645988}\n",
      "--- Step : 7 \n",
      "  ------- {'fairness_loss': 1.4857048, 'utility': 0.5011245, 'loss': -0.45655337}\n",
      "--- Step : 8 \n",
      "  ------- {'fairness_loss': 1.4858946, 'utility': 0.50122446, 'loss': -0.45664763}\n",
      "--- Step : 9 \n",
      "  ------- {'fairness_loss': 1.485347, 'utility': 0.5013031, 'loss': -0.45674267}\n",
      "--- Step : 10 \n",
      "  ------- {'fairness_loss': 1.4841748, 'utility': 0.5013633, 'loss': -0.45683804}\n",
      "--- Step : 11 \n",
      "  ------- {'fairness_loss': 1.482466, 'utility': 0.50140804, 'loss': -0.45693406}\n",
      "--- Step : 12 \n",
      "  ------- {'fairness_loss': 1.480287, 'utility': 0.50143903, 'loss': -0.45703042}\n",
      "--- Step : 13 \n",
      "  ------- {'fairness_loss': 1.4776958, 'utility': 0.50145805, 'loss': -0.45712718}\n",
      "--- Step : 14 \n",
      "  ------- {'fairness_loss': 1.4747337, 'utility': 0.5014664, 'loss': -0.45722437}\n",
      "--- Step : 15 \n",
      "  ------- {'fairness_loss': 1.4714743, 'utility': 0.5014649, 'loss': -0.4573207}\n",
      "--- Step : 16 \n",
      "  ------- {'fairness_loss': 1.4711416, 'utility': 0.5015466, 'loss': -0.45741236}\n",
      "--- Step : 17 \n",
      "  ------- {'fairness_loss': 1.4725697, 'utility': 0.5016865, 'loss': -0.45750943}\n",
      "--- Step : 18 \n",
      "  ------- {'fairness_loss': 1.4756104, 'utility': 0.50187004, 'loss': -0.45760173}\n",
      "--- Step : 19 \n",
      "  ------- {'fairness_loss': 1.477891, 'utility': 0.50203097, 'loss': -0.45769423}\n",
      "--- Step : 20 \n",
      "  ------- {'fairness_loss': 1.4794753, 'utility': 0.5021717, 'loss': -0.45778745}\n",
      "--- Step : 21 \n",
      "  ------- {'fairness_loss': 1.480429, 'utility': 0.50229394, 'loss': -0.45788106}\n",
      "--- Step : 22 \n",
      "  ------- {'fairness_loss': 1.4808135, 'utility': 0.50239956, 'loss': -0.45797515}\n",
      "--- Step : 23 \n",
      "  ------- {'fairness_loss': 1.4806776, 'utility': 0.50249034, 'loss': -0.45807}\n",
      "--- Step : 24 \n",
      "  ------- {'fairness_loss': 1.4800724, 'utility': 0.50256723, 'loss': -0.45816505}\n",
      "--- Step : 25 \n",
      "  ------- {'fairness_loss': 1.4790366, 'utility': 0.5026316, 'loss': -0.4582605}\n",
      "--- Step : 26 \n",
      "  ------- {'fairness_loss': 1.4776058, 'utility': 0.5026845, 'loss': -0.4583563}\n",
      "--- Step : 27 \n",
      "  ------- {'fairness_loss': 1.4760088, 'utility': 0.50272685, 'loss': -0.4584466}\n",
      "--- Step : 28 \n",
      "  ------- {'fairness_loss': 1.4762262, 'utility': 0.5028268, 'loss': -0.45854002}\n",
      "--- Step : 29 \n",
      "  ------- {'fairness_loss': 1.4780399, 'utility': 0.502978, 'loss': -0.45863682}\n",
      "--- Step : 30 \n",
      "  ------- {'fairness_loss': 1.4813958, 'utility': 0.50317067, 'loss': -0.4587288}\n",
      "--- Step : 31 \n",
      "  ------- {'fairness_loss': 1.4842533, 'utility': 0.5033473, 'loss': -0.4588197}\n",
      "--- Step : 32 \n",
      "  ------- {'fairness_loss': 1.4866126, 'utility': 0.503509, 'loss': -0.4589106}\n",
      "--- Step : 33 \n",
      "  ------- {'fairness_loss': 1.4885157, 'utility': 0.50365716, 'loss': -0.4590017}\n",
      "--- Step : 34 \n",
      "  ------- {'fairness_loss': 1.4900004, 'utility': 0.5037931, 'loss': -0.4590931}\n",
      "--- Step : 35 \n",
      "  ------- {'fairness_loss': 1.4911004, 'utility': 0.50391763, 'loss': -0.45918462}\n",
      "--- Step : 36 \n",
      "  ------- {'fairness_loss': 1.4918495, 'utility': 0.50403184, 'loss': -0.45927635}\n",
      "--- Step : 37 \n",
      "  ------- {'fairness_loss': 1.4922743, 'utility': 0.50413644, 'loss': -0.45936823}\n",
      "--- Step : 38 \n",
      "  ------- {'fairness_loss': 1.492401, 'utility': 0.50423217, 'loss': -0.45946014}\n",
      "--- Step : 39 \n",
      "  ------- {'fairness_loss': 1.4922507, 'utility': 0.50431985, 'loss': -0.45955232}\n",
      "--- Step : 40 \n",
      "  ------- {'fairness_loss': 1.4918485, 'utility': 0.5043999, 'loss': -0.45964444}\n",
      "--- Step : 41 \n",
      "  ------- {'fairness_loss': 1.4905312, 'utility': 0.50445306, 'loss': -0.45973712}\n",
      "--- Step : 42 \n",
      "  ------- {'fairness_loss': 1.4890633, 'utility': 0.5045018, 'loss': -0.45982993}\n",
      "--- Step : 43 \n",
      "  ------- {'fairness_loss': 1.4874561, 'utility': 0.5045463, 'loss': -0.4599226}\n",
      "--- Step : 44 \n",
      "  ------- {'fairness_loss': 1.4858301, 'utility': 0.504587, 'loss': -0.46001208}\n",
      "--- Step : 45 \n",
      "  ------- {'fairness_loss': 1.4861766, 'utility': 0.50468814, 'loss': -0.46010286}\n",
      "--- Step : 46 \n",
      "  ------- {'fairness_loss': 1.4880723, 'utility': 0.5048398, 'loss': -0.4601976}\n",
      "--- Step : 47 \n",
      "  ------- {'fairness_loss': 1.4890404, 'utility': 0.50495803, 'loss': -0.46028683}\n",
      "--- Step : 48 \n",
      "  ------- {'fairness_loss': 1.4889683, 'utility': 0.5050467, 'loss': -0.4603777}\n",
      "--- Step : 49 \n",
      "  ------- {'fairness_loss': 1.4881263, 'utility': 0.50510895, 'loss': -0.46046516}\n",
      "--- Step : 50 \n",
      "  ------- {'fairness_loss': 1.4883531, 'utility': 0.505205, 'loss': -0.4605544}\n",
      "--- Step : 51 \n",
      "  ------- {'fairness_loss': 1.4895351, 'utility': 0.50533074, 'loss': -0.4606447}\n",
      "--- Step : 52 \n",
      "  ------- {'fairness_loss': 1.4915267, 'utility': 0.5054776, 'loss': -0.4607318}\n",
      "--- Step : 53 \n",
      "  ------- {'fairness_loss': 1.4922723, 'utility': 0.50558645, 'loss': -0.4608183}\n",
      "--- Step : 54 \n",
      "  ------- {'fairness_loss': 1.4918195, 'utility': 0.50566155, 'loss': -0.46090695}\n",
      "--- Step : 55 \n",
      "  ------- {'fairness_loss': 1.4905316, 'utility': 0.5057069, 'loss': -0.46099097}\n",
      "--- Step : 56 \n",
      "  ------- {'fairness_loss': 1.4901488, 'utility': 0.5057805, 'loss': -0.46107605}\n",
      "--- Step : 57 \n",
      "  ------- {'fairness_loss': 1.4905735, 'utility': 0.50587964, 'loss': -0.46116245}\n",
      "--- Step : 58 \n",
      "  ------- {'fairness_loss': 1.4917237, 'utility': 0.506002, 'loss': -0.4612503}\n",
      "--- Step : 59 \n",
      "  ------- {'fairness_loss': 1.4935296, 'utility': 0.506145, 'loss': -0.46133912}\n",
      "--- Step : 60 \n",
      "  ------- {'fairness_loss': 1.4961962, 'utility': 0.5063066, 'loss': -0.4614207}\n",
      "--- Step : 61 \n",
      "  ------- {'fairness_loss': 1.4974843, 'utility': 0.5064294, 'loss': -0.46150485}\n",
      "--- Step : 62 \n",
      "  ------- {'fairness_loss': 1.497572, 'utility': 0.50651747, 'loss': -0.46159032}\n",
      "--- Step : 63 \n",
      "  ------- {'fairness_loss': 1.4967799, 'utility': 0.50657994, 'loss': -0.46167654}\n",
      "--- Step : 64 \n",
      "  ------- {'fairness_loss': 1.4951911, 'utility': 0.50661916, 'loss': -0.4617634}\n",
      "--- Step : 65 \n",
      "  ------- {'fairness_loss': 1.4948753, 'utility': 0.50669205, 'loss': -0.4618458}\n",
      "--- Step : 66 \n",
      "  ------- {'fairness_loss': 1.4955032, 'utility': 0.5067952, 'loss': -0.46193013}\n",
      "--- Step : 67 \n",
      "  ------- {'fairness_loss': 1.497062, 'utility': 0.5069254, 'loss': -0.46201354}\n",
      "--- Step : 68 \n",
      "  ------- {'fairness_loss': 1.497638, 'utility': 0.50702566, 'loss': -0.4620965}\n",
      "--- Step : 69 \n",
      "  ------- {'fairness_loss': 1.4972727, 'utility': 0.5070994, 'loss': -0.4621812}\n",
      "--- Step : 70 \n",
      "  ------- {'fairness_loss': 1.4962262, 'utility': 0.5071493, 'loss': -0.46226248}\n",
      "--- Step : 71 \n",
      "  ------- {'fairness_loss': 1.4962145, 'utility': 0.5072313, 'loss': -0.46234486}\n",
      "--- Step : 72 \n",
      "  ------- {'fairness_loss': 1.4971035, 'utility': 0.5073423, 'loss': -0.46242917}\n",
      "--- Step : 73 \n",
      "  ------- {'fairness_loss': 1.4988563, 'utility': 0.5074792, 'loss': -0.4625135}\n",
      "--- Step : 74 \n",
      "  ------- {'fairness_loss': 1.4996783, 'utility': 0.5075861, 'loss': -0.46259576}\n",
      "--- Step : 75 \n",
      "  ------- {'fairness_loss': 1.4995492, 'utility': 0.507666, 'loss': -0.4626795}\n",
      "--- Step : 76 \n",
      "  ------- {'fairness_loss': 1.4986786, 'utility': 0.5077218, 'loss': -0.46276143}\n",
      "--- Step : 77 \n",
      "  ------- {'fairness_loss': 1.4988372, 'utility': 0.50780904, 'loss': -0.46284392}\n",
      "--- Step : 78 \n",
      "  ------- {'fairness_loss': 1.4998753, 'utility': 0.5079244, 'loss': -0.46292812}\n",
      "--- Step : 79 \n",
      "  ------- {'fairness_loss': 1.5018578, 'utility': 0.50806516, 'loss': -0.46300942}\n",
      "--- Step : 80 \n",
      "  ------- {'fairness_loss': 1.5028223, 'utility': 0.50817585, 'loss': -0.4630912}\n",
      "--- Step : 81 \n",
      "  ------- {'fairness_loss': 1.5028322, 'utility': 0.5082596, 'loss': -0.46317464}\n",
      "--- Step : 82 \n",
      "  ------- {'fairness_loss': 1.5019855, 'utility': 0.508319, 'loss': -0.46325946}\n",
      "--- Step : 83 \n",
      "  ------- {'fairness_loss': 1.5005724, 'utility': 0.50835687, 'loss': -0.4633397}\n",
      "--- Step : 84 \n",
      "  ------- {'fairness_loss': 1.5002285, 'utility': 0.5084277, 'loss': -0.4634208}\n",
      "--- Step : 85 \n",
      "  ------- {'fairness_loss': 1.5008092, 'utility': 0.50852823, 'loss': -0.46350396}\n",
      "--- Step : 86 \n",
      "  ------- {'fairness_loss': 1.502222, 'utility': 0.5086555, 'loss': -0.46358883}\n",
      "--- Step : 87 \n",
      "  ------- {'fairness_loss': 1.5045016, 'utility': 0.5088067, 'loss': -0.46367165}\n",
      "--- Step : 88 \n",
      "  ------- {'fairness_loss': 1.5058159, 'utility': 0.50892717, 'loss': -0.4637527}\n",
      "--- Step : 89 \n",
      "  ------- {'fairness_loss': 1.506159, 'utility': 0.5090202, 'loss': -0.46383545}\n",
      "--- Step : 90 \n",
      "  ------- {'fairness_loss': 1.5056292, 'utility': 0.5090883, 'loss': -0.4639194}\n",
      "--- Step : 91 \n",
      "  ------- {'fairness_loss': 1.5043902, 'utility': 0.50913453, 'loss': -0.46400282}\n",
      "--- Step : 92 \n",
      "  ------- {'fairness_loss': 1.5042796, 'utility': 0.5092126, 'loss': -0.46408424}\n",
      "--- Step : 93 \n",
      "  ------- {'fairness_loss': 1.5050664, 'utility': 0.5093197, 'loss': -0.46416774}\n",
      "--- Step : 94 \n",
      "  ------- {'fairness_loss': 1.5067381, 'utility': 0.5094524, 'loss': -0.46425027}\n",
      "--- Step : 95 \n",
      "  ------- {'fairness_loss': 1.5074892, 'utility': 0.5095569, 'loss': -0.46433222}\n",
      "--- Step : 96 \n",
      "  ------- {'fairness_loss': 1.507338, 'utility': 0.50963575, 'loss': -0.4644156}\n",
      "--- Step : 97 \n",
      "  ------- {'fairness_loss': 1.5064769, 'utility': 0.5096918, 'loss': -0.46449748}\n",
      "--- Step : 98 \n",
      "  ------- {'fairness_loss': 1.5066437, 'utility': 0.50977874, 'loss': -0.46457943}\n",
      "--- Step : 99 \n",
      "  ------- {'fairness_loss': 1.5076741, 'utility': 0.50989366, 'loss': -0.46466345}\n",
      "--- Step : 100 \n",
      "  ------- {'fairness_loss': 1.5096397, 'utility': 0.5100334, 'loss': -0.46474424}\n",
      "--- Step : 101 \n",
      "  ------- {'fairness_loss': 1.5106273, 'utility': 0.51014435, 'loss': -0.46482554}\n",
      "--- Step : 102 \n",
      "  ------- {'fairness_loss': 1.5106995, 'utility': 0.5102296, 'loss': -0.4649086}\n",
      "--- Step : 103 \n",
      "  ------- {'fairness_loss': 1.5099515, 'utility': 0.5102915, 'loss': -0.46499297}\n",
      "--- Step : 104 \n",
      "  ------- {'fairness_loss': 1.5086403, 'utility': 0.51033247, 'loss': -0.46507326}\n",
      "--- Step : 105 \n",
      "  ------- {'fairness_loss': 1.5083929, 'utility': 0.5104061, 'loss': -0.4651543}\n",
      "--- Step : 106 \n",
      "  ------- {'fairness_loss': 1.5090514, 'utility': 0.5105086, 'loss': -0.46523705}\n",
      "--- Step : 107 \n",
      "  ------- {'fairness_loss': 1.5105231, 'utility': 0.5106375, 'loss': -0.46532184}\n",
      "--- Step : 108 \n",
      "  ------- {'fairness_loss': 1.512902, 'utility': 0.51078993, 'loss': -0.46540287}\n",
      "--- Step : 109 \n",
      "  ------- {'fairness_loss': 1.514308, 'utility': 0.51091254, 'loss': -0.4654833}\n",
      "--- Step : 110 \n",
      "  ------- {'fairness_loss': 1.5147734, 'utility': 0.5110087, 'loss': -0.46556547}\n",
      "--- Step : 111 \n",
      "  ------- {'fairness_loss': 1.5143926, 'utility': 0.51108074, 'loss': -0.46564895}\n",
      "--- Step : 112 \n",
      "  ------- {'fairness_loss': 1.5132562, 'utility': 0.5111314, 'loss': -0.4657337}\n",
      "--- Step : 113 \n",
      "  ------- {'fairness_loss': 1.5116813, 'utility': 0.511163, 'loss': -0.46581256}\n",
      "--- Step : 114 \n",
      "  ------- {'fairness_loss': 1.511172, 'utility': 0.51122785, 'loss': -0.46589267}\n",
      "--- Step : 115 \n",
      "  ------- {'fairness_loss': 1.511596, 'utility': 0.51132274, 'loss': -0.46597487}\n",
      "--- Step : 116 \n",
      "  ------- {'fairness_loss': 1.5128529, 'utility': 0.5114445, 'loss': -0.4660589}\n",
      "--- Step : 117 \n",
      "  ------- {'fairness_loss': 1.5148627, 'utility': 0.5115904, 'loss': -0.46614453}\n",
      "--- Step : 118 \n",
      "  ------- {'fairness_loss': 1.517842, 'utility': 0.51175797, 'loss': -0.4662227}\n",
      "--- Step : 119 \n",
      "  ------- {'fairness_loss': 1.5197616, 'utility': 0.511895, 'loss': -0.46630216}\n",
      "--- Step : 120 \n",
      "  ------- {'fairness_loss': 1.5207087, 'utility': 0.5120045, 'loss': -0.46638322}\n",
      "--- Step : 121 \n",
      "  ------- {'fairness_loss': 1.5207826, 'utility': 0.51208913, 'loss': -0.46646565}\n",
      "--- Step : 122 \n",
      "  ------- {'fairness_loss': 1.5200745, 'utility': 0.5121516, 'loss': -0.46654937}\n",
      "--- Step : 123 \n",
      "  ------- {'fairness_loss': 1.5186635, 'utility': 0.5121943, 'loss': -0.46663436}\n",
      "--- Step : 124 \n",
      "  ------- {'fairness_loss': 1.5167713, 'utility': 0.5122191, 'loss': -0.46671593}\n",
      "--- Step : 125 \n",
      "  ------- {'fairness_loss': 1.5160866, 'utility': 0.5122778, 'loss': -0.46679518}\n",
      "--- Step : 126 \n",
      "  ------- {'fairness_loss': 1.5163506, 'utility': 0.5123672, 'loss': -0.4668767}\n",
      "--- Step : 127 \n",
      "  ------- {'fairness_loss': 1.5174656, 'utility': 0.5124841, 'loss': -0.4669601}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 128 \n",
      "  ------- {'fairness_loss': 1.51935, 'utility': 0.5126255, 'loss': -0.467045}\n",
      "--- Step : 129 \n",
      "  ------- {'fairness_loss': 1.5222034, 'utility': 0.5127892, 'loss': -0.4671231}\n",
      "--- Step : 130 \n",
      "  ------- {'fairness_loss': 1.5240287, 'utility': 0.5129231, 'loss': -0.46720225}\n",
      "--- Step : 131 \n",
      "  ------- {'fairness_loss': 1.5249131, 'utility': 0.51303035, 'loss': -0.46728295}\n",
      "--- Step : 132 \n",
      "  ------- {'fairness_loss': 1.5249535, 'utility': 0.5131138, 'loss': -0.4673652}\n",
      "--- Step : 133 \n",
      "  ------- {'fairness_loss': 1.5242382, 'utility': 0.5131756, 'loss': -0.46744847}\n",
      "--- Step : 134 \n",
      "  ------- {'fairness_loss': 1.5228436, 'utility': 0.5132181, 'loss': -0.4675328}\n",
      "--- Step : 135 \n",
      "  ------- {'fairness_loss': 1.5210238, 'utility': 0.5132437, 'loss': -0.46761295}\n",
      "--- Step : 136 \n",
      "  ------- {'fairness_loss': 1.5203707, 'utility': 0.5133029, 'loss': -0.4676918}\n",
      "--- Step : 137 \n",
      "  ------- {'fairness_loss': 1.5206647, 'utility': 0.5133928, 'loss': -0.46777287}\n",
      "--- Step : 138 \n",
      "  ------- {'fairness_loss': 1.5218091, 'utility': 0.51351, 'loss': -0.46785572}\n",
      "--- Step : 139 \n",
      "  ------- {'fairness_loss': 1.5237168, 'utility': 0.51365167, 'loss': -0.46794015}\n",
      "--- Step : 140 \n",
      "  ------- {'fairness_loss': 1.5265745, 'utility': 0.5138157, 'loss': -0.46801847}\n",
      "--- Step : 141 \n",
      "  ------- {'fairness_loss': 1.5284466, 'utility': 0.5139505, 'loss': -0.46809712}\n",
      "--- Step : 142 \n",
      "  ------- {'fairness_loss': 1.5293976, 'utility': 0.51405925, 'loss': -0.46817732}\n",
      "--- Step : 143 \n",
      "  ------- {'fairness_loss': 1.5295202, 'utility': 0.5141444, 'loss': -0.46825883}\n",
      "--- Step : 144 \n",
      "  ------- {'fairness_loss': 1.5289015, 'utility': 0.5142084, 'loss': -0.46834132}\n",
      "--- Step : 145 \n",
      "  ------- {'fairness_loss': 1.5276186, 'utility': 0.5142537, 'loss': -0.46842512}\n",
      "--- Step : 146 \n",
      "  ------- {'fairness_loss': 1.5258847, 'utility': 0.5142819, 'loss': -0.46850538}\n",
      "--- Step : 147 \n",
      "  ------- {'fairness_loss': 1.5253317, 'utility': 0.5143438, 'loss': -0.46858385}\n",
      "--- Step : 148 \n",
      "  ------- {'fairness_loss': 1.5257181, 'utility': 0.514436, 'loss': -0.46866447}\n",
      "--- Step : 149 \n",
      "  ------- {'fairness_loss': 1.5269465, 'utility': 0.5145554, 'loss': -0.468747}\n",
      "--- Step : 150 \n",
      "  ------- {'fairness_loss': 1.5289739, 'utility': 0.5146991, 'loss': -0.46882987}\n",
      "--- Step : 151 \n",
      "  ------- {'fairness_loss': 1.5302445, 'utility': 0.51481634, 'loss': -0.46890903}\n",
      "--- Step : 152 \n",
      "  ------- {'fairness_loss': 1.5306752, 'utility': 0.51490974, 'loss': -0.4689895}\n",
      "--- Step : 153 \n",
      "  ------- {'fairness_loss': 1.5303538, 'utility': 0.5149816, 'loss': -0.46907103}\n",
      "--- Step : 154 \n",
      "  ------- {'fairness_loss': 1.529473, 'utility': 0.51503444, 'loss': -0.46915025}\n",
      "--- Step : 155 \n",
      "  ------- {'fairness_loss': 1.5296183, 'utility': 0.5151183, 'loss': -0.46922976}\n",
      "--- Step : 156 \n",
      "  ------- {'fairness_loss': 1.5306318, 'utility': 0.5152305, 'loss': -0.46931154}\n",
      "--- Step : 157 \n",
      "  ------- {'fairness_loss': 1.5325443, 'utility': 0.51536745, 'loss': -0.4693911}\n",
      "--- Step : 158 \n",
      "  ------- {'fairness_loss': 1.5336313, 'utility': 0.5154791, 'loss': -0.46947014}\n",
      "--- Step : 159 \n",
      "  ------- {'fairness_loss': 1.533916, 'utility': 0.515568, 'loss': -0.46955055}\n",
      "--- Step : 160 \n",
      "  ------- {'fairness_loss': 1.5334753, 'utility': 0.51563615, 'loss': -0.46963188}\n",
      "--- Step : 161 \n",
      "  ------- {'fairness_loss': 1.5324979, 'utility': 0.51568586, 'loss': -0.46971092}\n",
      "--- Step : 162 \n",
      "  ------- {'fairness_loss': 1.5325744, 'utility': 0.51576704, 'loss': -0.4697898}\n",
      "--- Step : 163 \n",
      "  ------- {'fairness_loss': 1.5335261, 'utility': 0.51587665, 'loss': -0.46987087}\n",
      "--- Step : 164 \n",
      "  ------- {'fairness_loss': 1.5353657, 'utility': 0.5160115, 'loss': -0.4699505}\n",
      "--- Step : 165 \n",
      "  ------- {'fairness_loss': 1.536414, 'utility': 0.5161217, 'loss': -0.47002926}\n",
      "--- Step : 166 \n",
      "  ------- {'fairness_loss': 1.5366789, 'utility': 0.51620936, 'loss': -0.470109}\n",
      "--- Step : 167 \n",
      "  ------- {'fairness_loss': 1.5362376, 'utility': 0.51627696, 'loss': -0.47018984}\n",
      "--- Step : 168 \n",
      "  ------- {'fairness_loss': 1.5353003, 'utility': 0.5163266, 'loss': -0.4702676}\n",
      "--- Step : 169 \n",
      "  ------- {'fairness_loss': 1.5353906, 'utility': 0.5164078, 'loss': -0.47034606}\n",
      "--- Step : 170 \n",
      "  ------- {'fairness_loss': 1.5363551, 'utility': 0.5165171, 'loss': -0.47042644}\n",
      "--- Step : 171 \n",
      "  ------- {'fairness_loss': 1.5381866, 'utility': 0.51665217, 'loss': -0.47050658}\n",
      "--- Step : 172 \n",
      "  ------- {'fairness_loss': 1.539263, 'utility': 0.5167625, 'loss': -0.4705846}\n",
      "--- Step : 173 \n",
      "  ------- {'fairness_loss': 1.53957, 'utility': 0.51685095, 'loss': -0.47066385}\n",
      "--- Step : 174 \n",
      "  ------- {'fairness_loss': 1.5391846, 'utility': 0.51691943, 'loss': -0.4707439}\n",
      "--- Step : 175 \n",
      "  ------- {'fairness_loss': 1.5383132, 'utility': 0.5169703, 'loss': -0.47082087}\n",
      "--- Step : 176 \n",
      "  ------- {'fairness_loss': 1.5384554, 'utility': 0.51705265, 'loss': -0.470899}\n",
      "--- Step : 177 \n",
      "  ------- {'fairness_loss': 1.5394689, 'utility': 0.5171631, 'loss': -0.47097903}\n",
      "--- Step : 178 \n",
      "  ------- {'fairness_loss': 1.5413655, 'utility': 0.517299, 'loss': -0.47105804}\n",
      "--- Step : 179 \n",
      "  ------- {'fairness_loss': 1.5425054, 'utility': 0.51741064, 'loss': -0.47113547}\n",
      "--- Step : 180 \n",
      "  ------- {'fairness_loss': 1.5428838, 'utility': 0.5175005, 'loss': -0.471214}\n",
      "--- Step : 181 \n",
      "  ------- {'fairness_loss': 1.5425786, 'utility': 0.51757085, 'loss': -0.4712935}\n",
      "--- Step : 182 \n",
      "  ------- {'fairness_loss': 1.5417379, 'utility': 0.5176236, 'loss': -0.47137147}\n",
      "--- Step : 183 \n",
      "  ------- {'fairness_loss': 1.5419523, 'utility': 0.5177077, 'loss': -0.47144914}\n",
      "--- Step : 184 \n",
      "  ------- {'fairness_loss': 1.5430334, 'utility': 0.51781976, 'loss': -0.47152877}\n",
      "--- Step : 185 \n",
      "  ------- {'fairness_loss': 1.5450729, 'utility': 0.5179571, 'loss': -0.4716049}\n",
      "--- Step : 186 \n",
      "  ------- {'fairness_loss': 1.5462897, 'utility': 0.5180703, 'loss': -0.4716816}\n",
      "--- Step : 187 \n",
      "  ------- {'fairness_loss': 1.5467561, 'utility': 0.51816213, 'loss': -0.47175944}\n",
      "--- Step : 188 \n",
      "  ------- {'fairness_loss': 1.5465424, 'utility': 0.5182344, 'loss': -0.47183812}\n",
      "--- Step : 189 \n",
      "  ------- {'fairness_loss': 1.5457225, 'utility': 0.5182895, 'loss': -0.47191784}\n",
      "--- Step : 190 \n",
      "  ------- {'fairness_loss': 1.5445352, 'utility': 0.51832885, 'loss': -0.4719928}\n",
      "--- Step : 191 \n",
      "  ------- {'fairness_loss': 1.5444028, 'utility': 0.5184008, 'loss': -0.4720687}\n",
      "--- Step : 192 \n",
      "  ------- {'fairness_loss': 1.545173, 'utility': 0.5185022, 'loss': -0.472147}\n",
      "--- Step : 193 \n",
      "  ------- {'fairness_loss': 1.5467582, 'utility': 0.51862985, 'loss': -0.4722271}\n",
      "--- Step : 194 \n",
      "  ------- {'fairness_loss': 1.5492887, 'utility': 0.51878107, 'loss': -0.4723024}\n",
      "--- Step : 195 \n",
      "  ------- {'fairness_loss': 1.5509943, 'utility': 0.5189076, 'loss': -0.47237778}\n",
      "--- Step : 196 \n",
      "  ------- {'fairness_loss': 1.5519161, 'utility': 0.5190114, 'loss': -0.4724539}\n",
      "--- Step : 197 \n",
      "  ------- {'fairness_loss': 1.552137, 'utility': 0.51909524, 'loss': -0.47253114}\n",
      "--- Step : 198 \n",
      "  ------- {'fairness_loss': 1.5517275, 'utility': 0.519161, 'loss': -0.47260916}\n",
      "--- Step : 199 \n",
      "  ------- {'fairness_loss': 1.550752, 'utility': 0.51921064, 'loss': -0.47268808}\n",
      "--- Step : 200 \n",
      "  ------- {'fairness_loss': 1.5493792, 'utility': 0.51924574, 'loss': -0.47276437}\n",
      "--- Step : 201 \n",
      "  ------- {'fairness_loss': 1.5491585, 'utility': 0.51931405, 'loss': -0.4728393}\n",
      "--- Step : 202 \n",
      "  ------- {'fairness_loss': 1.5498548, 'utility': 0.51941204, 'loss': -0.4729164}\n",
      "--- Step : 203 \n",
      "  ------- {'fairness_loss': 1.5513717, 'utility': 0.5195365, 'loss': -0.47299534}\n",
      "--- Step : 204 \n",
      "  ------- {'fairness_loss': 1.5538753, 'utility': 0.51968503, 'loss': -0.47306877}\n",
      "--- Step : 205 \n",
      "  ------- {'fairness_loss': 1.5555452, 'utility': 0.5198095, 'loss': -0.47314313}\n",
      "--- Step : 206 \n",
      "  ------- {'fairness_loss': 1.5564586, 'utility': 0.51991224, 'loss': -0.4732185}\n",
      "--- Step : 207 \n",
      "  ------- {'fairness_loss': 1.5566933, 'utility': 0.5199957, 'loss': -0.47329488}\n",
      "--- Step : 208 \n",
      "  ------- {'fairness_loss': 1.5563234, 'utility': 0.52006143, 'loss': -0.47337174}\n",
      "--- Step : 209 \n",
      "  ------- {'fairness_loss': 1.5554061, 'utility': 0.52011156, 'loss': -0.47344938}\n",
      "--- Step : 210 \n",
      "  ------- {'fairness_loss': 1.5540644, 'utility': 0.52014786, 'loss': -0.47352594}\n",
      "--- Step : 211 \n",
      "  ------- {'fairness_loss': 1.5539039, 'utility': 0.5202171, 'loss': -0.4736}\n",
      "--- Step : 212 \n",
      "  ------- {'fairness_loss': 1.5546585, 'utility': 0.520316, 'loss': -0.47367626}\n",
      "--- Step : 213 \n",
      "  ------- {'fairness_loss': 1.5562917, 'utility': 0.52044135, 'loss': -0.47375262}\n",
      "--- Step : 214 \n",
      "  ------- {'fairness_loss': 1.5572839, 'utility': 0.52054566, 'loss': -0.47382715}\n",
      "--- Step : 215 \n",
      "  ------- {'fairness_loss': 1.5576105, 'utility': 0.5206307, 'loss': -0.4739024}\n",
      "--- Step : 216 \n",
      "  ------- {'fairness_loss': 1.557341, 'utility': 0.5206985, 'loss': -0.47397825}\n",
      "--- Step : 217 \n",
      "  ------- {'fairness_loss': 1.5566608, 'utility': 0.52075124, 'loss': -0.47405142}\n",
      "--- Step : 218 \n",
      "  ------- {'fairness_loss': 1.5569774, 'utility': 0.5208351, 'loss': -0.47412577}\n",
      "--- Step : 219 \n",
      "  ------- {'fairness_loss': 1.5581572, 'utility': 0.52094716, 'loss': -0.47420245}\n",
      "--- Step : 220 \n",
      "  ------- {'fairness_loss': 1.5602913, 'utility': 0.52108437, 'loss': -0.47427562}\n",
      "--- Step : 221 \n",
      "  ------- {'fairness_loss': 1.5616933, 'utility': 0.5211997, 'loss': -0.4743489}\n",
      "--- Step : 222 \n",
      "  ------- {'fairness_loss': 1.5624062, 'utility': 0.5212951, 'loss': -0.47442287}\n",
      "--- Step : 223 \n",
      "  ------- {'fairness_loss': 1.5625004, 'utility': 0.52137256, 'loss': -0.47449756}\n",
      "--- Step : 224 \n",
      "  ------- {'fairness_loss': 1.5620384, 'utility': 0.52143407, 'loss': -0.47457293}\n",
      "--- Step : 225 \n",
      "  ------- {'fairness_loss': 1.561082, 'utility': 0.5214815, 'loss': -0.47464904}\n",
      "--- Step : 226 \n",
      "  ------- {'fairness_loss': 1.5599014, 'utility': 0.52151597, 'loss': -0.47471893}\n",
      "--- Step : 227 \n",
      "  ------- {'fairness_loss': 1.5597509, 'utility': 0.5215836, 'loss': -0.47479108}\n",
      "--- Step : 228 \n",
      "  ------- {'fairness_loss': 1.5605166, 'utility': 0.52168113, 'loss': -0.47486565}\n",
      "--- Step : 229 \n",
      "  ------- {'fairness_loss': 1.5621032, 'utility': 0.52180547, 'loss': -0.4749424}\n",
      "--- Step : 230 \n",
      "  ------- {'fairness_loss': 1.564598, 'utility': 0.52195364, 'loss': -0.4750157}\n",
      "--- Step : 231 \n",
      "  ------- {'fairness_loss': 1.5664036, 'utility': 0.5220795, 'loss': -0.4750874}\n",
      "--- Step : 232 \n",
      "  ------- {'fairness_loss': 1.5674995, 'utility': 0.5221848, 'loss': -0.4751598}\n",
      "--- Step : 233 \n",
      "  ------- {'fairness_loss': 1.5679643, 'utility': 0.52227175, 'loss': -0.47523284}\n",
      "--- Step : 234 \n",
      "  ------- {'fairness_loss': 1.5678583, 'utility': 0.52234244, 'loss': -0.4753067}\n",
      "--- Step : 235 \n",
      "  ------- {'fairness_loss': 1.567247, 'utility': 0.5223984, 'loss': -0.47538102}\n",
      "--- Step : 236 \n",
      "  ------- {'fairness_loss': 1.5661796, 'utility': 0.5224412, 'loss': -0.47545582}\n",
      "--- Step : 237 \n",
      "  ------- {'fairness_loss': 1.5648978, 'utility': 0.52247226, 'loss': -0.47552532}\n",
      "--- Step : 238 \n",
      "  ------- {'fairness_loss': 1.5646933, 'utility': 0.52253705, 'loss': -0.47559625}\n",
      "--- Step : 239 \n",
      "  ------- {'fairness_loss': 1.565415, 'utility': 0.5226319, 'loss': -0.47566944}\n",
      "--- Step : 240 \n",
      "  ------- {'fairness_loss': 1.5669651, 'utility': 0.5227539, 'loss': -0.47574493}\n",
      "--- Step : 241 \n",
      "  ------- {'fairness_loss': 1.5694352, 'utility': 0.5229, 'loss': -0.47581694}\n",
      "--- Step : 242 \n",
      "  ------- {'fairness_loss': 1.5712345, 'utility': 0.5230243, 'loss': -0.4758873}\n",
      "--- Step : 243 \n",
      "  ------- {'fairness_loss': 1.5723566, 'utility': 0.52312905, 'loss': -0.47595835}\n",
      "--- Step : 244 \n",
      "  ------- {'fairness_loss': 1.5728688, 'utility': 0.5232164, 'loss': -0.47603035}\n",
      "--- Step : 245 \n",
      "  ------- {'fairness_loss': 1.572831, 'utility': 0.5232878, 'loss': -0.47610283}\n",
      "--- Step : 246 \n",
      "  ------- {'fairness_loss': 1.5723083, 'utility': 0.52334493, 'loss': -0.4761757}\n",
      "--- Step : 247 \n",
      "  ------- {'fairness_loss': 1.5713466, 'utility': 0.52338946, 'loss': -0.47624907}\n",
      "--- Step : 248 \n",
      "  ------- {'fairness_loss': 1.5701268, 'utility': 0.5234228, 'loss': -0.476319}\n",
      "--- Step : 249 \n",
      "  ------- {'fairness_loss': 1.5700221, 'utility': 0.52348936, 'loss': -0.4763887}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 250 \n",
      "  ------- {'fairness_loss': 1.5708356, 'utility': 0.52358603, 'loss': -0.47646096}\n",
      "--- Step : 251 \n",
      "  ------- {'fairness_loss': 1.5724872, 'utility': 0.52370965, 'loss': -0.47653502}\n",
      "--- Step : 252 \n",
      "  ------- {'fairness_loss': 1.5736377, 'utility': 0.52381414, 'loss': -0.476605}\n",
      "--- Step : 253 \n",
      "  ------- {'fairness_loss': 1.5742002, 'utility': 0.5239018, 'loss': -0.4766758}\n",
      "--- Step : 254 \n",
      "  ------- {'fairness_loss': 1.5742373, 'utility': 0.5239741, 'loss': -0.476747}\n",
      "--- Step : 255 \n",
      "  ------- {'fairness_loss': 1.5738388, 'utility': 0.5240327, 'loss': -0.47681755}\n",
      "--- Step : 256 \n",
      "  ------- {'fairness_loss': 1.5744528, 'utility': 0.5241222, 'loss': -0.4768886}\n",
      "--- Step : 257 \n",
      "  ------- {'fairness_loss': 1.5760444, 'utility': 0.52423924, 'loss': -0.47695792}\n",
      "--- Step : 258 \n",
      "  ------- {'fairness_loss': 1.5770277, 'utility': 0.52433836, 'loss': -0.47702754}\n",
      "--- Step : 259 \n",
      "  ------- {'fairness_loss': 1.5774554, 'utility': 0.52442133, 'loss': -0.47709766}\n",
      "--- Step : 260 \n",
      "  ------- {'fairness_loss': 1.5773809, 'utility': 0.52448976, 'loss': -0.47716832}\n",
      "--- Step : 261 \n",
      "  ------- {'fairness_loss': 1.5768613, 'utility': 0.5245453, 'loss': -0.4772395}\n",
      "--- Step : 262 \n",
      "  ------- {'fairness_loss': 1.5760907, 'utility': 0.52458924, 'loss': -0.47730651}\n",
      "--- Step : 263 \n",
      "  ------- {'fairness_loss': 1.5763291, 'utility': 0.5246655, 'loss': -0.4773756}\n",
      "--- Step : 264 \n",
      "  ------- {'fairness_loss': 1.577455, 'utility': 0.52477074, 'loss': -0.4774471}\n",
      "--- Step : 265 \n",
      "  ------- {'fairness_loss': 1.5795074, 'utility': 0.52490205, 'loss': -0.47751683}\n",
      "--- Step : 266 \n",
      "  ------- {'fairness_loss': 1.5809811, 'utility': 0.52501446, 'loss': -0.47758502}\n",
      "--- Step : 267 \n",
      "  ------- {'fairness_loss': 1.5818709, 'utility': 0.5251097, 'loss': -0.4776536}\n",
      "--- Step : 268 \n",
      "  ------- {'fairness_loss': 1.5822337, 'utility': 0.5251899, 'loss': -0.47772288}\n",
      "--- Step : 269 \n",
      "  ------- {'fairness_loss': 1.5821221, 'utility': 0.5252561, 'loss': -0.47779244}\n",
      "--- Step : 270 \n",
      "  ------- {'fairness_loss': 1.5815915, 'utility': 0.5253101, 'loss': -0.47786236}\n",
      "--- Step : 271 \n",
      "  ------- {'fairness_loss': 1.5807294, 'utility': 0.5253532, 'loss': -0.47793132}\n",
      "--- Step : 272 \n",
      "  ------- {'fairness_loss': 1.5809777, 'utility': 0.5254287, 'loss': -0.4779994}\n",
      "--- Step : 273 \n",
      "  ------- {'fairness_loss': 1.5821455, 'utility': 0.5255333, 'loss': -0.47806895}\n",
      "--- Step : 274 \n",
      "  ------- {'fairness_loss': 1.5828378, 'utility': 0.52562225, 'loss': -0.4781371}\n",
      "--- Step : 275 \n",
      "  ------- {'fairness_loss': 1.5830427, 'utility': 0.525697, 'loss': -0.4782057}\n",
      "--- Step : 276 \n",
      "  ------- {'fairness_loss': 1.58286, 'utility': 0.525759, 'loss': -0.47827318}\n",
      "--- Step : 277 \n",
      "  ------- {'fairness_loss': 1.5836424, 'utility': 0.5258514, 'loss': -0.47834215}\n",
      "--- Step : 278 \n",
      "  ------- {'fairness_loss': 1.5854284, 'utility': 0.5259712, 'loss': -0.47840834}\n",
      "--- Step : 279 \n",
      "  ------- {'fairness_loss': 1.5866244, 'utility': 0.52607393, 'loss': -0.4784752}\n",
      "--- Step : 280 \n",
      "  ------- {'fairness_loss': 1.5872937, 'utility': 0.5261613, 'loss': -0.4785425}\n",
      "--- Step : 281 \n",
      "  ------- {'fairness_loss': 1.5875665, 'utility': 0.5262351, 'loss': -0.4786081}\n",
      "--- Step : 282 \n",
      "  ------- {'fairness_loss': 1.5871316, 'utility': 0.5262844, 'loss': -0.47867045}\n",
      "--- Step : 283 \n",
      "  ------- {'fairness_loss': 1.5860314, 'utility': 0.52631235, 'loss': -0.4787314}\n",
      "--- Step : 284 \n",
      "  ------- {'fairness_loss': 1.5857744, 'utility': 0.52636236, 'loss': -0.47878912}\n",
      "--- Step : 285 \n",
      "  ------- {'fairness_loss': 1.5861577, 'utility': 0.5264322, 'loss': -0.47884747}\n",
      "--- Step : 286 \n",
      "  ------- {'fairness_loss': 1.5871209, 'utility': 0.52652, 'loss': -0.4789064}\n",
      "--- Step : 287 \n",
      "  ------- {'fairness_loss': 1.5886022, 'utility': 0.52662396, 'loss': -0.4789659}\n",
      "--- Step : 288 \n",
      "  ------- {'fairness_loss': 1.5906906, 'utility': 0.5267424, 'loss': -0.47902167}\n",
      "--- Step : 289 \n",
      "  ------- {'fairness_loss': 1.5918323, 'utility': 0.52683276, 'loss': -0.4790778}\n",
      "--- Step : 290 \n",
      "  ------- {'fairness_loss': 1.592079, 'utility': 0.52689755, 'loss': -0.4791352}\n",
      "--- Step : 291 \n",
      "  ------- {'fairness_loss': 1.5915328, 'utility': 0.52693987, 'loss': -0.4791939}\n",
      "--- Step : 292 \n",
      "  ------- {'fairness_loss': 1.59044, 'utility': 0.5269619, 'loss': -0.47924873}\n",
      "--- Step : 293 \n",
      "  ------- {'fairness_loss': 1.5901159, 'utility': 0.5270067, 'loss': -0.4793032}\n",
      "--- Step : 294 \n",
      "  ------- {'fairness_loss': 1.5904493, 'utility': 0.527072, 'loss': -0.47935852}\n",
      "--- Step : 295 \n",
      "  ------- {'fairness_loss': 1.5913652, 'utility': 0.5271557, 'loss': -0.47941473}\n",
      "--- Step : 296 \n",
      "  ------- {'fairness_loss': 1.5928102, 'utility': 0.52725625, 'loss': -0.47947195}\n",
      "--- Step : 297 \n",
      "  ------- {'fairness_loss': 1.5947957, 'utility': 0.5273715, 'loss': -0.47952765}\n",
      "--- Step : 298 \n",
      "  ------- {'fairness_loss': 1.5959394, 'utility': 0.5274596, 'loss': -0.47958145}\n",
      "--- Step : 299 \n",
      "  ------- {'fairness_loss': 1.5962174, 'utility': 0.5275232, 'loss': -0.4796367}\n",
      "--- Step : 300 \n",
      "  ------- {'fairness_loss': 1.5957283, 'utility': 0.527565, 'loss': -0.47969314}\n",
      "--- Step : 301 \n",
      "  ------- {'fairness_loss': 1.596012, 'utility': 0.5276276, 'loss': -0.47974724}\n",
      "--- Step : 302 \n",
      "  ------- {'fairness_loss': 1.596907, 'utility': 0.5277089, 'loss': -0.47980168}\n",
      "--- Step : 303 \n",
      "  ------- {'fairness_loss': 1.5970356, 'utility': 0.52776676, 'loss': -0.4798557}\n",
      "--- Step : 304 \n",
      "  ------- {'fairness_loss': 1.5977923, 'utility': 0.5278441, 'loss': -0.4799103}\n",
      "--- Step : 305 \n",
      "  ------- {'fairness_loss': 1.5978274, 'utility': 0.5278983, 'loss': -0.47996348}\n",
      "--- Step : 306 \n",
      "  ------- {'fairness_loss': 1.5984867, 'utility': 0.5279724, 'loss': -0.4800178}\n",
      "--- Step : 307 \n",
      "  ------- {'fairness_loss': 1.5997717, 'utility': 0.52806395, 'loss': -0.4800708}\n",
      "--- Step : 308 \n",
      "  ------- {'fairness_loss': 1.6002293, 'utility': 0.52813137, 'loss': -0.48012447}\n",
      "--- Step : 309 \n",
      "  ------- {'fairness_loss': 1.5999578, 'utility': 0.5281772, 'loss': -0.48017848}\n",
      "--- Step : 310 \n",
      "  ------- {'fairness_loss': 1.6003926, 'utility': 0.52824366, 'loss': -0.48023188}\n",
      "--- Step : 311 \n",
      "  ------- {'fairness_loss': 1.6014453, 'utility': 0.5283285, 'loss': -0.4802851}\n",
      "--- Step : 312 \n",
      "  ------- {'fairness_loss': 1.6017113, 'utility': 0.5283902, 'loss': -0.4803389}\n",
      "--- Step : 313 \n",
      "  ------- {'fairness_loss': 1.6013522, 'utility': 0.5284309, 'loss': -0.4803903}\n",
      "--- Step : 314 \n",
      "  ------- {'fairness_loss': 1.6016598, 'utility': 0.52849287, 'loss': -0.48044306}\n",
      "--- Step : 315 \n",
      "  ------- {'fairness_loss': 1.6025699, 'utility': 0.528574, 'loss': -0.48049688}\n",
      "--- Step : 316 \n",
      "  ------- {'fairness_loss': 1.6040716, 'utility': 0.528672, 'loss': -0.48054984}\n",
      "--- Step : 317 \n",
      "  ------- {'fairness_loss': 1.6047881, 'utility': 0.5287457, 'loss': -0.4806021}\n",
      "--- Step : 318 \n",
      "  ------- {'fairness_loss': 1.6047376, 'utility': 0.5287978, 'loss': -0.48065567}\n",
      "--- Step : 319 \n",
      "  ------- {'fairness_loss': 1.6041238, 'utility': 0.52883047, 'loss': -0.48070675}\n",
      "--- Step : 320 \n",
      "  ------- {'fairness_loss': 1.604224, 'utility': 0.5288852, 'loss': -0.48075846}\n",
      "--- Step : 321 \n",
      "  ------- {'fairness_loss': 1.6049414, 'utility': 0.5289596, 'loss': -0.48081133}\n",
      "--- Step : 322 \n",
      "  ------- {'fairness_loss': 1.606224, 'utility': 0.52905184, 'loss': -0.48086512}\n",
      "--- Step : 323 \n",
      "  ------- {'fairness_loss': 1.6081445, 'utility': 0.5291601, 'loss': -0.48091576}\n",
      "--- Step : 324 \n",
      "  ------- {'fairness_loss': 1.6092262, 'utility': 0.5292436, 'loss': -0.4809668}\n",
      "--- Step : 325 \n",
      "  ------- {'fairness_loss': 1.6095166, 'utility': 0.52930474, 'loss': -0.48101926}\n",
      "--- Step : 326 \n",
      "  ------- {'fairness_loss': 1.6091061, 'utility': 0.5293459, 'loss': -0.48107275}\n",
      "--- Step : 327 \n",
      "  ------- {'fairness_loss': 1.608168, 'utility': 0.5293695, 'loss': -0.48112443}\n",
      "--- Step : 328 \n",
      "  ------- {'fairness_loss': 1.6080292, 'utility': 0.52941585, 'loss': -0.48117498}\n",
      "--- Step : 329 \n",
      "  ------- {'fairness_loss': 1.6085439, 'utility': 0.529483, 'loss': -0.4812267}\n",
      "--- Step : 330 \n",
      "  ------- {'fairness_loss': 1.6096413, 'utility': 0.5295687, 'loss': -0.48127943}\n",
      "--- Step : 331 \n",
      "  ------- {'fairness_loss': 1.6113129, 'utility': 0.52967113, 'loss': -0.48133174}\n",
      "--- Step : 332 \n",
      "  ------- {'fairness_loss': 1.6122525, 'utility': 0.52974993, 'loss': -0.48138237}\n",
      "--- Step : 333 \n",
      "  ------- {'fairness_loss': 1.6124392, 'utility': 0.52980745, 'loss': -0.4814343}\n",
      "--- Step : 334 \n",
      "  ------- {'fairness_loss': 1.6120052, 'utility': 0.52984613, 'loss': -0.48148596}\n",
      "--- Step : 335 \n",
      "  ------- {'fairness_loss': 1.6123124, 'utility': 0.52990615, 'loss': -0.48153678}\n",
      "--- Step : 336 \n",
      "  ------- {'fairness_loss': 1.6132278, 'utility': 0.52998567, 'loss': -0.48158884}\n",
      "--- Step : 337 \n",
      "  ------- {'fairness_loss': 1.6148072, 'utility': 0.53008246, 'loss': -0.48163825}\n",
      "--- Step : 338 \n",
      "  ------- {'fairness_loss': 1.615597, 'utility': 0.53015655, 'loss': -0.48168865}\n",
      "--- Step : 339 \n",
      "  ------- {'fairness_loss': 1.6156656, 'utility': 0.5302103, 'loss': -0.48174036}\n",
      "--- Step : 340 \n",
      "  ------- {'fairness_loss': 1.61512, 'utility': 0.53024596, 'loss': -0.48179236}\n",
      "--- Step : 341 \n",
      "  ------- {'fairness_loss': 1.6153581, 'utility': 0.5303033, 'loss': -0.48184255}\n",
      "--- Step : 342 \n",
      "  ------- {'fairness_loss': 1.6162142, 'utility': 0.5303804, 'loss': -0.48189402}\n",
      "--- Step : 343 \n",
      "  ------- {'fairness_loss': 1.617741, 'utility': 0.53047526, 'loss': -0.48194304}\n",
      "--- Step : 344 \n",
      "  ------- {'fairness_loss': 1.618495, 'utility': 0.53054786, 'loss': -0.48199302}\n",
      "--- Step : 345 \n",
      "  ------- {'fairness_loss': 1.6185495, 'utility': 0.53060067, 'loss': -0.4820442}\n",
      "--- Step : 346 \n",
      "  ------- {'fairness_loss': 1.6180118, 'utility': 0.5306357, 'loss': -0.48209536}\n",
      "--- Step : 347 \n",
      "  ------- {'fairness_loss': 1.6182559, 'utility': 0.5306928, 'loss': -0.48214513}\n",
      "--- Step : 348 \n",
      "  ------- {'fairness_loss': 1.618415, 'utility': 0.5307437, 'loss': -0.48219126}\n",
      "--- Step : 349 \n",
      "  ------- {'fairness_loss': 1.6183975, 'utility': 0.5307889, 'loss': -0.48223698}\n",
      "--- Step : 350 \n",
      "  ------- {'fairness_loss': 1.6182228, 'utility': 0.53082925, 'loss': -0.48228258}\n",
      "--- Step : 351 \n",
      "  ------- {'fairness_loss': 1.6179065, 'utility': 0.5308652, 'loss': -0.482328}\n",
      "--- Step : 352 \n",
      "  ------- {'fairness_loss': 1.617467, 'utility': 0.53089714, 'loss': -0.48237312}\n",
      "--- Step : 353 \n",
      "  ------- {'fairness_loss': 1.6169188, 'utility': 0.5309258, 'loss': -0.48241824}\n",
      "--- Step : 354 \n",
      "  ------- {'fairness_loss': 1.6162928, 'utility': 0.53095144, 'loss': -0.48246264}\n",
      "--- Step : 355 \n",
      "  ------- {'fairness_loss': 1.6158569, 'utility': 0.5309823, 'loss': -0.4825066}\n",
      "--- Step : 356 \n",
      "  ------- {'fairness_loss': 1.615583, 'utility': 0.5310179, 'loss': -0.4825504}\n",
      "--- Step : 357 \n",
      "  ------- {'fairness_loss': 1.615458, 'utility': 0.5310578, 'loss': -0.48259404}\n",
      "--- Step : 358 \n",
      "  ------- {'fairness_loss': 1.6154704, 'utility': 0.5311016, 'loss': -0.48263747}\n",
      "--- Step : 359 \n",
      "  ------- {'fairness_loss': 1.6156037, 'utility': 0.531149, 'loss': -0.48268092}\n",
      "--- Step : 360 \n",
      "  ------- {'fairness_loss': 1.615851, 'utility': 0.5311997, 'loss': -0.48272416}\n",
      "--- Step : 361 \n",
      "  ------- {'fairness_loss': 1.6162021, 'utility': 0.5312534, 'loss': -0.48276734}\n",
      "--- Step : 362 \n",
      "  ------- {'fairness_loss': 1.6166437, 'utility': 0.5313098, 'loss': -0.48281047}\n",
      "--- Step : 363 \n",
      "  ------- {'fairness_loss': 1.6171732, 'utility': 0.5313686, 'loss': -0.4828534}\n",
      "--- Step : 364 \n",
      "  ------- {'fairness_loss': 1.6177809, 'utility': 0.5314296, 'loss': -0.48289615}\n",
      "--- Step : 365 \n",
      "  ------- {'fairness_loss': 1.618457, 'utility': 0.5314927, 'loss': -0.482939}\n",
      "--- Step : 366 \n",
      "  ------- {'fairness_loss': 1.6191995, 'utility': 0.5315578, 'loss': -0.4829818}\n",
      "--- Step : 367 \n",
      "  ------- {'fairness_loss': 1.6199995, 'utility': 0.5316244, 'loss': -0.4830244}\n",
      "--- Step : 368 \n",
      "  ------- {'fairness_loss': 1.6208535, 'utility': 0.53169256, 'loss': -0.48306695}\n",
      "--- Step : 369 \n",
      "  ------- {'fairness_loss': 1.621758, 'utility': 0.53176206, 'loss': -0.48310933}\n",
      "--- Step : 370 \n",
      "  ------- {'fairness_loss': 1.6227044, 'utility': 0.53183293, 'loss': -0.4831518}\n",
      "--- Step : 371 \n",
      "  ------- {'fairness_loss': 1.6236929, 'utility': 0.53190494, 'loss': -0.48319414}\n",
      "--- Step : 372 \n",
      "  ------- {'fairness_loss': 1.6244711, 'utility': 0.5319702, 'loss': -0.48323607}\n",
      "--- Step : 373 \n",
      "  ------- {'fairness_loss': 1.6250464, 'utility': 0.5320294, 'loss': -0.483278}\n",
      "--- Step : 374 \n",
      "  ------- {'fairness_loss': 1.6254407, 'utility': 0.53208303, 'loss': -0.48331982}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 375 \n",
      "  ------- {'fairness_loss': 1.6256741, 'utility': 0.53213185, 'loss': -0.48336163}\n",
      "--- Step : 376 \n",
      "  ------- {'fairness_loss': 1.6257643, 'utility': 0.5321765, 'loss': -0.48340356}\n",
      "--- Step : 377 \n",
      "  ------- {'fairness_loss': 1.6257302, 'utility': 0.5322172, 'loss': -0.4834453}\n",
      "--- Step : 378 \n",
      "  ------- {'fairness_loss': 1.6258492, 'utility': 0.5322624, 'loss': -0.48348692}\n",
      "--- Step : 379 \n",
      "  ------- {'fairness_loss': 1.6261014, 'utility': 0.5323116, 'loss': -0.48352858}\n",
      "--- Step : 380 \n",
      "  ------- {'fairness_loss': 1.6264752, 'utility': 0.5323642, 'loss': -0.48356992}\n",
      "--- Step : 381 \n",
      "  ------- {'fairness_loss': 1.6269611, 'utility': 0.5324201, 'loss': -0.48361126}\n",
      "--- Step : 382 \n",
      "  ------- {'fairness_loss': 1.6275451, 'utility': 0.5324791, 'loss': -0.48365277}\n",
      "--- Step : 383 \n",
      "  ------- {'fairness_loss': 1.6282321, 'utility': 0.53254074, 'loss': -0.48369378}\n",
      "--- Step : 384 \n",
      "  ------- {'fairness_loss': 1.6287379, 'utility': 0.53259706, 'loss': -0.48373494}\n",
      "--- Step : 385 \n",
      "  ------- {'fairness_loss': 1.6290886, 'utility': 0.53264886, 'loss': -0.4837762}\n",
      "--- Step : 386 \n",
      "  ------- {'fairness_loss': 1.6292994, 'utility': 0.5326962, 'loss': -0.48381722}\n",
      "--- Step : 387 \n",
      "  ------- {'fairness_loss': 1.6293883, 'utility': 0.53274, 'loss': -0.48385835}\n",
      "--- Step : 388 \n",
      "  ------- {'fairness_loss': 1.6293691, 'utility': 0.5327803, 'loss': -0.4838992}\n",
      "--- Step : 389 \n",
      "  ------- {'fairness_loss': 1.6295149, 'utility': 0.53282535, 'loss': -0.48393992}\n",
      "--- Step : 390 \n",
      "  ------- {'fairness_loss': 1.6298039, 'utility': 0.53287476, 'loss': -0.48398066}\n",
      "--- Step : 391 \n",
      "  ------- {'fairness_loss': 1.6302259, 'utility': 0.5329283, 'loss': -0.4840215}\n",
      "--- Step : 392 \n",
      "  ------- {'fairness_loss': 1.6307712, 'utility': 0.5329853, 'loss': -0.4840622}\n",
      "--- Step : 393 \n",
      "  ------- {'fairness_loss': 1.6314248, 'utility': 0.5330454, 'loss': -0.48410267}\n",
      "--- Step : 394 \n",
      "  ------- {'fairness_loss': 1.6319247, 'utility': 0.5331009, 'loss': -0.48414317}\n",
      "--- Step : 395 \n",
      "  ------- {'fairness_loss': 1.632281, 'utility': 0.5331522, 'loss': -0.4841838}\n",
      "--- Step : 396 \n",
      "  ------- {'fairness_loss': 1.6325159, 'utility': 0.53319955, 'loss': -0.48422408}\n",
      "--- Step : 397 \n",
      "  ------- {'fairness_loss': 1.6326396, 'utility': 0.5332436, 'loss': -0.4842644}\n",
      "--- Step : 398 \n",
      "  ------- {'fairness_loss': 1.6326692, 'utility': 0.53328484, 'loss': -0.48430476}\n",
      "--- Step : 399 \n",
      "  ------- {'fairness_loss': 1.6328695, 'utility': 0.5333309, 'loss': -0.48434484}\n",
      "--- Step : 400 \n",
      "  ------- {'fairness_loss': 1.6332215, 'utility': 0.53338164, 'loss': -0.48438498}\n",
      "--- Step : 401 \n",
      "  ------- {'fairness_loss': 1.6337106, 'utility': 0.53343654, 'loss': -0.48442522}\n",
      "--- Step : 402 \n",
      "  ------- {'fairness_loss': 1.6343317, 'utility': 0.53349507, 'loss': -0.48446512}\n",
      "--- Step : 403 \n",
      "  ------- {'fairness_loss': 1.6348155, 'utility': 0.53354937, 'loss': -0.4845049}\n",
      "--- Step : 404 \n",
      "  ------- {'fairness_loss': 1.6351743, 'utility': 0.53360003, 'loss': -0.4845448}\n",
      "--- Step : 405 \n",
      "  ------- {'fairness_loss': 1.6354189, 'utility': 0.5336473, 'loss': -0.48458475}\n",
      "--- Step : 406 \n",
      "  ------- {'fairness_loss': 1.635569, 'utility': 0.5336915, 'loss': -0.48462445}\n",
      "--- Step : 407 \n",
      "  ------- {'fairness_loss': 1.6356322, 'utility': 0.53373307, 'loss': -0.4846641}\n",
      "--- Step : 408 \n",
      "  ------- {'fairness_loss': 1.6358786, 'utility': 0.5337801, 'loss': -0.48470375}\n",
      "--- Step : 409 \n",
      "  ------- {'fairness_loss': 1.6362809, 'utility': 0.53383183, 'loss': -0.48474342}\n",
      "--- Step : 410 \n",
      "  ------- {'fairness_loss': 1.636832, 'utility': 0.5338878, 'loss': -0.48478284}\n",
      "--- Step : 411 \n",
      "  ------- {'fairness_loss': 1.6372638, 'utility': 0.53394026, 'loss': -0.48482233}\n",
      "--- Step : 412 \n",
      "  ------- {'fairness_loss': 1.6375899, 'utility': 0.5339894, 'loss': -0.48486173}\n",
      "--- Step : 413 \n",
      "  ------- {'fairness_loss': 1.63782, 'utility': 0.53403574, 'loss': -0.48490113}\n",
      "--- Step : 414 \n",
      "  ------- {'fairness_loss': 1.6379672, 'utility': 0.53407925, 'loss': -0.48494023}\n",
      "--- Step : 415 \n",
      "  ------- {'fairness_loss': 1.6380455, 'utility': 0.53412074, 'loss': -0.48497936}\n",
      "--- Step : 416 \n",
      "  ------- {'fairness_loss': 1.6383109, 'utility': 0.5341678, 'loss': -0.4850185}\n",
      "--- Step : 417 \n",
      "  ------- {'fairness_loss': 1.6387417, 'utility': 0.53421986, 'loss': -0.48505762}\n",
      "--- Step : 418 \n",
      "  ------- {'fairness_loss': 1.6393294, 'utility': 0.53427655, 'loss': -0.48509666}\n",
      "--- Step : 419 \n",
      "  ------- {'fairness_loss': 1.6398106, 'utility': 0.5343298, 'loss': -0.48513547}\n",
      "--- Step : 420 \n",
      "  ------- {'fairness_loss': 1.6401914, 'utility': 0.53438, 'loss': -0.48517427}\n",
      "--- Step : 421 \n",
      "  ------- {'fairness_loss': 1.6404825, 'utility': 0.5344276, 'loss': -0.4852131}\n",
      "--- Step : 422 \n",
      "  ------- {'fairness_loss': 1.6406953, 'utility': 0.5344729, 'loss': -0.48525202}\n",
      "--- Step : 423 \n",
      "  ------- {'fairness_loss': 1.6408402, 'utility': 0.53451586, 'loss': -0.48529065}\n",
      "--- Step : 424 \n",
      "  ------- {'fairness_loss': 1.6409279, 'utility': 0.53455704, 'loss': -0.4853292}\n",
      "--- Step : 425 \n",
      "  ------- {'fairness_loss': 1.6412148, 'utility': 0.5346043, 'loss': -0.48536786}\n",
      "--- Step : 426 \n",
      "  ------- {'fairness_loss': 1.6416824, 'utility': 0.5346569, 'loss': -0.4854064}\n",
      "--- Step : 427 \n",
      "  ------- {'fairness_loss': 1.6420671, 'utility': 0.53470665, 'loss': -0.48544464}\n",
      "--- Step : 428 \n",
      "  ------- {'fairness_loss': 1.6423707, 'utility': 0.53475416, 'loss': -0.48548305}\n",
      "--- Step : 429 \n",
      "  ------- {'fairness_loss': 1.6426088, 'utility': 0.53479964, 'loss': -0.48552138}\n",
      "--- Step : 430 \n",
      "  ------- {'fairness_loss': 1.6427861, 'utility': 0.5348432, 'loss': -0.4855596}\n",
      "--- Step : 431 \n",
      "  ------- {'fairness_loss': 1.6429169, 'utility': 0.5348852, 'loss': -0.48559773}\n",
      "--- Step : 432 \n",
      "  ------- {'fairness_loss': 1.643249, 'utility': 0.53493327, 'loss': -0.4856358}\n",
      "--- Step : 433 \n",
      "  ------- {'fairness_loss': 1.6437687, 'utility': 0.5349869, 'loss': -0.48567384}\n",
      "--- Step : 434 \n",
      "  ------- {'fairness_loss': 1.644206, 'utility': 0.5350381, 'loss': -0.48571193}\n",
      "--- Step : 435 \n",
      "  ------- {'fairness_loss': 1.6445739, 'utility': 0.53508705, 'loss': -0.48574984}\n",
      "--- Step : 436 \n",
      "  ------- {'fairness_loss': 1.6448783, 'utility': 0.5351341, 'loss': -0.48578772}\n",
      "--- Step : 437 \n",
      "  ------- {'fairness_loss': 1.6451275, 'utility': 0.53517926, 'loss': -0.48582542}\n",
      "--- Step : 438 \n",
      "  ------- {'fairness_loss': 1.6453431, 'utility': 0.53522307, 'loss': -0.4858628}\n",
      "--- Step : 439 \n",
      "  ------- {'fairness_loss': 1.6472008, 'utility': 0.5353165, 'loss': -0.4859005}\n",
      "--- Step : 440 \n",
      "  ------- {'fairness_loss': 1.6488626, 'utility': 0.5354038, 'loss': -0.48593792}\n",
      "--- Step : 441 \n",
      "  ------- {'fairness_loss': 1.6503363, 'utility': 0.5354853, 'loss': -0.48597524}\n",
      "--- Step : 442 \n",
      "  ------- {'fairness_loss': 1.6516396, 'utility': 0.53556186, 'loss': -0.48601267}\n",
      "--- Step : 443 \n",
      "  ------- {'fairness_loss': 1.652787, 'utility': 0.53563356, 'loss': -0.48604995}\n",
      "--- Step : 444 \n",
      "  ------- {'fairness_loss': 1.6538007, 'utility': 0.53570116, 'loss': -0.48608714}\n",
      "--- Step : 445 \n",
      "  ------- {'fairness_loss': 1.6546881, 'utility': 0.535765, 'loss': -0.48612434}\n",
      "--- Step : 446 \n",
      "  ------- {'fairness_loss': 1.6554648, 'utility': 0.5358254, 'loss': -0.48616144}\n",
      "--- Step : 447 \n",
      "  ------- {'fairness_loss': 1.6561413, 'utility': 0.5358829, 'loss': -0.48619866}\n",
      "--- Step : 448 \n",
      "  ------- {'fairness_loss': 1.6567291, 'utility': 0.5359376, 'loss': -0.48623574}\n",
      "--- Step : 449 \n",
      "  ------- {'fairness_loss': 1.6572428, 'utility': 0.53599, 'loss': -0.48627272}\n",
      "--- Step : 450 \n",
      "  ------- {'fairness_loss': 1.6576841, 'utility': 0.53604025, 'loss': -0.48630974}\n",
      "--- Step : 451 \n",
      "  ------- {'fairness_loss': 1.6580645, 'utility': 0.5360885, 'loss': -0.4863466}\n",
      "--- Step : 452 \n",
      "  ------- {'fairness_loss': 1.658392, 'utility': 0.5361353, 'loss': -0.48638356}\n",
      "--- Step : 453 \n",
      "  ------- {'fairness_loss': 1.6586732, 'utility': 0.5361806, 'loss': -0.48642042}\n",
      "--- Step : 454 \n",
      "  ------- {'fairness_loss': 1.6589128, 'utility': 0.53622454, 'loss': -0.48645717}\n",
      "--- Step : 455 \n",
      "  ------- {'fairness_loss': 1.6591182, 'utility': 0.5362676, 'loss': -0.48649403}\n",
      "--- Step : 456 \n",
      "  ------- {'fairness_loss': 1.6592947, 'utility': 0.5363094, 'loss': -0.48653057}\n",
      "--- Step : 457 \n",
      "  ------- {'fairness_loss': 1.6594461, 'utility': 0.53635055, 'loss': -0.48656717}\n",
      "--- Step : 458 \n",
      "  ------- {'fairness_loss': 1.6595762, 'utility': 0.53639096, 'loss': -0.48660368}\n",
      "--- Step : 459 \n",
      "  ------- {'fairness_loss': 1.6596901, 'utility': 0.5364309, 'loss': -0.4866402}\n",
      "--- Step : 460 \n",
      "  ------- {'fairness_loss': 1.6597917, 'utility': 0.5364705, 'loss': -0.48667672}\n",
      "--- Step : 461 \n",
      "  ------- {'fairness_loss': 1.659885, 'utility': 0.5365095, 'loss': -0.48671296}\n",
      "--- Step : 462 \n",
      "  ------- {'fairness_loss': 1.6599674, 'utility': 0.5365483, 'loss': -0.4867493}\n",
      "--- Step : 463 \n",
      "  ------- {'fairness_loss': 1.660047, 'utility': 0.5365871, 'loss': -0.4867857}\n",
      "--- Step : 464 \n",
      "  ------- {'fairness_loss': 1.6601243, 'utility': 0.53662544, 'loss': -0.4868217}\n",
      "--- Step : 465 \n",
      "  ------- {'fairness_loss': 1.6602021, 'utility': 0.5366639, 'loss': -0.48685783}\n",
      "--- Step : 466 \n",
      "  ------- {'fairness_loss': 1.66028, 'utility': 0.53670233, 'loss': -0.48689395}\n",
      "--- Step : 467 \n",
      "  ------- {'fairness_loss': 1.660364, 'utility': 0.5367408, 'loss': -0.48692986}\n",
      "--- Step : 468 \n",
      "  ------- {'fairness_loss': 1.6604521, 'utility': 0.53677946, 'loss': -0.4869659}\n",
      "--- Step : 469 \n",
      "  ------- {'fairness_loss': 1.6605465, 'utility': 0.5368181, 'loss': -0.4870017}\n",
      "--- Step : 470 \n",
      "  ------- {'fairness_loss': 1.6606476, 'utility': 0.53685695, 'loss': -0.4870375}\n",
      "--- Step : 471 \n",
      "  ------- {'fairness_loss': 1.660757, 'utility': 0.53689593, 'loss': -0.4870732}\n",
      "--- Step : 472 \n",
      "  ------- {'fairness_loss': 1.6608768, 'utility': 0.5369352, 'loss': -0.48710892}\n",
      "--- Step : 473 \n",
      "  ------- {'fairness_loss': 1.6610508, 'utility': 0.5369748, 'loss': -0.48714328}\n",
      "--- Step : 474 \n",
      "  ------- {'fairness_loss': 1.6627965, 'utility': 0.5370638, 'loss': -0.48717988}\n",
      "--- Step : 475 \n",
      "  ------- {'fairness_loss': 1.6644306, 'utility': 0.5371484, 'loss': -0.4872155}\n",
      "--- Step : 476 \n",
      "  ------- {'fairness_loss': 1.6659253, 'utility': 0.5372284, 'loss': -0.48725066}\n",
      "--- Step : 477 \n",
      "  ------- {'fairness_loss': 1.6672885, 'utility': 0.5373049, 'loss': -0.4872862}\n",
      "--- Step : 478 \n",
      "  ------- {'fairness_loss': 1.6685407, 'utility': 0.53737754, 'loss': -0.48732132}\n",
      "--- Step : 479 \n",
      "  ------- {'fairness_loss': 1.6696863, 'utility': 0.5374473, 'loss': -0.4873567}\n",
      "--- Step : 480 \n",
      "  ------- {'fairness_loss': 1.6707389, 'utility': 0.53751385, 'loss': -0.48739168}\n",
      "--- Step : 481 \n",
      "  ------- {'fairness_loss': 1.6717101, 'utility': 0.53757805, 'loss': -0.48742676}\n",
      "--- Step : 482 \n",
      "  ------- {'fairness_loss': 1.6726052, 'utility': 0.53764, 'loss': -0.4874618}\n",
      "--- Step : 483 \n",
      "  ------- {'fairness_loss': 1.6734302, 'utility': 0.53769994, 'loss': -0.48749703}\n",
      "--- Step : 484 \n",
      "  ------- {'fairness_loss': 1.6741965, 'utility': 0.5377577, 'loss': -0.4875318}\n",
      "--- Step : 485 \n",
      "  ------- {'fairness_loss': 1.6749107, 'utility': 0.53781396, 'loss': -0.48756665}\n",
      "--- Step : 486 \n",
      "  ------- {'fairness_loss': 1.6755772, 'utility': 0.5378689, 'loss': -0.4876016}\n",
      "--- Step : 487 \n",
      "  ------- {'fairness_loss': 1.6762035, 'utility': 0.5379225, 'loss': -0.4876364}\n",
      "--- Step : 488 \n",
      "  ------- {'fairness_loss': 1.676791, 'utility': 0.53797495, 'loss': -0.48767123}\n",
      "--- Step : 489 \n",
      "  ------- {'fairness_loss': 1.6773454, 'utility': 0.5380263, 'loss': -0.48770592}\n",
      "--- Step : 490 \n",
      "  ------- {'fairness_loss': 1.6778758, 'utility': 0.5380768, 'loss': -0.48774055}\n",
      "--- Step : 491 \n",
      "  ------- {'fairness_loss': 1.6783799, 'utility': 0.5381264, 'loss': -0.48777503}\n",
      "--- Step : 492 \n",
      "  ------- {'fairness_loss': 1.6788651, 'utility': 0.53817564, 'loss': -0.4878097}\n",
      "--- Step : 493 \n",
      "  ------- {'fairness_loss': 1.6793303, 'utility': 0.538224, 'loss': -0.48784408}\n",
      "--- Step : 494 \n",
      "  ------- {'fairness_loss': 1.6797847, 'utility': 0.538272, 'loss': -0.4878785}\n",
      "--- Step : 495 \n",
      "  ------- {'fairness_loss': 1.6802258, 'utility': 0.5383196, 'loss': -0.4879128}\n",
      "--- Step : 496 \n",
      "  ------- {'fairness_loss': 1.6806575, 'utility': 0.53836673, 'loss': -0.48794702}\n",
      "--- Step : 497 \n",
      "  ------- {'fairness_loss': 1.6810817, 'utility': 0.5384138, 'loss': -0.48798138}\n",
      "--- Step : 498 \n",
      "  ------- {'fairness_loss': 1.681502, 'utility': 0.5384607, 'loss': -0.48801562}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 499 \n",
      "  ------- {'fairness_loss': 1.6819166, 'utility': 0.5385073, 'loss': -0.48804978}\n",
      "--- Step : 500 \n",
      "  ------- {'fairness_loss': 1.6823311, 'utility': 0.5385538, 'loss': -0.48808384}\n",
      "--- Step : 501 \n",
      "  ------- {'fairness_loss': 1.6827455, 'utility': 0.53860015, 'loss': -0.48811778}\n",
      "--- Step : 502 \n",
      "  ------- {'fairness_loss': 1.6831582, 'utility': 0.5386466, 'loss': -0.48815185}\n",
      "--- Step : 503 \n",
      "  ------- {'fairness_loss': 1.6835748, 'utility': 0.5386929, 'loss': -0.48818564}\n",
      "--- Step : 504 \n",
      "  ------- {'fairness_loss': 1.6839938, 'utility': 0.5387392, 'loss': -0.48821938}\n",
      "--- Step : 505 \n",
      "  ------- {'fairness_loss': 1.6844158, 'utility': 0.53878564, 'loss': -0.48825318}\n",
      "--- Step : 506 \n",
      "  ------- {'fairness_loss': 1.6848438, 'utility': 0.5388324, 'loss': -0.48828712}\n",
      "--- Step : 507 \n",
      "  ------- {'fairness_loss': 1.6852762, 'utility': 0.538879, 'loss': -0.4883207}\n",
      "--- Step : 508 \n",
      "  ------- {'fairness_loss': 1.6857154, 'utility': 0.5389257, 'loss': -0.48835424}\n",
      "--- Step : 509 \n",
      "  ------- {'fairness_loss': 1.6861621, 'utility': 0.53897274, 'loss': -0.48838788}\n",
      "--- Step : 510 \n",
      "  ------- {'fairness_loss': 1.6866152, 'utility': 0.5390196, 'loss': -0.48842114}\n",
      "--- Step : 511 \n",
      "  ------- {'fairness_loss': 1.6870736, 'utility': 0.539067, 'loss': -0.48845476}\n",
      "--- Step : 512 \n",
      "  ------- {'fairness_loss': 1.68754, 'utility': 0.53911436, 'loss': -0.48848817}\n",
      "--- Step : 513 \n",
      "  ------- {'fairness_loss': 1.6880168, 'utility': 0.53916204, 'loss': -0.48852155}\n",
      "--- Step : 514 \n",
      "  ------- {'fairness_loss': 1.6884987, 'utility': 0.5392097, 'loss': -0.48855478}\n",
      "--- Step : 515 \n",
      "  ------- {'fairness_loss': 1.6889931, 'utility': 0.5392578, 'loss': -0.48858804}\n",
      "--- Step : 516 \n",
      "  ------- {'fairness_loss': 1.6894954, 'utility': 0.53930604, 'loss': -0.48862118}\n",
      "--- Step : 517 \n",
      "  ------- {'fairness_loss': 1.6900065, 'utility': 0.5393544, 'loss': -0.4886542}\n",
      "--- Step : 518 \n",
      "  ------- {'fairness_loss': 1.6905255, 'utility': 0.53940314, 'loss': -0.48868737}\n",
      "--- Step : 519 \n",
      "  ------- {'fairness_loss': 1.6910548, 'utility': 0.53945184, 'loss': -0.48872018}\n",
      "--- Step : 520 \n",
      "  ------- {'fairness_loss': 1.6915934, 'utility': 0.5395011, 'loss': -0.48875326}\n",
      "--- Step : 521 \n",
      "  ------- {'fairness_loss': 1.6921384, 'utility': 0.53955036, 'loss': -0.48878622}\n",
      "--- Step : 522 \n",
      "  ------- {'fairness_loss': 1.6926953, 'utility': 0.5395998, 'loss': -0.4888189}\n",
      "--- Step : 523 \n",
      "  ------- {'fairness_loss': 1.6932615, 'utility': 0.5396496, 'loss': -0.48885176}\n",
      "--- Step : 524 \n",
      "  ------- {'fairness_loss': 1.6938361, 'utility': 0.5396996, 'loss': -0.48888454}\n",
      "--- Step : 525 \n",
      "  ------- {'fairness_loss': 1.6944206, 'utility': 0.53974974, 'loss': -0.4889171}\n",
      "--- Step : 526 \n",
      "  ------- {'fairness_loss': 1.6950159, 'utility': 0.53980017, 'loss': -0.4889497}\n",
      "--- Step : 527 \n",
      "  ------- {'fairness_loss': 1.695617, 'utility': 0.53985083, 'loss': -0.48898232}\n",
      "--- Step : 528 \n",
      "  ------- {'fairness_loss': 1.6962302, 'utility': 0.53990173, 'loss': -0.48901483}\n",
      "--- Step : 529 \n",
      "  ------- {'fairness_loss': 1.6968484, 'utility': 0.5399528, 'loss': -0.48904735}\n",
      "--- Step : 530 \n",
      "  ------- {'fairness_loss': 1.6974778, 'utility': 0.540004, 'loss': -0.48907968}\n",
      "--- Step : 531 \n",
      "  ------- {'fairness_loss': 1.6981171, 'utility': 0.5400556, 'loss': -0.48911205}\n",
      "--- Step : 532 \n",
      "  ------- {'fairness_loss': 1.6987648, 'utility': 0.54010725, 'loss': -0.4891443}\n",
      "--- Step : 533 \n",
      "  ------- {'fairness_loss': 1.6994197, 'utility': 0.54015917, 'loss': -0.48917657}\n",
      "--- Step : 534 \n",
      "  ------- {'fairness_loss': 1.7000817, 'utility': 0.5402113, 'loss': -0.48920888}\n",
      "--- Step : 535 \n",
      "  ------- {'fairness_loss': 1.7007552, 'utility': 0.5402636, 'loss': -0.48924094}\n",
      "--- Step : 536 \n",
      "  ------- {'fairness_loss': 1.7014347, 'utility': 0.540316, 'loss': -0.48927295}\n",
      "--- Step : 537 \n",
      "  ------- {'fairness_loss': 1.7021214, 'utility': 0.5403687, 'loss': -0.48930502}\n",
      "--- Step : 538 \n",
      "  ------- {'fairness_loss': 1.7028191, 'utility': 0.5404216, 'loss': -0.48933703}\n",
      "--- Step : 539 \n",
      "  ------- {'fairness_loss': 1.7035211, 'utility': 0.5404747, 'loss': -0.4893691}\n",
      "--- Step : 540 \n",
      "  ------- {'fairness_loss': 1.704233, 'utility': 0.5405279, 'loss': -0.4894009}\n",
      "--- Step : 541 \n",
      "  ------- {'fairness_loss': 1.704952, 'utility': 0.5405812, 'loss': -0.48943266}\n",
      "--- Step : 542 \n",
      "  ------- {'fairness_loss': 1.705678, 'utility': 0.5406347, 'loss': -0.48946434}\n",
      "--- Step : 543 \n",
      "  ------- {'fairness_loss': 1.7064116, 'utility': 0.54068846, 'loss': -0.4894961}\n",
      "--- Step : 544 \n",
      "  ------- {'fairness_loss': 1.7071508, 'utility': 0.54074234, 'loss': -0.48952782}\n",
      "--- Step : 545 \n",
      "  ------- {'fairness_loss': 1.7078987, 'utility': 0.5407964, 'loss': -0.48955944}\n",
      "--- Step : 546 \n",
      "  ------- {'fairness_loss': 1.7086526, 'utility': 0.5408505, 'loss': -0.48959094}\n",
      "--- Step : 547 \n",
      "  ------- {'fairness_loss': 1.7094134, 'utility': 0.5409049, 'loss': -0.48962247}\n",
      "--- Step : 548 \n",
      "  ------- {'fairness_loss': 1.7101797, 'utility': 0.5409594, 'loss': -0.48965403}\n",
      "--- Step : 549 \n",
      "  ------- {'fairness_loss': 1.7109531, 'utility': 0.541014, 'loss': -0.48968542}\n",
      "--- Step : 550 \n",
      "  ------- {'fairness_loss': 1.7117325, 'utility': 0.54106885, 'loss': -0.4897169}\n",
      "--- Step : 551 \n",
      "  ------- {'fairness_loss': 1.712517, 'utility': 0.5411236, 'loss': -0.48974812}\n",
      "--- Step : 552 \n",
      "  ------- {'fairness_loss': 1.7133098, 'utility': 0.5411787, 'loss': -0.4897794}\n",
      "--- Step : 553 \n",
      "  ------- {'fairness_loss': 1.714105, 'utility': 0.5412337, 'loss': -0.4898106}\n",
      "--- Step : 554 \n",
      "  ------- {'fairness_loss': 1.7149079, 'utility': 0.541289, 'loss': -0.48984173}\n",
      "--- Step : 555 \n",
      "  ------- {'fairness_loss': 1.7157158, 'utility': 0.5413444, 'loss': -0.48987293}\n",
      "--- Step : 556 \n",
      "  ------- {'fairness_loss': 1.7165306, 'utility': 0.5413999, 'loss': -0.489904}\n",
      "--- Step : 557 \n",
      "  ------- {'fairness_loss': 1.7173485, 'utility': 0.5414554, 'loss': -0.48993492}\n",
      "--- Step : 558 \n",
      "  ------- {'fairness_loss': 1.7181728, 'utility': 0.54151106, 'loss': -0.4899659}\n",
      "--- Step : 559 \n",
      "  ------- {'fairness_loss': 1.7190003, 'utility': 0.54156685, 'loss': -0.48999685}\n",
      "--- Step : 560 \n",
      "  ------- {'fairness_loss': 1.7198362, 'utility': 0.5416228, 'loss': -0.49002773}\n",
      "--- Step : 561 \n",
      "  ------- {'fairness_loss': 1.7206734, 'utility': 0.5416787, 'loss': -0.49005854}\n",
      "--- Step : 562 \n",
      "  ------- {'fairness_loss': 1.721515, 'utility': 0.54173476, 'loss': -0.4900893}\n",
      "--- Step : 563 \n",
      "  ------- {'fairness_loss': 1.7223642, 'utility': 0.54179096, 'loss': -0.49012005}\n",
      "--- Step : 564 \n",
      "  ------- {'fairness_loss': 1.7232162, 'utility': 0.5418471, 'loss': -0.49015063}\n",
      "--- Step : 565 \n",
      "  ------- {'fairness_loss': 1.7240711, 'utility': 0.5419034, 'loss': -0.49018124}\n",
      "--- Step : 566 \n",
      "  ------- {'fairness_loss': 1.7249326, 'utility': 0.5419597, 'loss': -0.49021173}\n",
      "--- Step : 567 \n",
      "  ------- {'fairness_loss': 1.7257966, 'utility': 0.54201627, 'loss': -0.49024236}\n",
      "--- Step : 568 \n",
      "  ------- {'fairness_loss': 1.7266654, 'utility': 0.5420728, 'loss': -0.49027282}\n",
      "--- Step : 569 \n",
      "  ------- {'fairness_loss': 1.7275364, 'utility': 0.54212934, 'loss': -0.49030325}\n",
      "--- Step : 570 \n",
      "  ------- {'fairness_loss': 1.7284126, 'utility': 0.54218596, 'loss': -0.4903336}\n",
      "--- Step : 571 \n",
      "  ------- {'fairness_loss': 1.7292923, 'utility': 0.5422427, 'loss': -0.49036396}\n",
      "--- Step : 572 \n",
      "  ------- {'fairness_loss': 1.7301744, 'utility': 0.54229945, 'loss': -0.49039423}\n",
      "--- Step : 573 \n",
      "  ------- {'fairness_loss': 1.7310617, 'utility': 0.5423563, 'loss': -0.49042445}\n",
      "--- Step : 574 \n",
      "  ------- {'fairness_loss': 1.7319511, 'utility': 0.5424131, 'loss': -0.49045458}\n",
      "--- Step : 575 \n",
      "  ------- {'fairness_loss': 1.7328424, 'utility': 0.54247, 'loss': -0.4904847}\n",
      "--- Step : 576 \n",
      "  ------- {'fairness_loss': 1.7337397, 'utility': 0.542527, 'loss': -0.4905148}\n",
      "--- Step : 577 \n",
      "  ------- {'fairness_loss': 1.7346362, 'utility': 0.542584, 'loss': -0.49054492}\n",
      "--- Step : 578 \n",
      "  ------- {'fairness_loss': 1.7355409, 'utility': 0.5426409, 'loss': -0.4905747}\n",
      "--- Step : 579 \n",
      "  ------- {'fairness_loss': 1.736444, 'utility': 0.5426981, 'loss': -0.49060476}\n",
      "--- Step : 580 \n",
      "  ------- {'fairness_loss': 1.7373528, 'utility': 0.54275507, 'loss': -0.49063447}\n",
      "--- Step : 581 \n",
      "  ------- {'fairness_loss': 1.7382598, 'utility': 0.5428124, 'loss': -0.4906646}\n",
      "--- Step : 582 \n",
      "  ------- {'fairness_loss': 1.7391738, 'utility': 0.5428695, 'loss': -0.49069428}\n",
      "--- Step : 583 \n",
      "  ------- {'fairness_loss': 1.7400888, 'utility': 0.5429267, 'loss': -0.49072406}\n",
      "--- Step : 584 \n",
      "  ------- {'fairness_loss': 1.7410066, 'utility': 0.54298395, 'loss': -0.49075374}\n",
      "--- Step : 585 \n",
      "  ------- {'fairness_loss': 1.7419266, 'utility': 0.54304117, 'loss': -0.49078336}\n",
      "--- Step : 586 \n",
      "  ------- {'fairness_loss': 1.7428447, 'utility': 0.54309845, 'loss': -0.4908131}\n",
      "--- Step : 587 \n",
      "  ------- {'fairness_loss': 1.7437724, 'utility': 0.5431556, 'loss': -0.49084243}\n",
      "--- Step : 588 \n",
      "  ------- {'fairness_loss': 1.7446966, 'utility': 0.54321283, 'loss': -0.49087194}\n",
      "--- Step : 589 \n",
      "  ------- {'fairness_loss': 1.7456251, 'utility': 0.5432703, 'loss': -0.49090153}\n",
      "--- Step : 590 \n",
      "  ------- {'fairness_loss': 1.7465559, 'utility': 0.54332757, 'loss': -0.49093089}\n",
      "--- Step : 591 \n",
      "  ------- {'fairness_loss': 1.7474883, 'utility': 0.5433849, 'loss': -0.49096027}\n",
      "--- Step : 592 \n",
      "  ------- {'fairness_loss': 1.7484208, 'utility': 0.54344213, 'loss': -0.4909895}\n",
      "--- Step : 593 \n",
      "  ------- {'fairness_loss': 1.7493538, 'utility': 0.5434996, 'loss': -0.49101898}\n",
      "--- Step : 594 \n",
      "  ------- {'fairness_loss': 1.750292, 'utility': 0.5435568, 'loss': -0.49104804}\n",
      "--- Step : 595 \n",
      "  ------- {'fairness_loss': 1.7512314, 'utility': 0.54361403, 'loss': -0.4910771}\n",
      "--- Step : 596 \n",
      "  ------- {'fairness_loss': 1.7521701, 'utility': 0.5436715, 'loss': -0.4911064}\n",
      "--- Step : 597 \n",
      "  ------- {'fairness_loss': 1.7531106, 'utility': 0.5437288, 'loss': -0.4911355}\n",
      "--- Step : 598 \n",
      "  ------- {'fairness_loss': 1.754055, 'utility': 0.5437861, 'loss': -0.49116445}\n",
      "--- Step : 599 \n",
      "  ------- {'fairness_loss': 1.7549996, 'utility': 0.54384345, 'loss': -0.49119347}\n",
      "--- Step : 600 \n",
      "  ------- {'fairness_loss': 1.7559437, 'utility': 0.54390067, 'loss': -0.49122235}\n",
      "--- Step : 601 \n",
      "  ------- {'fairness_loss': 1.7568903, 'utility': 0.5439578, 'loss': -0.4912511}\n",
      "--- Step : 602 \n",
      "  ------- {'fairness_loss': 1.7578385, 'utility': 0.5440152, 'loss': -0.49128008}\n",
      "--- Step : 603 \n",
      "  ------- {'fairness_loss': 1.7587868, 'utility': 0.54407245, 'loss': -0.49130884}\n",
      "--- Step : 604 \n",
      "  ------- {'fairness_loss': 1.759737, 'utility': 0.5441297, 'loss': -0.49133763}\n",
      "--- Step : 605 \n",
      "  ------- {'fairness_loss': 1.7606887, 'utility': 0.5441869, 'loss': -0.49136624}\n",
      "--- Step : 606 \n",
      "  ------- {'fairness_loss': 1.761637, 'utility': 0.5442442, 'loss': -0.49139512}\n",
      "--- Step : 607 \n",
      "  ------- {'fairness_loss': 1.7625915, 'utility': 0.5443013, 'loss': -0.49142352}\n",
      "--- Step : 608 \n",
      "  ------- {'fairness_loss': 1.7635446, 'utility': 0.5443584, 'loss': -0.49145204}\n",
      "--- Step : 609 \n",
      "  ------- {'fairness_loss': 1.7644987, 'utility': 0.5444156, 'loss': -0.49148065}\n",
      "--- Step : 610 \n",
      "  ------- {'fairness_loss': 1.7654527, 'utility': 0.5444727, 'loss': -0.4915091}\n",
      "--- Step : 611 \n",
      "  ------- {'fairness_loss': 1.7664075, 'utility': 0.5445298, 'loss': -0.49153757}\n",
      "--- Step : 612 \n",
      "  ------- {'fairness_loss': 1.7673638, 'utility': 0.5445868, 'loss': -0.49156585}\n",
      "--- Step : 613 \n",
      "  ------- {'fairness_loss': 1.7683206, 'utility': 0.5446439, 'loss': -0.49159425}\n",
      "--- Step : 614 \n",
      "  ------- {'fairness_loss': 1.7692782, 'utility': 0.54470074, 'loss': -0.4916224}\n",
      "--- Step : 615 \n",
      "  ------- {'fairness_loss': 1.770234, 'utility': 0.5447578, 'loss': -0.49165076}\n",
      "--- Step : 616 \n",
      "  ------- {'fairness_loss': 1.7711921, 'utility': 0.54481477, 'loss': -0.491679}\n",
      "--- Step : 617 \n",
      "  ------- {'fairness_loss': 1.7721497, 'utility': 0.54487175, 'loss': -0.49170727}\n",
      "--- Step : 618 \n",
      "  ------- {'fairness_loss': 1.77311, 'utility': 0.54492855, 'loss': -0.49173525}\n",
      "--- Step : 619 \n",
      "  ------- {'fairness_loss': 1.7740697, 'utility': 0.54498535, 'loss': -0.49176326}\n",
      "--- Step : 620 \n",
      "  ------- {'fairness_loss': 1.7750285, 'utility': 0.5450422, 'loss': -0.49179137}\n",
      "--- Step : 621 \n",
      "  ------- {'fairness_loss': 1.7759877, 'utility': 0.5450988, 'loss': -0.49181914}\n",
      "--- Step : 622 \n",
      "  ------- {'fairness_loss': 1.7769451, 'utility': 0.5451556, 'loss': -0.49184722}\n",
      "--- Step : 623 \n",
      "  ------- {'fairness_loss': 1.7779061, 'utility': 0.54521215, 'loss': -0.49187496}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 624 \n",
      "  ------- {'fairness_loss': 1.7788684, 'utility': 0.5452689, 'loss': -0.49190283}\n",
      "--- Step : 625 \n",
      "  ------- {'fairness_loss': 1.7798271, 'utility': 0.54532546, 'loss': -0.49193063}\n",
      "--- Step : 626 \n",
      "  ------- {'fairness_loss': 1.7807864, 'utility': 0.545382, 'loss': -0.49195844}\n",
      "--- Step : 627 \n",
      "  ------- {'fairness_loss': 1.7817459, 'utility': 0.5454386, 'loss': -0.49198622}\n",
      "--- Step : 628 \n",
      "  ------- {'fairness_loss': 1.7827051, 'utility': 0.54549485, 'loss': -0.4920137}\n",
      "--- Step : 629 \n",
      "  ------- {'fairness_loss': 1.7836664, 'utility': 0.54555136, 'loss': -0.49204138}\n",
      "--- Step : 630 \n",
      "  ------- {'fairness_loss': 1.784627, 'utility': 0.5456077, 'loss': -0.4920689}\n",
      "--- Step : 631 \n",
      "  ------- {'fairness_loss': 1.7855859, 'utility': 0.5456639, 'loss': -0.4920963}\n",
      "--- Step : 632 \n",
      "  ------- {'fairness_loss': 1.786544, 'utility': 0.5457202, 'loss': -0.4921239}\n",
      "--- Step : 633 \n",
      "  ------- {'fairness_loss': 1.7875032, 'utility': 0.54577625, 'loss': -0.49215114}\n",
      "--- Step : 634 \n",
      "  ------- {'fairness_loss': 1.7884632, 'utility': 0.54583246, 'loss': -0.49217856}\n",
      "--- Step : 635 \n",
      "  ------- {'fairness_loss': 1.7894208, 'utility': 0.54588866, 'loss': -0.49220604}\n",
      "--- Step : 636 \n",
      "  ------- {'fairness_loss': 1.7903794, 'utility': 0.5459447, 'loss': -0.4922333}\n",
      "--- Step : 637 \n",
      "  ------- {'fairness_loss': 1.7913581, 'utility': 0.54600054, 'loss': -0.4922598}\n",
      "--- Step : 638 \n",
      "  ------- {'fairness_loss': 1.7911774, 'utility': 0.5460228, 'loss': -0.49228746}\n",
      "--- Step : 639 \n",
      "  ------- {'fairness_loss': 1.7911307, 'utility': 0.54604834, 'loss': -0.49231443}\n",
      "--- Step : 640 \n",
      "  ------- {'fairness_loss': 1.7911868, 'utility': 0.546077, 'loss': -0.4923414}\n",
      "--- Step : 641 \n",
      "  ------- {'fairness_loss': 1.7913392, 'utility': 0.54610854, 'loss': -0.49236837}\n",
      "--- Step : 642 \n",
      "  ------- {'fairness_loss': 1.7915784, 'utility': 0.54614246, 'loss': -0.4923951}\n",
      "--- Step : 643 \n",
      "  ------- {'fairness_loss': 1.7918969, 'utility': 0.54617894, 'loss': -0.49242204}\n",
      "--- Step : 644 \n",
      "  ------- {'fairness_loss': 1.792288, 'utility': 0.5462175, 'loss': -0.49244887}\n",
      "--- Step : 645 \n",
      "  ------- {'fairness_loss': 1.7927417, 'utility': 0.546258, 'loss': -0.49247572}\n",
      "--- Step : 646 \n",
      "  ------- {'fairness_loss': 1.7932578, 'utility': 0.5463002, 'loss': -0.49250245}\n",
      "--- Step : 647 \n",
      "  ------- {'fairness_loss': 1.7938287, 'utility': 0.5463441, 'loss': -0.49252924}\n",
      "--- Step : 648 \n",
      "  ------- {'fairness_loss': 1.7944489, 'utility': 0.54638934, 'loss': -0.4925559}\n",
      "--- Step : 649 \n",
      "  ------- {'fairness_loss': 1.795114, 'utility': 0.5464358, 'loss': -0.49258235}\n",
      "--- Step : 650 \n",
      "  ------- {'fairness_loss': 1.7958196, 'utility': 0.5464836, 'loss': -0.492609}\n",
      "--- Step : 651 \n",
      "  ------- {'fairness_loss': 1.7965645, 'utility': 0.5465326, 'loss': -0.49263564}\n",
      "--- Step : 652 \n",
      "  ------- {'fairness_loss': 1.797342, 'utility': 0.54658234, 'loss': -0.49266207}\n",
      "--- Step : 653 \n",
      "  ------- {'fairness_loss': 1.7981551, 'utility': 0.54663306, 'loss': -0.49268842}\n",
      "--- Step : 654 \n",
      "  ------- {'fairness_loss': 1.7978858, 'utility': 0.5466515, 'loss': -0.4927149}\n",
      "--- Step : 655 \n",
      "  ------- {'fairness_loss': 1.7977619, 'utility': 0.5466738, 'loss': -0.49274093}\n",
      "--- Step : 656 \n",
      "  ------- {'fairness_loss': 1.7977613, 'utility': 0.54669994, 'loss': -0.4927671}\n",
      "--- Step : 657 \n",
      "  ------- {'fairness_loss': 1.7978742, 'utility': 0.5467296, 'loss': -0.4927934}\n",
      "--- Step : 658 \n",
      "  ------- {'fairness_loss': 1.7980918, 'utility': 0.5467624, 'loss': -0.49281967}\n",
      "--- Step : 659 \n",
      "  ------- {'fairness_loss': 1.7984043, 'utility': 0.5467979, 'loss': -0.49284574}\n",
      "--- Step : 660 \n",
      "  ------- {'fairness_loss': 1.7988033, 'utility': 0.54683584, 'loss': -0.49287173}\n",
      "--- Step : 661 \n",
      "  ------- {'fairness_loss': 1.79928, 'utility': 0.5468761, 'loss': -0.4928977}\n",
      "--- Step : 662 \n",
      "  ------- {'fairness_loss': 1.7998284, 'utility': 0.5469186, 'loss': -0.49292374}\n",
      "--- Step : 663 \n",
      "  ------- {'fairness_loss': 1.8004417, 'utility': 0.546963, 'loss': -0.49294972}\n",
      "--- Step : 664 \n",
      "  ------- {'fairness_loss': 1.801111, 'utility': 0.54700905, 'loss': -0.4929757}\n",
      "--- Step : 665 \n",
      "  ------- {'fairness_loss': 1.8018359, 'utility': 0.5470568, 'loss': -0.49300173}\n",
      "--- Step : 666 \n",
      "  ------- {'fairness_loss': 1.8026065, 'utility': 0.54710585, 'loss': -0.49302766}\n",
      "--- Step : 667 \n",
      "  ------- {'fairness_loss': 1.8034228, 'utility': 0.5471559, 'loss': -0.49305323}\n",
      "--- Step : 668 \n",
      "  ------- {'fairness_loss': 1.8042786, 'utility': 0.54720753, 'loss': -0.4930792}\n",
      "--- Step : 669 \n",
      "  ------- {'fairness_loss': 1.8052038, 'utility': 0.5472599, 'loss': -0.4931038}\n",
      "--- Step : 670 \n",
      "  ------- {'fairness_loss': 1.8050065, 'utility': 0.5472806, 'loss': -0.49313042}\n",
      "--- Step : 671 \n",
      "  ------- {'fairness_loss': 1.8049865, 'utility': 0.5473056, 'loss': -0.493156}\n",
      "--- Step : 672 \n",
      "  ------- {'fairness_loss': 1.8050897, 'utility': 0.54733413, 'loss': -0.49318144}\n",
      "--- Step : 673 \n",
      "  ------- {'fairness_loss': 1.8053082, 'utility': 0.547366, 'loss': -0.49320677}\n",
      "--- Step : 674 \n",
      "  ------- {'fairness_loss': 1.8056341, 'utility': 0.5474012, 'loss': -0.49323216}\n",
      "--- Step : 675 \n",
      "  ------- {'fairness_loss': 1.8060517, 'utility': 0.5474393, 'loss': -0.49325773}\n",
      "--- Step : 676 \n",
      "  ------- {'fairness_loss': 1.8065563, 'utility': 0.54747975, 'loss': -0.49328306}\n",
      "--- Step : 677 \n",
      "  ------- {'fairness_loss': 1.8071378, 'utility': 0.54752254, 'loss': -0.49330842}\n",
      "--- Step : 678 \n",
      "  ------- {'fairness_loss': 1.8077934, 'utility': 0.5475676, 'loss': -0.49333382}\n",
      "--- Step : 679 \n",
      "  ------- {'fairness_loss': 1.8085119, 'utility': 0.5476144, 'loss': -0.49335903}\n",
      "--- Step : 680 \n",
      "  ------- {'fairness_loss': 1.8092855, 'utility': 0.54766303, 'loss': -0.49338448}\n",
      "--- Step : 681 \n",
      "  ------- {'fairness_loss': 1.8101425, 'utility': 0.54771304, 'loss': -0.49340877}\n",
      "--- Step : 682 \n",
      "  ------- {'fairness_loss': 1.8099232, 'utility': 0.5477321, 'loss': -0.49343443}\n",
      "--- Step : 683 \n",
      "  ------- {'fairness_loss': 1.8098791, 'utility': 0.54775584, 'loss': -0.49345946}\n",
      "--- Step : 684 \n",
      "  ------- {'fairness_loss': 1.8099748, 'utility': 0.54778355, 'loss': -0.49348432}\n",
      "--- Step : 685 \n",
      "  ------- {'fairness_loss': 1.8101944, 'utility': 0.54781526, 'loss': -0.49350944}\n",
      "--- Step : 686 \n",
      "  ------- {'fairness_loss': 1.8105279, 'utility': 0.54785, 'loss': -0.49353418}\n",
      "--- Step : 687 \n",
      "  ------- {'fairness_loss': 1.8109642, 'utility': 0.54788804, 'loss': -0.49355912}\n",
      "--- Step : 688 \n",
      "  ------- {'fairness_loss': 1.811493, 'utility': 0.5479288, 'loss': -0.49358404}\n",
      "--- Step : 689 \n",
      "  ------- {'fairness_loss': 1.8121074, 'utility': 0.5479721, 'loss': -0.49360886}\n",
      "--- Step : 690 \n",
      "  ------- {'fairness_loss': 1.8127995, 'utility': 0.5480177, 'loss': -0.4936337}\n",
      "--- Step : 691 \n",
      "  ------- {'fairness_loss': 1.8135587, 'utility': 0.5480652, 'loss': -0.49365842}\n",
      "--- Step : 692 \n",
      "  ------- {'fairness_loss': 1.8143798, 'utility': 0.54811466, 'loss': -0.49368328}\n",
      "--- Step : 693 \n",
      "  ------- {'fairness_loss': 1.8153082, 'utility': 0.5481657, 'loss': -0.49370643}\n",
      "--- Step : 694 \n",
      "  ------- {'fairness_loss': 1.815131, 'utility': 0.54818636, 'loss': -0.49373242}\n",
      "--- Step : 695 \n",
      "  ------- {'fairness_loss': 1.8151538, 'utility': 0.5482115, 'loss': -0.4937569}\n",
      "--- Step : 696 \n",
      "  ------- {'fairness_loss': 1.8153197, 'utility': 0.54824084, 'loss': -0.49378127}\n",
      "--- Step : 697 \n",
      "  ------- {'fairness_loss': 1.815608, 'utility': 0.54827386, 'loss': -0.49380562}\n",
      "--- Step : 698 \n",
      "  ------- {'fairness_loss': 1.8160129, 'utility': 0.5483104, 'loss': -0.49383003}\n",
      "--- Step : 699 \n",
      "  ------- {'fairness_loss': 1.8165208, 'utility': 0.54835004, 'loss': -0.4938544}\n",
      "--- Step : 700 \n",
      "  ------- {'fairness_loss': 1.8171201, 'utility': 0.54839236, 'loss': -0.49387875}\n",
      "--- Step : 701 \n",
      "  ------- {'fairness_loss': 1.8178056, 'utility': 0.5484375, 'loss': -0.4939033}\n",
      "--- Step : 702 \n",
      "  ------- {'fairness_loss': 1.8185781, 'utility': 0.54848456, 'loss': -0.4939272}\n",
      "--- Step : 703 \n",
      "  ------- {'fairness_loss': 1.8183538, 'utility': 0.54850227, 'loss': -0.49395165}\n",
      "--- Step : 704 \n",
      "  ------- {'fairness_loss': 1.8183103, 'utility': 0.54852474, 'loss': -0.49397543}\n",
      "--- Step : 705 \n",
      "  ------- {'fairness_loss': 1.8184168, 'utility': 0.5485521, 'loss': -0.4939996}\n",
      "--- Step : 706 \n",
      "  ------- {'fairness_loss': 1.8186641, 'utility': 0.5485834, 'loss': -0.49402347}\n",
      "--- Step : 707 \n",
      "  ------- {'fairness_loss': 1.8190374, 'utility': 0.5486187, 'loss': -0.49404755}\n",
      "--- Step : 708 \n",
      "  ------- {'fairness_loss': 1.8195235, 'utility': 0.54865724, 'loss': -0.49407154}\n",
      "--- Step : 709 \n",
      "  ------- {'fairness_loss': 1.8201121, 'utility': 0.54869896, 'loss': -0.4940956}\n",
      "--- Step : 710 \n",
      "  ------- {'fairness_loss': 1.8207905, 'utility': 0.5487433, 'loss': -0.49411958}\n",
      "--- Step : 711 \n",
      "  ------- {'fairness_loss': 1.8215556, 'utility': 0.5487902, 'loss': -0.49414355}\n",
      "--- Step : 712 \n",
      "  ------- {'fairness_loss': 1.8223958, 'utility': 0.54883933, 'loss': -0.49416745}\n",
      "--- Step : 713 \n",
      "  ------- {'fairness_loss': 1.8233522, 'utility': 0.54889053, 'loss': -0.49418998}\n",
      "--- Step : 714 \n",
      "  ------- {'fairness_loss': 1.8232412, 'utility': 0.54891235, 'loss': -0.4942151}\n",
      "--- Step : 715 \n",
      "  ------- {'fairness_loss': 1.8233402, 'utility': 0.5489389, 'loss': -0.49423867}\n",
      "--- Step : 716 \n",
      "  ------- {'fairness_loss': 1.8235817, 'utility': 0.5489696, 'loss': -0.4942622}\n",
      "--- Step : 717 \n",
      "  ------- {'fairness_loss': 1.8239523, 'utility': 0.5490045, 'loss': -0.49428594}\n",
      "--- Step : 718 \n",
      "  ------- {'fairness_loss': 1.824447, 'utility': 0.5490427, 'loss': -0.4943093}\n",
      "--- Step : 719 \n",
      "  ------- {'fairness_loss': 1.8250452, 'utility': 0.54908425, 'loss': -0.49433288}\n",
      "--- Step : 720 \n",
      "  ------- {'fairness_loss': 1.8257457, 'utility': 0.5491288, 'loss': -0.4943564}\n",
      "--- Step : 721 \n",
      "  ------- {'fairness_loss': 1.8255002, 'utility': 0.54914486, 'loss': -0.49437985}\n",
      "--- Step : 722 \n",
      "  ------- {'fairness_loss': 1.8254449, 'utility': 0.5491664, 'loss': -0.49440303}\n",
      "--- Step : 723 \n",
      "  ------- {'fairness_loss': 1.825555, 'utility': 0.54919285, 'loss': -0.4944262}\n",
      "--- Step : 724 \n",
      "  ------- {'fairness_loss': 1.8258152, 'utility': 0.54922384, 'loss': -0.49444938}\n",
      "--- Step : 725 \n",
      "  ------- {'fairness_loss': 1.8262088, 'utility': 0.5492591, 'loss': -0.49447286}\n",
      "--- Step : 726 \n",
      "  ------- {'fairness_loss': 1.8267292, 'utility': 0.54929787, 'loss': -0.494496}\n",
      "--- Step : 727 \n",
      "  ------- {'fairness_loss': 1.8273587, 'utility': 0.5493401, 'loss': -0.49451935}\n",
      "--- Step : 728 \n",
      "  ------- {'fairness_loss': 1.8280866, 'utility': 0.54938513, 'loss': -0.49454254}\n",
      "--- Step : 729 \n",
      "  ------- {'fairness_loss': 1.8289088, 'utility': 0.5494331, 'loss': -0.49456584}\n",
      "--- Step : 730 \n",
      "  ------- {'fairness_loss': 1.829832, 'utility': 0.5494834, 'loss': -0.49458846}\n",
      "--- Step : 731 \n",
      "  ------- {'fairness_loss': 1.8297708, 'utility': 0.5495053, 'loss': -0.49461216}\n",
      "--- Step : 732 \n",
      "  ------- {'fairness_loss': 1.829903, 'utility': 0.5495319, 'loss': -0.49463478}\n",
      "--- Step : 733 \n",
      "  ------- {'fairness_loss': 1.830185, 'utility': 0.5495632, 'loss': -0.4946577}\n",
      "--- Step : 734 \n",
      "  ------- {'fairness_loss': 1.830617, 'utility': 0.54959893, 'loss': -0.49468043}\n",
      "--- Step : 735 \n",
      "  ------- {'fairness_loss': 1.8290306, 'utility': 0.5495735, 'loss': -0.49470258}\n",
      "--- Step : 736 \n",
      "  ------- {'fairness_loss': 1.827785, 'utility': 0.5495581, 'loss': -0.49472454}\n",
      "--- Step : 737 \n",
      "  ------- {'fairness_loss': 1.8268375, 'utility': 0.54955167, 'loss': -0.49474654}\n",
      "--- Step : 738 \n",
      "  ------- {'fairness_loss': 1.8261644, 'utility': 0.5495537, 'loss': -0.49476877}\n",
      "--- Step : 739 \n",
      "  ------- {'fairness_loss': 1.8257359, 'utility': 0.54956305, 'loss': -0.49479097}\n",
      "--- Step : 740 \n",
      "  ------- {'fairness_loss': 1.8255299, 'utility': 0.5495791, 'loss': -0.4948132}\n",
      "--- Step : 741 \n",
      "  ------- {'fairness_loss': 1.8255244, 'utility': 0.5496014, 'loss': -0.49483564}\n",
      "--- Step : 742 \n",
      "  ------- {'fairness_loss': 1.8257034, 'utility': 0.5496291, 'loss': -0.494858}\n",
      "--- Step : 743 \n",
      "  ------- {'fairness_loss': 1.8260453, 'utility': 0.5496618, 'loss': -0.49488047}\n",
      "--- Step : 744 \n",
      "  ------- {'fairness_loss': 1.8265368, 'utility': 0.549699, 'loss': -0.4949029}\n",
      "--- Step : 745 \n",
      "  ------- {'fairness_loss': 1.8271611, 'utility': 0.5497403, 'loss': -0.4949255}\n",
      "--- Step : 746 \n",
      "  ------- {'fairness_loss': 1.827908, 'utility': 0.5497853, 'loss': -0.4949481}\n",
      "--- Step : 747 \n",
      "  ------- {'fairness_loss': 1.8287618, 'utility': 0.54983336, 'loss': -0.4949705}\n",
      "--- Step : 748 \n",
      "  ------- {'fairness_loss': 1.8297164, 'utility': 0.5498847, 'loss': -0.49499318}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 749 \n",
      "  ------- {'fairness_loss': 1.8307575, 'utility': 0.5499387, 'loss': -0.49501595}\n",
      "--- Step : 750 \n",
      "  ------- {'fairness_loss': 1.8319176, 'utility': 0.54999477, 'loss': -0.49503723}\n",
      "--- Step : 751 \n",
      "  ------- {'fairness_loss': 1.8310075, 'utility': 0.5499902, 'loss': -0.49505997}\n",
      "--- Step : 752 \n",
      "  ------- {'fairness_loss': 1.8304111, 'utility': 0.54999375, 'loss': -0.49508142}\n",
      "--- Step : 753 \n",
      "  ------- {'fairness_loss': 1.8300577, 'utility': 0.5500049, 'loss': -0.49510318}\n",
      "--- Step : 754 \n",
      "  ------- {'fairness_loss': 1.8299326, 'utility': 0.5500227, 'loss': -0.49512476}\n",
      "--- Step : 755 \n",
      "  ------- {'fairness_loss': 1.8300042, 'utility': 0.55004674, 'loss': -0.49514663}\n",
      "--- Step : 756 \n",
      "  ------- {'fairness_loss': 1.8302583, 'utility': 0.5500762, 'loss': -0.49516845}\n",
      "--- Step : 757 \n",
      "  ------- {'fairness_loss': 1.8306779, 'utility': 0.5501108, 'loss': -0.49519047}\n",
      "--- Step : 758 \n",
      "  ------- {'fairness_loss': 1.8312469, 'utility': 0.55014986, 'loss': -0.49521247}\n",
      "--- Step : 759 \n",
      "  ------- {'fairness_loss': 1.8319483, 'utility': 0.5501929, 'loss': -0.49523443}\n",
      "--- Step : 760 \n",
      "  ------- {'fairness_loss': 1.8328843, 'utility': 0.5502395, 'loss': -0.49525297}\n",
      "--- Step : 761 \n",
      "  ------- {'fairness_loss': 1.831694, 'utility': 0.5502281, 'loss': -0.4952773}\n",
      "--- Step : 762 \n",
      "  ------- {'fairness_loss': 1.8309225, 'utility': 0.550226, 'loss': -0.4952983}\n",
      "--- Step : 763 \n",
      "  ------- {'fairness_loss': 1.8304173, 'utility': 0.550232, 'loss': -0.4953195}\n",
      "--- Step : 764 \n",
      "  ------- {'fairness_loss': 1.8301637, 'utility': 0.55024564, 'loss': -0.49534073}\n",
      "--- Step : 765 \n",
      "  ------- {'fairness_loss': 1.8301331, 'utility': 0.55026597, 'loss': -0.49536198}\n",
      "--- Step : 766 \n",
      "  ------- {'fairness_loss': 1.8303035, 'utility': 0.55029255, 'loss': -0.49538344}\n",
      "--- Step : 767 \n",
      "  ------- {'fairness_loss': 1.8306578, 'utility': 0.5503247, 'loss': -0.49540496}\n",
      "--- Step : 768 \n",
      "  ------- {'fairness_loss': 1.831176, 'utility': 0.55036175, 'loss': -0.49542648}\n",
      "--- Step : 769 \n",
      "  ------- {'fairness_loss': 1.8318446, 'utility': 0.55040324, 'loss': -0.4954479}\n",
      "--- Step : 770 \n",
      "  ------- {'fairness_loss': 1.8326432, 'utility': 0.55044895, 'loss': -0.49546966}\n",
      "--- Step : 771 \n",
      "  ------- {'fairness_loss': 1.8337322, 'utility': 0.5504983, 'loss': -0.49548635}\n",
      "--- Step : 772 \n",
      "  ------- {'fairness_loss': 1.8326353, 'utility': 0.55049086, 'loss': -0.4955118}\n",
      "--- Step : 773 \n",
      "  ------- {'fairness_loss': 1.8319988, 'utility': 0.5504924, 'loss': -0.49553245}\n",
      "--- Step : 774 \n",
      "  ------- {'fairness_loss': 1.8316336, 'utility': 0.5505023, 'loss': -0.49555328}\n",
      "--- Step : 775 \n",
      "  ------- {'fairness_loss': 1.8315042, 'utility': 0.55051935, 'loss': -0.49557424}\n",
      "--- Step : 776 \n",
      "  ------- {'fairness_loss': 1.8316002, 'utility': 0.55054307, 'loss': -0.49559507}\n",
      "--- Step : 777 \n",
      "  ------- {'fairness_loss': 1.8318896, 'utility': 0.5505729, 'loss': -0.4956162}\n",
      "--- Step : 778 \n",
      "  ------- {'fairness_loss': 1.83236, 'utility': 0.55060816, 'loss': -0.49563736}\n",
      "--- Step : 779 \n",
      "  ------- {'fairness_loss': 1.8329884, 'utility': 0.5506481, 'loss': -0.49565846}\n",
      "--- Step : 780 \n",
      "  ------- {'fairness_loss': 1.8338895, 'utility': 0.55069274, 'loss': -0.49567604}\n",
      "--- Step : 781 \n",
      "  ------- {'fairness_loss': 1.832754, 'utility': 0.5506824, 'loss': -0.49569982}\n",
      "--- Step : 782 \n",
      "  ------- {'fairness_loss': 1.832055, 'utility': 0.55068165, 'loss': -0.49572}\n",
      "--- Step : 783 \n",
      "  ------- {'fairness_loss': 1.8316405, 'utility': 0.5506895, 'loss': -0.4957403}\n",
      "--- Step : 784 \n",
      "  ------- {'fairness_loss': 1.8314775, 'utility': 0.55070513, 'loss': -0.4957608}\n",
      "--- Step : 785 \n",
      "  ------- {'fairness_loss': 1.8315475, 'utility': 0.5507277, 'loss': -0.4957813}\n",
      "--- Step : 786 \n",
      "  ------- {'fairness_loss': 1.831825, 'utility': 0.5507567, 'loss': -0.49580196}\n",
      "--- Step : 787 \n",
      "  ------- {'fairness_loss': 1.8322875, 'utility': 0.5507915, 'loss': -0.49582288}\n",
      "--- Step : 788 \n",
      "  ------- {'fairness_loss': 1.8329206, 'utility': 0.5508314, 'loss': -0.49584377}\n",
      "--- Step : 789 \n",
      "  ------- {'fairness_loss': 1.8337353, 'utility': 0.55087584, 'loss': -0.4958638}\n",
      "--- Step : 790 \n",
      "  ------- {'fairness_loss': 1.8327584, 'utility': 0.550867, 'loss': -0.49588427}\n",
      "--- Step : 791 \n",
      "  ------- {'fairness_loss': 1.8321203, 'utility': 0.55086786, 'loss': -0.49590424}\n",
      "--- Step : 792 \n",
      "  ------- {'fairness_loss': 1.8317679, 'utility': 0.5508772, 'loss': -0.49592417}\n",
      "--- Step : 793 \n",
      "  ------- {'fairness_loss': 1.8316683, 'utility': 0.5508944, 'loss': -0.49594432}\n",
      "--- Step : 794 \n",
      "  ------- {'fairness_loss': 1.8318008, 'utility': 0.5509187, 'loss': -0.49596468}\n",
      "--- Step : 795 \n",
      "  ------- {'fairness_loss': 1.8321416, 'utility': 0.5509494, 'loss': -0.49598515}\n",
      "--- Step : 796 \n",
      "  ------- {'fairness_loss': 1.8326685, 'utility': 0.5509857, 'loss': -0.49600565}\n",
      "--- Step : 797 \n",
      "  ------- {'fairness_loss': 1.8333673, 'utility': 0.55102724, 'loss': -0.49602622}\n",
      "--- Step : 798 \n",
      "  ------- {'fairness_loss': 1.8342878, 'utility': 0.5510733, 'loss': -0.4960447}\n",
      "--- Step : 799 \n",
      "  ------- {'fairness_loss': 1.8333727, 'utility': 0.55106735, 'loss': -0.49606618}\n",
      "--- Step : 800 \n",
      "  ------- {'fairness_loss': 1.8328342, 'utility': 0.5510709, 'loss': -0.4960859}\n",
      "--- Step : 801 \n",
      "  ------- {'fairness_loss': 1.8325783, 'utility': 0.55108285, 'loss': -0.4961055}\n",
      "--- Step : 802 \n",
      "  ------- {'fairness_loss': 1.8325703, 'utility': 0.5511025, 'loss': -0.4961254}\n",
      "--- Step : 803 \n",
      "  ------- {'fairness_loss': 1.8327914, 'utility': 0.55112934, 'loss': -0.4961456}\n",
      "--- Step : 804 \n",
      "  ------- {'fairness_loss': 1.8332145, 'utility': 0.5511621, 'loss': -0.4961657}\n",
      "--- Step : 805 \n",
      "  ------- {'fairness_loss': 1.8338262, 'utility': 0.5512006, 'loss': -0.49618584}\n",
      "--- Step : 806 \n",
      "  ------- {'fairness_loss': 1.8346949, 'utility': 0.5512442, 'loss': -0.49620336}\n",
      "--- Step : 807 \n",
      "  ------- {'fairness_loss': 1.8337342, 'utility': 0.5512372, 'loss': -0.4962252}\n",
      "--- Step : 808 \n",
      "  ------- {'fairness_loss': 1.83318, 'utility': 0.5512398, 'loss': -0.4962444}\n",
      "--- Step : 809 \n",
      "  ------- {'fairness_loss': 1.8329133, 'utility': 0.5512512, 'loss': -0.49626377}\n",
      "--- Step : 810 \n",
      "  ------- {'fairness_loss': 1.8329035, 'utility': 0.5512706, 'loss': -0.4962835}\n",
      "--- Step : 811 \n",
      "  ------- {'fairness_loss': 1.833126, 'utility': 0.55129683, 'loss': -0.49630305}\n",
      "--- Step : 812 \n",
      "  ------- {'fairness_loss': 1.8335599, 'utility': 0.55132973, 'loss': -0.49632293}\n",
      "--- Step : 813 \n",
      "  ------- {'fairness_loss': 1.8341817, 'utility': 0.5513685, 'loss': -0.49634302}\n",
      "--- Step : 814 \n",
      "  ------- {'fairness_loss': 1.8350947, 'utility': 0.5514122, 'loss': -0.49635938}\n",
      "--- Step : 815 \n",
      "  ------- {'fairness_loss': 1.8341601, 'utility': 0.55140656, 'loss': -0.49638176}\n",
      "--- Step : 816 \n",
      "  ------- {'fairness_loss': 1.8336598, 'utility': 0.5514105, 'loss': -0.4964007}\n",
      "--- Step : 817 \n",
      "  ------- {'fairness_loss': 1.8334458, 'utility': 0.55142325, 'loss': -0.49641988}\n",
      "--- Step : 818 \n",
      "  ------- {'fairness_loss': 1.8334887, 'utility': 0.5514439, 'loss': -0.49643922}\n",
      "--- Step : 819 \n",
      "  ------- {'fairness_loss': 1.833764, 'utility': 0.55147165, 'loss': -0.49645874}\n",
      "--- Step : 820 \n",
      "  ------- {'fairness_loss': 1.8342481, 'utility': 0.5515059, 'loss': -0.4964785}\n",
      "--- Step : 821 \n",
      "  ------- {'fairness_loss': 1.8349891, 'utility': 0.5515458, 'loss': -0.49649614}\n",
      "--- Step : 822 \n",
      "  ------- {'fairness_loss': 1.8340389, 'utility': 0.5515377, 'loss': -0.49651653}\n",
      "--- Step : 823 \n",
      "  ------- {'fairness_loss': 1.8334814, 'utility': 0.55153954, 'loss': -0.4965351}\n",
      "--- Step : 824 \n",
      "  ------- {'fairness_loss': 1.8332207, 'utility': 0.5515507, 'loss': -0.49655408}\n",
      "--- Step : 825 \n",
      "  ------- {'fairness_loss': 1.8332279, 'utility': 0.5515699, 'loss': -0.49657303}\n",
      "--- Step : 826 \n",
      "  ------- {'fairness_loss': 1.8334733, 'utility': 0.55159646, 'loss': -0.49659225}\n",
      "--- Step : 827 \n",
      "  ------- {'fairness_loss': 1.8339367, 'utility': 0.5516298, 'loss': -0.49661168}\n",
      "--- Step : 828 \n",
      "  ------- {'fairness_loss': 1.8345951, 'utility': 0.551669, 'loss': -0.49663115}\n",
      "--- Step : 829 \n",
      "  ------- {'fairness_loss': 1.8355619, 'utility': 0.55171376, 'loss': -0.4966469}\n",
      "--- Step : 830 \n",
      "  ------- {'fairness_loss': 1.8347274, 'utility': 0.55171084, 'loss': -0.49666902}\n",
      "--- Step : 831 \n",
      "  ------- {'fairness_loss': 1.8343363, 'utility': 0.55171764, 'loss': -0.49668756}\n",
      "--- Step : 832 \n",
      "  ------- {'fairness_loss': 1.8342291, 'utility': 0.55173314, 'loss': -0.49670625}\n",
      "--- Step : 833 \n",
      "  ------- {'fairness_loss': 1.8343778, 'utility': 0.5517563, 'loss': -0.496725}\n",
      "--- Step : 834 \n",
      "  ------- {'fairness_loss': 1.8347565, 'utility': 0.55178684, 'loss': -0.49674416}\n",
      "--- Step : 835 \n",
      "  ------- {'fairness_loss': 1.8354222, 'utility': 0.5518237, 'loss': -0.49676102}\n",
      "--- Step : 836 \n",
      "  ------- {'fairness_loss': 1.8344463, 'utility': 0.5518145, 'loss': -0.4967811}\n",
      "--- Step : 837 \n",
      "  ------- {'fairness_loss': 1.8338886, 'utility': 0.5518159, 'loss': -0.49679926}\n",
      "--- Step : 838 \n",
      "  ------- {'fairness_loss': 1.8336354, 'utility': 0.5518267, 'loss': -0.49681765}\n",
      "--- Step : 839 \n",
      "  ------- {'fairness_loss': 1.8336548, 'utility': 0.55184585, 'loss': -0.49683622}\n",
      "--- Step : 840 \n",
      "  ------- {'fairness_loss': 1.8339224, 'utility': 0.5518726, 'loss': -0.49685493}\n",
      "--- Step : 841 \n",
      "  ------- {'fairness_loss': 1.8344116, 'utility': 0.5519062, 'loss': -0.4968739}\n",
      "--- Step : 842 \n",
      "  ------- {'fairness_loss': 1.8351003, 'utility': 0.551946, 'loss': -0.496893}\n",
      "--- Step : 843 \n",
      "  ------- {'fairness_loss': 1.8361553, 'utility': 0.5519913, 'loss': -0.49690664}\n",
      "--- Step : 844 \n",
      "  ------- {'fairness_loss': 1.8354118, 'utility': 0.551991, 'loss': -0.49692863}\n",
      "--- Step : 845 \n",
      "  ------- {'fairness_loss': 1.8334596, 'utility': 0.55195034, 'loss': -0.49694654}\n",
      "--- Step : 846 \n",
      "  ------- {'fairness_loss': 1.8320026, 'utility': 0.5519235, 'loss': -0.49696344}\n",
      "--- Step : 847 \n",
      "  ------- {'fairness_loss': 1.8309495, 'utility': 0.55190897, 'loss': -0.4969805}\n",
      "--- Step : 848 \n",
      "  ------- {'fairness_loss': 1.8302565, 'utility': 0.5519056, 'loss': -0.4969979}\n",
      "--- Step : 849 \n",
      "  ------- {'fairness_loss': 1.8298938, 'utility': 0.5519124, 'loss': -0.49701563}\n",
      "--- Step : 850 \n",
      "  ------- {'fairness_loss': 1.829822, 'utility': 0.55192834, 'loss': -0.4970337}\n",
      "--- Step : 851 \n",
      "  ------- {'fairness_loss': 1.8300189, 'utility': 0.55195254, 'loss': -0.49705198}\n",
      "--- Step : 852 \n",
      "  ------- {'fairness_loss': 1.8304541, 'utility': 0.5519842, 'loss': -0.49707058}\n",
      "--- Step : 853 \n",
      "  ------- {'fairness_loss': 1.8311048, 'utility': 0.5520224, 'loss': -0.49708927}\n",
      "--- Step : 854 \n",
      "  ------- {'fairness_loss': 1.8319471, 'utility': 0.55206674, 'loss': -0.49710834}\n",
      "--- Step : 855 \n",
      "  ------- {'fairness_loss': 1.8329678, 'utility': 0.5521163, 'loss': -0.49712723}\n",
      "--- Step : 856 \n",
      "  ------- {'fairness_loss': 1.8341432, 'utility': 0.5521708, 'loss': -0.49714652}\n",
      "--- Step : 857 \n",
      "  ------- {'fairness_loss': 1.8354809, 'utility': 0.5522295, 'loss': -0.49716508}\n",
      "--- Step : 858 \n",
      "  ------- {'fairness_loss': 1.8353206, 'utility': 0.55224305, 'loss': -0.49718344}\n",
      "--- Step : 859 \n",
      "  ------- {'fairness_loss': 1.8354645, 'utility': 0.5522653, 'loss': -0.49720135}\n",
      "--- Step : 860 \n",
      "  ------- {'fairness_loss': 1.8342692, 'utility': 0.5522462, 'loss': -0.49721813}\n",
      "--- Step : 861 \n",
      "  ------- {'fairness_loss': 1.833468, 'utility': 0.552239, 'loss': -0.49723497}\n",
      "--- Step : 862 \n",
      "  ------- {'fairness_loss': 1.8330065, 'utility': 0.5522424, 'loss': -0.4972522}\n",
      "--- Step : 863 \n",
      "  ------- {'fairness_loss': 1.8328516, 'utility': 0.5522552, 'loss': -0.49726966}\n",
      "--- Step : 864 \n",
      "  ------- {'fairness_loss': 1.8329743, 'utility': 0.5522768, 'loss': -0.49728757}\n",
      "--- Step : 865 \n",
      "  ------- {'fairness_loss': 1.8333454, 'utility': 0.55230594, 'loss': -0.49730557}\n",
      "--- Step : 866 \n",
      "  ------- {'fairness_loss': 1.8339429, 'utility': 0.55234224, 'loss': -0.49732396}\n",
      "--- Step : 867 \n",
      "  ------- {'fairness_loss': 1.8347428, 'utility': 0.5523845, 'loss': -0.49734223}\n",
      "--- Step : 868 \n",
      "  ------- {'fairness_loss': 1.8357679, 'utility': 0.5524327, 'loss': -0.4973597}\n",
      "--- Step : 869 \n",
      "  ------- {'fairness_loss': 1.835334, 'utility': 0.55243814, 'loss': -0.4973781}\n",
      "--- Step : 870 \n",
      "  ------- {'fairness_loss': 1.835247, 'utility': 0.55245274, 'loss': -0.49739534}\n",
      "--- Step : 871 \n",
      "  ------- {'fairness_loss': 1.8354323, 'utility': 0.55247587, 'loss': -0.4974129}\n",
      "--- Step : 872 \n",
      "  ------- {'fairness_loss': 1.8359202, 'utility': 0.55250686, 'loss': -0.49742925}\n",
      "--- Step : 873 \n",
      "  ------- {'fairness_loss': 1.8349925, 'utility': 0.5524972, 'loss': -0.49744743}\n",
      "--- Step : 874 \n",
      "  ------- {'fairness_loss': 1.8344795, 'utility': 0.55249864, 'loss': -0.49746424}\n",
      "--- Step : 875 \n",
      "  ------- {'fairness_loss': 1.8342814, 'utility': 0.5525098, 'loss': -0.49748135}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 876 \n",
      "  ------- {'fairness_loss': 1.8343728, 'utility': 0.5525298, 'loss': -0.49749863}\n",
      "--- Step : 877 \n",
      "  ------- {'fairness_loss': 1.8347173, 'utility': 0.5525579, 'loss': -0.49751636}\n",
      "--- Step : 878 \n",
      "  ------- {'fairness_loss': 1.8352939, 'utility': 0.55259293, 'loss': -0.49753413}\n",
      "--- Step : 879 \n",
      "  ------- {'fairness_loss': 1.836174, 'utility': 0.55263466, 'loss': -0.49754944}\n",
      "--- Step : 880 \n",
      "  ------- {'fairness_loss': 1.8355614, 'utility': 0.55263585, 'loss': -0.49756902}\n",
      "--- Step : 881 \n",
      "  ------- {'fairness_loss': 1.8353616, 'utility': 0.5526466, 'loss': -0.4975857}\n",
      "--- Step : 882 \n",
      "  ------- {'fairness_loss': 1.8354474, 'utility': 0.5526664, 'loss': -0.497603}\n",
      "--- Step : 883 \n",
      "  ------- {'fairness_loss': 1.835823, 'utility': 0.5526944, 'loss': -0.4976197}\n",
      "--- Step : 884 \n",
      "  ------- {'fairness_loss': 1.834902, 'utility': 0.5526836, 'loss': -0.49763653}\n",
      "--- Step : 885 \n",
      "  ------- {'fairness_loss': 1.8343732, 'utility': 0.55268407, 'loss': -0.4976529}\n",
      "--- Step : 886 \n",
      "  ------- {'fairness_loss': 1.8341631, 'utility': 0.55269456, 'loss': -0.49766967}\n",
      "--- Step : 887 \n",
      "  ------- {'fairness_loss': 1.8342459, 'utility': 0.55271405, 'loss': -0.49768668}\n",
      "--- Step : 888 \n",
      "  ------- {'fairness_loss': 1.8345912, 'utility': 0.5527415, 'loss': -0.4977038}\n",
      "--- Step : 889 \n",
      "  ------- {'fairness_loss': 1.8351673, 'utility': 0.55277663, 'loss': -0.4977216}\n",
      "--- Step : 890 \n",
      "  ------- {'fairness_loss': 1.8360156, 'utility': 0.5528182, 'loss': -0.4977377}\n",
      "--- Step : 891 \n",
      "  ------- {'fairness_loss': 1.835496, 'utility': 0.55282044, 'loss': -0.49775556}\n",
      "--- Step : 892 \n",
      "  ------- {'fairness_loss': 1.8353485, 'utility': 0.5528326, 'loss': -0.49777216}\n",
      "--- Step : 893 \n",
      "  ------- {'fairness_loss': 1.8354876, 'utility': 0.5528536, 'loss': -0.49778897}\n",
      "--- Step : 894 \n",
      "  ------- {'fairness_loss': 1.8359149, 'utility': 0.55288273, 'loss': -0.4978053}\n",
      "--- Step : 895 \n",
      "  ------- {'fairness_loss': 1.835081, 'utility': 0.5528743, 'loss': -0.4978219}\n",
      "--- Step : 896 \n",
      "  ------- {'fairness_loss': 1.8346332, 'utility': 0.552877, 'loss': -0.49783802}\n",
      "--- Step : 897 \n",
      "  ------- {'fairness_loss': 1.834503, 'utility': 0.55288965, 'loss': -0.49785456}\n",
      "--- Step : 898 \n",
      "  ------- {'fairness_loss': 1.8346598, 'utility': 0.55291104, 'loss': -0.49787125}\n",
      "--- Step : 899 \n",
      "  ------- {'fairness_loss': 1.8350725, 'utility': 0.55294067, 'loss': -0.4978885}\n",
      "--- Step : 900 \n",
      "  ------- {'fairness_loss': 1.835721, 'utility': 0.55297744, 'loss': -0.49790582}\n",
      "--- Step : 901 \n",
      "  ------- {'fairness_loss': 1.8367536, 'utility': 0.5530204, 'loss': -0.4979178}\n",
      "--- Step : 902 \n",
      "  ------- {'fairness_loss': 1.8363066, 'utility': 0.55302554, 'loss': -0.49793634}\n",
      "--- Step : 903 \n",
      "  ------- {'fairness_loss': 1.8347595, 'utility': 0.55299664, 'loss': -0.49795386}\n",
      "--- Step : 904 \n",
      "  ------- {'fairness_loss': 1.8337344, 'utility': 0.55298114, 'loss': -0.4979691}\n",
      "--- Step : 905 \n",
      "  ------- {'fairness_loss': 1.8330897, 'utility': 0.5529772, 'loss': -0.49798453}\n",
      "--- Step : 906 \n",
      "  ------- {'fairness_loss': 1.8327861, 'utility': 0.5529841, 'loss': -0.49800053}\n",
      "--- Step : 907 \n",
      "  ------- {'fairness_loss': 1.8327913, 'utility': 0.55300057, 'loss': -0.49801683}\n",
      "--- Step : 908 \n",
      "  ------- {'fairness_loss': 1.833072, 'utility': 0.55302566, 'loss': -0.4980335}\n",
      "--- Step : 909 \n",
      "  ------- {'fairness_loss': 1.8336035, 'utility': 0.55305856, 'loss': -0.49805045}\n",
      "--- Step : 910 \n",
      "  ------- {'fairness_loss': 1.8343617, 'utility': 0.5530985, 'loss': -0.49806765}\n",
      "--- Step : 911 \n",
      "  ------- {'fairness_loss': 1.8353215, 'utility': 0.55314475, 'loss': -0.4980851}\n",
      "--- Step : 912 \n",
      "  ------- {'fairness_loss': 1.8366138, 'utility': 0.55319667, 'loss': -0.49809825}\n",
      "--- Step : 913 \n",
      "  ------- {'fairness_loss': 1.8365302, 'utility': 0.5532107, 'loss': -0.49811476}\n",
      "--- Step : 914 \n",
      "  ------- {'fairness_loss': 1.8352513, 'utility': 0.5531908, 'loss': -0.4981333}\n",
      "--- Step : 915 \n",
      "  ------- {'fairness_loss': 1.8345048, 'utility': 0.55318356, 'loss': -0.4981484}\n",
      "--- Step : 916 \n",
      "  ------- {'fairness_loss': 1.83411, 'utility': 0.55318725, 'loss': -0.49816394}\n",
      "--- Step : 917 \n",
      "  ------- {'fairness_loss': 1.8340331, 'utility': 0.5532011, 'loss': -0.4981801}\n",
      "--- Step : 918 \n",
      "  ------- {'fairness_loss': 1.8342454, 'utility': 0.55322355, 'loss': -0.49819618}\n",
      "--- Step : 919 \n",
      "  ------- {'fairness_loss': 1.8347161, 'utility': 0.55325425, 'loss': -0.49821275}\n",
      "--- Step : 920 \n",
      "  ------- {'fairness_loss': 1.8354218, 'utility': 0.5532922, 'loss': -0.49822956}\n",
      "--- Step : 921 \n",
      "  ------- {'fairness_loss': 1.8364598, 'utility': 0.5533369, 'loss': -0.49824312}\n",
      "--- Step : 922 \n",
      "  ------- {'fairness_loss': 1.8361712, 'utility': 0.5533453, 'loss': -0.4982602}\n",
      "--- Step : 923 \n",
      "  ------- {'fairness_loss': 1.8348376, 'utility': 0.5533218, 'loss': -0.49827665}\n",
      "--- Step : 924 \n",
      "  ------- {'fairness_loss': 1.8339907, 'utility': 0.5533109, 'loss': -0.49829113}\n",
      "--- Step : 925 \n",
      "  ------- {'fairness_loss': 1.8335085, 'utility': 0.55331147, 'loss': -0.4983062}\n",
      "--- Step : 926 \n",
      "  ------- {'fairness_loss': 1.8333567, 'utility': 0.55332243, 'loss': -0.49832174}\n",
      "--- Step : 927 \n",
      "  ------- {'fairness_loss': 1.8335036, 'utility': 0.55334276, 'loss': -0.49833766}\n",
      "--- Step : 928 \n",
      "  ------- {'fairness_loss': 1.8339176, 'utility': 0.5533716, 'loss': -0.49835408}\n",
      "--- Step : 929 \n",
      "  ------- {'fairness_loss': 1.8345755, 'utility': 0.5534078, 'loss': -0.49837053}\n",
      "--- Step : 930 \n",
      "  ------- {'fairness_loss': 1.835447, 'utility': 0.55345094, 'loss': -0.49838755}\n",
      "--- Step : 931 \n",
      "  ------- {'fairness_loss': 1.8366895, 'utility': 0.55349994, 'loss': -0.49839926}\n",
      "--- Step : 932 \n",
      "  ------- {'fairness_loss': 1.8366113, 'utility': 0.5535136, 'loss': -0.49841526}\n",
      "--- Step : 933 \n",
      "  ------- {'fairness_loss': 1.8353802, 'utility': 0.5534957, 'loss': -0.4984343}\n",
      "--- Step : 934 \n",
      "  ------- {'fairness_loss': 1.8347014, 'utility': 0.5534898, 'loss': -0.49844876}\n",
      "--- Step : 935 \n",
      "  ------- {'fairness_loss': 1.8343786, 'utility': 0.55349505, 'loss': -0.4984637}\n",
      "--- Step : 936 \n",
      "  ------- {'fairness_loss': 1.8343688, 'utility': 0.5535102, 'loss': -0.49847913}\n",
      "--- Step : 937 \n",
      "  ------- {'fairness_loss': 1.8346432, 'utility': 0.5535342, 'loss': -0.49849492}\n",
      "--- Step : 938 \n",
      "  ------- {'fairness_loss': 1.8351756, 'utility': 0.5535664, 'loss': -0.49851114}\n",
      "--- Step : 939 \n",
      "  ------- {'fairness_loss': 1.8359965, 'utility': 0.5536057, 'loss': -0.4985258}\n",
      "--- Step : 940 \n",
      "  ------- {'fairness_loss': 1.8356314, 'utility': 0.55361164, 'loss': -0.4985427}\n",
      "--- Step : 941 \n",
      "  ------- {'fairness_loss': 1.8356445, 'utility': 0.55362725, 'loss': -0.49855793}\n",
      "--- Step : 942 \n",
      "  ------- {'fairness_loss': 1.8359973, 'utility': 0.5536517, 'loss': -0.49857178}\n",
      "--- Step : 943 \n",
      "  ------- {'fairness_loss': 1.8352188, 'utility': 0.5536444, 'loss': -0.49858785}\n",
      "--- Step : 944 \n",
      "  ------- {'fairness_loss': 1.834861, 'utility': 0.55364835, 'loss': -0.4986025}\n",
      "--- Step : 945 \n",
      "  ------- {'fairness_loss': 1.8348248, 'utility': 0.5536624, 'loss': -0.49861768}\n",
      "--- Step : 946 \n",
      "  ------- {'fairness_loss': 1.8350772, 'utility': 0.55368555, 'loss': -0.49863324}\n",
      "--- Step : 947 \n",
      "  ------- {'fairness_loss': 1.8355895, 'utility': 0.553717, 'loss': -0.49864933}\n",
      "--- Step : 948 \n",
      "  ------- {'fairness_loss': 1.8364967, 'utility': 0.55375564, 'loss': -0.49866074}\n",
      "--- Step : 949 \n",
      "  ------- {'fairness_loss': 1.8361458, 'utility': 0.5537615, 'loss': -0.4986771}\n",
      "--- Step : 950 \n",
      "  ------- {'fairness_loss': 1.8348322, 'utility': 0.55373836, 'loss': -0.4986934}\n",
      "--- Step : 951 \n",
      "  ------- {'fairness_loss': 1.8340306, 'utility': 0.55372816, 'loss': -0.49870723}\n",
      "--- Step : 952 \n",
      "  ------- {'fairness_loss': 1.8335965, 'utility': 0.5537295, 'loss': -0.49872157}\n",
      "--- Step : 953 \n",
      "  ------- {'fairness_loss': 1.8334951, 'utility': 0.5537412, 'loss': -0.49873635}\n",
      "--- Step : 954 \n",
      "  ------- {'fairness_loss': 1.8336911, 'utility': 0.55376244, 'loss': -0.4987517}\n",
      "--- Step : 955 \n",
      "  ------- {'fairness_loss': 1.834156, 'utility': 0.55379194, 'loss': -0.49876726}\n",
      "--- Step : 956 \n",
      "  ------- {'fairness_loss': 1.8348616, 'utility': 0.5538292, 'loss': -0.49878335}\n",
      "--- Step : 957 \n",
      "  ------- {'fairness_loss': 1.8358463, 'utility': 0.5538733, 'loss': -0.49879792}\n",
      "--- Step : 958 \n",
      "  ------- {'fairness_loss': 1.8357236, 'utility': 0.5538848, 'loss': -0.4988131}\n",
      "--- Step : 959 \n",
      "  ------- {'fairness_loss': 1.8346697, 'utility': 0.55386776, 'loss': -0.49882767}\n",
      "--- Step : 960 \n",
      "  ------- {'fairness_loss': 1.8340489, 'utility': 0.55386287, 'loss': -0.4988414}\n",
      "--- Step : 961 \n",
      "  ------- {'fairness_loss': 1.8337783, 'utility': 0.5538691, 'loss': -0.49885577}\n",
      "--- Step : 962 \n",
      "  ------- {'fairness_loss': 1.8338228, 'utility': 0.55388534, 'loss': -0.49887067}\n",
      "--- Step : 963 \n",
      "  ------- {'fairness_loss': 1.8341547, 'utility': 0.5539104, 'loss': -0.49888575}\n",
      "--- Step : 964 \n",
      "  ------- {'fairness_loss': 1.8347427, 'utility': 0.55394375, 'loss': -0.4989015}\n",
      "--- Step : 965 \n",
      "  ------- {'fairness_loss': 1.8355918, 'utility': 0.5539843, 'loss': -0.49891654}\n",
      "--- Step : 966 \n",
      "  ------- {'fairness_loss': 1.8353918, 'utility': 0.55399334, 'loss': -0.4989316}\n",
      "--- Step : 967 \n",
      "  ------- {'fairness_loss': 1.8355563, 'utility': 0.5540123, 'loss': -0.49894562}\n",
      "--- Step : 968 \n",
      "  ------- {'fairness_loss': 1.8347538, 'utility': 0.5540027, 'loss': -0.49896008}\n",
      "--- Step : 969 \n",
      "  ------- {'fairness_loss': 1.8343499, 'utility': 0.5540043, 'loss': -0.49897382}\n",
      "--- Step : 970 \n",
      "  ------- {'fairness_loss': 1.8342757, 'utility': 0.55401653, 'loss': -0.49898827}\n",
      "--- Step : 971 \n",
      "  ------- {'fairness_loss': 1.8345007, 'utility': 0.5540381, 'loss': -0.49900308}\n",
      "--- Step : 972 \n",
      "  ------- {'fairness_loss': 1.8349923, 'utility': 0.55406815, 'loss': -0.49901837}\n",
      "--- Step : 973 \n",
      "  ------- {'fairness_loss': 1.8358127, 'utility': 0.5541057, 'loss': -0.4990313}\n",
      "--- Step : 974 \n",
      "  ------- {'fairness_loss': 1.8355452, 'utility': 0.55411327, 'loss': -0.49904692}\n",
      "--- Step : 975 \n",
      "  ------- {'fairness_loss': 1.8344278, 'utility': 0.5540936, 'loss': -0.49906075}\n",
      "--- Step : 976 \n",
      "  ------- {'fairness_loss': 1.8337559, 'utility': 0.55408686, 'loss': -0.4990742}\n",
      "--- Step : 977 \n",
      "  ------- {'fairness_loss': 1.8334448, 'utility': 0.5540912, 'loss': -0.49908787}\n",
      "--- Step : 978 \n",
      "  ------- {'fairness_loss': 1.8334551, 'utility': 0.55410594, 'loss': -0.4991023}\n",
      "--- Step : 979 \n",
      "  ------- {'fairness_loss': 1.8337575, 'utility': 0.5541299, 'loss': -0.49911717}\n",
      "--- Step : 980 \n",
      "  ------- {'fairness_loss': 1.8343225, 'utility': 0.55416197, 'loss': -0.4991323}\n",
      "--- Step : 981 \n",
      "  ------- {'fairness_loss': 1.8351223, 'utility': 0.55420154, 'loss': -0.49914786}\n",
      "--- Step : 982 \n",
      "  ------- {'fairness_loss': 1.8363404, 'utility': 0.55424786, 'loss': -0.49915764}\n",
      "--- Step : 983 \n",
      "  ------- {'fairness_loss': 1.8364048, 'utility': 0.55426353, 'loss': -0.49917138}\n",
      "--- Step : 984 \n",
      "  ------- {'fairness_loss': 1.8354323, 'utility': 0.55425227, 'loss': -0.4991893}\n",
      "--- Step : 985 \n",
      "  ------- {'fairness_loss': 1.8338195, 'utility': 0.5542171, 'loss': -0.49920252}\n",
      "--- Step : 986 \n",
      "  ------- {'fairness_loss': 1.8327119, 'utility': 0.554196, 'loss': -0.49921465}\n",
      "--- Step : 987 \n",
      "  ------- {'fairness_loss': 1.8320094, 'utility': 0.55418783, 'loss': -0.49922755}\n",
      "--- Step : 988 \n",
      "  ------- {'fairness_loss': 1.8316699, 'utility': 0.55419123, 'loss': -0.49924114}\n",
      "--- Step : 989 \n",
      "  ------- {'fairness_loss': 1.8316618, 'utility': 0.5542051, 'loss': -0.49925527}\n",
      "--- Step : 990 \n",
      "  ------- {'fairness_loss': 1.8319507, 'utility': 0.55422807, 'loss': -0.49926955}\n",
      "--- Step : 991 \n",
      "  ------- {'fairness_loss': 1.8325013, 'utility': 0.5542596, 'loss': -0.49928457}\n",
      "--- Step : 992 \n",
      "  ------- {'fairness_loss': 1.8332946, 'utility': 0.5542987, 'loss': -0.49929985}\n",
      "--- Step : 993 \n",
      "  ------- {'fairness_loss': 1.8343017, 'utility': 0.55434465, 'loss': -0.49931562}\n",
      "--- Step : 994 \n",
      "  ------- {'fairness_loss': 1.8356189, 'utility': 0.5543964, 'loss': -0.49932784}\n",
      "--- Step : 995 \n",
      "  ------- {'fairness_loss': 1.8359345, 'utility': 0.5544186, 'loss': -0.4993406}\n",
      "--- Step : 996 \n",
      "  ------- {'fairness_loss': 1.8352288, 'utility': 0.5544138, 'loss': -0.49935693}\n",
      "--- Step : 997 \n",
      "  ------- {'fairness_loss': 1.8338431, 'utility': 0.5543855, 'loss': -0.4993702}\n",
      "--- Step : 998 \n",
      "  ------- {'fairness_loss': 1.8329418, 'utility': 0.55437076, 'loss': -0.4993825}\n",
      "--- Step : 999 \n",
      "  ------- {'fairness_loss': 1.832425, 'utility': 0.55436814, 'loss': -0.4993954}\n",
      "--- Step : 1000 \n",
      "  ------- {'fairness_loss': 1.8322564, 'utility': 0.55437654, 'loss': -0.49940884}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1001 \n",
      "  ------- {'fairness_loss': 1.8324001, 'utility': 0.55439484, 'loss': -0.49942285}\n",
      "--- Step : 1002 \n",
      "  ------- {'fairness_loss': 1.8328255, 'utility': 0.5544221, 'loss': -0.49943733}\n",
      "--- Step : 1003 \n",
      "  ------- {'fairness_loss': 1.8335042, 'utility': 0.55445725, 'loss': -0.4994521}\n",
      "--- Step : 1004 \n",
      "  ------- {'fairness_loss': 1.8344077, 'utility': 0.5544997, 'loss': -0.49946746}\n",
      "--- Step : 1005 \n",
      "  ------- {'fairness_loss': 1.8356819, 'utility': 0.5545487, 'loss': -0.49947822}\n",
      "--- Step : 1006 \n",
      "  ------- {'fairness_loss': 1.8359336, 'utility': 0.55456877, 'loss': -0.49949077}\n",
      "--- Step : 1007 \n",
      "  ------- {'fairness_loss': 1.8352073, 'utility': 0.55456316, 'loss': -0.49950695}\n",
      "--- Step : 1008 \n",
      "  ------- {'fairness_loss': 1.8338028, 'utility': 0.5545349, 'loss': -0.49952084}\n",
      "--- Step : 1009 \n",
      "  ------- {'fairness_loss': 1.8329166, 'utility': 0.55452025, 'loss': -0.49953276}\n",
      "--- Step : 1010 \n",
      "  ------- {'fairness_loss': 1.8324149, 'utility': 0.5545177, 'loss': -0.49954525}\n",
      "--- Step : 1011 \n",
      "  ------- {'fairness_loss': 1.8322585, 'utility': 0.55452627, 'loss': -0.4995585}\n",
      "--- Step : 1012 \n",
      "  ------- {'fairness_loss': 1.8324159, 'utility': 0.5545447, 'loss': -0.49957222}\n",
      "--- Step : 1013 \n",
      "  ------- {'fairness_loss': 1.8328519, 'utility': 0.5545721, 'loss': -0.49958655}\n",
      "--- Step : 1014 \n",
      "  ------- {'fairness_loss': 1.833542, 'utility': 0.55460745, 'loss': -0.4996012}\n",
      "--- Step : 1015 \n",
      "  ------- {'fairness_loss': 1.8344567, 'utility': 0.55465, 'loss': -0.49961632}\n",
      "--- Step : 1016 \n",
      "  ------- {'fairness_loss': 1.835804, 'utility': 0.554699, 'loss': -0.49962488}\n",
      "--- Step : 1017 \n",
      "  ------- {'fairness_loss': 1.8361045, 'utility': 0.55472016, 'loss': -0.49963704}\n",
      "--- Step : 1018 \n",
      "  ------- {'fairness_loss': 1.8354552, 'utility': 0.5547163, 'loss': -0.49965262}\n",
      "--- Step : 1019 \n",
      "  ------- {'fairness_loss': 1.8340491, 'utility': 0.55469024, 'loss': -0.49966878}\n",
      "--- Step : 1020 \n",
      "  ------- {'fairness_loss': 1.8332356, 'utility': 0.5546777, 'loss': -0.49968067}\n",
      "--- Step : 1021 \n",
      "  ------- {'fairness_loss': 1.8328063, 'utility': 0.5546771, 'loss': -0.49969295}\n",
      "--- Step : 1022 \n",
      "  ------- {'fairness_loss': 1.8329278, 'utility': 0.55469424, 'loss': -0.4997064}\n",
      "--- Step : 1023 \n",
      "  ------- {'fairness_loss': 1.8335519, 'utility': 0.5547275, 'loss': -0.49972093}\n",
      "--- Step : 1024 \n",
      "  ------- {'fairness_loss': 1.8344209, 'utility': 0.5547681, 'loss': -0.49973547}\n",
      "--- Step : 1025 \n",
      "  ------- {'fairness_loss': 1.8344678, 'utility': 0.55478233, 'loss': -0.4997483}\n",
      "--- Step : 1026 \n",
      "  ------- {'fairness_loss': 1.8337475, 'utility': 0.5547733, 'loss': -0.49976084}\n",
      "--- Step : 1027 \n",
      "  ------- {'fairness_loss': 1.8334199, 'utility': 0.5547757, 'loss': -0.49977311}\n",
      "--- Step : 1028 \n",
      "  ------- {'fairness_loss': 1.8334167, 'utility': 0.5547887, 'loss': -0.4997862}\n",
      "--- Step : 1029 \n",
      "  ------- {'fairness_loss': 1.8337113, 'utility': 0.5548113, 'loss': -0.49979997}\n",
      "--- Step : 1030 \n",
      "  ------- {'fairness_loss': 1.834274, 'utility': 0.55484205, 'loss': -0.49981382}\n",
      "--- Step : 1031 \n",
      "  ------- {'fairness_loss': 1.8340536, 'utility': 0.55484825, 'loss': -0.49982664}\n",
      "--- Step : 1032 \n",
      "  ------- {'fairness_loss': 1.8341552, 'utility': 0.55486435, 'loss': -0.4998397}\n",
      "--- Step : 1033 \n",
      "  ------- {'fairness_loss': 1.834614, 'utility': 0.5548898, 'loss': -0.49985138}\n",
      "--- Step : 1034 \n",
      "  ------- {'fairness_loss': 1.8341748, 'utility': 0.554891, 'loss': -0.49986574}\n",
      "--- Step : 1035 \n",
      "  ------- {'fairness_loss': 1.8341439, 'utility': 0.55490273, 'loss': -0.4998784}\n",
      "--- Step : 1036 \n",
      "  ------- {'fairness_loss': 1.83447, 'utility': 0.55492425, 'loss': -0.49989015}\n",
      "--- Step : 1037 \n",
      "  ------- {'fairness_loss': 1.8339485, 'utility': 0.5549223, 'loss': -0.49990383}\n",
      "--- Step : 1038 \n",
      "  ------- {'fairness_loss': 1.8340331, 'utility': 0.5549377, 'loss': -0.49991673}\n",
      "--- Step : 1039 \n",
      "  ------- {'fairness_loss': 1.8347316, 'utility': 0.55496943, 'loss': -0.4999275}\n",
      "--- Step : 1040 \n",
      "  ------- {'fairness_loss': 1.8345249, 'utility': 0.55497664, 'loss': -0.4999409}\n",
      "--- Step : 1041 \n",
      "  ------- {'fairness_loss': 1.8336253, 'utility': 0.5549623, 'loss': -0.4999535}\n",
      "--- Step : 1042 \n",
      "  ------- {'fairness_loss': 1.8333781, 'utility': 0.5549667, 'loss': -0.49996534}\n",
      "--- Step : 1043 \n",
      "  ------- {'fairness_loss': 1.8336396, 'utility': 0.55498815, 'loss': -0.49997896}\n",
      "--- Step : 1044 \n",
      "  ------- {'fairness_loss': 1.8344282, 'utility': 0.5550247, 'loss': -0.49999183}\n",
      "--- Step : 1045 \n",
      "  ------- {'fairness_loss': 1.8346611, 'utility': 0.5550435, 'loss': -0.5000037}\n",
      "--- Step : 1046 \n",
      "  ------- {'fairness_loss': 1.8340652, 'utility': 0.5550399, 'loss': -0.50001794}\n",
      "--- Step : 1047 \n",
      "  ------- {'fairness_loss': 1.8331732, 'utility': 0.5550227, 'loss': -0.50002754}\n",
      "--- Step : 1048 \n",
      "  ------- {'fairness_loss': 1.8328589, 'utility': 0.55502456, 'loss': -0.5000388}\n",
      "--- Step : 1049 \n",
      "  ------- {'fairness_loss': 1.8330512, 'utility': 0.5550435, 'loss': -0.500052}\n",
      "--- Step : 1050 \n",
      "  ------- {'fairness_loss': 1.8337015, 'utility': 0.5550776, 'loss': -0.5000666}\n",
      "--- Step : 1051 \n",
      "  ------- {'fairness_loss': 1.8349313, 'utility': 0.5551256, 'loss': -0.50007766}\n",
      "--- Step : 1052 \n",
      "  ------- {'fairness_loss': 1.835329, 'utility': 0.5551485, 'loss': -0.50008863}\n",
      "--- Step : 1053 \n",
      "  ------- {'fairness_loss': 1.8348815, 'utility': 0.5551491, 'loss': -0.50010264}\n",
      "--- Step : 1054 \n",
      "  ------- {'fairness_loss': 1.8337774, 'utility': 0.55512995, 'loss': -0.50011665}\n",
      "--- Step : 1055 \n",
      "  ------- {'fairness_loss': 1.8334002, 'utility': 0.55512965, 'loss': -0.5001276}\n",
      "--- Step : 1056 \n",
      "  ------- {'fairness_loss': 1.833534, 'utility': 0.5551464, 'loss': -0.50014037}\n",
      "--- Step : 1057 \n",
      "  ------- {'fairness_loss': 1.8341465, 'utility': 0.5551785, 'loss': -0.50015414}\n",
      "--- Step : 1058 \n",
      "  ------- {'fairness_loss': 1.8342695, 'utility': 0.5551941, 'loss': -0.500166}\n",
      "--- Step : 1059 \n",
      "  ------- {'fairness_loss': 1.8338904, 'utility': 0.555195, 'loss': -0.5001783}\n",
      "--- Step : 1060 \n",
      "  ------- {'fairness_loss': 1.8340578, 'utility': 0.5552128, 'loss': -0.5001911}\n",
      "--- Step : 1061 \n",
      "  ------- {'fairness_loss': 1.8337809, 'utility': 0.5552158, 'loss': -0.50020236}\n",
      "--- Step : 1062 \n",
      "  ------- {'fairness_loss': 1.8340044, 'utility': 0.5552355, 'loss': -0.50021535}\n",
      "--- Step : 1063 \n",
      "  ------- {'fairness_loss': 1.8348043, 'utility': 0.55526996, 'loss': -0.50022584}\n",
      "--- Step : 1064 \n",
      "  ------- {'fairness_loss': 1.8350213, 'utility': 0.5552881, 'loss': -0.50023746}\n",
      "--- Step : 1065 \n",
      "  ------- {'fairness_loss': 1.8344746, 'utility': 0.5552852, 'loss': -0.500251}\n",
      "--- Step : 1066 \n",
      "  ------- {'fairness_loss': 1.8335866, 'utility': 0.55526984, 'loss': -0.50026226}\n",
      "--- Step : 1067 \n",
      "  ------- {'fairness_loss': 1.8333176, 'utility': 0.5552731, 'loss': -0.5002736}\n",
      "--- Step : 1068 \n",
      "  ------- {'fairness_loss': 1.8335449, 'utility': 0.5552927, 'loss': -0.5002864}\n",
      "--- Step : 1069 \n",
      "  ------- {'fairness_loss': 1.8342345, 'utility': 0.5553272, 'loss': -0.50030017}\n",
      "--- Step : 1070 \n",
      "  ------- {'fairness_loss': 1.8344648, 'utility': 0.55534554, 'loss': -0.5003116}\n",
      "--- Step : 1071 \n",
      "  ------- {'fairness_loss': 1.8341721, 'utility': 0.5553496, 'loss': -0.5003244}\n",
      "--- Step : 1072 \n",
      "  ------- {'fairness_loss': 1.8335459, 'utility': 0.5553408, 'loss': -0.50033444}\n",
      "--- Step : 1073 \n",
      "  ------- {'fairness_loss': 1.8334547, 'utility': 0.5553496, 'loss': -0.50034595}\n",
      "--- Step : 1074 \n",
      "  ------- {'fairness_loss': 1.8338337, 'utility': 0.5553743, 'loss': -0.5003593}\n",
      "--- Step : 1075 \n",
      "  ------- {'fairness_loss': 1.834741, 'utility': 0.5554131, 'loss': -0.5003709}\n",
      "--- Step : 1076 \n",
      "  ------- {'fairness_loss': 1.8351388, 'utility': 0.55543584, 'loss': -0.50038165}\n",
      "--- Step : 1077 \n",
      "  ------- {'fairness_loss': 1.8347695, 'utility': 0.5554378, 'loss': -0.5003947}\n",
      "--- Step : 1078 \n",
      "  ------- {'fairness_loss': 1.8340052, 'utility': 0.55542755, 'loss': -0.5004074}\n",
      "--- Step : 1079 \n",
      "  ------- {'fairness_loss': 1.8338718, 'utility': 0.5554347, 'loss': -0.50041854}\n",
      "--- Step : 1080 \n",
      "  ------- {'fairness_loss': 1.8342125, 'utility': 0.55545807, 'loss': -0.5004317}\n",
      "--- Step : 1081 \n",
      "  ------- {'fairness_loss': 1.8351547, 'utility': 0.5554955, 'loss': -0.50044084}\n",
      "--- Step : 1082 \n",
      "  ------- {'fairness_loss': 1.835301, 'utility': 0.5555112, 'loss': -0.50045216}\n",
      "--- Step : 1083 \n",
      "  ------- {'fairness_loss': 1.8347148, 'utility': 0.55550754, 'loss': -0.5004661}\n",
      "--- Step : 1084 \n",
      "  ------- {'fairness_loss': 1.8338228, 'utility': 0.55549216, 'loss': -0.5004775}\n",
      "--- Step : 1085 \n",
      "  ------- {'fairness_loss': 1.8335577, 'utility': 0.5554949, 'loss': -0.50048816}\n",
      "--- Step : 1086 \n",
      "  ------- {'fairness_loss': 1.8337756, 'utility': 0.555514, 'loss': -0.5005007}\n",
      "--- Step : 1087 \n",
      "  ------- {'fairness_loss': 1.8344686, 'utility': 0.5555477, 'loss': -0.5005137}\n",
      "--- Step : 1088 \n",
      "  ------- {'fairness_loss': 1.8347183, 'utility': 0.555566, 'loss': -0.50052446}\n",
      "--- Step : 1089 \n",
      "  ------- {'fairness_loss': 1.8344772, 'utility': 0.5555712, 'loss': -0.50053686}\n",
      "--- Step : 1090 \n",
      "  ------- {'fairness_loss': 1.8338838, 'utility': 0.5555642, 'loss': -0.5005477}\n",
      "--- Step : 1091 \n",
      "  ------- {'fairness_loss': 1.833839, 'utility': 0.55557436, 'loss': -0.5005592}\n",
      "--- Step : 1092 \n",
      "  ------- {'fairness_loss': 1.8342549, 'utility': 0.55559987, 'loss': -0.5005722}\n",
      "--- Step : 1093 \n",
      "  ------- {'fairness_loss': 1.835277, 'utility': 0.55563927, 'loss': -0.50058097}\n",
      "--- Step : 1094 \n",
      "  ------- {'fairness_loss': 1.8355232, 'utility': 0.5556573, 'loss': -0.50059164}\n",
      "--- Step : 1095 \n",
      "  ------- {'fairness_loss': 1.8350505, 'utility': 0.55565643, 'loss': -0.5006049}\n",
      "--- Step : 1096 \n",
      "  ------- {'fairness_loss': 1.8340262, 'utility': 0.55563825, 'loss': -0.50061744}\n",
      "--- Step : 1097 \n",
      "  ------- {'fairness_loss': 1.8336921, 'utility': 0.5556385, 'loss': -0.50062776}\n",
      "--- Step : 1098 \n",
      "  ------- {'fairness_loss': 1.8338418, 'utility': 0.555655, 'loss': -0.50063974}\n",
      "--- Step : 1099 \n",
      "  ------- {'fairness_loss': 1.8344597, 'utility': 0.5556863, 'loss': -0.5006525}\n",
      "--- Step : 1100 \n",
      "  ------- {'fairness_loss': 1.8346567, 'utility': 0.55570304, 'loss': -0.50066334}\n",
      "--- Step : 1101 \n",
      "  ------- {'fairness_loss': 1.8343922, 'utility': 0.5557072, 'loss': -0.50067544}\n",
      "--- Step : 1102 \n",
      "  ------- {'fairness_loss': 1.8338157, 'utility': 0.5556999, 'loss': -0.5006854}\n",
      "--- Step : 1103 \n",
      "  ------- {'fairness_loss': 1.8337662, 'utility': 0.55570966, 'loss': -0.50069666}\n",
      "--- Step : 1104 \n",
      "  ------- {'fairness_loss': 1.8341721, 'utility': 0.5557345, 'loss': -0.50070935}\n",
      "--- Step : 1105 \n",
      "  ------- {'fairness_loss': 1.8351557, 'utility': 0.5557734, 'loss': -0.5007187}\n",
      "--- Step : 1106 \n",
      "  ------- {'fairness_loss': 1.8354155, 'utility': 0.5557915, 'loss': -0.500729}\n",
      "--- Step : 1107 \n",
      "  ------- {'fairness_loss': 1.8349837, 'utility': 0.5557913, 'loss': -0.50074184}\n",
      "--- Step : 1108 \n",
      "  ------- {'fairness_loss': 1.8340178, 'utility': 0.5557749, 'loss': -0.5007544}\n",
      "--- Step : 1109 \n",
      "  ------- {'fairness_loss': 1.8337206, 'utility': 0.55577606, 'loss': -0.5007644}\n",
      "--- Step : 1110 \n",
      "  ------- {'fairness_loss': 1.8338994, 'utility': 0.5557935, 'loss': -0.5007765}\n",
      "--- Step : 1111 \n",
      "  ------- {'fairness_loss': 1.8345612, 'utility': 0.5558251, 'loss': -0.5007883}\n",
      "--- Step : 1112 \n",
      "  ------- {'fairness_loss': 1.8348107, 'utility': 0.55584294, 'loss': -0.50079864}\n",
      "--- Step : 1113 \n",
      "  ------- {'fairness_loss': 1.8343971, 'utility': 0.5558429, 'loss': -0.500811}\n",
      "--- Step : 1114 \n",
      "  ------- {'fairness_loss': 1.8337291, 'utility': 0.5558324, 'loss': -0.5008205}\n",
      "--- Step : 1115 \n",
      "  ------- {'fairness_loss': 1.8339118, 'utility': 0.55585, 'loss': -0.5008327}\n",
      "--- Step : 1116 \n",
      "  ------- {'fairness_loss': 1.834597, 'utility': 0.5558817, 'loss': -0.50084376}\n",
      "--- Step : 1117 \n",
      "  ------- {'fairness_loss': 1.8346584, 'utility': 0.5558942, 'loss': -0.50085443}\n",
      "--- Step : 1118 \n",
      "  ------- {'fairness_loss': 1.8341128, 'utility': 0.55589, 'loss': -0.50086665}\n",
      "--- Step : 1119 \n",
      "  ------- {'fairness_loss': 1.8345244, 'utility': 0.5559126, 'loss': -0.5008769}\n",
      "--- Step : 1120 \n",
      "  ------- {'fairness_loss': 1.8345009, 'utility': 0.5559229, 'loss': -0.5008879}\n",
      "--- Step : 1121 \n",
      "  ------- {'fairness_loss': 1.8341037, 'utility': 0.5559221, 'loss': -0.50089896}\n",
      "--- Step : 1122 \n",
      "  ------- {'fairness_loss': 1.8346187, 'utility': 0.5559478, 'loss': -0.5009092}\n",
      "--- Step : 1123 \n",
      "  ------- {'fairness_loss': 1.8345003, 'utility': 0.55595535, 'loss': -0.50092036}\n",
      "--- Step : 1124 \n",
      "  ------- {'fairness_loss': 1.8342096, 'utility': 0.5559575, 'loss': -0.5009312}\n",
      "--- Step : 1125 \n",
      "  ------- {'fairness_loss': 1.8339359, 'utility': 0.55596006, 'loss': -0.500942}\n",
      "--- Step : 1126 \n",
      "  ------- {'fairness_loss': 1.8345404, 'utility': 0.5559886, 'loss': -0.5009524}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1127 \n",
      "  ------- {'fairness_loss': 1.8345329, 'utility': 0.55599904, 'loss': -0.50096303}\n",
      "--- Step : 1128 \n",
      "  ------- {'fairness_loss': 1.8339528, 'utility': 0.55599314, 'loss': -0.50097454}\n",
      "--- Step : 1129 \n",
      "  ------- {'fairness_loss': 1.8334997, 'utility': 0.5559886, 'loss': -0.5009836}\n",
      "--- Step : 1130 \n",
      "  ------- {'fairness_loss': 1.8338147, 'utility': 0.5560106, 'loss': -0.5009962}\n",
      "--- Step : 1131 \n",
      "  ------- {'fairness_loss': 1.8341728, 'utility': 0.55603117, 'loss': -0.501006}\n",
      "--- Step : 1132 \n",
      "  ------- {'fairness_loss': 1.8341129, 'utility': 0.55604005, 'loss': -0.5010167}\n",
      "--- Step : 1133 \n",
      "  ------- {'fairness_loss': 1.8336735, 'utility': 0.55603826, 'loss': -0.50102806}\n",
      "--- Step : 1134 \n",
      "  ------- {'fairness_loss': 1.8330271, 'utility': 0.5560271, 'loss': -0.5010363}\n",
      "--- Step : 1135 \n",
      "  ------- {'fairness_loss': 1.8331592, 'utility': 0.55604315, 'loss': -0.5010484}\n",
      "--- Step : 1136 \n",
      "  ------- {'fairness_loss': 1.8341755, 'utility': 0.55608356, 'loss': -0.5010583}\n",
      "--- Step : 1137 \n",
      "  ------- {'fairness_loss': 1.8347806, 'utility': 0.5561103, 'loss': -0.5010669}\n",
      "--- Step : 1138 \n",
      "  ------- {'fairness_loss': 1.834741, 'utility': 0.55611974, 'loss': -0.50107753}\n",
      "--- Step : 1139 \n",
      "  ------- {'fairness_loss': 1.8341266, 'utility': 0.5561134, 'loss': -0.50108963}\n",
      "--- Step : 1140 \n",
      "  ------- {'fairness_loss': 1.8332093, 'utility': 0.5560984, 'loss': -0.50110215}\n",
      "--- Step : 1141 \n",
      "  ------- {'fairness_loss': 1.8322669, 'utility': 0.55607575, 'loss': -0.50110775}\n",
      "--- Step : 1142 \n",
      "  ------- {'fairness_loss': 1.8321213, 'utility': 0.556081, 'loss': -0.50111735}\n",
      "--- Step : 1143 \n",
      "  ------- {'fairness_loss': 1.832636, 'utility': 0.5561115, 'loss': -0.5011324}\n",
      "--- Step : 1144 \n",
      "  ------- {'fairness_loss': 1.8340895, 'utility': 0.5561644, 'loss': -0.5011417}\n",
      "--- Step : 1145 \n",
      "  ------- {'fairness_loss': 1.8351341, 'utility': 0.5562027, 'loss': -0.5011487}\n",
      "--- Step : 1146 \n",
      "  ------- {'fairness_loss': 1.8355032, 'utility': 0.5562228, 'loss': -0.5011577}\n",
      "--- Step : 1147 \n",
      "  ------- {'fairness_loss': 1.8352627, 'utility': 0.55622673, 'loss': -0.50116885}\n",
      "--- Step : 1148 \n",
      "  ------- {'fairness_loss': 1.8344735, 'utility': 0.55621576, 'loss': -0.50118154}\n",
      "--- Step : 1149 \n",
      "  ------- {'fairness_loss': 1.8332341, 'utility': 0.556192, 'loss': -0.50119495}\n",
      "--- Step : 1150 \n",
      "  ------- {'fairness_loss': 1.8319606, 'utility': 0.55616176, 'loss': -0.50120294}\n",
      "--- Step : 1151 \n",
      "  ------- {'fairness_loss': 1.8316263, 'utility': 0.5561599, 'loss': -0.5012111}\n",
      "--- Step : 1152 \n",
      "  ------- {'fairness_loss': 1.8319637, 'utility': 0.55618334, 'loss': -0.5012244}\n",
      "--- Step : 1153 \n",
      "  ------- {'fairness_loss': 1.8331182, 'utility': 0.5562296, 'loss': -0.501236}\n",
      "--- Step : 1154 \n",
      "  ------- {'fairness_loss': 1.8339349, 'utility': 0.55626243, 'loss': -0.50124437}\n",
      "--- Step : 1155 \n",
      "  ------- {'fairness_loss': 1.8343244, 'utility': 0.5562831, 'loss': -0.50125337}\n",
      "--- Step : 1156 \n",
      "  ------- {'fairness_loss': 1.8341302, 'utility': 0.5562882, 'loss': -0.5012643}\n",
      "--- Step : 1157 \n",
      "  ------- {'fairness_loss': 1.8336115, 'utility': 0.55628383, 'loss': -0.5012755}\n",
      "--- Step : 1158 \n",
      "  ------- {'fairness_loss': 1.8327991, 'utility': 0.5562713, 'loss': -0.50128734}\n",
      "--- Step : 1159 \n",
      "  ------- {'fairness_loss': 1.8318135, 'utility': 0.5562519, 'loss': -0.5012975}\n",
      "--- Step : 1160 \n",
      "  ------- {'fairness_loss': 1.8317292, 'utility': 0.55625904, 'loss': -0.5013072}\n",
      "--- Step : 1161 \n",
      "  ------- {'fairness_loss': 1.832387, 'utility': 0.55629027, 'loss': -0.50131863}\n",
      "--- Step : 1162 \n",
      "  ------- {'fairness_loss': 1.8327379, 'utility': 0.5563101, 'loss': -0.501328}\n",
      "--- Step : 1163 \n",
      "  ------- {'fairness_loss': 1.8327147, 'utility': 0.5563195, 'loss': -0.501338}\n",
      "--- Step : 1164 \n",
      "  ------- {'fairness_loss': 1.8323531, 'utility': 0.55631953, 'loss': -0.501349}\n",
      "--- Step : 1165 \n",
      "  ------- {'fairness_loss': 1.8317487, 'utility': 0.5563114, 'loss': -0.501359}\n",
      "--- Step : 1166 \n",
      "  ------- {'fairness_loss': 1.8319585, 'utility': 0.5563287, 'loss': -0.50136995}\n",
      "--- Step : 1167 \n",
      "  ------- {'fairness_loss': 1.8318706, 'utility': 0.5563361, 'loss': -0.50137997}\n",
      "--- Step : 1168 \n",
      "  ------- {'fairness_loss': 1.8322902, 'utility': 0.556358, 'loss': -0.50138927}\n",
      "--- Step : 1169 \n",
      "  ------- {'fairness_loss': 1.8323418, 'utility': 0.5563695, 'loss': -0.5013992}\n",
      "--- Step : 1170 \n",
      "  ------- {'fairness_loss': 1.8320602, 'utility': 0.5563718, 'loss': -0.50141}\n",
      "--- Step : 1171 \n",
      "  ------- {'fairness_loss': 1.8315768, 'utility': 0.55636567, 'loss': -0.50141835}\n",
      "--- Step : 1172 \n",
      "  ------- {'fairness_loss': 1.8318207, 'utility': 0.5563846, 'loss': -0.50143}\n",
      "--- Step : 1173 \n",
      "  ------- {'fairness_loss': 1.8321102, 'utility': 0.5564028, 'loss': -0.5014395}\n",
      "--- Step : 1174 \n",
      "  ------- {'fairness_loss': 1.8320568, 'utility': 0.5564114, 'loss': -0.5014497}\n",
      "--- Step : 1175 \n",
      "  ------- {'fairness_loss': 1.8317155, 'utility': 0.55641115, 'loss': -0.50145966}\n",
      "--- Step : 1176 \n",
      "  ------- {'fairness_loss': 1.8314707, 'utility': 0.5564121, 'loss': -0.501468}\n",
      "--- Step : 1177 \n",
      "  ------- {'fairness_loss': 1.8319247, 'utility': 0.5564374, 'loss': -0.5014796}\n",
      "--- Step : 1178 \n",
      "  ------- {'fairness_loss': 1.8324358, 'utility': 0.55646145, 'loss': -0.5014884}\n",
      "--- Step : 1179 \n",
      "  ------- {'fairness_loss': 1.8325762, 'utility': 0.55647504, 'loss': -0.50149775}\n",
      "--- Step : 1180 \n",
      "  ------- {'fairness_loss': 1.8323858, 'utility': 0.5564795, 'loss': -0.50150794}\n",
      "--- Step : 1181 \n",
      "  ------- {'fairness_loss': 1.8318977, 'utility': 0.5564755, 'loss': -0.5015186}\n",
      "--- Step : 1182 \n",
      "  ------- {'fairness_loss': 1.8312366, 'utility': 0.5564645, 'loss': -0.50152737}\n",
      "--- Step : 1183 \n",
      "  ------- {'fairness_loss': 1.8313438, 'utility': 0.5564787, 'loss': -0.5015384}\n",
      "--- Step : 1184 \n",
      "  ------- {'fairness_loss': 1.8322803, 'utility': 0.5565155, 'loss': -0.5015471}\n",
      "--- Step : 1185 \n",
      "  ------- {'fairness_loss': 1.8328466, 'utility': 0.5565409, 'loss': -0.5015555}\n",
      "--- Step : 1186 \n",
      "  ------- {'fairness_loss': 1.8330538, 'utility': 0.5565562, 'loss': -0.5015646}\n",
      "--- Step : 1187 \n",
      "  ------- {'fairness_loss': 1.8327423, 'utility': 0.5565575, 'loss': -0.50157523}\n",
      "--- Step : 1188 \n",
      "  ------- {'fairness_loss': 1.8321671, 'utility': 0.55655116, 'loss': -0.50158614}\n",
      "--- Step : 1189 \n",
      "  ------- {'fairness_loss': 1.83136, 'utility': 0.55653775, 'loss': -0.5015969}\n",
      "--- Step : 1190 \n",
      "  ------- {'fairness_loss': 1.8307775, 'utility': 0.5565271, 'loss': -0.5016037}\n",
      "--- Step : 1191 \n",
      "  ------- {'fairness_loss': 1.8308985, 'utility': 0.5565417, 'loss': -0.50161475}\n",
      "--- Step : 1192 \n",
      "  ------- {'fairness_loss': 1.8317707, 'utility': 0.55657846, 'loss': -0.50162536}\n",
      "--- Step : 1193 \n",
      "  ------- {'fairness_loss': 1.8323522, 'utility': 0.55660427, 'loss': -0.5016337}\n",
      "--- Step : 1194 \n",
      "  ------- {'fairness_loss': 1.8325791, 'utility': 0.55662, 'loss': -0.50164264}\n",
      "--- Step : 1195 \n",
      "  ------- {'fairness_loss': 1.8323058, 'utility': 0.5566221, 'loss': -0.5016529}\n",
      "--- Step : 1196 \n",
      "  ------- {'fairness_loss': 1.8317662, 'utility': 0.55661654, 'loss': -0.50166357}\n",
      "--- Step : 1197 \n",
      "  ------- {'fairness_loss': 1.8310181, 'utility': 0.5566044, 'loss': -0.5016738}\n",
      "--- Step : 1198 \n",
      "  ------- {'fairness_loss': 1.8304762, 'utility': 0.55659497, 'loss': -0.5016807}\n",
      "--- Step : 1199 \n",
      "  ------- {'fairness_loss': 1.8306165, 'utility': 0.55661017, 'loss': -0.5016917}\n",
      "--- Step : 1200 \n",
      "  ------- {'fairness_loss': 1.8315153, 'utility': 0.55664754, 'loss': -0.5017021}\n",
      "--- Step : 1201 \n",
      "  ------- {'fairness_loss': 1.8321259, 'utility': 0.5566739, 'loss': -0.5017101}\n",
      "--- Step : 1202 \n",
      "  ------- {'fairness_loss': 1.8322188, 'utility': 0.55668586, 'loss': -0.5017193}\n",
      "--- Step : 1203 \n",
      "  ------- {'fairness_loss': 1.8318415, 'utility': 0.55668473, 'loss': -0.5017295}\n",
      "--- Step : 1204 \n",
      "  ------- {'fairness_loss': 1.8312163, 'utility': 0.55667686, 'loss': -0.5017404}\n",
      "--- Step : 1205 \n",
      "  ------- {'fairness_loss': 1.830444, 'utility': 0.55666244, 'loss': -0.5017491}\n",
      "--- Step : 1206 \n",
      "  ------- {'fairness_loss': 1.8304724, 'utility': 0.5566732, 'loss': -0.50175905}\n",
      "--- Step : 1207 \n",
      "  ------- {'fairness_loss': 1.8312669, 'utility': 0.55670637, 'loss': -0.50176835}\n",
      "--- Step : 1208 \n",
      "  ------- {'fairness_loss': 1.8317487, 'utility': 0.5567291, 'loss': -0.50177664}\n",
      "--- Step : 1209 \n",
      "  ------- {'fairness_loss': 1.8319072, 'utility': 0.5567427, 'loss': -0.5017855}\n",
      "--- Step : 1210 \n",
      "  ------- {'fairness_loss': 1.8315921, 'utility': 0.5567434, 'loss': -0.50179565}\n",
      "--- Step : 1211 \n",
      "  ------- {'fairness_loss': 1.8310366, 'utility': 0.55673707, 'loss': -0.50180596}\n",
      "--- Step : 1212 \n",
      "  ------- {'fairness_loss': 1.8303165, 'utility': 0.5567248, 'loss': -0.5018153}\n",
      "--- Step : 1213 \n",
      "  ------- {'fairness_loss': 1.8298005, 'utility': 0.5567153, 'loss': -0.5018213}\n",
      "--- Step : 1214 \n",
      "  ------- {'fairness_loss': 1.8299378, 'utility': 0.55673003, 'loss': -0.5018319}\n",
      "--- Step : 1215 \n",
      "  ------- {'fairness_loss': 1.8307656, 'utility': 0.5567663, 'loss': -0.50184333}\n",
      "--- Step : 1216 \n",
      "  ------- {'fairness_loss': 1.8316699, 'utility': 0.5568008, 'loss': -0.50185066}\n",
      "--- Step : 1217 \n",
      "  ------- {'fairness_loss': 1.8320677, 'utility': 0.5568205, 'loss': -0.5018585}\n",
      "--- Step : 1218 \n",
      "  ------- {'fairness_loss': 1.831971, 'utility': 0.556827, 'loss': -0.5018679}\n",
      "--- Step : 1219 \n",
      "  ------- {'fairness_loss': 1.8314358, 'utility': 0.5568217, 'loss': -0.5018786}\n",
      "--- Step : 1220 \n",
      "  ------- {'fairness_loss': 1.8305385, 'utility': 0.55680585, 'loss': -0.5018897}\n",
      "--- Step : 1221 \n",
      "  ------- {'fairness_loss': 1.8296009, 'utility': 0.556785, 'loss': -0.501897}\n",
      "--- Step : 1222 \n",
      "  ------- {'fairness_loss': 1.829462, 'utility': 0.5567893, 'loss': -0.50190544}\n",
      "--- Step : 1223 \n",
      "  ------- {'fairness_loss': 1.8299649, 'utility': 0.55681634, 'loss': -0.5019174}\n",
      "--- Step : 1224 \n",
      "  ------- {'fairness_loss': 1.8305403, 'utility': 0.5568422, 'loss': -0.501926}\n",
      "--- Step : 1225 \n",
      "  ------- {'fairness_loss': 1.8308185, 'utility': 0.5568591, 'loss': -0.5019345}\n",
      "--- Step : 1226 \n",
      "  ------- {'fairness_loss': 1.8308092, 'utility': 0.5568678, 'loss': -0.5019435}\n",
      "--- Step : 1227 \n",
      "  ------- {'fairness_loss': 1.8305379, 'utility': 0.55686927, 'loss': -0.5019531}\n",
      "--- Step : 1228 \n",
      "  ------- {'fairness_loss': 1.8300381, 'utility': 0.5568642, 'loss': -0.5019631}\n",
      "--- Step : 1229 \n",
      "  ------- {'fairness_loss': 1.8293933, 'utility': 0.5568533, 'loss': -0.5019715}\n",
      "--- Step : 1230 \n",
      "  ------- {'fairness_loss': 1.8295071, 'utility': 0.55686647, 'loss': -0.50198126}\n",
      "--- Step : 1231 \n",
      "  ------- {'fairness_loss': 1.8296555, 'utility': 0.55687994, 'loss': -0.50199026}\n",
      "--- Step : 1232 \n",
      "  ------- {'fairness_loss': 1.8298203, 'utility': 0.5568938, 'loss': -0.5019992}\n",
      "--- Step : 1233 \n",
      "  ------- {'fairness_loss': 1.8297312, 'utility': 0.5569003, 'loss': -0.5020084}\n",
      "--- Step : 1234 \n",
      "  ------- {'fairness_loss': 1.8294175, 'utility': 0.55689996, 'loss': -0.50201744}\n",
      "--- Step : 1235 \n",
      "  ------- {'fairness_loss': 1.8291657, 'utility': 0.5569014, 'loss': -0.50202644}\n",
      "--- Step : 1236 \n",
      "  ------- {'fairness_loss': 1.8289999, 'utility': 0.55690473, 'loss': -0.5020347}\n",
      "--- Step : 1237 \n",
      "  ------- {'fairness_loss': 1.8295332, 'utility': 0.5569303, 'loss': -0.5020443}\n",
      "--- Step : 1238 \n",
      "  ------- {'fairness_loss': 1.8298203, 'utility': 0.5569472, 'loss': -0.50205255}\n",
      "--- Step : 1239 \n",
      "  ------- {'fairness_loss': 1.8298297, 'utility': 0.5569563, 'loss': -0.5020614}\n",
      "--- Step : 1240 \n",
      "  ------- {'fairness_loss': 1.8295914, 'utility': 0.5569585, 'loss': -0.5020708}\n",
      "--- Step : 1241 \n",
      "  ------- {'fairness_loss': 1.8291334, 'utility': 0.5569543, 'loss': -0.5020803}\n",
      "--- Step : 1242 \n",
      "  ------- {'fairness_loss': 1.8285755, 'utility': 0.5569446, 'loss': -0.50208735}\n",
      "--- Step : 1243 \n",
      "  ------- {'fairness_loss': 1.8287038, 'utility': 0.5569585, 'loss': -0.50209737}\n",
      "--- Step : 1244 \n",
      "  ------- {'fairness_loss': 1.8295854, 'utility': 0.5569936, 'loss': -0.5021061}\n",
      "--- Step : 1245 \n",
      "  ------- {'fairness_loss': 1.8301982, 'utility': 0.55701923, 'loss': -0.5021133}\n",
      "--- Step : 1246 \n",
      "  ------- {'fairness_loss': 1.8303474, 'utility': 0.55703187, 'loss': -0.50212145}\n",
      "--- Step : 1247 \n",
      "  ------- {'fairness_loss': 1.8300741, 'utility': 0.55703324, 'loss': -0.50213104}\n",
      "--- Step : 1248 \n",
      "  ------- {'fairness_loss': 1.8294228, 'utility': 0.557024, 'loss': -0.5021413}\n",
      "--- Step : 1249 \n",
      "  ------- {'fairness_loss': 1.8286418, 'utility': 0.5570103, 'loss': -0.502151}\n",
      "--- Step : 1250 \n",
      "  ------- {'fairness_loss': 1.8281077, 'utility': 0.5569997, 'loss': -0.50215644}\n",
      "--- Step : 1251 \n",
      "  ------- {'fairness_loss': 1.828207, 'utility': 0.5570126, 'loss': -0.5021664}\n",
      "--- Step : 1252 \n",
      "  ------- {'fairness_loss': 1.8289819, 'utility': 0.5570465, 'loss': -0.502177}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1253 \n",
      "  ------- {'fairness_loss': 1.8295667, 'utility': 0.55707127, 'loss': -0.5021843}\n",
      "--- Step : 1254 \n",
      "  ------- {'fairness_loss': 1.8297036, 'utility': 0.5570836, 'loss': -0.5021925}\n",
      "--- Step : 1255 \n",
      "  ------- {'fairness_loss': 1.8294296, 'utility': 0.55708486, 'loss': -0.502202}\n",
      "--- Step : 1256 \n",
      "  ------- {'fairness_loss': 1.8288034, 'utility': 0.5570761, 'loss': -0.502212}\n",
      "--- Step : 1257 \n",
      "  ------- {'fairness_loss': 1.828092, 'utility': 0.55706257, 'loss': -0.5022198}\n",
      "--- Step : 1258 \n",
      "  ------- {'fairness_loss': 1.8281198, 'utility': 0.5570725, 'loss': -0.5022289}\n",
      "--- Step : 1259 \n",
      "  ------- {'fairness_loss': 1.8288659, 'utility': 0.55710375, 'loss': -0.5022378}\n",
      "--- Step : 1260 \n",
      "  ------- {'fairness_loss': 1.8293765, 'utility': 0.5571261, 'loss': -0.50224483}\n",
      "--- Step : 1261 \n",
      "  ------- {'fairness_loss': 1.8294473, 'utility': 0.5571367, 'loss': -0.5022533}\n",
      "--- Step : 1262 \n",
      "  ------- {'fairness_loss': 1.8291271, 'utility': 0.5571363, 'loss': -0.5022625}\n",
      "--- Step : 1263 \n",
      "  ------- {'fairness_loss': 1.8284677, 'utility': 0.55712664, 'loss': -0.5022726}\n",
      "--- Step : 1264 \n",
      "  ------- {'fairness_loss': 1.8279642, 'utility': 0.55711985, 'loss': -0.50228095}\n",
      "--- Step : 1265 \n",
      "  ------- {'fairness_loss': 1.8276136, 'utility': 0.5571159, 'loss': -0.5022875}\n",
      "--- Step : 1266 \n",
      "  ------- {'fairness_loss': 1.8278724, 'utility': 0.5571343, 'loss': -0.5022981}\n",
      "--- Step : 1267 \n",
      "  ------- {'fairness_loss': 1.828203, 'utility': 0.5571529, 'loss': -0.5023068}\n",
      "--- Step : 1268 \n",
      "  ------- {'fairness_loss': 1.8283134, 'utility': 0.55716455, 'loss': -0.50231516}\n",
      "--- Step : 1269 \n",
      "  ------- {'fairness_loss': 1.8281935, 'utility': 0.55716956, 'loss': -0.50232375}\n",
      "--- Step : 1270 \n",
      "  ------- {'fairness_loss': 1.8278753, 'utility': 0.5571688, 'loss': -0.5023325}\n",
      "--- Step : 1271 \n",
      "  ------- {'fairness_loss': 1.8276445, 'utility': 0.5571703, 'loss': -0.5023409}\n",
      "--- Step : 1272 \n",
      "  ------- {'fairness_loss': 1.8274772, 'utility': 0.5571737, 'loss': -0.50234944}\n",
      "--- Step : 1273 \n",
      "  ------- {'fairness_loss': 1.8273757, 'utility': 0.55717915, 'loss': -0.5023579}\n",
      "--- Step : 1274 \n",
      "  ------- {'fairness_loss': 1.8280058, 'utility': 0.5572058, 'loss': -0.50236565}\n",
      "--- Step : 1275 \n",
      "  ------- {'fairness_loss': 1.8283943, 'utility': 0.55722463, 'loss': -0.5023728}\n",
      "--- Step : 1276 \n",
      "  ------- {'fairness_loss': 1.8283724, 'utility': 0.55723226, 'loss': -0.5023811}\n",
      "--- Step : 1277 \n",
      "  ------- {'fairness_loss': 1.8279846, 'utility': 0.5572299, 'loss': -0.5023903}\n",
      "--- Step : 1278 \n",
      "  ------- {'fairness_loss': 1.8272884, 'utility': 0.5572186, 'loss': -0.5024}\n",
      "--- Step : 1279 \n",
      "  ------- {'fairness_loss': 1.8265977, 'utility': 0.55720335, 'loss': -0.5024054}\n",
      "--- Step : 1280 \n",
      "  ------- {'fairness_loss': 1.8265783, 'utility': 0.5572114, 'loss': -0.50241405}\n",
      "--- Step : 1281 \n",
      "  ------- {'fairness_loss': 1.8271757, 'utility': 0.5572402, 'loss': -0.5024249}\n",
      "--- Step : 1282 \n",
      "  ------- {'fairness_loss': 1.8276289, 'utility': 0.5572612, 'loss': -0.50243235}\n",
      "--- Step : 1283 \n",
      "  ------- {'fairness_loss': 1.827689, 'utility': 0.55727106, 'loss': -0.5024404}\n",
      "--- Step : 1284 \n",
      "  ------- {'fairness_loss': 1.8273845, 'utility': 0.55727094, 'loss': -0.5024494}\n",
      "--- Step : 1285 \n",
      "  ------- {'fairness_loss': 1.8269149, 'utility': 0.557266, 'loss': -0.5024586}\n",
      "--- Step : 1286 \n",
      "  ------- {'fairness_loss': 1.8263999, 'utility': 0.55725634, 'loss': -0.50246435}\n",
      "--- Step : 1287 \n",
      "  ------- {'fairness_loss': 1.8265173, 'utility': 0.5572694, 'loss': -0.5024739}\n",
      "--- Step : 1288 \n",
      "  ------- {'fairness_loss': 1.8273516, 'utility': 0.5573026, 'loss': -0.50248206}\n",
      "--- Step : 1289 \n",
      "  ------- {'fairness_loss': 1.8278213, 'utility': 0.55732375, 'loss': -0.5024891}\n",
      "--- Step : 1290 \n",
      "  ------- {'fairness_loss': 1.8278933, 'utility': 0.5573339, 'loss': -0.5024971}\n",
      "--- Step : 1291 \n",
      "  ------- {'fairness_loss': 1.8276063, 'utility': 0.5573341, 'loss': -0.50250596}\n",
      "--- Step : 1292 \n",
      "  ------- {'fairness_loss': 1.8269953, 'utility': 0.5573256, 'loss': -0.50251573}\n",
      "--- Step : 1293 \n",
      "  ------- {'fairness_loss': 1.8262223, 'utility': 0.5573091, 'loss': -0.5025224}\n",
      "--- Step : 1294 \n",
      "  ------- {'fairness_loss': 1.8261737, 'utility': 0.5573158, 'loss': -0.50253063}\n",
      "--- Step : 1295 \n",
      "  ------- {'fairness_loss': 1.8267533, 'utility': 0.55734307, 'loss': -0.50254047}\n",
      "--- Step : 1296 \n",
      "  ------- {'fairness_loss': 1.827181, 'utility': 0.5573628, 'loss': -0.5025474}\n",
      "--- Step : 1297 \n",
      "  ------- {'fairness_loss': 1.8272251, 'utility': 0.5573721, 'loss': -0.5025554}\n",
      "--- Step : 1298 \n",
      "  ------- {'fairness_loss': 1.8269218, 'utility': 0.5573719, 'loss': -0.50256425}\n",
      "--- Step : 1299 \n",
      "  ------- {'fairness_loss': 1.8263439, 'utility': 0.5573632, 'loss': -0.5025729}\n",
      "--- Step : 1300 \n",
      "  ------- {'fairness_loss': 1.8259501, 'utility': 0.5573576, 'loss': -0.5025791}\n",
      "--- Step : 1301 \n",
      "  ------- {'fairness_loss': 1.8261644, 'utility': 0.5573739, 'loss': -0.5025889}\n",
      "--- Step : 1302 \n",
      "  ------- {'fairness_loss': 1.8264539, 'utility': 0.5573908, 'loss': -0.5025972}\n",
      "--- Step : 1303 \n",
      "  ------- {'fairness_loss': 1.826667, 'utility': 0.5574045, 'loss': -0.5026045}\n",
      "--- Step : 1304 \n",
      "  ------- {'fairness_loss': 1.8265243, 'utility': 0.5574086, 'loss': -0.5026128}\n",
      "--- Step : 1305 \n",
      "  ------- {'fairness_loss': 1.8260758, 'utility': 0.55740374, 'loss': -0.5026215}\n",
      "--- Step : 1306 \n",
      "  ------- {'fairness_loss': 1.8257519, 'utility': 0.55740184, 'loss': -0.5026293}\n",
      "--- Step : 1307 \n",
      "  ------- {'fairness_loss': 1.8261337, 'utility': 0.55742115, 'loss': -0.50263715}\n",
      "--- Step : 1308 \n",
      "  ------- {'fairness_loss': 1.8263217, 'utility': 0.55743414, 'loss': -0.5026445}\n",
      "--- Step : 1309 \n",
      "  ------- {'fairness_loss': 1.8261656, 'utility': 0.55743754, 'loss': -0.5026526}\n",
      "--- Step : 1310 \n",
      "  ------- {'fairness_loss': 1.8257028, 'utility': 0.5574325, 'loss': -0.5026614}\n",
      "--- Step : 1311 \n",
      "  ------- {'fairness_loss': 1.8252057, 'utility': 0.55742353, 'loss': -0.50266737}\n",
      "--- Step : 1312 \n",
      "  ------- {'fairness_loss': 1.8253249, 'utility': 0.55743647, 'loss': -0.5026767}\n",
      "--- Step : 1313 \n",
      "  ------- {'fairness_loss': 1.8261689, 'utility': 0.5574688, 'loss': -0.5026837}\n",
      "--- Step : 1314 \n",
      "  ------- {'fairness_loss': 1.8266543, 'utility': 0.55749, 'loss': -0.5026904}\n",
      "--- Step : 1315 \n",
      "  ------- {'fairness_loss': 1.8267653, 'utility': 0.5575009, 'loss': -0.50269794}\n",
      "--- Step : 1316 \n",
      "  ------- {'fairness_loss': 1.8265452, 'utility': 0.55750257, 'loss': -0.5027062}\n",
      "--- Step : 1317 \n",
      "  ------- {'fairness_loss': 1.8260231, 'utility': 0.5574961, 'loss': -0.50271535}\n",
      "--- Step : 1318 \n",
      "  ------- {'fairness_loss': 1.8252476, 'utility': 0.557482, 'loss': -0.5027246}\n",
      "--- Step : 1319 \n",
      "  ------- {'fairness_loss': 1.8245738, 'utility': 0.5574655, 'loss': -0.5027283}\n",
      "--- Step : 1320 \n",
      "  ------- {'fairness_loss': 1.8245122, 'utility': 0.5574713, 'loss': -0.5027359}\n",
      "--- Step : 1321 \n",
      "  ------- {'fairness_loss': 1.8249785, 'utility': 0.55749714, 'loss': -0.5027478}\n",
      "--- Step : 1322 \n",
      "  ------- {'fairness_loss': 1.8262547, 'utility': 0.5575411, 'loss': -0.50275344}\n",
      "--- Step : 1323 \n",
      "  ------- {'fairness_loss': 1.8271289, 'utility': 0.5575729, 'loss': -0.50275904}\n",
      "--- Step : 1324 \n",
      "  ------- {'fairness_loss': 1.827598, 'utility': 0.5575934, 'loss': -0.5027655}\n",
      "--- Step : 1325 \n",
      "  ------- {'fairness_loss': 1.8277054, 'utility': 0.557604, 'loss': -0.50277287}\n",
      "--- Step : 1326 \n",
      "  ------- {'fairness_loss': 1.8274835, 'utility': 0.5576058, 'loss': -0.5027813}\n",
      "--- Step : 1327 \n",
      "  ------- {'fairness_loss': 1.8269744, 'utility': 0.5575994, 'loss': -0.5027902}\n",
      "--- Step : 1328 \n",
      "  ------- {'fairness_loss': 1.8262026, 'utility': 0.55758584, 'loss': -0.50279975}\n",
      "--- Step : 1329 \n",
      "  ------- {'fairness_loss': 1.8252069, 'utility': 0.5575659, 'loss': -0.5028097}\n",
      "--- Step : 1330 \n",
      "  ------- {'fairness_loss': 1.8243788, 'utility': 0.557547, 'loss': -0.5028156}\n",
      "--- Step : 1331 \n",
      "  ------- {'fairness_loss': 1.8242553, 'utility': 0.5575504, 'loss': -0.5028227}\n",
      "--- Step : 1332 \n",
      "  ------- {'fairness_loss': 1.8247021, 'utility': 0.5575738, 'loss': -0.5028327}\n",
      "--- Step : 1333 \n",
      "  ------- {'fairness_loss': 1.8252538, 'utility': 0.5575976, 'loss': -0.50284}\n",
      "--- Step : 1334 \n",
      "  ------- {'fairness_loss': 1.8254837, 'utility': 0.5576114, 'loss': -0.5028469}\n",
      "--- Step : 1335 \n",
      "  ------- {'fairness_loss': 1.8253839, 'utility': 0.55761606, 'loss': -0.5028545}\n",
      "--- Step : 1336 \n",
      "  ------- {'fairness_loss': 1.8249964, 'utility': 0.5576129, 'loss': -0.502863}\n",
      "--- Step : 1337 \n",
      "  ------- {'fairness_loss': 1.8243828, 'utility': 0.5576024, 'loss': -0.5028709}\n",
      "--- Step : 1338 \n",
      "  ------- {'fairness_loss': 1.8239537, 'utility': 0.55759585, 'loss': -0.50287724}\n",
      "--- Step : 1339 \n",
      "  ------- {'fairness_loss': 1.8241287, 'utility': 0.5576101, 'loss': -0.50288624}\n",
      "--- Step : 1340 \n",
      "  ------- {'fairness_loss': 1.8243833, 'utility': 0.5576256, 'loss': -0.5028941}\n",
      "--- Step : 1341 \n",
      "  ------- {'fairness_loss': 1.824712, 'utility': 0.55764216, 'loss': -0.5029008}\n",
      "--- Step : 1342 \n",
      "  ------- {'fairness_loss': 1.8247181, 'utility': 0.55764973, 'loss': -0.5029082}\n",
      "--- Step : 1343 \n",
      "  ------- {'fairness_loss': 1.8244287, 'utility': 0.5576491, 'loss': -0.5029162}\n",
      "--- Step : 1344 \n",
      "  ------- {'fairness_loss': 1.8238919, 'utility': 0.55764127, 'loss': -0.5029245}\n",
      "--- Step : 1345 \n",
      "  ------- {'fairness_loss': 1.823527, 'utility': 0.55763686, 'loss': -0.50293106}\n",
      "--- Step : 1346 \n",
      "  ------- {'fairness_loss': 1.823789, 'utility': 0.5576532, 'loss': -0.5029395}\n",
      "--- Step : 1347 \n",
      "  ------- {'fairness_loss': 1.8239182, 'utility': 0.55766416, 'loss': -0.5029466}\n",
      "--- Step : 1348 \n",
      "  ------- {'fairness_loss': 1.8238825, 'utility': 0.5576706, 'loss': -0.5029541}\n",
      "--- Step : 1349 \n",
      "  ------- {'fairness_loss': 1.8237011, 'utility': 0.5576729, 'loss': -0.5029619}\n",
      "--- Step : 1350 \n",
      "  ------- {'fairness_loss': 1.8233906, 'utility': 0.5576713, 'loss': -0.5029696}\n",
      "--- Step : 1351 \n",
      "  ------- {'fairness_loss': 1.8232183, 'utility': 0.5576727, 'loss': -0.5029761}\n",
      "--- Step : 1352 \n",
      "  ------- {'fairness_loss': 1.8236585, 'utility': 0.55769384, 'loss': -0.5029841}\n",
      "--- Step : 1353 \n",
      "  ------- {'fairness_loss': 1.8238324, 'utility': 0.557706, 'loss': -0.502991}\n",
      "--- Step : 1354 \n",
      "  ------- {'fairness_loss': 1.8237034, 'utility': 0.5577097, 'loss': -0.5029986}\n",
      "--- Step : 1355 \n",
      "  ------- {'fairness_loss': 1.8233103, 'utility': 0.5577061, 'loss': -0.5030068}\n",
      "--- Step : 1356 \n",
      "  ------- {'fairness_loss': 1.8230569, 'utility': 0.5577055, 'loss': -0.5030138}\n",
      "--- Step : 1357 \n",
      "  ------- {'fairness_loss': 1.8234682, 'utility': 0.5577251, 'loss': -0.503021}\n",
      "--- Step : 1358 \n",
      "  ------- {'fairness_loss': 1.8235875, 'utility': 0.5577357, 'loss': -0.50302804}\n",
      "--- Step : 1359 \n",
      "  ------- {'fairness_loss': 1.8234181, 'utility': 0.5577381, 'loss': -0.5030356}\n",
      "--- Step : 1360 \n",
      "  ------- {'fairness_loss': 1.8229928, 'utility': 0.5577335, 'loss': -0.5030437}\n",
      "--- Step : 1361 \n",
      "  ------- {'fairness_loss': 1.822734, 'utility': 0.557732, 'loss': -0.50304997}\n",
      "--- Step : 1362 \n",
      "  ------- {'fairness_loss': 1.8230889, 'utility': 0.55775064, 'loss': -0.50305796}\n",
      "--- Step : 1363 \n",
      "  ------- {'fairness_loss': 1.823187, 'utility': 0.5577606, 'loss': -0.503065}\n",
      "--- Step : 1364 \n",
      "  ------- {'fairness_loss': 1.8230035, 'utility': 0.5577626, 'loss': -0.5030725}\n",
      "--- Step : 1365 \n",
      "  ------- {'fairness_loss': 1.8225973, 'utility': 0.55775774, 'loss': -0.50307983}\n",
      "--- Step : 1366 \n",
      "  ------- {'fairness_loss': 1.8228604, 'utility': 0.55777305, 'loss': -0.5030872}\n",
      "--- Step : 1367 \n",
      "  ------- {'fairness_loss': 1.8228577, 'utility': 0.55778, 'loss': -0.5030943}\n",
      "--- Step : 1368 \n",
      "  ------- {'fairness_loss': 1.8225937, 'utility': 0.5577796, 'loss': -0.5031018}\n",
      "--- Step : 1369 \n",
      "  ------- {'fairness_loss': 1.8223449, 'utility': 0.55777866, 'loss': -0.5031083}\n",
      "--- Step : 1370 \n",
      "  ------- {'fairness_loss': 1.8227096, 'utility': 0.5577974, 'loss': -0.5031161}\n",
      "--- Step : 1371 \n",
      "  ------- {'fairness_loss': 1.8228227, 'utility': 0.55780756, 'loss': -0.50312287}\n",
      "--- Step : 1372 \n",
      "  ------- {'fairness_loss': 1.8226583, 'utility': 0.55781007, 'loss': -0.5031303}\n",
      "--- Step : 1373 \n",
      "  ------- {'fairness_loss': 1.8222624, 'utility': 0.5578057, 'loss': -0.5031378}\n",
      "--- Step : 1374 \n",
      "  ------- {'fairness_loss': 1.8219329, 'utility': 0.557801, 'loss': -0.503143}\n",
      "--- Step : 1375 \n",
      "  ------- {'fairness_loss': 1.8221451, 'utility': 0.5578166, 'loss': -0.50315225}\n",
      "--- Step : 1376 \n",
      "  ------- {'fairness_loss': 1.8223618, 'utility': 0.55782986, 'loss': -0.503159}\n",
      "--- Step : 1377 \n",
      "  ------- {'fairness_loss': 1.8223057, 'utility': 0.5578353, 'loss': -0.50316614}\n",
      "--- Step : 1378 \n",
      "  ------- {'fairness_loss': 1.8219947, 'utility': 0.55783385, 'loss': -0.503174}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1379 \n",
      "  ------- {'fairness_loss': 1.8215648, 'utility': 0.55782574, 'loss': -0.5031788}\n",
      "--- Step : 1380 \n",
      "  ------- {'fairness_loss': 1.8216875, 'utility': 0.5578382, 'loss': -0.5031876}\n",
      "--- Step : 1381 \n",
      "  ------- {'fairness_loss': 1.822508, 'utility': 0.55786896, 'loss': -0.50319374}\n",
      "--- Step : 1382 \n",
      "  ------- {'fairness_loss': 1.8230222, 'utility': 0.55789006, 'loss': -0.5031994}\n",
      "--- Step : 1383 \n",
      "  ------- {'fairness_loss': 1.8232249, 'utility': 0.55790263, 'loss': -0.5032059}\n",
      "--- Step : 1384 \n",
      "  ------- {'fairness_loss': 1.8231518, 'utility': 0.55790764, 'loss': -0.5032131}\n",
      "--- Step : 1385 \n",
      "  ------- {'fairness_loss': 1.8228287, 'utility': 0.5579056, 'loss': -0.50322074}\n",
      "--- Step : 1386 \n",
      "  ------- {'fairness_loss': 1.8222818, 'utility': 0.55789727, 'loss': -0.50322884}\n",
      "--- Step : 1387 \n",
      "  ------- {'fairness_loss': 1.8215386, 'utility': 0.55788356, 'loss': -0.5032374}\n",
      "--- Step : 1388 \n",
      "  ------- {'fairness_loss': 1.8209767, 'utility': 0.55787075, 'loss': -0.5032414}\n",
      "--- Step : 1389 \n",
      "  ------- {'fairness_loss': 1.8209883, 'utility': 0.5578786, 'loss': -0.503249}\n",
      "--- Step : 1390 \n",
      "  ------- {'fairness_loss': 1.8215675, 'utility': 0.55790514, 'loss': -0.5032581}\n",
      "--- Step : 1391 \n",
      "  ------- {'fairness_loss': 1.821952, 'utility': 0.5579228, 'loss': -0.50326425}\n",
      "--- Step : 1392 \n",
      "  ------- {'fairness_loss': 1.8220497, 'utility': 0.55793226, 'loss': -0.50327075}\n",
      "--- Step : 1393 \n",
      "  ------- {'fairness_loss': 1.8218884, 'utility': 0.55793464, 'loss': -0.503278}\n",
      "--- Step : 1394 \n",
      "  ------- {'fairness_loss': 1.821495, 'utility': 0.55793065, 'loss': -0.5032858}\n",
      "--- Step : 1395 \n",
      "  ------- {'fairness_loss': 1.8209362, 'utility': 0.5579208, 'loss': -0.50329274}\n",
      "--- Step : 1396 \n",
      "  ------- {'fairness_loss': 1.8210471, 'utility': 0.55793136, 'loss': -0.50329995}\n",
      "--- Step : 1397 \n",
      "  ------- {'fairness_loss': 1.8211184, 'utility': 0.5579403, 'loss': -0.50330675}\n",
      "--- Step : 1398 \n",
      "  ------- {'fairness_loss': 1.8211408, 'utility': 0.557948, 'loss': -0.5033138}\n",
      "--- Step : 1399 \n",
      "  ------- {'fairness_loss': 1.8209366, 'utility': 0.5579489, 'loss': -0.5033208}\n",
      "--- Step : 1400 \n",
      "  ------- {'fairness_loss': 1.8207122, 'utility': 0.5579491, 'loss': -0.5033278}\n",
      "--- Step : 1401 \n",
      "  ------- {'fairness_loss': 1.8205867, 'utility': 0.5579523, 'loss': -0.5033347}\n",
      "--- Step : 1402 \n",
      "  ------- {'fairness_loss': 1.8205546, 'utility': 0.55795825, 'loss': -0.5033416}\n",
      "--- Step : 1403 \n",
      "  ------- {'fairness_loss': 1.8204136, 'utility': 0.55796105, 'loss': -0.50334865}\n",
      "--- Step : 1404 \n",
      "  ------- {'fairness_loss': 1.8202115, 'utility': 0.55796087, 'loss': -0.50335455}\n",
      "--- Step : 1405 \n",
      "  ------- {'fairness_loss': 1.8206116, 'utility': 0.5579799, 'loss': -0.5033615}\n",
      "--- Step : 1406 \n",
      "  ------- {'fairness_loss': 1.8207737, 'utility': 0.55799115, 'loss': -0.50336796}\n",
      "--- Step : 1407 \n",
      "  ------- {'fairness_loss': 1.8206836, 'utility': 0.55799526, 'loss': -0.50337476}\n",
      "--- Step : 1408 \n",
      "  ------- {'fairness_loss': 1.8203646, 'utility': 0.5579932, 'loss': -0.5033822}\n",
      "--- Step : 1409 \n",
      "  ------- {'fairness_loss': 1.8198959, 'utility': 0.55798537, 'loss': -0.50338846}\n",
      "--- Step : 1410 \n",
      "  ------- {'fairness_loss': 1.8200384, 'utility': 0.55799747, 'loss': -0.50339633}\n",
      "--- Step : 1411 \n",
      "  ------- {'fairness_loss': 1.8199794, 'utility': 0.5580024, 'loss': -0.503403}\n",
      "--- Step : 1412 \n",
      "  ------- {'fairness_loss': 1.8202676, 'utility': 0.5580172, 'loss': -0.50340915}\n",
      "--- Step : 1413 \n",
      "  ------- {'fairness_loss': 1.8202959, 'utility': 0.55802464, 'loss': -0.50341576}\n",
      "--- Step : 1414 \n",
      "  ------- {'fairness_loss': 1.8200895, 'utility': 0.5580258, 'loss': -0.5034231}\n",
      "--- Step : 1415 \n",
      "  ------- {'fairness_loss': 1.8197219, 'utility': 0.55802083, 'loss': -0.5034292}\n",
      "--- Step : 1416 \n",
      "  ------- {'fairness_loss': 1.8199679, 'utility': 0.5580354, 'loss': -0.5034363}\n",
      "--- Step : 1417 \n",
      "  ------- {'fairness_loss': 1.8201803, 'utility': 0.5580482, 'loss': -0.50344276}\n",
      "--- Step : 1418 \n",
      "  ------- {'fairness_loss': 1.8201556, 'utility': 0.55805415, 'loss': -0.5034495}\n",
      "--- Step : 1419 \n",
      "  ------- {'fairness_loss': 1.8199157, 'utility': 0.5580538, 'loss': -0.50345635}\n",
      "--- Step : 1420 \n",
      "  ------- {'fairness_loss': 1.8196745, 'utility': 0.55805314, 'loss': -0.5034629}\n",
      "--- Step : 1421 \n",
      "  ------- {'fairness_loss': 1.8194414, 'utility': 0.5580524, 'loss': -0.50346917}\n",
      "--- Step : 1422 \n",
      "  ------- {'fairness_loss': 1.819696, 'utility': 0.5580674, 'loss': -0.5034765}\n",
      "--- Step : 1423 \n",
      "  ------- {'fairness_loss': 1.8199303, 'utility': 0.5580804, 'loss': -0.50348246}\n",
      "--- Step : 1424 \n",
      "  ------- {'fairness_loss': 1.8199228, 'utility': 0.55808675, 'loss': -0.5034891}\n",
      "--- Step : 1425 \n",
      "  ------- {'fairness_loss': 1.8196963, 'utility': 0.5580868, 'loss': -0.50349593}\n",
      "--- Step : 1426 \n",
      "  ------- {'fairness_loss': 1.8192679, 'utility': 0.5580812, 'loss': -0.5035032}\n",
      "--- Step : 1427 \n",
      "  ------- {'fairness_loss': 1.8189136, 'utility': 0.5580761, 'loss': -0.5035087}\n",
      "--- Step : 1428 \n",
      "  ------- {'fairness_loss': 1.8191359, 'utility': 0.5580904, 'loss': -0.5035163}\n",
      "--- Step : 1429 \n",
      "  ------- {'fairness_loss': 1.8191671, 'utility': 0.5580977, 'loss': -0.5035227}\n",
      "--- Step : 1430 \n",
      "  ------- {'fairness_loss': 1.818976, 'utility': 0.55809873, 'loss': -0.5035294}\n",
      "--- Step : 1431 \n",
      "  ------- {'fairness_loss': 1.8186405, 'utility': 0.5580943, 'loss': -0.5035351}\n",
      "--- Step : 1432 \n",
      "  ------- {'fairness_loss': 1.8188854, 'utility': 0.5581091, 'loss': -0.50354254}\n",
      "--- Step : 1433 \n",
      "  ------- {'fairness_loss': 1.8189359, 'utility': 0.558117, 'loss': -0.5035489}\n",
      "--- Step : 1434 \n",
      "  ------- {'fairness_loss': 1.8187656, 'utility': 0.55811876, 'loss': -0.5035558}\n",
      "--- Step : 1435 \n",
      "  ------- {'fairness_loss': 1.8184493, 'utility': 0.5581148, 'loss': -0.5035614}\n",
      "--- Step : 1436 \n",
      "  ------- {'fairness_loss': 1.8187149, 'utility': 0.55813, 'loss': -0.5035686}\n",
      "--- Step : 1437 \n",
      "  ------- {'fairness_loss': 1.8187827, 'utility': 0.55813843, 'loss': -0.50357497}\n",
      "--- Step : 1438 \n",
      "  ------- {'fairness_loss': 1.8186312, 'utility': 0.5581405, 'loss': -0.5035816}\n",
      "--- Step : 1439 \n",
      "  ------- {'fairness_loss': 1.8183278, 'utility': 0.55813736, 'loss': -0.50358754}\n",
      "--- Step : 1440 \n",
      "  ------- {'fairness_loss': 1.8185105, 'utility': 0.5581497, 'loss': -0.5035944}\n",
      "--- Step : 1441 \n",
      "  ------- {'fairness_loss': 1.8186712, 'utility': 0.558161, 'loss': -0.5036009}\n",
      "--- Step : 1442 \n",
      "  ------- {'fairness_loss': 1.8186134, 'utility': 0.55816567, 'loss': -0.5036073}\n",
      "--- Step : 1443 \n",
      "  ------- {'fairness_loss': 1.8183657, 'utility': 0.55816466, 'loss': -0.5036137}\n",
      "--- Step : 1444 \n",
      "  ------- {'fairness_loss': 1.8181252, 'utility': 0.5581639, 'loss': -0.50362015}\n",
      "--- Step : 1445 \n",
      "  ------- {'fairness_loss': 1.8183919, 'utility': 0.5581785, 'loss': -0.5036267}\n",
      "--- Step : 1446 \n",
      "  ------- {'fairness_loss': 1.8184484, 'utility': 0.5581863, 'loss': -0.50363284}\n",
      "--- Step : 1447 \n",
      "  ------- {'fairness_loss': 1.8182961, 'utility': 0.5581884, 'loss': -0.5036395}\n",
      "--- Step : 1448 \n",
      "  ------- {'fairness_loss': 1.8179682, 'utility': 0.5581849, 'loss': -0.5036459}\n",
      "--- Step : 1449 \n",
      "  ------- {'fairness_loss': 1.8176868, 'utility': 0.5581818, 'loss': -0.5036512}\n",
      "--- Step : 1450 \n",
      "  ------- {'fairness_loss': 1.8179651, 'utility': 0.55819756, 'loss': -0.5036586}\n",
      "--- Step : 1451 \n",
      "  ------- {'fairness_loss': 1.8182441, 'utility': 0.55821174, 'loss': -0.50366443}\n",
      "--- Step : 1452 \n",
      "  ------- {'fairness_loss': 1.8182969, 'utility': 0.5582194, 'loss': -0.50367045}\n",
      "--- Step : 1453 \n",
      "  ------- {'fairness_loss': 1.8181417, 'utility': 0.5582212, 'loss': -0.50367695}\n",
      "--- Step : 1454 \n",
      "  ------- {'fairness_loss': 1.8177989, 'utility': 0.55821794, 'loss': -0.503684}\n",
      "--- Step : 1455 \n",
      "  ------- {'fairness_loss': 1.8173344, 'utility': 0.5582099, 'loss': -0.5036899}\n",
      "--- Step : 1456 \n",
      "  ------- {'fairness_loss': 1.81737, 'utility': 0.55821776, 'loss': -0.5036967}\n",
      "--- Step : 1457 \n",
      "  ------- {'fairness_loss': 1.8179319, 'utility': 0.55824023, 'loss': -0.5037023}\n",
      "--- Step : 1458 \n",
      "  ------- {'fairness_loss': 1.818253, 'utility': 0.5582553, 'loss': -0.5037077}\n",
      "--- Step : 1459 \n",
      "  ------- {'fairness_loss': 1.818343, 'utility': 0.5582641, 'loss': -0.5037138}\n",
      "--- Step : 1460 \n",
      "  ------- {'fairness_loss': 1.8182222, 'utility': 0.55826694, 'loss': -0.5037203}\n",
      "--- Step : 1461 \n",
      "  ------- {'fairness_loss': 1.8179188, 'utility': 0.5582647, 'loss': -0.50372714}\n",
      "--- Step : 1462 \n",
      "  ------- {'fairness_loss': 1.8174487, 'utility': 0.5582576, 'loss': -0.5037341}\n",
      "--- Step : 1463 \n",
      "  ------- {'fairness_loss': 1.8170341, 'utility': 0.5582513, 'loss': -0.5037403}\n",
      "--- Step : 1464 \n",
      "  ------- {'fairness_loss': 1.8167013, 'utility': 0.55824596, 'loss': -0.5037449}\n",
      "--- Step : 1465 \n",
      "  ------- {'fairness_loss': 1.8168792, 'utility': 0.55825925, 'loss': -0.5037529}\n",
      "--- Step : 1466 \n",
      "  ------- {'fairness_loss': 1.817072, 'utility': 0.55827135, 'loss': -0.5037592}\n",
      "--- Step : 1467 \n",
      "  ------- {'fairness_loss': 1.817251, 'utility': 0.5582824, 'loss': -0.50376487}\n",
      "--- Step : 1468 \n",
      "  ------- {'fairness_loss': 1.8172246, 'utility': 0.55828756, 'loss': -0.5037708}\n",
      "--- Step : 1469 \n",
      "  ------- {'fairness_loss': 1.8170011, 'utility': 0.55828744, 'loss': -0.5037774}\n",
      "--- Step : 1470 \n",
      "  ------- {'fairness_loss': 1.8166156, 'utility': 0.55828255, 'loss': -0.50378406}\n",
      "--- Step : 1471 \n",
      "  ------- {'fairness_loss': 1.8161656, 'utility': 0.5582734, 'loss': -0.5037884}\n",
      "--- Step : 1472 \n",
      "  ------- {'fairness_loss': 1.8162487, 'utility': 0.55828327, 'loss': -0.5037958}\n",
      "--- Step : 1473 \n",
      "  ------- {'fairness_loss': 1.8169636, 'utility': 0.5583104, 'loss': -0.50380147}\n",
      "--- Step : 1474 \n",
      "  ------- {'fairness_loss': 1.8174475, 'utility': 0.55833006, 'loss': -0.50380665}\n",
      "--- Step : 1475 \n",
      "  ------- {'fairness_loss': 1.8176926, 'utility': 0.55834305, 'loss': -0.50381225}\n",
      "--- Step : 1476 \n",
      "  ------- {'fairness_loss': 1.8177273, 'utility': 0.55835, 'loss': -0.5038182}\n",
      "--- Step : 1477 \n",
      "  ------- {'fairness_loss': 1.8175687, 'utility': 0.5583516, 'loss': -0.50382453}\n",
      "--- Step : 1478 \n",
      "  ------- {'fairness_loss': 1.8172382, 'utility': 0.55834854, 'loss': -0.5038314}\n",
      "--- Step : 1479 \n",
      "  ------- {'fairness_loss': 1.8167535, 'utility': 0.558341, 'loss': -0.5038384}\n",
      "--- Step : 1480 \n",
      "  ------- {'fairness_loss': 1.8161527, 'utility': 0.5583295, 'loss': -0.5038449}\n",
      "--- Step : 1481 \n",
      "  ------- {'fairness_loss': 1.8156832, 'utility': 0.55831957, 'loss': -0.5038491}\n",
      "--- Step : 1482 \n",
      "  ------- {'fairness_loss': 1.8157527, 'utility': 0.55832875, 'loss': -0.5038562}\n",
      "--- Step : 1483 \n",
      "  ------- {'fairness_loss': 1.8162909, 'utility': 0.5583518, 'loss': -0.5038631}\n",
      "--- Step : 1484 \n",
      "  ------- {'fairness_loss': 1.8168174, 'utility': 0.5583728, 'loss': -0.5038683}\n",
      "--- Step : 1485 \n",
      "  ------- {'fairness_loss': 1.8171206, 'utility': 0.5583872, 'loss': -0.5038736}\n",
      "--- Step : 1486 \n",
      "  ------- {'fairness_loss': 1.817207, 'utility': 0.5583957, 'loss': -0.5038795}\n",
      "--- Step : 1487 \n",
      "  ------- {'fairness_loss': 1.8171035, 'utility': 0.55839866, 'loss': -0.50388557}\n",
      "--- Step : 1488 \n",
      "  ------- {'fairness_loss': 1.8168278, 'utility': 0.5583968, 'loss': -0.503892}\n",
      "--- Step : 1489 \n",
      "  ------- {'fairness_loss': 1.8163989, 'utility': 0.55839086, 'loss': -0.5038989}\n",
      "--- Step : 1490 \n",
      "  ------- {'fairness_loss': 1.8158681, 'utility': 0.5583808, 'loss': -0.50390476}\n",
      "--- Step : 1491 \n",
      "  ------- {'fairness_loss': 1.8153931, 'utility': 0.55837226, 'loss': -0.5039105}\n",
      "--- Step : 1492 \n",
      "  ------- {'fairness_loss': 1.8154218, 'utility': 0.5583795, 'loss': -0.5039168}\n",
      "--- Step : 1493 \n",
      "  ------- {'fairness_loss': 1.8154474, 'utility': 0.5583862, 'loss': -0.50392276}\n",
      "--- Step : 1494 \n",
      "  ------- {'fairness_loss': 1.8154595, 'utility': 0.55839264, 'loss': -0.50392884}\n",
      "--- Step : 1495 \n",
      "  ------- {'fairness_loss': 1.8154596, 'utility': 0.5583988, 'loss': -0.503935}\n",
      "--- Step : 1496 \n",
      "  ------- {'fairness_loss': 1.8154492, 'utility': 0.55840445, 'loss': -0.50394094}\n",
      "--- Step : 1497 \n",
      "  ------- {'fairness_loss': 1.8154444, 'utility': 0.55841017, 'loss': -0.50394684}\n",
      "--- Step : 1498 \n",
      "  ------- {'fairness_loss': 1.8152711, 'utility': 0.5584108, 'loss': -0.5039527}\n",
      "--- Step : 1499 \n",
      "  ------- {'fairness_loss': 1.8149391, 'utility': 0.5584071, 'loss': -0.50395894}\n",
      "--- Step : 1500 \n",
      "  ------- {'fairness_loss': 1.8145188, 'utility': 0.55839956, 'loss': -0.503964}\n",
      "--- Step : 1501 \n",
      "  ------- {'fairness_loss': 1.8145633, 'utility': 0.55840766, 'loss': -0.50397074}\n",
      "--- Step : 1502 \n",
      "  ------- {'fairness_loss': 1.8149627, 'utility': 0.558425, 'loss': -0.5039761}\n",
      "--- Step : 1503 \n",
      "  ------- {'fairness_loss': 1.815163, 'utility': 0.55843633, 'loss': -0.5039815}\n",
      "--- Step : 1504 \n",
      "  ------- {'fairness_loss': 1.8151677, 'utility': 0.5584425, 'loss': -0.50398743}\n",
      "--- Step : 1505 \n",
      "  ------- {'fairness_loss': 1.8150042, 'utility': 0.5584434, 'loss': -0.5039933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1506 \n",
      "  ------- {'fairness_loss': 1.8146853, 'utility': 0.5584404, 'loss': -0.5039998}\n",
      "--- Step : 1507 \n",
      "  ------- {'fairness_loss': 1.8142468, 'utility': 0.5584332, 'loss': -0.5040058}\n",
      "--- Step : 1508 \n",
      "  ------- {'fairness_loss': 1.8143268, 'utility': 0.5584418, 'loss': -0.504012}\n",
      "--- Step : 1509 \n",
      "  ------- {'fairness_loss': 1.8144068, 'utility': 0.5584498, 'loss': -0.5040176}\n",
      "--- Step : 1510 \n",
      "  ------- {'fairness_loss': 1.8143119, 'utility': 0.55845284, 'loss': -0.5040235}\n",
      "--- Step : 1511 \n",
      "  ------- {'fairness_loss': 1.8140764, 'utility': 0.5584515, 'loss': -0.50402915}\n",
      "--- Step : 1512 \n",
      "  ------- {'fairness_loss': 1.8143348, 'utility': 0.55846506, 'loss': -0.504035}\n",
      "--- Step : 1513 \n",
      "  ------- {'fairness_loss': 1.8144189, 'utility': 0.558473, 'loss': -0.5040404}\n",
      "--- Step : 1514 \n",
      "  ------- {'fairness_loss': 1.8143268, 'utility': 0.55847615, 'loss': -0.5040463}\n",
      "--- Step : 1515 \n",
      "  ------- {'fairness_loss': 1.8140973, 'utility': 0.55847496, 'loss': -0.50405204}\n",
      "--- Step : 1516 \n",
      "  ------- {'fairness_loss': 1.8138847, 'utility': 0.5584742, 'loss': -0.50405765}\n",
      "--- Step : 1517 \n",
      "  ------- {'fairness_loss': 1.8137039, 'utility': 0.5584743, 'loss': -0.5040632}\n",
      "--- Step : 1518 \n",
      "  ------- {'fairness_loss': 1.8139827, 'utility': 0.5584887, 'loss': -0.50406927}\n",
      "--- Step : 1519 \n",
      "  ------- {'fairness_loss': 1.8142588, 'utility': 0.5585024, 'loss': -0.50407463}\n",
      "--- Step : 1520 \n",
      "  ------- {'fairness_loss': 1.8143542, 'utility': 0.55851084, 'loss': -0.50408024}\n",
      "--- Step : 1521 \n",
      "  ------- {'fairness_loss': 1.814279, 'utility': 0.55851406, 'loss': -0.50408566}\n",
      "--- Step : 1522 \n",
      "  ------- {'fairness_loss': 1.8140472, 'utility': 0.55851316, 'loss': -0.50409174}\n",
      "--- Step : 1523 \n",
      "  ------- {'fairness_loss': 1.8136823, 'utility': 0.55850863, 'loss': -0.5040982}\n",
      "--- Step : 1524 \n",
      "  ------- {'fairness_loss': 1.8133678, 'utility': 0.55850476, 'loss': -0.5041037}\n",
      "--- Step : 1525 \n",
      "  ------- {'fairness_loss': 1.8131101, 'utility': 0.55850184, 'loss': -0.50410855}\n",
      "--- Step : 1526 \n",
      "  ------- {'fairness_loss': 1.81329, 'utility': 0.55851394, 'loss': -0.5041152}\n",
      "--- Step : 1527 \n",
      "  ------- {'fairness_loss': 1.8134964, 'utility': 0.55852544, 'loss': -0.5041205}\n",
      "--- Step : 1528 \n",
      "  ------- {'fairness_loss': 1.8135306, 'utility': 0.5585318, 'loss': -0.5041259}\n",
      "--- Step : 1529 \n",
      "  ------- {'fairness_loss': 1.8134001, 'utility': 0.5585336, 'loss': -0.5041316}\n",
      "--- Step : 1530 \n",
      "  ------- {'fairness_loss': 1.8131266, 'utility': 0.55853134, 'loss': -0.5041376}\n",
      "--- Step : 1531 \n",
      "  ------- {'fairness_loss': 1.8127402, 'utility': 0.55852544, 'loss': -0.50414324}\n",
      "--- Step : 1532 \n",
      "  ------- {'fairness_loss': 1.8128599, 'utility': 0.55853474, 'loss': -0.50414896}\n",
      "--- Step : 1533 \n",
      "  ------- {'fairness_loss': 1.8128268, 'utility': 0.5585395, 'loss': -0.5041547}\n",
      "--- Step : 1534 \n",
      "  ------- {'fairness_loss': 1.8126419, 'utility': 0.5585398, 'loss': -0.5041605}\n",
      "--- Step : 1535 \n",
      "  ------- {'fairness_loss': 1.8125013, 'utility': 0.5585406, 'loss': -0.50416553}\n",
      "--- Step : 1536 \n",
      "  ------- {'fairness_loss': 1.8128271, 'utility': 0.55855584, 'loss': -0.504171}\n",
      "--- Step : 1537 \n",
      "  ------- {'fairness_loss': 1.8129865, 'utility': 0.5585659, 'loss': -0.5041763}\n",
      "--- Step : 1538 \n",
      "  ------- {'fairness_loss': 1.8129776, 'utility': 0.5585711, 'loss': -0.5041818}\n",
      "--- Step : 1539 \n",
      "  ------- {'fairness_loss': 1.812819, 'utility': 0.55857223, 'loss': -0.50418764}\n",
      "--- Step : 1540 \n",
      "  ------- {'fairness_loss': 1.8125209, 'utility': 0.55856943, 'loss': -0.5041938}\n",
      "--- Step : 1541 \n",
      "  ------- {'fairness_loss': 1.8121562, 'utility': 0.55856305, 'loss': -0.5041984}\n",
      "--- Step : 1542 \n",
      "  ------- {'fairness_loss': 1.812242, 'utility': 0.558572, 'loss': -0.50420475}\n",
      "--- Step : 1543 \n",
      "  ------- {'fairness_loss': 1.8123441, 'utility': 0.5585806, 'loss': -0.50421023}\n",
      "--- Step : 1544 \n",
      "  ------- {'fairness_loss': 1.8124425, 'utility': 0.5585889, 'loss': -0.50421566}\n",
      "--- Step : 1545 \n",
      "  ------- {'fairness_loss': 1.8123893, 'utility': 0.5585928, 'loss': -0.50422114}\n",
      "--- Step : 1546 \n",
      "  ------- {'fairness_loss': 1.8121985, 'utility': 0.5585928, 'loss': -0.50422686}\n",
      "--- Step : 1547 \n",
      "  ------- {'fairness_loss': 1.8120339, 'utility': 0.5585933, 'loss': -0.5042323}\n",
      "--- Step : 1548 \n",
      "  ------- {'fairness_loss': 1.8118848, 'utility': 0.55859435, 'loss': -0.50423783}\n",
      "--- Step : 1549 \n",
      "  ------- {'fairness_loss': 1.8117577, 'utility': 0.55859625, 'loss': -0.5042435}\n",
      "--- Step : 1550 \n",
      "  ------- {'fairness_loss': 1.8116517, 'utility': 0.55859834, 'loss': -0.5042488}\n",
      "--- Step : 1551 \n",
      "  ------- {'fairness_loss': 1.811892, 'utility': 0.5586107, 'loss': -0.5042539}\n",
      "--- Step : 1552 \n",
      "  ------- {'fairness_loss': 1.8119687, 'utility': 0.55861807, 'loss': -0.504259}\n",
      "--- Step : 1553 \n",
      "  ------- {'fairness_loss': 1.8118892, 'utility': 0.55862105, 'loss': -0.50426435}\n",
      "--- Step : 1554 \n",
      "  ------- {'fairness_loss': 1.8116715, 'utility': 0.5586203, 'loss': -0.50427014}\n",
      "--- Step : 1555 \n",
      "  ------- {'fairness_loss': 1.8113356, 'utility': 0.55861604, 'loss': -0.504276}\n",
      "--- Step : 1556 \n",
      "  ------- {'fairness_loss': 1.8113635, 'utility': 0.5586225, 'loss': -0.5042816}\n",
      "--- Step : 1557 \n",
      "  ------- {'fairness_loss': 1.8112575, 'utility': 0.5586247, 'loss': -0.50428694}\n",
      "--- Step : 1558 \n",
      "  ------- {'fairness_loss': 1.8116361, 'utility': 0.558641, 'loss': -0.50429195}\n",
      "--- Step : 1559 \n",
      "  ------- {'fairness_loss': 1.8118372, 'utility': 0.55865234, 'loss': -0.50429726}\n",
      "--- Step : 1560 \n",
      "  ------- {'fairness_loss': 1.8118805, 'utility': 0.55865884, 'loss': -0.50430244}\n",
      "--- Step : 1561 \n",
      "  ------- {'fairness_loss': 1.8117744, 'utility': 0.5586614, 'loss': -0.50430816}\n",
      "--- Step : 1562 \n",
      "  ------- {'fairness_loss': 1.8115573, 'utility': 0.5586601, 'loss': -0.50431335}\n",
      "--- Step : 1563 \n",
      "  ------- {'fairness_loss': 1.8113737, 'utility': 0.55865973, 'loss': -0.50431854}\n",
      "--- Step : 1564 \n",
      "  ------- {'fairness_loss': 1.8112106, 'utility': 0.55866015, 'loss': -0.50432384}\n",
      "--- Step : 1565 \n",
      "  ------- {'fairness_loss': 1.8110749, 'utility': 0.5586614, 'loss': -0.50432914}\n",
      "--- Step : 1566 \n",
      "  ------- {'fairness_loss': 1.8109564, 'utility': 0.55866325, 'loss': -0.50433457}\n",
      "--- Step : 1567 \n",
      "  ------- {'fairness_loss': 1.8108573, 'utility': 0.5586657, 'loss': -0.50434}\n",
      "--- Step : 1568 \n",
      "  ------- {'fairness_loss': 1.8107755, 'utility': 0.5586688, 'loss': -0.50434554}\n",
      "--- Step : 1569 \n",
      "  ------- {'fairness_loss': 1.8107088, 'utility': 0.5586723, 'loss': -0.504351}\n",
      "--- Step : 1570 \n",
      "  ------- {'fairness_loss': 1.8106624, 'utility': 0.55867624, 'loss': -0.5043564}\n",
      "--- Step : 1571 \n",
      "  ------- {'fairness_loss': 1.8104954, 'utility': 0.5586767, 'loss': -0.50436187}\n",
      "--- Step : 1572 \n",
      "  ------- {'fairness_loss': 1.8102324, 'utility': 0.5586735, 'loss': -0.5043665}\n",
      "--- Step : 1573 \n",
      "  ------- {'fairness_loss': 1.8102868, 'utility': 0.558681, 'loss': -0.5043724}\n",
      "--- Step : 1574 \n",
      "  ------- {'fairness_loss': 1.8106911, 'utility': 0.5586977, 'loss': -0.50437695}\n",
      "--- Step : 1575 \n",
      "  ------- {'fairness_loss': 1.8109212, 'utility': 0.5587095, 'loss': -0.5043819}\n",
      "--- Step : 1576 \n",
      "  ------- {'fairness_loss': 1.8109943, 'utility': 0.55871683, 'loss': -0.504387}\n",
      "--- Step : 1577 \n",
      "  ------- {'fairness_loss': 1.8109242, 'utility': 0.55872005, 'loss': -0.5043923}\n",
      "--- Step : 1578 \n",
      "  ------- {'fairness_loss': 1.8107264, 'utility': 0.5587199, 'loss': -0.5043981}\n",
      "--- Step : 1579 \n",
      "  ------- {'fairness_loss': 1.8104137, 'utility': 0.55871624, 'loss': -0.5044038}\n",
      "--- Step : 1580 \n",
      "  ------- {'fairness_loss': 1.810027, 'utility': 0.55870974, 'loss': -0.50440896}\n",
      "--- Step : 1581 \n",
      "  ------- {'fairness_loss': 1.8097414, 'utility': 0.55870485, 'loss': -0.5044126}\n",
      "--- Step : 1582 \n",
      "  ------- {'fairness_loss': 1.8098596, 'utility': 0.5587147, 'loss': -0.5044189}\n",
      "--- Step : 1583 \n",
      "  ------- {'fairness_loss': 1.810436, 'utility': 0.55873775, 'loss': -0.5044247}\n",
      "--- Step : 1584 \n",
      "  ------- {'fairness_loss': 1.8108675, 'utility': 0.5587552, 'loss': -0.5044292}\n",
      "--- Step : 1585 \n",
      "  ------- {'fairness_loss': 1.8111268, 'utility': 0.5587677, 'loss': -0.5044339}\n",
      "--- Step : 1586 \n",
      "  ------- {'fairness_loss': 1.8112293, 'utility': 0.5587759, 'loss': -0.504439}\n",
      "--- Step : 1587 \n",
      "  ------- {'fairness_loss': 1.8111875, 'utility': 0.55877995, 'loss': -0.50444436}\n",
      "--- Step : 1588 \n",
      "  ------- {'fairness_loss': 1.8110228, 'utility': 0.55878055, 'loss': -0.50444984}\n",
      "--- Step : 1589 \n",
      "  ------- {'fairness_loss': 1.8107497, 'utility': 0.5587777, 'loss': -0.5044552}\n",
      "--- Step : 1590 \n",
      "  ------- {'fairness_loss': 1.8105353, 'utility': 0.5587762, 'loss': -0.50446016}\n",
      "--- Step : 1591 \n",
      "  ------- {'fairness_loss': 1.8103509, 'utility': 0.5587758, 'loss': -0.5044653}\n",
      "--- Step : 1592 \n",
      "  ------- {'fairness_loss': 1.8101976, 'utility': 0.55877626, 'loss': -0.50447035}\n",
      "--- Step : 1593 \n",
      "  ------- {'fairness_loss': 1.810071, 'utility': 0.5587779, 'loss': -0.5044758}\n",
      "--- Step : 1594 \n",
      "  ------- {'fairness_loss': 1.8099712, 'utility': 0.5587799, 'loss': -0.5044808}\n",
      "--- Step : 1595 \n",
      "  ------- {'fairness_loss': 1.8098919, 'utility': 0.55878294, 'loss': -0.5044862}\n",
      "--- Step : 1596 \n",
      "  ------- {'fairness_loss': 1.8098341, 'utility': 0.5587865, 'loss': -0.5044915}\n",
      "--- Step : 1597 \n",
      "  ------- {'fairness_loss': 1.8097981, 'utility': 0.5587905, 'loss': -0.5044966}\n",
      "--- Step : 1598 \n",
      "  ------- {'fairness_loss': 1.809654, 'utility': 0.5587915, 'loss': -0.5045019}\n",
      "--- Step : 1599 \n",
      "  ------- {'fairness_loss': 1.8093989, 'utility': 0.55878896, 'loss': -0.504507}\n",
      "--- Step : 1600 \n",
      "  ------- {'fairness_loss': 1.8090521, 'utility': 0.5587838, 'loss': -0.50451225}\n",
      "--- Step : 1601 \n",
      "  ------- {'fairness_loss': 1.8087597, 'utility': 0.55878013, 'loss': -0.5045173}\n",
      "--- Step : 1602 \n",
      "  ------- {'fairness_loss': 1.8089525, 'utility': 0.5587909, 'loss': -0.5045223}\n",
      "--- Step : 1603 \n",
      "  ------- {'fairness_loss': 1.8090196, 'utility': 0.5587977, 'loss': -0.50452715}\n",
      "--- Step : 1604 \n",
      "  ------- {'fairness_loss': 1.8089541, 'utility': 0.5588009, 'loss': -0.5045323}\n",
      "--- Step : 1605 \n",
      "  ------- {'fairness_loss': 1.8087726, 'utility': 0.5588007, 'loss': -0.5045375}\n",
      "--- Step : 1606 \n",
      "  ------- {'fairness_loss': 1.8084897, 'utility': 0.55879754, 'loss': -0.5045428}\n",
      "--- Step : 1607 \n",
      "  ------- {'fairness_loss': 1.8081822, 'utility': 0.5587917, 'loss': -0.5045462}\n",
      "--- Step : 1608 \n",
      "  ------- {'fairness_loss': 1.8082783, 'utility': 0.5588009, 'loss': -0.50455254}\n",
      "--- Step : 1609 \n",
      "  ------- {'fairness_loss': 1.8088498, 'utility': 0.55882293, 'loss': -0.50455743}\n",
      "--- Step : 1610 \n",
      "  ------- {'fairness_loss': 1.8092706, 'utility': 0.55883974, 'loss': -0.5045616}\n",
      "--- Step : 1611 \n",
      "  ------- {'fairness_loss': 1.8095268, 'utility': 0.5588522, 'loss': -0.5045664}\n",
      "--- Step : 1612 \n",
      "  ------- {'fairness_loss': 1.8096377, 'utility': 0.55886024, 'loss': -0.50457114}\n",
      "--- Step : 1613 \n",
      "  ------- {'fairness_loss': 1.8096186, 'utility': 0.55886495, 'loss': -0.5045764}\n",
      "--- Step : 1614 \n",
      "  ------- {'fairness_loss': 1.8094819, 'utility': 0.5588659, 'loss': -0.50458145}\n",
      "--- Step : 1615 \n",
      "  ------- {'fairness_loss': 1.8092389, 'utility': 0.5588641, 'loss': -0.50458694}\n",
      "--- Step : 1616 \n",
      "  ------- {'fairness_loss': 1.8089066, 'utility': 0.55885965, 'loss': -0.5045925}\n",
      "--- Step : 1617 \n",
      "  ------- {'fairness_loss': 1.8086487, 'utility': 0.55885655, 'loss': -0.50459707}\n",
      "--- Step : 1618 \n",
      "  ------- {'fairness_loss': 1.8084321, 'utility': 0.5588549, 'loss': -0.5046019}\n",
      "--- Step : 1619 \n",
      "  ------- {'fairness_loss': 1.8082557, 'utility': 0.5588545, 'loss': -0.50460684}\n",
      "--- Step : 1620 \n",
      "  ------- {'fairness_loss': 1.8081127, 'utility': 0.5588553, 'loss': -0.5046119}\n",
      "--- Step : 1621 \n",
      "  ------- {'fairness_loss': 1.8080021, 'utility': 0.5588569, 'loss': -0.50461686}\n",
      "--- Step : 1622 \n",
      "  ------- {'fairness_loss': 1.8079176, 'utility': 0.55885965, 'loss': -0.5046221}\n",
      "--- Step : 1623 \n",
      "  ------- {'fairness_loss': 1.8078637, 'utility': 0.558863, 'loss': -0.50462705}\n",
      "--- Step : 1624 \n",
      "  ------- {'fairness_loss': 1.8078283, 'utility': 0.5588672, 'loss': -0.50463235}\n",
      "--- Step : 1625 \n",
      "  ------- {'fairness_loss': 1.8078375, 'utility': 0.55887216, 'loss': -0.50463706}\n",
      "--- Step : 1626 \n",
      "  ------- {'fairness_loss': 1.807733, 'utility': 0.5588738, 'loss': -0.5046418}\n",
      "--- Step : 1627 \n",
      "  ------- {'fairness_loss': 1.8075262, 'utility': 0.5588724, 'loss': -0.5046466}\n",
      "--- Step : 1628 \n",
      "  ------- {'fairness_loss': 1.8072252, 'utility': 0.5588686, 'loss': -0.50465184}\n",
      "--- Step : 1629 \n",
      "  ------- {'fairness_loss': 1.8068929, 'utility': 0.55886245, 'loss': -0.50465566}\n",
      "--- Step : 1630 \n",
      "  ------- {'fairness_loss': 1.8068794, 'utility': 0.5588671, 'loss': -0.5046607}\n",
      "--- Step : 1631 \n",
      "  ------- {'fairness_loss': 1.8071642, 'utility': 0.55888134, 'loss': -0.50466645}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1632 \n",
      "  ------- {'fairness_loss': 1.8073487, 'utility': 0.55889153, 'loss': -0.5046711}\n",
      "--- Step : 1633 \n",
      "  ------- {'fairness_loss': 1.8074044, 'utility': 0.5588981, 'loss': -0.504676}\n",
      "--- Step : 1634 \n",
      "  ------- {'fairness_loss': 1.807341, 'utility': 0.5589013, 'loss': -0.5046811}\n",
      "--- Step : 1635 \n",
      "  ------- {'fairness_loss': 1.8071839, 'utility': 0.55890137, 'loss': -0.5046859}\n",
      "--- Step : 1636 \n",
      "  ------- {'fairness_loss': 1.8070719, 'utility': 0.5589026, 'loss': -0.50469047}\n",
      "--- Step : 1637 \n",
      "  ------- {'fairness_loss': 1.8069922, 'utility': 0.5589052, 'loss': -0.5046954}\n",
      "--- Step : 1638 \n",
      "  ------- {'fairness_loss': 1.806942, 'utility': 0.55890846, 'loss': -0.5047002}\n",
      "--- Step : 1639 \n",
      "  ------- {'fairness_loss': 1.806917, 'utility': 0.5589125, 'loss': -0.504705}\n",
      "--- Step : 1640 \n",
      "  ------- {'fairness_loss': 1.8069141, 'utility': 0.5589174, 'loss': -0.50470996}\n",
      "--- Step : 1641 \n",
      "  ------- {'fairness_loss': 1.8069444, 'utility': 0.5589231, 'loss': -0.5047148}\n",
      "--- Step : 1642 \n",
      "  ------- {'fairness_loss': 1.8068669, 'utility': 0.5589255, 'loss': -0.5047195}\n",
      "--- Step : 1643 \n",
      "  ------- {'fairness_loss': 1.8066894, 'utility': 0.55892515, 'loss': -0.5047245}\n",
      "--- Step : 1644 \n",
      "  ------- {'fairness_loss': 1.8064263, 'utility': 0.5589223, 'loss': -0.5047295}\n",
      "--- Step : 1645 \n",
      "  ------- {'fairness_loss': 1.8062327, 'utility': 0.5589209, 'loss': -0.5047339}\n",
      "--- Step : 1646 \n",
      "  ------- {'fairness_loss': 1.8064941, 'utility': 0.5589335, 'loss': -0.5047387}\n",
      "--- Step : 1647 \n",
      "  ------- {'fairness_loss': 1.806639, 'utility': 0.55894226, 'loss': -0.5047431}\n",
      "--- Step : 1648 \n",
      "  ------- {'fairness_loss': 1.8066634, 'utility': 0.5589477, 'loss': -0.5047478}\n",
      "--- Step : 1649 \n",
      "  ------- {'fairness_loss': 1.80658, 'utility': 0.55894995, 'loss': -0.5047526}\n",
      "--- Step : 1650 \n",
      "  ------- {'fairness_loss': 1.8064001, 'utility': 0.55894965, 'loss': -0.50475764}\n",
      "--- Step : 1651 \n",
      "  ------- {'fairness_loss': 1.806137, 'utility': 0.5589468, 'loss': -0.50476265}\n",
      "--- Step : 1652 \n",
      "  ------- {'fairness_loss': 1.8058428, 'utility': 0.55894166, 'loss': -0.5047664}\n",
      "--- Step : 1653 \n",
      "  ------- {'fairness_loss': 1.8059701, 'utility': 0.5589509, 'loss': -0.5047718}\n",
      "--- Step : 1654 \n",
      "  ------- {'fairness_loss': 1.8061315, 'utility': 0.5589606, 'loss': -0.50477666}\n",
      "--- Step : 1655 \n",
      "  ------- {'fairness_loss': 1.8063076, 'utility': 0.5589705, 'loss': -0.5047813}\n",
      "--- Step : 1656 \n",
      "  ------- {'fairness_loss': 1.8063672, 'utility': 0.55897707, 'loss': -0.5047861}\n",
      "--- Step : 1657 \n",
      "  ------- {'fairness_loss': 1.806322, 'utility': 0.5589804, 'loss': -0.5047907}\n",
      "--- Step : 1658 \n",
      "  ------- {'fairness_loss': 1.806179, 'utility': 0.5589809, 'loss': -0.5047955}\n",
      "--- Step : 1659 \n",
      "  ------- {'fairness_loss': 1.8060839, 'utility': 0.55898273, 'loss': -0.5048002}\n",
      "--- Step : 1660 \n",
      "  ------- {'fairness_loss': 1.8060211, 'utility': 0.55898565, 'loss': -0.504805}\n",
      "--- Step : 1661 \n",
      "  ------- {'fairness_loss': 1.8059964, 'utility': 0.5589895, 'loss': -0.5048096}\n",
      "--- Step : 1662 \n",
      "  ------- {'fairness_loss': 1.8058743, 'utility': 0.5589903, 'loss': -0.5048141}\n",
      "--- Step : 1663 \n",
      "  ------- {'fairness_loss': 1.805672, 'utility': 0.5589891, 'loss': -0.5048189}\n",
      "--- Step : 1664 \n",
      "  ------- {'fairness_loss': 1.8055171, 'utility': 0.5589891, 'loss': -0.50482357}\n",
      "--- Step : 1665 \n",
      "  ------- {'fairness_loss': 1.8054013, 'utility': 0.55899024, 'loss': -0.5048282}\n",
      "--- Step : 1666 \n",
      "  ------- {'fairness_loss': 1.8053248, 'utility': 0.55899274, 'loss': -0.504833}\n",
      "--- Step : 1667 \n",
      "  ------- {'fairness_loss': 1.805167, 'utility': 0.55899256, 'loss': -0.5048376}\n",
      "--- Step : 1668 \n",
      "  ------- {'fairness_loss': 1.8049548, 'utility': 0.5589903, 'loss': -0.5048417}\n",
      "--- Step : 1669 \n",
      "  ------- {'fairness_loss': 1.8051686, 'utility': 0.5590018, 'loss': -0.50484675}\n",
      "--- Step : 1670 \n",
      "  ------- {'fairness_loss': 1.805292, 'utility': 0.5590098, 'loss': -0.50485104}\n",
      "--- Step : 1671 \n",
      "  ------- {'fairness_loss': 1.8053054, 'utility': 0.5590148, 'loss': -0.50485563}\n",
      "--- Step : 1672 \n",
      "  ------- {'fairness_loss': 1.8052189, 'utility': 0.559017, 'loss': -0.50486046}\n",
      "--- Step : 1673 \n",
      "  ------- {'fairness_loss': 1.8050481, 'utility': 0.5590166, 'loss': -0.50486517}\n",
      "--- Step : 1674 \n",
      "  ------- {'fairness_loss': 1.8048105, 'utility': 0.5590141, 'loss': -0.50486976}\n",
      "--- Step : 1675 \n",
      "  ------- {'fairness_loss': 1.8046484, 'utility': 0.5590132, 'loss': -0.50487375}\n",
      "--- Step : 1676 \n",
      "  ------- {'fairness_loss': 1.8048981, 'utility': 0.55902606, 'loss': -0.5048791}\n",
      "--- Step : 1677 \n",
      "  ------- {'fairness_loss': 1.8051851, 'utility': 0.5590389, 'loss': -0.50488335}\n",
      "--- Step : 1678 \n",
      "  ------- {'fairness_loss': 1.8053497, 'utility': 0.5590481, 'loss': -0.50488764}\n",
      "--- Step : 1679 \n",
      "  ------- {'fairness_loss': 1.8054066, 'utility': 0.55905426, 'loss': -0.50489205}\n",
      "--- Step : 1680 \n",
      "  ------- {'fairness_loss': 1.8053634, 'utility': 0.5590575, 'loss': -0.5048966}\n",
      "--- Step : 1681 \n",
      "  ------- {'fairness_loss': 1.8052316, 'utility': 0.55905837, 'loss': -0.5049014}\n",
      "--- Step : 1682 \n",
      "  ------- {'fairness_loss': 1.8050205, 'utility': 0.5590567, 'loss': -0.50490606}\n",
      "--- Step : 1683 \n",
      "  ------- {'fairness_loss': 1.804872, 'utility': 0.5590568, 'loss': -0.50491065}\n",
      "--- Step : 1684 \n",
      "  ------- {'fairness_loss': 1.8047668, 'utility': 0.559058, 'loss': -0.504915}\n",
      "--- Step : 1685 \n",
      "  ------- {'fairness_loss': 1.8047012, 'utility': 0.5590607, 'loss': -0.50491965}\n",
      "--- Step : 1686 \n",
      "  ------- {'fairness_loss': 1.8046685, 'utility': 0.5590644, 'loss': -0.50492436}\n",
      "--- Step : 1687 \n",
      "  ------- {'fairness_loss': 1.8046721, 'utility': 0.55906904, 'loss': -0.5049289}\n",
      "--- Step : 1688 \n",
      "  ------- {'fairness_loss': 1.8045918, 'utility': 0.5590711, 'loss': -0.50493336}\n",
      "--- Step : 1689 \n",
      "  ------- {'fairness_loss': 1.8044295, 'utility': 0.5590707, 'loss': -0.5049378}\n",
      "--- Step : 1690 \n",
      "  ------- {'fairness_loss': 1.8041998, 'utility': 0.5590684, 'loss': -0.5049424}\n",
      "--- Step : 1691 \n",
      "  ------- {'fairness_loss': 1.8040257, 'utility': 0.5590676, 'loss': -0.5049468}\n",
      "--- Step : 1692 \n",
      "  ------- {'fairness_loss': 1.8038981, 'utility': 0.5590684, 'loss': -0.5049514}\n",
      "--- Step : 1693 \n",
      "  ------- {'fairness_loss': 1.80381, 'utility': 0.55907035, 'loss': -0.50495607}\n",
      "--- Step : 1694 \n",
      "  ------- {'fairness_loss': 1.8037744, 'utility': 0.5590735, 'loss': -0.5049603}\n",
      "--- Step : 1695 \n",
      "  ------- {'fairness_loss': 1.8036548, 'utility': 0.55907446, 'loss': -0.5049648}\n",
      "--- Step : 1696 \n",
      "  ------- {'fairness_loss': 1.8034776, 'utility': 0.5590731, 'loss': -0.50496876}\n",
      "--- Step : 1697 \n",
      "  ------- {'fairness_loss': 1.8036144, 'utility': 0.55908185, 'loss': -0.5049734}\n",
      "--- Step : 1698 \n",
      "  ------- {'fairness_loss': 1.8036673, 'utility': 0.559088, 'loss': -0.504978}\n",
      "--- Step : 1699 \n",
      "  ------- {'fairness_loss': 1.8036286, 'utility': 0.5590913, 'loss': -0.5049825}\n",
      "--- Step : 1700 \n",
      "  ------- {'fairness_loss': 1.8035061, 'utility': 0.5590923, 'loss': -0.5049871}\n",
      "--- Step : 1701 \n",
      "  ------- {'fairness_loss': 1.8033284, 'utility': 0.5590911, 'loss': -0.50499123}\n",
      "--- Step : 1702 \n",
      "  ------- {'fairness_loss': 1.8035882, 'utility': 0.5591036, 'loss': -0.50499594}\n",
      "--- Step : 1703 \n",
      "  ------- {'fairness_loss': 1.8037525, 'utility': 0.55911297, 'loss': -0.5050004}\n",
      "--- Step : 1704 \n",
      "  ------- {'fairness_loss': 1.8038152, 'utility': 0.55911916, 'loss': -0.5050047}\n",
      "--- Step : 1705 \n",
      "  ------- {'fairness_loss': 1.8037966, 'utility': 0.55912274, 'loss': -0.5050088}\n",
      "--- Step : 1706 \n",
      "  ------- {'fairness_loss': 1.8038092, 'utility': 0.5591275, 'loss': -0.5050132}\n",
      "--- Step : 1707 \n",
      "  ------- {'fairness_loss': 1.8038522, 'utility': 0.5591333, 'loss': -0.50501776}\n",
      "--- Step : 1708 \n",
      "  ------- {'fairness_loss': 1.8039252, 'utility': 0.5591399, 'loss': -0.50502217}\n",
      "--- Step : 1709 \n",
      "  ------- {'fairness_loss': 1.8040301, 'utility': 0.5591471, 'loss': -0.5050262}\n",
      "--- Step : 1710 \n",
      "  ------- {'fairness_loss': 1.8040416, 'utility': 0.55915207, 'loss': -0.5050308}\n",
      "--- Step : 1711 \n",
      "  ------- {'fairness_loss': 1.8039707, 'utility': 0.5591543, 'loss': -0.50503516}\n",
      "--- Step : 1712 \n",
      "  ------- {'fairness_loss': 1.8038187, 'utility': 0.5591543, 'loss': -0.5050397}\n",
      "--- Step : 1713 \n",
      "  ------- {'fairness_loss': 1.803613, 'utility': 0.55915225, 'loss': -0.50504386}\n",
      "--- Step : 1714 \n",
      "  ------- {'fairness_loss': 1.803465, 'utility': 0.5591519, 'loss': -0.5050479}\n",
      "--- Step : 1715 \n",
      "  ------- {'fairness_loss': 1.8033618, 'utility': 0.55915326, 'loss': -0.5050524}\n",
      "--- Step : 1716 \n",
      "  ------- {'fairness_loss': 1.8033019, 'utility': 0.55915594, 'loss': -0.50505686}\n",
      "--- Step : 1717 \n",
      "  ------- {'fairness_loss': 1.803281, 'utility': 0.55915993, 'loss': -0.5050615}\n",
      "--- Step : 1718 \n",
      "  ------- {'fairness_loss': 1.8033015, 'utility': 0.55916476, 'loss': -0.50506574}\n",
      "--- Step : 1719 \n",
      "  ------- {'fairness_loss': 1.8032428, 'utility': 0.5591673, 'loss': -0.50507003}\n",
      "--- Step : 1720 \n",
      "  ------- {'fairness_loss': 1.803114, 'utility': 0.5591676, 'loss': -0.5050742}\n",
      "--- Step : 1721 \n",
      "  ------- {'fairness_loss': 1.8029127, 'utility': 0.55916625, 'loss': -0.50507885}\n",
      "--- Step : 1722 \n",
      "  ------- {'fairness_loss': 1.8026657, 'utility': 0.55916286, 'loss': -0.5050829}\n",
      "--- Step : 1723 \n",
      "  ------- {'fairness_loss': 1.8024765, 'utility': 0.55916154, 'loss': -0.50508726}\n",
      "--- Step : 1724 \n",
      "  ------- {'fairness_loss': 1.8023407, 'utility': 0.55916184, 'loss': -0.5050916}\n",
      "--- Step : 1725 \n",
      "  ------- {'fairness_loss': 1.8022536, 'utility': 0.55916363, 'loss': -0.505096}\n",
      "--- Step : 1726 \n",
      "  ------- {'fairness_loss': 1.802209, 'utility': 0.55916685, 'loss': -0.5051006}\n",
      "--- Step : 1727 \n",
      "  ------- {'fairness_loss': 1.8021, 'utility': 0.5591677, 'loss': -0.50510466}\n",
      "--- Step : 1728 \n",
      "  ------- {'fairness_loss': 1.8019351, 'utility': 0.5591667, 'loss': -0.50510865}\n",
      "--- Step : 1729 \n",
      "  ------- {'fairness_loss': 1.8020979, 'utility': 0.559176, 'loss': -0.50511307}\n",
      "--- Step : 1730 \n",
      "  ------- {'fairness_loss': 1.8021771, 'utility': 0.55918264, 'loss': -0.50511736}\n",
      "--- Step : 1731 \n",
      "  ------- {'fairness_loss': 1.8021696, 'utility': 0.55918676, 'loss': -0.50512165}\n",
      "--- Step : 1732 \n",
      "  ------- {'fairness_loss': 1.8020856, 'utility': 0.5591887, 'loss': -0.5051262}\n",
      "--- Step : 1733 \n",
      "  ------- {'fairness_loss': 1.8019509, 'utility': 0.55918866, 'loss': -0.5051301}\n",
      "--- Step : 1734 \n",
      "  ------- {'fairness_loss': 1.8018613, 'utility': 0.55919003, 'loss': -0.5051342}\n",
      "--- Step : 1735 \n",
      "  ------- {'fairness_loss': 1.8018193, 'utility': 0.559193, 'loss': -0.50513846}\n",
      "--- Step : 1736 \n",
      "  ------- {'fairness_loss': 1.801815, 'utility': 0.5591971, 'loss': -0.5051427}\n",
      "--- Step : 1737 \n",
      "  ------- {'fairness_loss': 1.801847, 'utility': 0.55920255, 'loss': -0.50514716}\n",
      "--- Step : 1738 \n",
      "  ------- {'fairness_loss': 1.801917, 'utility': 0.5592089, 'loss': -0.5051514}\n",
      "--- Step : 1739 \n",
      "  ------- {'fairness_loss': 1.8019134, 'utility': 0.55921286, 'loss': -0.50515544}\n",
      "--- Step : 1740 \n",
      "  ------- {'fairness_loss': 1.8018358, 'utility': 0.55921465, 'loss': -0.50515956}\n",
      "--- Step : 1741 \n",
      "  ------- {'fairness_loss': 1.8016884, 'utility': 0.5592146, 'loss': -0.50516397}\n",
      "--- Step : 1742 \n",
      "  ------- {'fairness_loss': 1.8014922, 'utility': 0.55921304, 'loss': -0.50516826}\n",
      "--- Step : 1743 \n",
      "  ------- {'fairness_loss': 1.8013525, 'utility': 0.55921304, 'loss': -0.5051725}\n",
      "--- Step : 1744 \n",
      "  ------- {'fairness_loss': 1.8012648, 'utility': 0.5592144, 'loss': -0.5051765}\n",
      "--- Step : 1745 \n",
      "  ------- {'fairness_loss': 1.8012247, 'utility': 0.5592175, 'loss': -0.5051808}\n",
      "--- Step : 1746 \n",
      "  ------- {'fairness_loss': 1.801234, 'utility': 0.5592219, 'loss': -0.5051849}\n",
      "--- Step : 1747 \n",
      "  ------- {'fairness_loss': 1.8011696, 'utility': 0.5592241, 'loss': -0.50518906}\n",
      "--- Step : 1748 \n",
      "  ------- {'fairness_loss': 1.8010403, 'utility': 0.55922437, 'loss': -0.5051932}\n",
      "--- Step : 1749 \n",
      "  ------- {'fairness_loss': 1.8008716, 'utility': 0.5592231, 'loss': -0.505197}\n",
      "--- Step : 1750 \n",
      "  ------- {'fairness_loss': 1.8010157, 'utility': 0.55923206, 'loss': -0.5052016}\n",
      "--- Step : 1751 \n",
      "  ------- {'fairness_loss': 1.8010921, 'utility': 0.55923855, 'loss': -0.5052058}\n",
      "--- Step : 1752 \n",
      "  ------- {'fairness_loss': 1.8010865, 'utility': 0.55924255, 'loss': -0.5052099}\n",
      "--- Step : 1753 \n",
      "  ------- {'fairness_loss': 1.80102, 'utility': 0.55924463, 'loss': -0.50521404}\n",
      "--- Step : 1754 \n",
      "  ------- {'fairness_loss': 1.8010031, 'utility': 0.55924803, 'loss': -0.5052179}\n",
      "--- Step : 1755 \n",
      "  ------- {'fairness_loss': 1.8010244, 'utility': 0.5592529, 'loss': -0.5052222}\n",
      "--- Step : 1756 \n",
      "  ------- {'fairness_loss': 1.8010801, 'utility': 0.5592589, 'loss': -0.5052265}\n",
      "--- Step : 1757 \n",
      "  ------- {'fairness_loss': 1.8011788, 'utility': 0.5592658, 'loss': -0.5052304}\n",
      "--- Step : 1758 \n",
      "  ------- {'fairness_loss': 1.8011986, 'utility': 0.55927044, 'loss': -0.5052345}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1759 \n",
      "  ------- {'fairness_loss': 1.8011494, 'utility': 0.55927306, 'loss': -0.5052386}\n",
      "--- Step : 1760 \n",
      "  ------- {'fairness_loss': 1.8010353, 'utility': 0.55927384, 'loss': -0.50524276}\n",
      "--- Step : 1761 \n",
      "  ------- {'fairness_loss': 1.8008703, 'utility': 0.559273, 'loss': -0.5052469}\n",
      "--- Step : 1762 \n",
      "  ------- {'fairness_loss': 1.8007653, 'utility': 0.55927384, 'loss': -0.5052509}\n",
      "--- Step : 1763 \n",
      "  ------- {'fairness_loss': 1.8007096, 'utility': 0.5592762, 'loss': -0.5052549}\n",
      "--- Step : 1764 \n",
      "  ------- {'fairness_loss': 1.800697, 'utility': 0.5592801, 'loss': -0.5052592}\n",
      "--- Step : 1765 \n",
      "  ------- {'fairness_loss': 1.8007326, 'utility': 0.55928516, 'loss': -0.5052632}\n",
      "--- Step : 1766 \n",
      "  ------- {'fairness_loss': 1.8007008, 'utility': 0.5592882, 'loss': -0.5052672}\n",
      "--- Step : 1767 \n",
      "  ------- {'fairness_loss': 1.8006043, 'utility': 0.5592894, 'loss': -0.50527126}\n",
      "--- Step : 1768 \n",
      "  ------- {'fairness_loss': 1.8004533, 'utility': 0.55928916, 'loss': -0.50527555}\n",
      "--- Step : 1769 \n",
      "  ------- {'fairness_loss': 1.8002582, 'utility': 0.55928713, 'loss': -0.50527936}\n",
      "--- Step : 1770 \n",
      "  ------- {'fairness_loss': 1.8001242, 'utility': 0.5592872, 'loss': -0.5052835}\n",
      "--- Step : 1771 \n",
      "  ------- {'fairness_loss': 1.8000445, 'utility': 0.5592888, 'loss': -0.50528747}\n",
      "--- Step : 1772 \n",
      "  ------- {'fairness_loss': 1.8000143, 'utility': 0.559292, 'loss': -0.5052916}\n",
      "--- Step : 1773 \n",
      "  ------- {'fairness_loss': 1.800028, 'utility': 0.5592967, 'loss': -0.5052959}\n",
      "--- Step : 1774 \n",
      "  ------- {'fairness_loss': 1.7999843, 'utility': 0.55929935, 'loss': -0.5052998}\n",
      "--- Step : 1775 \n",
      "  ------- {'fairness_loss': 1.7998779, 'utility': 0.5593001, 'loss': -0.5053038}\n",
      "--- Step : 1776 \n",
      "  ------- {'fairness_loss': 1.7997189, 'utility': 0.55929947, 'loss': -0.5053079}\n",
      "--- Step : 1777 \n",
      "  ------- {'fairness_loss': 1.7995489, 'utility': 0.55929744, 'loss': -0.50531095}\n",
      "--- Step : 1778 \n",
      "  ------- {'fairness_loss': 1.799767, 'utility': 0.55930895, 'loss': -0.50531596}\n",
      "--- Step : 1779 \n",
      "  ------- {'fairness_loss': 1.7999343, 'utility': 0.55931777, 'loss': -0.5053197}\n",
      "--- Step : 1780 \n",
      "  ------- {'fairness_loss': 1.8000196, 'utility': 0.5593242, 'loss': -0.50532365}\n",
      "--- Step : 1781 \n",
      "  ------- {'fairness_loss': 1.8000312, 'utility': 0.5593287, 'loss': -0.50532776}\n",
      "--- Step : 1782 \n",
      "  ------- {'fairness_loss': 1.799984, 'utility': 0.55933136, 'loss': -0.5053318}\n",
      "--- Step : 1783 \n",
      "  ------- {'fairness_loss': 1.7999883, 'utility': 0.55933535, 'loss': -0.5053357}\n",
      "--- Step : 1784 \n",
      "  ------- {'fairness_loss': 1.8000315, 'utility': 0.55934083, 'loss': -0.50533986}\n",
      "--- Step : 1785 \n",
      "  ------- {'fairness_loss': 1.8001194, 'utility': 0.5593473, 'loss': -0.5053437}\n",
      "--- Step : 1786 \n",
      "  ------- {'fairness_loss': 1.8001368, 'utility': 0.55935186, 'loss': -0.5053477}\n",
      "--- Step : 1787 \n",
      "  ------- {'fairness_loss': 1.8000897, 'utility': 0.55935454, 'loss': -0.50535184}\n",
      "--- Step : 1788 \n",
      "  ------- {'fairness_loss': 1.799994, 'utility': 0.55935556, 'loss': -0.5053557}\n",
      "--- Step : 1789 \n",
      "  ------- {'fairness_loss': 1.7999518, 'utility': 0.5593582, 'loss': -0.50535965}\n",
      "--- Step : 1790 \n",
      "  ------- {'fairness_loss': 1.799954, 'utility': 0.5593621, 'loss': -0.50536346}\n",
      "--- Step : 1791 \n",
      "  ------- {'fairness_loss': 1.8000035, 'utility': 0.5593678, 'loss': -0.5053677}\n",
      "--- Step : 1792 \n",
      "  ------- {'fairness_loss': 1.7999918, 'utility': 0.5593711, 'loss': -0.50537133}\n",
      "--- Step : 1793 \n",
      "  ------- {'fairness_loss': 1.7999187, 'utility': 0.5593729, 'loss': -0.5053753}\n",
      "--- Step : 1794 \n",
      "  ------- {'fairness_loss': 1.7997962, 'utility': 0.5593733, 'loss': -0.50537944}\n",
      "--- Step : 1795 \n",
      "  ------- {'fairness_loss': 1.7997307, 'utility': 0.55937535, 'loss': -0.50538343}\n",
      "--- Step : 1796 \n",
      "  ------- {'fairness_loss': 1.7997192, 'utility': 0.5593788, 'loss': -0.50538725}\n",
      "--- Step : 1797 \n",
      "  ------- {'fairness_loss': 1.7996509, 'utility': 0.5593807, 'loss': -0.5053912}\n",
      "--- Step : 1798 \n",
      "  ------- {'fairness_loss': 1.7995365, 'utility': 0.5593811, 'loss': -0.50539505}\n",
      "--- Step : 1799 \n",
      "  ------- {'fairness_loss': 1.7994746, 'utility': 0.55938315, 'loss': -0.5053989}\n",
      "--- Step : 1800 \n",
      "  ------- {'fairness_loss': 1.7994639, 'utility': 0.5593869, 'loss': -0.505403}\n",
      "--- Step : 1801 \n",
      "  ------- {'fairness_loss': 1.7993996, 'utility': 0.55938894, 'loss': -0.505407}\n",
      "--- Step : 1802 \n",
      "  ------- {'fairness_loss': 1.7992898, 'utility': 0.5593894, 'loss': -0.50541073}\n",
      "--- Step : 1803 \n",
      "  ------- {'fairness_loss': 1.7992342, 'utility': 0.5593917, 'loss': -0.50541466}\n",
      "--- Step : 1804 \n",
      "  ------- {'fairness_loss': 1.7992313, 'utility': 0.5593954, 'loss': -0.5054184}\n",
      "--- Step : 1805 \n",
      "  ------- {'fairness_loss': 1.7991722, 'utility': 0.5593975, 'loss': -0.50542235}\n",
      "--- Step : 1806 \n",
      "  ------- {'fairness_loss': 1.7990625, 'utility': 0.5593982, 'loss': -0.5054263}\n",
      "--- Step : 1807 \n",
      "  ------- {'fairness_loss': 1.7989156, 'utility': 0.5593975, 'loss': -0.50543004}\n",
      "--- Step : 1808 \n",
      "  ------- {'fairness_loss': 1.7988286, 'utility': 0.5593988, 'loss': -0.5054339}\n",
      "--- Step : 1809 \n",
      "  ------- {'fairness_loss': 1.798793, 'utility': 0.55940163, 'loss': -0.50543785}\n",
      "--- Step : 1810 \n",
      "  ------- {'fairness_loss': 1.7988086, 'utility': 0.559406, 'loss': -0.5054417}\n",
      "--- Step : 1811 \n",
      "  ------- {'fairness_loss': 1.7987717, 'utility': 0.55940866, 'loss': -0.50544554}\n",
      "--- Step : 1812 \n",
      "  ------- {'fairness_loss': 1.7986834, 'utility': 0.5594099, 'loss': -0.5054494}\n",
      "--- Step : 1813 \n",
      "  ------- {'fairness_loss': 1.7985525, 'utility': 0.5594098, 'loss': -0.5054532}\n",
      "--- Step : 1814 \n",
      "  ------- {'fairness_loss': 1.798481, 'utility': 0.5594115, 'loss': -0.5054571}\n",
      "--- Step : 1815 \n",
      "  ------- {'fairness_loss': 1.7984638, 'utility': 0.55941486, 'loss': -0.505461}\n",
      "--- Step : 1816 \n",
      "  ------- {'fairness_loss': 1.798397, 'utility': 0.5594168, 'loss': -0.50546485}\n",
      "--- Step : 1817 \n",
      "  ------- {'fairness_loss': 1.7982864, 'utility': 0.5594171, 'loss': -0.50546855}\n",
      "--- Step : 1818 \n",
      "  ------- {'fairness_loss': 1.798234, 'utility': 0.55941945, 'loss': -0.5054724}\n",
      "--- Step : 1819 \n",
      "  ------- {'fairness_loss': 1.7982309, 'utility': 0.55942327, 'loss': -0.50547636}\n",
      "--- Step : 1820 \n",
      "  ------- {'fairness_loss': 1.7981825, 'utility': 0.55942535, 'loss': -0.5054799}\n",
      "--- Step : 1821 \n",
      "  ------- {'fairness_loss': 1.7980855, 'utility': 0.5594265, 'loss': -0.5054839}\n",
      "--- Step : 1822 \n",
      "  ------- {'fairness_loss': 1.7979488, 'utility': 0.5594261, 'loss': -0.5054877}\n",
      "--- Step : 1823 \n",
      "  ------- {'fairness_loss': 1.7978749, 'utility': 0.5594276, 'loss': -0.5054914}\n",
      "--- Step : 1824 \n",
      "  ------- {'fairness_loss': 1.797852, 'utility': 0.5594308, 'loss': -0.5054952}\n",
      "--- Step : 1825 \n",
      "  ------- {'fairness_loss': 1.7978822, 'utility': 0.5594355, 'loss': -0.505499}\n",
      "--- Step : 1826 \n",
      "  ------- {'fairness_loss': 1.7978622, 'utility': 0.5594386, 'loss': -0.5055027}\n",
      "--- Step : 1827 \n",
      "  ------- {'fairness_loss': 1.797791, 'utility': 0.5594404, 'loss': -0.50550663}\n",
      "--- Step : 1828 \n",
      "  ------- {'fairness_loss': 1.7976774, 'utility': 0.5594407, 'loss': -0.50551033}\n",
      "--- Step : 1829 \n",
      "  ------- {'fairness_loss': 1.7975335, 'utility': 0.5594401, 'loss': -0.5055141}\n",
      "--- Step : 1830 \n",
      "  ------- {'fairness_loss': 1.7974501, 'utility': 0.5594412, 'loss': -0.5055177}\n",
      "--- Step : 1831 \n",
      "  ------- {'fairness_loss': 1.7974212, 'utility': 0.55944407, 'loss': -0.5055214}\n",
      "--- Step : 1832 \n",
      "  ------- {'fairness_loss': 1.7974409, 'utility': 0.55944866, 'loss': -0.5055254}\n",
      "--- Step : 1833 \n",
      "  ------- {'fairness_loss': 1.7975172, 'utility': 0.55945456, 'loss': -0.50552905}\n",
      "--- Step : 1834 \n",
      "  ------- {'fairness_loss': 1.7975353, 'utility': 0.5594588, 'loss': -0.50553274}\n",
      "--- Step : 1835 \n",
      "  ------- {'fairness_loss': 1.7975047, 'utility': 0.55946153, 'loss': -0.5055364}\n",
      "--- Step : 1836 \n",
      "  ------- {'fairness_loss': 1.7974231, 'utility': 0.5594629, 'loss': -0.5055402}\n",
      "--- Step : 1837 \n",
      "  ------- {'fairness_loss': 1.7973038, 'utility': 0.559463, 'loss': -0.5055439}\n",
      "--- Step : 1838 \n",
      "  ------- {'fairness_loss': 1.7971492, 'utility': 0.55946237, 'loss': -0.5055479}\n",
      "--- Step : 1839 \n",
      "  ------- {'fairness_loss': 1.7970659, 'utility': 0.55946356, 'loss': -0.5055516}\n",
      "--- Step : 1840 \n",
      "  ------- {'fairness_loss': 1.7970358, 'utility': 0.55946636, 'loss': -0.5055553}\n",
      "--- Step : 1841 \n",
      "  ------- {'fairness_loss': 1.7970603, 'utility': 0.5594709, 'loss': -0.5055591}\n",
      "--- Step : 1842 \n",
      "  ------- {'fairness_loss': 1.7970349, 'utility': 0.5594739, 'loss': -0.50556284}\n",
      "--- Step : 1843 \n",
      "  ------- {'fairness_loss': 1.7969676, 'utility': 0.5594756, 'loss': -0.5055666}\n",
      "--- Step : 1844 \n",
      "  ------- {'fairness_loss': 1.796958, 'utility': 0.55947894, 'loss': -0.5055702}\n",
      "--- Step : 1845 \n",
      "  ------- {'fairness_loss': 1.7969043, 'utility': 0.5594809, 'loss': -0.50557375}\n",
      "--- Step : 1846 \n",
      "  ------- {'fairness_loss': 1.7968118, 'utility': 0.55948186, 'loss': -0.5055775}\n",
      "--- Step : 1847 \n",
      "  ------- {'fairness_loss': 1.7967763, 'utility': 0.55948454, 'loss': -0.50558126}\n",
      "--- Step : 1848 \n",
      "  ------- {'fairness_loss': 1.7967972, 'utility': 0.5594889, 'loss': -0.50558496}\n",
      "--- Step : 1849 \n",
      "  ------- {'fairness_loss': 1.7967712, 'utility': 0.55949175, 'loss': -0.50558865}\n",
      "--- Step : 1850 \n",
      "  ------- {'fairness_loss': 1.7967019, 'utility': 0.5594934, 'loss': -0.50559235}\n",
      "--- Step : 1851 \n",
      "  ------- {'fairness_loss': 1.7966937, 'utility': 0.55949676, 'loss': -0.5055959}\n",
      "--- Step : 1852 \n",
      "  ------- {'fairness_loss': 1.7966388, 'utility': 0.55949885, 'loss': -0.5055997}\n",
      "--- Step : 1853 \n",
      "  ------- {'fairness_loss': 1.7966434, 'utility': 0.5595026, 'loss': -0.5056033}\n",
      "--- Step : 1854 \n",
      "  ------- {'fairness_loss': 1.796601, 'utility': 0.55950505, 'loss': -0.505607}\n",
      "--- Step : 1855 \n",
      "  ------- {'fairness_loss': 1.796528, 'utility': 0.5595064, 'loss': -0.5056106}\n",
      "--- Step : 1856 \n",
      "  ------- {'fairness_loss': 1.7965066, 'utility': 0.55950946, 'loss': -0.5056143}\n",
      "--- Step : 1857 \n",
      "  ------- {'fairness_loss': 1.7965388, 'utility': 0.5595141, 'loss': -0.5056179}\n",
      "--- Step : 1858 \n",
      "  ------- {'fairness_loss': 1.7965286, 'utility': 0.55951744, 'loss': -0.5056216}\n",
      "--- Step : 1859 \n",
      "  ------- {'fairness_loss': 1.7964727, 'utility': 0.55951947, 'loss': -0.5056253}\n",
      "--- Step : 1860 \n",
      "  ------- {'fairness_loss': 1.7963871, 'utility': 0.5595204, 'loss': -0.5056288}\n",
      "--- Step : 1861 \n",
      "  ------- {'fairness_loss': 1.7963604, 'utility': 0.55952317, 'loss': -0.50563234}\n",
      "--- Step : 1862 \n",
      "  ------- {'fairness_loss': 1.7963842, 'utility': 0.55952764, 'loss': -0.5056361}\n",
      "--- Step : 1863 \n",
      "  ------- {'fairness_loss': 1.7964625, 'utility': 0.5595335, 'loss': -0.5056396}\n",
      "--- Step : 1864 \n",
      "  ------- {'fairness_loss': 1.7964906, 'utility': 0.55953795, 'loss': -0.50564325}\n",
      "--- Step : 1865 \n",
      "  ------- {'fairness_loss': 1.7964717, 'utility': 0.55954117, 'loss': -0.505647}\n",
      "--- Step : 1866 \n",
      "  ------- {'fairness_loss': 1.7964131, 'utility': 0.55954295, 'loss': -0.5056506}\n",
      "--- Step : 1867 \n",
      "  ------- {'fairness_loss': 1.796318, 'utility': 0.5595438, 'loss': -0.5056543}\n",
      "--- Step : 1868 \n",
      "  ------- {'fairness_loss': 1.7962891, 'utility': 0.5595465, 'loss': -0.5056578}\n",
      "--- Step : 1869 \n",
      "  ------- {'fairness_loss': 1.7963159, 'utility': 0.5595508, 'loss': -0.50566137}\n",
      "--- Step : 1870 \n",
      "  ------- {'fairness_loss': 1.7962977, 'utility': 0.55955386, 'loss': -0.50566494}\n",
      "--- Step : 1871 \n",
      "  ------- {'fairness_loss': 1.7962434, 'utility': 0.5595559, 'loss': -0.5056686}\n",
      "--- Step : 1872 \n",
      "  ------- {'fairness_loss': 1.7962468, 'utility': 0.55955964, 'loss': -0.5056722}\n",
      "--- Step : 1873 \n",
      "  ------- {'fairness_loss': 1.796304, 'utility': 0.5595649, 'loss': -0.5056758}\n",
      "--- Step : 1874 \n",
      "  ------- {'fairness_loss': 1.7963165, 'utility': 0.55956894, 'loss': -0.5056794}\n",
      "--- Step : 1875 \n",
      "  ------- {'fairness_loss': 1.7962848, 'utility': 0.55957144, 'loss': -0.5056829}\n",
      "--- Step : 1876 \n",
      "  ------- {'fairness_loss': 1.7962202, 'utility': 0.55957305, 'loss': -0.50568646}\n",
      "--- Step : 1877 \n",
      "  ------- {'fairness_loss': 1.7962136, 'utility': 0.5595765, 'loss': -0.5056901}\n",
      "--- Step : 1878 \n",
      "  ------- {'fairness_loss': 1.796263, 'utility': 0.55958164, 'loss': -0.50569373}\n",
      "--- Step : 1879 \n",
      "  ------- {'fairness_loss': 1.7962705, 'utility': 0.5595854, 'loss': -0.50569725}\n",
      "--- Step : 1880 \n",
      "  ------- {'fairness_loss': 1.7962344, 'utility': 0.5595877, 'loss': -0.5057007}\n",
      "--- Step : 1881 \n",
      "  ------- {'fairness_loss': 1.7961693, 'utility': 0.5595892, 'loss': -0.5057041}\n",
      "--- Step : 1882 \n",
      "  ------- {'fairness_loss': 1.7961617, 'utility': 0.55959266, 'loss': -0.5057078}\n",
      "--- Step : 1883 \n",
      "  ------- {'fairness_loss': 1.7962062, 'utility': 0.5595977, 'loss': -0.5057115}\n",
      "--- Step : 1884 \n",
      "  ------- {'fairness_loss': 1.7963063, 'utility': 0.5596041, 'loss': -0.5057149}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1885 \n",
      "  ------- {'fairness_loss': 1.7963605, 'utility': 0.55960906, 'loss': -0.50571823}\n",
      "--- Step : 1886 \n",
      "  ------- {'fairness_loss': 1.7963672, 'utility': 0.5596129, 'loss': -0.50572187}\n",
      "--- Step : 1887 \n",
      "  ------- {'fairness_loss': 1.7963346, 'utility': 0.55961555, 'loss': -0.5057255}\n",
      "--- Step : 1888 \n",
      "  ------- {'fairness_loss': 1.7962651, 'utility': 0.5596171, 'loss': -0.50572914}\n",
      "--- Step : 1889 \n",
      "  ------- {'fairness_loss': 1.7961735, 'utility': 0.5596177, 'loss': -0.5057325}\n",
      "--- Step : 1890 \n",
      "  ------- {'fairness_loss': 1.7961462, 'utility': 0.5596204, 'loss': -0.505736}\n",
      "--- Step : 1891 \n",
      "  ------- {'fairness_loss': 1.7961746, 'utility': 0.55962473, 'loss': -0.5057395}\n",
      "--- Step : 1892 \n",
      "  ------- {'fairness_loss': 1.7962452, 'utility': 0.5596305, 'loss': -0.50574315}\n",
      "--- Step : 1893 \n",
      "  ------- {'fairness_loss': 1.7963775, 'utility': 0.55963784, 'loss': -0.50574654}\n",
      "--- Step : 1894 \n",
      "  ------- {'fairness_loss': 1.7964622, 'utility': 0.55964386, 'loss': -0.50575}\n",
      "--- Step : 1895 \n",
      "  ------- {'fairness_loss': 1.7964998, 'utility': 0.55964833, 'loss': -0.50575334}\n",
      "--- Step : 1896 \n",
      "  ------- {'fairness_loss': 1.7964902, 'utility': 0.55965155, 'loss': -0.50575686}\n",
      "--- Step : 1897 \n",
      "  ------- {'fairness_loss': 1.7964473, 'utility': 0.559654, 'loss': -0.50576055}\n",
      "--- Step : 1898 \n",
      "  ------- {'fairness_loss': 1.7963717, 'utility': 0.55965525, 'loss': -0.5057641}\n",
      "--- Step : 1899 \n",
      "  ------- {'fairness_loss': 1.7962785, 'utility': 0.5596558, 'loss': -0.5057674}\n",
      "--- Step : 1900 \n",
      "  ------- {'fairness_loss': 1.796246, 'utility': 0.55965835, 'loss': -0.505771}\n",
      "--- Step : 1901 \n",
      "  ------- {'fairness_loss': 1.7962711, 'utility': 0.5596626, 'loss': -0.50577444}\n",
      "--- Step : 1902 \n",
      "  ------- {'fairness_loss': 1.7963463, 'utility': 0.5596685, 'loss': -0.5057781}\n",
      "--- Step : 1903 \n",
      "  ------- {'fairness_loss': 1.7964736, 'utility': 0.55967575, 'loss': -0.50578153}\n",
      "--- Step : 1904 \n",
      "  ------- {'fairness_loss': 1.7965579, 'utility': 0.55968153, 'loss': -0.5057848}\n",
      "--- Step : 1905 \n",
      "  ------- {'fairness_loss': 1.7965957, 'utility': 0.5596862, 'loss': -0.5057883}\n",
      "--- Step : 1906 \n",
      "  ------- {'fairness_loss': 1.7965932, 'utility': 0.5596899, 'loss': -0.5057921}\n",
      "--- Step : 1907 \n",
      "  ------- {'fairness_loss': 1.7965575, 'utility': 0.5596921, 'loss': -0.50579536}\n",
      "--- Step : 1908 \n",
      "  ------- {'fairness_loss': 1.7964941, 'utility': 0.5596937, 'loss': -0.5057989}\n",
      "--- Step : 1909 \n",
      "  ------- {'fairness_loss': 1.7964954, 'utility': 0.5596971, 'loss': -0.5058022}\n",
      "--- Step : 1910 \n",
      "  ------- {'fairness_loss': 1.7965499, 'utility': 0.5597022, 'loss': -0.50580573}\n",
      "--- Step : 1911 \n",
      "  ------- {'fairness_loss': 1.7966559, 'utility': 0.5597089, 'loss': -0.5058092}\n",
      "--- Step : 1912 \n",
      "  ------- {'fairness_loss': 1.7967217, 'utility': 0.5597142, 'loss': -0.5058125}\n",
      "--- Step : 1913 \n",
      "  ------- {'fairness_loss': 1.7967458, 'utility': 0.5597184, 'loss': -0.505816}\n",
      "--- Step : 1914 \n",
      "  ------- {'fairness_loss': 1.7967308, 'utility': 0.55972147, 'loss': -0.50581956}\n",
      "--- Step : 1915 \n",
      "  ------- {'fairness_loss': 1.7966889, 'utility': 0.5597236, 'loss': -0.50582296}\n",
      "--- Step : 1916 \n",
      "  ------- {'fairness_loss': 1.7967083, 'utility': 0.5597276, 'loss': -0.50582635}\n",
      "--- Step : 1917 \n",
      "  ------- {'fairness_loss': 1.7967806, 'utility': 0.5597332, 'loss': -0.5058298}\n",
      "--- Step : 1918 \n",
      "  ------- {'fairness_loss': 1.7969079, 'utility': 0.5597404, 'loss': -0.5058332}\n",
      "--- Step : 1919 \n",
      "  ------- {'fairness_loss': 1.7969908, 'utility': 0.55974615, 'loss': -0.5058364}\n",
      "--- Step : 1920 \n",
      "  ------- {'fairness_loss': 1.7970306, 'utility': 0.55975085, 'loss': -0.50583994}\n",
      "--- Step : 1921 \n",
      "  ------- {'fairness_loss': 1.7970325, 'utility': 0.5597544, 'loss': -0.5058434}\n",
      "--- Step : 1922 \n",
      "  ------- {'fairness_loss': 1.7970021, 'utility': 0.559757, 'loss': -0.5058469}\n",
      "--- Step : 1923 \n",
      "  ------- {'fairness_loss': 1.7969466, 'utility': 0.5597586, 'loss': -0.5058502}\n",
      "--- Step : 1924 \n",
      "  ------- {'fairness_loss': 1.7969557, 'utility': 0.55976236, 'loss': -0.5058537}\n",
      "--- Step : 1925 \n",
      "  ------- {'fairness_loss': 1.79702, 'utility': 0.5597676, 'loss': -0.505857}\n",
      "--- Step : 1926 \n",
      "  ------- {'fairness_loss': 1.7971308, 'utility': 0.5597745, 'loss': -0.50586057}\n",
      "--- Step : 1927 \n",
      "  ------- {'fairness_loss': 1.7972083, 'utility': 0.55978, 'loss': -0.5058637}\n",
      "--- Step : 1928 \n",
      "  ------- {'fairness_loss': 1.7972436, 'utility': 0.55978465, 'loss': -0.50586736}\n",
      "--- Step : 1929 \n",
      "  ------- {'fairness_loss': 1.7972444, 'utility': 0.55978787, 'loss': -0.5058705}\n",
      "--- Step : 1930 \n",
      "  ------- {'fairness_loss': 1.7972184, 'utility': 0.5597906, 'loss': -0.50587404}\n",
      "--- Step : 1931 \n",
      "  ------- {'fairness_loss': 1.7972524, 'utility': 0.5597948, 'loss': -0.5058772}\n",
      "--- Step : 1932 \n",
      "  ------- {'fairness_loss': 1.7973354, 'utility': 0.5598009, 'loss': -0.50588083}\n",
      "--- Step : 1933 \n",
      "  ------- {'fairness_loss': 1.7974765, 'utility': 0.5598084, 'loss': -0.50588405}\n",
      "--- Step : 1934 \n",
      "  ------- {'fairness_loss': 1.7975729, 'utility': 0.5598147, 'loss': -0.5058875}\n",
      "--- Step : 1935 \n",
      "  ------- {'fairness_loss': 1.7976263, 'utility': 0.55981964, 'loss': -0.50589085}\n",
      "--- Step : 1936 \n",
      "  ------- {'fairness_loss': 1.7976465, 'utility': 0.5598236, 'loss': -0.5058942}\n",
      "--- Step : 1937 \n",
      "  ------- {'fairness_loss': 1.7976314, 'utility': 0.55982673, 'loss': -0.50589776}\n",
      "--- Step : 1938 \n",
      "  ------- {'fairness_loss': 1.797595, 'utility': 0.5598287, 'loss': -0.50590086}\n",
      "--- Step : 1939 \n",
      "  ------- {'fairness_loss': 1.79762, 'utility': 0.55983275, 'loss': -0.50590414}\n",
      "--- Step : 1940 \n",
      "  ------- {'fairness_loss': 1.797698, 'utility': 0.55983865, 'loss': -0.5059077}\n",
      "--- Step : 1941 \n",
      "  ------- {'fairness_loss': 1.7978266, 'utility': 0.55984586, 'loss': -0.50591105}\n",
      "--- Step : 1942 \n",
      "  ------- {'fairness_loss': 1.7979202, 'utility': 0.55985194, 'loss': -0.50591433}\n",
      "--- Step : 1943 \n",
      "  ------- {'fairness_loss': 1.797974, 'utility': 0.559857, 'loss': -0.5059178}\n",
      "--- Step : 1944 \n",
      "  ------- {'fairness_loss': 1.7979889, 'utility': 0.55986077, 'loss': -0.5059211}\n",
      "--- Step : 1945 \n",
      "  ------- {'fairness_loss': 1.7979796, 'utility': 0.55986387, 'loss': -0.50592446}\n",
      "--- Step : 1946 \n",
      "  ------- {'fairness_loss': 1.7980329, 'utility': 0.5598686, 'loss': -0.50592756}\n",
      "--- Step : 1947 \n",
      "  ------- {'fairness_loss': 1.7981336, 'utility': 0.5598752, 'loss': -0.5059312}\n",
      "--- Step : 1948 \n",
      "  ------- {'fairness_loss': 1.798293, 'utility': 0.5598832, 'loss': -0.50593436}\n",
      "--- Step : 1949 \n",
      "  ------- {'fairness_loss': 1.7984058, 'utility': 0.55988973, 'loss': -0.5059376}\n",
      "--- Step : 1950 \n",
      "  ------- {'fairness_loss': 1.7984775, 'utility': 0.5598953, 'loss': -0.505941}\n",
      "--- Step : 1951 \n",
      "  ------- {'fairness_loss': 1.7985166, 'utility': 0.5598998, 'loss': -0.5059443}\n",
      "--- Step : 1952 \n",
      "  ------- {'fairness_loss': 1.7985172, 'utility': 0.5599032, 'loss': -0.5059477}\n",
      "--- Step : 1953 \n",
      "  ------- {'fairness_loss': 1.7984917, 'utility': 0.5599057, 'loss': -0.5059509}\n",
      "--- Step : 1954 \n",
      "  ------- {'fairness_loss': 1.7985333, 'utility': 0.55991036, 'loss': -0.5059544}\n",
      "--- Step : 1955 \n",
      "  ------- {'fairness_loss': 1.7986296, 'utility': 0.55991656, 'loss': -0.50595766}\n",
      "--- Step : 1956 \n",
      "  ------- {'fairness_loss': 1.7986906, 'utility': 0.55992174, 'loss': -0.505961}\n",
      "--- Step : 1957 \n",
      "  ------- {'fairness_loss': 1.7988104, 'utility': 0.5599287, 'loss': -0.5059644}\n",
      "--- Step : 1958 \n",
      "  ------- {'fairness_loss': 1.7988896, 'utility': 0.55993414, 'loss': -0.50596744}\n",
      "--- Step : 1959 \n",
      "  ------- {'fairness_loss': 1.7989285, 'utility': 0.5599386, 'loss': -0.5059708}\n",
      "--- Step : 1960 \n",
      "  ------- {'fairness_loss': 1.7989433, 'utility': 0.5599425, 'loss': -0.5059742}\n",
      "--- Step : 1961 \n",
      "  ------- {'fairness_loss': 1.799014, 'utility': 0.559948, 'loss': -0.50597763}\n",
      "--- Step : 1962 \n",
      "  ------- {'fairness_loss': 1.7991405, 'utility': 0.559955, 'loss': -0.5059808}\n",
      "--- Step : 1963 \n",
      "  ------- {'fairness_loss': 1.799231, 'utility': 0.55996084, 'loss': -0.5059839}\n",
      "--- Step : 1964 \n",
      "  ------- {'fairness_loss': 1.799283, 'utility': 0.55996585, 'loss': -0.50598735}\n",
      "--- Step : 1965 \n",
      "  ------- {'fairness_loss': 1.7993017, 'utility': 0.5599697, 'loss': -0.5059907}\n",
      "--- Step : 1966 \n",
      "  ------- {'fairness_loss': 1.7993847, 'utility': 0.55997556, 'loss': -0.505994}\n",
      "--- Step : 1967 \n",
      "  ------- {'fairness_loss': 1.7994336, 'utility': 0.55998015, 'loss': -0.5059971}\n",
      "--- Step : 1968 \n",
      "  ------- {'fairness_loss': 1.7995374, 'utility': 0.5599865, 'loss': -0.50600034}\n",
      "--- Step : 1969 \n",
      "  ------- {'fairness_loss': 1.7996055, 'utility': 0.55999196, 'loss': -0.5060038}\n",
      "--- Step : 1970 \n",
      "  ------- {'fairness_loss': 1.7996445, 'utility': 0.55999625, 'loss': -0.5060069}\n",
      "--- Step : 1971 \n",
      "  ------- {'fairness_loss': 1.7997396, 'utility': 0.5600023, 'loss': -0.5060101}\n",
      "--- Step : 1972 \n",
      "  ------- {'fairness_loss': 1.7998899, 'utility': 0.56001014, 'loss': -0.50601345}\n",
      "--- Step : 1973 \n",
      "  ------- {'fairness_loss': 1.7999991, 'utility': 0.56001663, 'loss': -0.5060167}\n",
      "--- Step : 1974 \n",
      "  ------- {'fairness_loss': 1.8000721, 'utility': 0.56002206, 'loss': -0.5060199}\n",
      "--- Step : 1975 \n",
      "  ------- {'fairness_loss': 1.8001107, 'utility': 0.5600265, 'loss': -0.5060232}\n",
      "--- Step : 1976 \n",
      "  ------- {'fairness_loss': 1.8001205, 'utility': 0.56003016, 'loss': -0.50602657}\n",
      "--- Step : 1977 \n",
      "  ------- {'fairness_loss': 1.8001963, 'utility': 0.56003547, 'loss': -0.5060296}\n",
      "--- Step : 1978 \n",
      "  ------- {'fairness_loss': 1.8003232, 'utility': 0.56004274, 'loss': -0.50603306}\n",
      "--- Step : 1979 \n",
      "  ------- {'fairness_loss': 1.800417, 'utility': 0.56004864, 'loss': -0.50603616}\n",
      "--- Step : 1980 \n",
      "  ------- {'fairness_loss': 1.8004743, 'utility': 0.5600537, 'loss': -0.5060395}\n",
      "--- Step : 1981 \n",
      "  ------- {'fairness_loss': 1.8005064, 'utility': 0.56005776, 'loss': -0.5060426}\n",
      "--- Step : 1982 \n",
      "  ------- {'fairness_loss': 1.800596, 'utility': 0.5600638, 'loss': -0.5060459}\n",
      "--- Step : 1983 \n",
      "  ------- {'fairness_loss': 1.8007342, 'utility': 0.5600713, 'loss': -0.5060493}\n",
      "--- Step : 1984 \n",
      "  ------- {'fairness_loss': 1.8008426, 'utility': 0.56007767, 'loss': -0.5060524}\n",
      "--- Step : 1985 \n",
      "  ------- {'fairness_loss': 1.8009127, 'utility': 0.56008303, 'loss': -0.50605565}\n",
      "--- Step : 1986 \n",
      "  ------- {'fairness_loss': 1.800955, 'utility': 0.5600874, 'loss': -0.50605875}\n",
      "--- Step : 1987 \n",
      "  ------- {'fairness_loss': 1.8010547, 'utility': 0.56009364, 'loss': -0.50606203}\n",
      "--- Step : 1988 \n",
      "  ------- {'fairness_loss': 1.8012099, 'utility': 0.5601016, 'loss': -0.5060653}\n",
      "--- Step : 1989 \n",
      "  ------- {'fairness_loss': 1.8013283, 'utility': 0.56010824, 'loss': -0.5060684}\n",
      "--- Step : 1990 \n",
      "  ------- {'fairness_loss': 1.8014082, 'utility': 0.5601139, 'loss': -0.5060717}\n",
      "--- Step : 1991 \n",
      "  ------- {'fairness_loss': 1.8014554, 'utility': 0.56011856, 'loss': -0.5060749}\n",
      "--- Step : 1992 \n",
      "  ------- {'fairness_loss': 1.8014796, 'utility': 0.56012243, 'loss': -0.50607806}\n",
      "--- Step : 1993 \n",
      "  ------- {'fairness_loss': 1.8015646, 'utility': 0.56012815, 'loss': -0.5060812}\n",
      "--- Step : 1994 \n",
      "  ------- {'fairness_loss': 1.8017002, 'utility': 0.56013554, 'loss': -0.50608456}\n",
      "--- Step : 1995 \n",
      "  ------- {'fairness_loss': 1.8018955, 'utility': 0.56014454, 'loss': -0.50608766}\n",
      "--- Step : 1996 \n",
      "  ------- {'fairness_loss': 1.8020501, 'utility': 0.5601521, 'loss': -0.50609064}\n",
      "--- Step : 1997 \n",
      "  ------- {'fairness_loss': 1.8021598, 'utility': 0.56015867, 'loss': -0.50609386}\n",
      "--- Step : 1998 \n",
      "  ------- {'fairness_loss': 1.8022394, 'utility': 0.5601642, 'loss': -0.506097}\n",
      "--- Step : 1999 \n",
      "  ------- {'fairness_loss': 1.8022835, 'utility': 0.5601688, 'loss': -0.5061003}\n",
      "--- Step : 2000 \n",
      "  ------- {'fairness_loss': 1.8023001, 'utility': 0.56017256, 'loss': -0.5061036}\n",
      "--- Step : 2001 \n",
      "  ------- {'fairness_loss': 1.8023018, 'utility': 0.5601758, 'loss': -0.50610673}\n",
      "--- Step : 2002 \n",
      "  ------- {'fairness_loss': 1.8023669, 'utility': 0.5601808, 'loss': -0.5061098}\n",
      "--- Step : 2003 \n",
      "  ------- {'fairness_loss': 1.802488, 'utility': 0.5601875, 'loss': -0.5061129}\n",
      "--- Step : 2004 \n",
      "  ------- {'fairness_loss': 1.8026582, 'utility': 0.560196, 'loss': -0.5061162}\n",
      "--- Step : 2005 \n",
      "  ------- {'fairness_loss': 1.802885, 'utility': 0.560206, 'loss': -0.50611943}\n",
      "--- Step : 2006 \n",
      "  ------- {'fairness_loss': 1.803068, 'utility': 0.56021446, 'loss': -0.5061224}\n",
      "--- Step : 2007 \n",
      "  ------- {'fairness_loss': 1.803209, 'utility': 0.56022185, 'loss': -0.50612557}\n",
      "--- Step : 2008 \n",
      "  ------- {'fairness_loss': 1.803315, 'utility': 0.56022805, 'loss': -0.5061286}\n",
      "--- Step : 2009 \n",
      "  ------- {'fairness_loss': 1.8033859, 'utility': 0.5602335, 'loss': -0.5061319}\n",
      "--- Step : 2010 \n",
      "  ------- {'fairness_loss': 1.8034241, 'utility': 0.5602379, 'loss': -0.50613517}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2011 \n",
      "  ------- {'fairness_loss': 1.803436, 'utility': 0.56024164, 'loss': -0.50613856}\n",
      "--- Step : 2012 \n",
      "  ------- {'fairness_loss': 1.8034352, 'utility': 0.56024456, 'loss': -0.5061415}\n",
      "--- Step : 2013 \n",
      "  ------- {'fairness_loss': 1.8035016, 'utility': 0.5602497, 'loss': -0.50614464}\n",
      "--- Step : 2014 \n",
      "  ------- {'fairness_loss': 1.8036249, 'utility': 0.5602566, 'loss': -0.50614786}\n",
      "--- Step : 2015 \n",
      "  ------- {'fairness_loss': 1.8037941, 'utility': 0.5602651, 'loss': -0.5061513}\n",
      "--- Step : 2016 \n",
      "  ------- {'fairness_loss': 1.8040233, 'utility': 0.56027496, 'loss': -0.50615424}\n",
      "--- Step : 2017 \n",
      "  ------- {'fairness_loss': 1.8042116, 'utility': 0.5602837, 'loss': -0.5061574}\n",
      "--- Step : 2018 \n",
      "  ------- {'fairness_loss': 1.8043575, 'utility': 0.56029105, 'loss': -0.5061603}\n",
      "--- Step : 2019 \n",
      "  ------- {'fairness_loss': 1.8044673, 'utility': 0.5602976, 'loss': -0.5061636}\n",
      "--- Step : 2020 \n",
      "  ------- {'fairness_loss': 1.8045433, 'utility': 0.56030285, 'loss': -0.5061666}\n",
      "--- Step : 2021 \n",
      "  ------- {'fairness_loss': 1.8045882, 'utility': 0.5603076, 'loss': -0.50617}\n",
      "--- Step : 2022 \n",
      "  ------- {'fairness_loss': 1.8046082, 'utility': 0.5603114, 'loss': -0.50617313}\n",
      "--- Step : 2023 \n",
      "  ------- {'fairness_loss': 1.8046162, 'utility': 0.56031454, 'loss': -0.50617605}\n",
      "--- Step : 2024 \n",
      "  ------- {'fairness_loss': 1.8046894, 'utility': 0.5603197, 'loss': -0.50617903}\n",
      "--- Step : 2025 \n",
      "  ------- {'fairness_loss': 1.8048189, 'utility': 0.5603268, 'loss': -0.50618225}\n",
      "--- Step : 2026 \n",
      "  ------- {'fairness_loss': 1.8049971, 'utility': 0.5603355, 'loss': -0.5061856}\n",
      "--- Step : 2027 \n",
      "  ------- {'fairness_loss': 1.8052311, 'utility': 0.56034565, 'loss': -0.5061887}\n",
      "--- Step : 2028 \n",
      "  ------- {'fairness_loss': 1.8054262, 'utility': 0.5603546, 'loss': -0.5061918}\n",
      "--- Step : 2029 \n",
      "  ------- {'fairness_loss': 1.80558, 'utility': 0.56036216, 'loss': -0.5061948}\n",
      "--- Step : 2030 \n",
      "  ------- {'fairness_loss': 1.805698, 'utility': 0.56036884, 'loss': -0.50619787}\n",
      "--- Step : 2031 \n",
      "  ------- {'fairness_loss': 1.8057832, 'utility': 0.5603745, 'loss': -0.506201}\n",
      "--- Step : 2032 \n",
      "  ------- {'fairness_loss': 1.8058375, 'utility': 0.5603794, 'loss': -0.50620425}\n",
      "--- Step : 2033 \n",
      "  ------- {'fairness_loss': 1.805867, 'utility': 0.56038356, 'loss': -0.5062075}\n",
      "--- Step : 2034 \n",
      "  ------- {'fairness_loss': 1.8059653, 'utility': 0.56038946, 'loss': -0.5062105}\n",
      "--- Step : 2035 \n",
      "  ------- {'fairness_loss': 1.8061221, 'utility': 0.5603973, 'loss': -0.50621367}\n",
      "--- Step : 2036 \n",
      "  ------- {'fairness_loss': 1.8062447, 'utility': 0.5604041, 'loss': -0.50621676}\n",
      "--- Step : 2037 \n",
      "  ------- {'fairness_loss': 1.8063378, 'utility': 0.5604099, 'loss': -0.50621974}\n",
      "--- Step : 2038 \n",
      "  ------- {'fairness_loss': 1.8064879, 'utility': 0.56041765, 'loss': -0.506223}\n",
      "--- Step : 2039 \n",
      "  ------- {'fairness_loss': 1.8066051, 'utility': 0.5604242, 'loss': -0.50622606}\n",
      "--- Step : 2040 \n",
      "  ------- {'fairness_loss': 1.8066919, 'utility': 0.5604299, 'loss': -0.5062291}\n",
      "--- Step : 2041 \n",
      "  ------- {'fairness_loss': 1.8068395, 'utility': 0.56043744, 'loss': -0.50623226}\n",
      "--- Step : 2042 \n",
      "  ------- {'fairness_loss': 1.807047, 'utility': 0.5604466, 'loss': -0.50623524}\n",
      "--- Step : 2043 \n",
      "  ------- {'fairness_loss': 1.8072108, 'utility': 0.5604546, 'loss': -0.5062383}\n",
      "--- Step : 2044 \n",
      "  ------- {'fairness_loss': 1.807339, 'utility': 0.5604616, 'loss': -0.50624144}\n",
      "--- Step : 2045 \n",
      "  ------- {'fairness_loss': 1.8074355, 'utility': 0.5604676, 'loss': -0.50624454}\n",
      "--- Step : 2046 \n",
      "  ------- {'fairness_loss': 1.8075011, 'utility': 0.56047285, 'loss': -0.5062478}\n",
      "--- Step : 2047 \n",
      "  ------- {'fairness_loss': 1.8075495, 'utility': 0.5604771, 'loss': -0.5062506}\n",
      "--- Step : 2048 \n",
      "  ------- {'fairness_loss': 1.807661, 'utility': 0.56048346, 'loss': -0.5062536}\n",
      "--- Step : 2049 \n",
      "  ------- {'fairness_loss': 1.8078266, 'utility': 0.5604915, 'loss': -0.5062567}\n",
      "--- Step : 2050 \n",
      "  ------- {'fairness_loss': 1.8080479, 'utility': 0.5605014, 'loss': -0.50626}\n",
      "--- Step : 2051 \n",
      "  ------- {'fairness_loss': 1.8082328, 'utility': 0.56051, 'loss': -0.506263}\n",
      "--- Step : 2052 \n",
      "  ------- {'fairness_loss': 1.8083814, 'utility': 0.56051743, 'loss': -0.506266}\n",
      "--- Step : 2053 \n",
      "  ------- {'fairness_loss': 1.808495, 'utility': 0.5605239, 'loss': -0.5062691}\n",
      "--- Step : 2054 \n",
      "  ------- {'fairness_loss': 1.8085777, 'utility': 0.56052953, 'loss': -0.5062722}\n",
      "--- Step : 2055 \n",
      "  ------- {'fairness_loss': 1.808633, 'utility': 0.5605341, 'loss': -0.5062751}\n",
      "--- Step : 2056 \n",
      "  ------- {'fairness_loss': 1.8087591, 'utility': 0.560541, 'loss': -0.5062782}\n",
      "--- Step : 2057 \n",
      "  ------- {'fairness_loss': 1.8089408, 'utility': 0.56054956, 'loss': -0.5062813}\n",
      "--- Step : 2058 \n",
      "  ------- {'fairness_loss': 1.8090869, 'utility': 0.56055707, 'loss': -0.5062845}\n",
      "--- Step : 2059 \n",
      "  ------- {'fairness_loss': 1.8092002, 'utility': 0.5605636, 'loss': -0.50628763}\n",
      "--- Step : 2060 \n",
      "  ------- {'fairness_loss': 1.8092892, 'utility': 0.5605692, 'loss': -0.50629056}\n",
      "--- Step : 2061 \n",
      "  ------- {'fairness_loss': 1.809437, 'utility': 0.5605767, 'loss': -0.5062936}\n",
      "--- Step : 2062 \n",
      "  ------- {'fairness_loss': 1.8096443, 'utility': 0.56058586, 'loss': -0.5062965}\n",
      "--- Step : 2063 \n",
      "  ------- {'fairness_loss': 1.8098131, 'utility': 0.560594, 'loss': -0.5062996}\n",
      "--- Step : 2064 \n",
      "  ------- {'fairness_loss': 1.8099461, 'utility': 0.56060106, 'loss': -0.50630265}\n",
      "--- Step : 2065 \n",
      "  ------- {'fairness_loss': 1.8100494, 'utility': 0.5606072, 'loss': -0.5063057}\n",
      "--- Step : 2066 \n",
      "  ------- {'fairness_loss': 1.8101279, 'utility': 0.56061256, 'loss': -0.50630873}\n",
      "--- Step : 2067 \n",
      "  ------- {'fairness_loss': 1.8102669, 'utility': 0.5606198, 'loss': -0.5063118}\n",
      "--- Step : 2068 \n",
      "  ------- {'fairness_loss': 1.8104669, 'utility': 0.5606288, 'loss': -0.50631475}\n",
      "--- Step : 2069 \n",
      "  ------- {'fairness_loss': 1.8106308, 'utility': 0.56063676, 'loss': -0.50631785}\n",
      "--- Step : 2070 \n",
      "  ------- {'fairness_loss': 1.8107582, 'utility': 0.5606436, 'loss': -0.5063209}\n",
      "--- Step : 2071 \n",
      "  ------- {'fairness_loss': 1.8108588, 'utility': 0.56064963, 'loss': -0.5063239}\n",
      "--- Step : 2072 \n",
      "  ------- {'fairness_loss': 1.8109363, 'utility': 0.56065506, 'loss': -0.506327}\n",
      "--- Step : 2073 \n",
      "  ------- {'fairness_loss': 1.8110749, 'utility': 0.5606622, 'loss': -0.50632995}\n",
      "--- Step : 2074 \n",
      "  ------- {'fairness_loss': 1.8112704, 'utility': 0.5606712, 'loss': -0.5063331}\n",
      "--- Step : 2075 \n",
      "  ------- {'fairness_loss': 1.8115247, 'utility': 0.56068176, 'loss': -0.50633603}\n",
      "--- Step : 2076 \n",
      "  ------- {'fairness_loss': 1.8117408, 'utility': 0.56069106, 'loss': -0.50633883}\n",
      "--- Step : 2077 \n",
      "  ------- {'fairness_loss': 1.8119134, 'utility': 0.56069934, 'loss': -0.50634193}\n",
      "--- Step : 2078 \n",
      "  ------- {'fairness_loss': 1.8120514, 'utility': 0.56070644, 'loss': -0.5063449}\n",
      "--- Step : 2079 \n",
      "  ------- {'fairness_loss': 1.8121614, 'utility': 0.5607128, 'loss': -0.50634795}\n",
      "--- Step : 2080 \n",
      "  ------- {'fairness_loss': 1.8122389, 'utility': 0.5607181, 'loss': -0.50635093}\n",
      "--- Step : 2081 \n",
      "  ------- {'fairness_loss': 1.8122936, 'utility': 0.5607229, 'loss': -0.5063541}\n",
      "--- Step : 2082 \n",
      "  ------- {'fairness_loss': 1.8124216, 'utility': 0.5607298, 'loss': -0.50635713}\n",
      "--- Step : 2083 \n",
      "  ------- {'fairness_loss': 1.812608, 'utility': 0.5607385, 'loss': -0.5063603}\n",
      "--- Step : 2084 \n",
      "  ------- {'fairness_loss': 1.8127601, 'utility': 0.5607461, 'loss': -0.5063633}\n",
      "--- Step : 2085 \n",
      "  ------- {'fairness_loss': 1.8128844, 'utility': 0.56075263, 'loss': -0.5063661}\n",
      "--- Step : 2086 \n",
      "  ------- {'fairness_loss': 1.813068, 'utility': 0.5607612, 'loss': -0.5063692}\n",
      "--- Step : 2087 \n",
      "  ------- {'fairness_loss': 1.8132184, 'utility': 0.56076866, 'loss': -0.5063721}\n",
      "--- Step : 2088 \n",
      "  ------- {'fairness_loss': 1.8133376, 'utility': 0.5607752, 'loss': -0.5063751}\n",
      "--- Step : 2089 \n",
      "  ------- {'fairness_loss': 1.8135202, 'utility': 0.5607836, 'loss': -0.506378}\n",
      "--- Step : 2090 \n",
      "  ------- {'fairness_loss': 1.8136687, 'utility': 0.56079125, 'loss': -0.5063812}\n",
      "--- Step : 2091 \n",
      "  ------- {'fairness_loss': 1.8137882, 'utility': 0.56079763, 'loss': -0.506384}\n",
      "--- Step : 2092 \n",
      "  ------- {'fairness_loss': 1.8139697, 'utility': 0.5608063, 'loss': -0.5063872}\n",
      "--- Step : 2093 \n",
      "  ------- {'fairness_loss': 1.8141187, 'utility': 0.56081367, 'loss': -0.5063901}\n",
      "--- Step : 2094 \n",
      "  ------- {'fairness_loss': 1.814239, 'utility': 0.56082016, 'loss': -0.506393}\n",
      "--- Step : 2095 \n",
      "  ------- {'fairness_loss': 1.8144171, 'utility': 0.5608285, 'loss': -0.506396}\n",
      "--- Step : 2096 \n",
      "  ------- {'fairness_loss': 1.8146614, 'utility': 0.5608387, 'loss': -0.50639886}\n",
      "--- Step : 2097 \n",
      "  ------- {'fairness_loss': 1.8148639, 'utility': 0.56084764, 'loss': -0.5064017}\n",
      "--- Step : 2098 \n",
      "  ------- {'fairness_loss': 1.8150274, 'utility': 0.5608557, 'loss': -0.5064049}\n",
      "--- Step : 2099 \n",
      "  ------- {'fairness_loss': 1.8151629, 'utility': 0.5608626, 'loss': -0.50640774}\n",
      "--- Step : 2100 \n",
      "  ------- {'fairness_loss': 1.8152639, 'utility': 0.56086886, 'loss': -0.50641096}\n",
      "--- Step : 2101 \n",
      "  ------- {'fairness_loss': 1.8153429, 'utility': 0.5608742, 'loss': -0.50641394}\n",
      "--- Step : 2102 \n",
      "  ------- {'fairness_loss': 1.8154957, 'utility': 0.5608817, 'loss': -0.5064168}\n",
      "--- Step : 2103 \n",
      "  ------- {'fairness_loss': 1.8157018, 'utility': 0.5608908, 'loss': -0.5064197}\n",
      "--- Step : 2104 \n",
      "  ------- {'fairness_loss': 1.815877, 'utility': 0.560899, 'loss': -0.5064227}\n",
      "--- Step : 2105 \n",
      "  ------- {'fairness_loss': 1.8160175, 'utility': 0.56090623, 'loss': -0.50642574}\n",
      "--- Step : 2106 \n",
      "  ------- {'fairness_loss': 1.8161311, 'utility': 0.5609125, 'loss': -0.50642854}\n",
      "--- Step : 2107 \n",
      "  ------- {'fairness_loss': 1.8163127, 'utility': 0.5609211, 'loss': -0.5064317}\n",
      "--- Step : 2108 \n",
      "  ------- {'fairness_loss': 1.8165501, 'utility': 0.56093115, 'loss': -0.5064346}\n",
      "--- Step : 2109 \n",
      "  ------- {'fairness_loss': 1.8167529, 'utility': 0.56093997, 'loss': -0.50643736}\n",
      "--- Step : 2110 \n",
      "  ------- {'fairness_loss': 1.8169183, 'utility': 0.56094784, 'loss': -0.5064403}\n",
      "--- Step : 2111 \n",
      "  ------- {'fairness_loss': 1.817052, 'utility': 0.5609549, 'loss': -0.5064434}\n",
      "--- Step : 2112 \n",
      "  ------- {'fairness_loss': 1.8171543, 'utility': 0.56096107, 'loss': -0.5064464}\n",
      "--- Step : 2113 \n",
      "  ------- {'fairness_loss': 1.8172411, 'utility': 0.5609665, 'loss': -0.5064493}\n",
      "--- Step : 2114 \n",
      "  ------- {'fairness_loss': 1.8173952, 'utility': 0.56097394, 'loss': -0.5064521}\n",
      "--- Step : 2115 \n",
      "  ------- {'fairness_loss': 1.817604, 'utility': 0.5609834, 'loss': -0.5064553}\n",
      "--- Step : 2116 \n",
      "  ------- {'fairness_loss': 1.8178773, 'utility': 0.56099457, 'loss': -0.5064582}\n",
      "--- Step : 2117 \n",
      "  ------- {'fairness_loss': 1.8181068, 'utility': 0.5610042, 'loss': -0.506461}\n",
      "--- Step : 2118 \n",
      "  ------- {'fairness_loss': 1.8183018, 'utility': 0.5610129, 'loss': -0.5064639}\n",
      "--- Step : 2119 \n",
      "  ------- {'fairness_loss': 1.818461, 'utility': 0.5610207, 'loss': -0.50646687}\n",
      "--- Step : 2120 \n",
      "  ------- {'fairness_loss': 1.8185897, 'utility': 0.5610275, 'loss': -0.50646985}\n",
      "--- Step : 2121 \n",
      "  ------- {'fairness_loss': 1.8186905, 'utility': 0.5610334, 'loss': -0.5064727}\n",
      "--- Step : 2122 \n",
      "  ------- {'fairness_loss': 1.8187677, 'utility': 0.5610389, 'loss': -0.50647587}\n",
      "--- Step : 2123 \n",
      "  ------- {'fairness_loss': 1.818918, 'utility': 0.5610462, 'loss': -0.50647867}\n",
      "--- Step : 2124 \n",
      "  ------- {'fairness_loss': 1.8191289, 'utility': 0.56105554, 'loss': -0.50648165}\n",
      "--- Step : 2125 \n",
      "  ------- {'fairness_loss': 1.8193092, 'utility': 0.5610639, 'loss': -0.5064846}\n",
      "--- Step : 2126 \n",
      "  ------- {'fairness_loss': 1.8194532, 'utility': 0.5610712, 'loss': -0.5064876}\n",
      "--- Step : 2127 \n",
      "  ------- {'fairness_loss': 1.8196663, 'utility': 0.5610804, 'loss': -0.5064904}\n",
      "--- Step : 2128 \n",
      "  ------- {'fairness_loss': 1.8198462, 'utility': 0.5610887, 'loss': -0.5064933}\n",
      "--- Step : 2129 \n",
      "  ------- {'fairness_loss': 1.8199892, 'utility': 0.56109595, 'loss': -0.50649625}\n",
      "--- Step : 2130 \n",
      "  ------- {'fairness_loss': 1.8201107, 'utility': 0.56110245, 'loss': -0.5064991}\n",
      "--- Step : 2131 \n",
      "  ------- {'fairness_loss': 1.8202952, 'utility': 0.561111, 'loss': -0.5065021}\n",
      "--- Step : 2132 \n",
      "  ------- {'fairness_loss': 1.8205411, 'utility': 0.56112134, 'loss': -0.50650513}\n",
      "--- Step : 2133 \n",
      "  ------- {'fairness_loss': 1.8207523, 'utility': 0.56113046, 'loss': -0.5065079}\n",
      "--- Step : 2134 \n",
      "  ------- {'fairness_loss': 1.8209274, 'utility': 0.5611387, 'loss': -0.50651085}\n",
      "--- Step : 2135 \n",
      "  ------- {'fairness_loss': 1.8210701, 'utility': 0.56114596, 'loss': -0.50651383}\n",
      "--- Step : 2136 \n",
      "  ------- {'fairness_loss': 1.8211839, 'utility': 0.5611523, 'loss': -0.50651675}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2137 \n",
      "  ------- {'fairness_loss': 1.8212842, 'utility': 0.56115794, 'loss': -0.50651944}\n",
      "--- Step : 2138 \n",
      "  ------- {'fairness_loss': 1.8214489, 'utility': 0.56116587, 'loss': -0.5065224}\n",
      "--- Step : 2139 \n",
      "  ------- {'fairness_loss': 1.8216712, 'utility': 0.5611755, 'loss': -0.5065254}\n",
      "--- Step : 2140 \n",
      "  ------- {'fairness_loss': 1.821958, 'utility': 0.5611869, 'loss': -0.5065282}\n",
      "--- Step : 2141 \n",
      "  ------- {'fairness_loss': 1.8222028, 'utility': 0.56119716, 'loss': -0.50653106}\n",
      "--- Step : 2142 \n",
      "  ------- {'fairness_loss': 1.8224087, 'utility': 0.56120634, 'loss': -0.5065341}\n",
      "--- Step : 2143 \n",
      "  ------- {'fairness_loss': 1.8225839, 'utility': 0.5612144, 'loss': -0.50653684}\n",
      "--- Step : 2144 \n",
      "  ------- {'fairness_loss': 1.8227259, 'utility': 0.5612216, 'loss': -0.5065398}\n",
      "--- Step : 2145 \n",
      "  ------- {'fairness_loss': 1.8228401, 'utility': 0.56122804, 'loss': -0.50654286}\n",
      "--- Step : 2146 \n",
      "  ------- {'fairness_loss': 1.8229314, 'utility': 0.56123364, 'loss': -0.5065457}\n",
      "--- Step : 2147 \n",
      "  ------- {'fairness_loss': 1.823096, 'utility': 0.5612415, 'loss': -0.50654864}\n",
      "--- Step : 2148 \n",
      "  ------- {'fairness_loss': 1.8233261, 'utility': 0.56125116, 'loss': -0.5065514}\n",
      "--- Step : 2149 \n",
      "  ------- {'fairness_loss': 1.8235185, 'utility': 0.5612599, 'loss': -0.50655437}\n",
      "--- Step : 2150 \n",
      "  ------- {'fairness_loss': 1.8236818, 'utility': 0.5612677, 'loss': -0.5065572}\n",
      "--- Step : 2151 \n",
      "  ------- {'fairness_loss': 1.8238169, 'utility': 0.56127477, 'loss': -0.50656027}\n",
      "--- Step : 2152 \n",
      "  ------- {'fairness_loss': 1.8240173, 'utility': 0.5612836, 'loss': -0.50656307}\n",
      "--- Step : 2153 \n",
      "  ------- {'fairness_loss': 1.8242834, 'utility': 0.56129426, 'loss': -0.50656575}\n",
      "--- Step : 2154 \n",
      "  ------- {'fairness_loss': 1.824511, 'utility': 0.561304, 'loss': -0.5065687}\n",
      "--- Step : 2155 \n",
      "  ------- {'fairness_loss': 1.8247007, 'utility': 0.5613125, 'loss': -0.5065715}\n",
      "--- Step : 2156 \n",
      "  ------- {'fairness_loss': 1.8248615, 'utility': 0.56132036, 'loss': -0.5065745}\n",
      "--- Step : 2157 \n",
      "  ------- {'fairness_loss': 1.824989, 'utility': 0.56132716, 'loss': -0.5065775}\n",
      "--- Step : 2158 \n",
      "  ------- {'fairness_loss': 1.8250982, 'utility': 0.56133324, 'loss': -0.5065803}\n",
      "--- Step : 2159 \n",
      "  ------- {'fairness_loss': 1.8252773, 'utility': 0.56134135, 'loss': -0.50658303}\n",
      "--- Step : 2160 \n",
      "  ------- {'fairness_loss': 1.8255185, 'utility': 0.5613515, 'loss': -0.50658596}\n",
      "--- Step : 2161 \n",
      "  ------- {'fairness_loss': 1.8257288, 'utility': 0.5613606, 'loss': -0.50658876}\n",
      "--- Step : 2162 \n",
      "  ------- {'fairness_loss': 1.8259003, 'utility': 0.5613688, 'loss': -0.5065918}\n",
      "--- Step : 2163 \n",
      "  ------- {'fairness_loss': 1.8260437, 'utility': 0.56137604, 'loss': -0.5065947}\n",
      "--- Step : 2164 \n",
      "  ------- {'fairness_loss': 1.8261688, 'utility': 0.5613825, 'loss': -0.5065974}\n",
      "--- Step : 2165 \n",
      "  ------- {'fairness_loss': 1.826359, 'utility': 0.5613911, 'loss': -0.5066003}\n",
      "--- Step : 2166 \n",
      "  ------- {'fairness_loss': 1.826609, 'utility': 0.56140155, 'loss': -0.5066033}\n",
      "--- Step : 2167 \n",
      "  ------- {'fairness_loss': 1.8268291, 'utility': 0.561411, 'loss': -0.50660616}\n",
      "--- Step : 2168 \n",
      "  ------- {'fairness_loss': 1.8270134, 'utility': 0.56141925, 'loss': -0.50660884}\n",
      "--- Step : 2169 \n",
      "  ------- {'fairness_loss': 1.8271654, 'utility': 0.5614269, 'loss': -0.50661194}\n",
      "--- Step : 2170 \n",
      "  ------- {'fairness_loss': 1.8273005, 'utility': 0.5614336, 'loss': -0.5066146}\n",
      "--- Step : 2171 \n",
      "  ------- {'fairness_loss': 1.8274965, 'utility': 0.56144243, 'loss': -0.50661755}\n",
      "--- Step : 2172 \n",
      "  ------- {'fairness_loss': 1.8277562, 'utility': 0.5614531, 'loss': -0.5066204}\n",
      "--- Step : 2173 \n",
      "  ------- {'fairness_loss': 1.8279829, 'utility': 0.5614628, 'loss': -0.5066233}\n",
      "--- Step : 2174 \n",
      "  ------- {'fairness_loss': 1.8281767, 'utility': 0.5614713, 'loss': -0.506626}\n",
      "--- Step : 2175 \n",
      "  ------- {'fairness_loss': 1.8283346, 'utility': 0.56147903, 'loss': -0.506629}\n",
      "--- Step : 2176 \n",
      "  ------- {'fairness_loss': 1.8284698, 'utility': 0.5614858, 'loss': -0.50663173}\n",
      "--- Step : 2177 \n",
      "  ------- {'fairness_loss': 1.828673, 'utility': 0.5614949, 'loss': -0.5066347}\n",
      "--- Step : 2178 \n",
      "  ------- {'fairness_loss': 1.8288485, 'utility': 0.5615029, 'loss': -0.5066374}\n",
      "--- Step : 2179 \n",
      "  ------- {'fairness_loss': 1.8290877, 'utility': 0.561513, 'loss': -0.5066404}\n",
      "--- Step : 2180 \n",
      "  ------- {'fairness_loss': 1.8292953, 'utility': 0.56152207, 'loss': -0.50664324}\n",
      "--- Step : 2181 \n",
      "  ------- {'fairness_loss': 1.82947, 'utility': 0.5615301, 'loss': -0.50664604}\n",
      "--- Step : 2182 \n",
      "  ------- {'fairness_loss': 1.8296158, 'utility': 0.56153744, 'loss': -0.50664896}\n",
      "--- Step : 2183 \n",
      "  ------- {'fairness_loss': 1.8298331, 'utility': 0.5615467, 'loss': -0.5066517}\n",
      "--- Step : 2184 \n",
      "  ------- {'fairness_loss': 1.8300148, 'utility': 0.5615549, 'loss': -0.50665444}\n",
      "--- Step : 2185 \n",
      "  ------- {'fairness_loss': 1.830174, 'utility': 0.5615626, 'loss': -0.50665736}\n",
      "--- Step : 2186 \n",
      "  ------- {'fairness_loss': 1.8303957, 'utility': 0.5615721, 'loss': -0.5066602}\n",
      "--- Step : 2187 \n",
      "  ------- {'fairness_loss': 1.8306868, 'utility': 0.5615835, 'loss': -0.5066629}\n",
      "--- Step : 2188 \n",
      "  ------- {'fairness_loss': 1.8309368, 'utility': 0.56159383, 'loss': -0.5066657}\n",
      "--- Step : 2189 \n",
      "  ------- {'fairness_loss': 1.831152, 'utility': 0.5616031, 'loss': -0.50666857}\n",
      "--- Step : 2190 \n",
      "  ------- {'fairness_loss': 1.8313318, 'utility': 0.56161135, 'loss': -0.5066714}\n",
      "--- Step : 2191 \n",
      "  ------- {'fairness_loss': 1.8314837, 'utility': 0.56161875, 'loss': -0.50667423}\n",
      "--- Step : 2192 \n",
      "  ------- {'fairness_loss': 1.8316063, 'utility': 0.5616254, 'loss': -0.5066772}\n",
      "--- Step : 2193 \n",
      "  ------- {'fairness_loss': 1.8317132, 'utility': 0.5616313, 'loss': -0.50667995}\n",
      "--- Step : 2194 \n",
      "  ------- {'fairness_loss': 1.8318958, 'utility': 0.56163955, 'loss': -0.5066827}\n",
      "--- Step : 2195 \n",
      "  ------- {'fairness_loss': 1.8321395, 'utility': 0.56164974, 'loss': -0.50668555}\n",
      "--- Step : 2196 \n",
      "  ------- {'fairness_loss': 1.83245, 'utility': 0.56166184, 'loss': -0.50668836}\n",
      "--- Step : 2197 \n",
      "  ------- {'fairness_loss': 1.8327214, 'utility': 0.56167275, 'loss': -0.5066911}\n",
      "--- Step : 2198 \n",
      "  ------- {'fairness_loss': 1.8329535, 'utility': 0.5616825, 'loss': -0.5066939}\n",
      "--- Step : 2199 \n",
      "  ------- {'fairness_loss': 1.8331509, 'utility': 0.5616912, 'loss': -0.5066967}\n",
      "--- Step : 2200 \n",
      "  ------- {'fairness_loss': 1.8333188, 'utility': 0.56169903, 'loss': -0.50669944}\n",
      "--- Step : 2201 \n",
      "  ------- {'fairness_loss': 1.833456, 'utility': 0.5617062, 'loss': -0.5067025}\n",
      "--- Step : 2202 \n",
      "  ------- {'fairness_loss': 1.8335726, 'utility': 0.5617125, 'loss': -0.50670534}\n",
      "--- Step : 2203 \n",
      "  ------- {'fairness_loss': 1.8336726, 'utility': 0.5617182, 'loss': -0.506708}\n",
      "--- Step : 2204 \n",
      "  ------- {'fairness_loss': 1.8338493, 'utility': 0.5617262, 'loss': -0.5067107}\n",
      "--- Step : 2205 \n",
      "  ------- {'fairness_loss': 1.8340874, 'utility': 0.56173635, 'loss': -0.50671375}\n",
      "--- Step : 2206 \n",
      "  ------- {'fairness_loss': 1.8343909, 'utility': 0.5617483, 'loss': -0.5067166}\n",
      "--- Step : 2207 \n",
      "  ------- {'fairness_loss': 1.8346575, 'utility': 0.5617591, 'loss': -0.5067194}\n",
      "--- Step : 2208 \n",
      "  ------- {'fairness_loss': 1.834888, 'utility': 0.56176865, 'loss': -0.50672203}\n",
      "--- Step : 2209 \n",
      "  ------- {'fairness_loss': 1.8350862, 'utility': 0.5617774, 'loss': -0.50672483}\n",
      "--- Step : 2210 \n",
      "  ------- {'fairness_loss': 1.835251, 'utility': 0.5617852, 'loss': -0.5067277}\n",
      "--- Step : 2211 \n",
      "  ------- {'fairness_loss': 1.8353908, 'utility': 0.56179225, 'loss': -0.50673056}\n",
      "--- Step : 2212 \n",
      "  ------- {'fairness_loss': 1.8355085, 'utility': 0.5617986, 'loss': -0.5067333}\n",
      "--- Step : 2213 \n",
      "  ------- {'fairness_loss': 1.8357034, 'utility': 0.56180716, 'loss': -0.50673604}\n",
      "--- Step : 2214 \n",
      "  ------- {'fairness_loss': 1.8359617, 'utility': 0.56181777, 'loss': -0.5067389}\n",
      "--- Step : 2215 \n",
      "  ------- {'fairness_loss': 1.8361889, 'utility': 0.56182754, 'loss': -0.5067419}\n",
      "--- Step : 2216 \n",
      "  ------- {'fairness_loss': 1.8363857, 'utility': 0.5618362, 'loss': -0.5067446}\n",
      "--- Step : 2217 \n",
      "  ------- {'fairness_loss': 1.836552, 'utility': 0.5618439, 'loss': -0.5067473}\n",
      "--- Step : 2218 \n",
      "  ------- {'fairness_loss': 1.8367888, 'utility': 0.5618538, 'loss': -0.50675017}\n",
      "--- Step : 2219 \n",
      "  ------- {'fairness_loss': 1.8369929, 'utility': 0.56186265, 'loss': -0.50675285}\n",
      "--- Step : 2220 \n",
      "  ------- {'fairness_loss': 1.8371663, 'utility': 0.56187075, 'loss': -0.50675577}\n",
      "--- Step : 2221 \n",
      "  ------- {'fairness_loss': 1.8374126, 'utility': 0.5618809, 'loss': -0.5067585}\n",
      "--- Step : 2222 \n",
      "  ------- {'fairness_loss': 1.8376266, 'utility': 0.56189007, 'loss': -0.50676125}\n",
      "--- Step : 2223 \n",
      "  ------- {'fairness_loss': 1.8378081, 'utility': 0.56189835, 'loss': -0.5067641}\n",
      "--- Step : 2224 \n",
      "  ------- {'fairness_loss': 1.8379655, 'utility': 0.56190574, 'loss': -0.5067668}\n",
      "--- Step : 2225 \n",
      "  ------- {'fairness_loss': 1.8381928, 'utility': 0.56191546, 'loss': -0.50676966}\n",
      "--- Step : 2226 \n",
      "  ------- {'fairness_loss': 1.8384889, 'utility': 0.561927, 'loss': -0.50677234}\n",
      "--- Step : 2227 \n",
      "  ------- {'fairness_loss': 1.8387451, 'utility': 0.56193745, 'loss': -0.5067751}\n",
      "--- Step : 2228 \n",
      "  ------- {'fairness_loss': 1.8389691, 'utility': 0.5619468, 'loss': -0.50677776}\n",
      "--- Step : 2229 \n",
      "  ------- {'fairness_loss': 1.8391608, 'utility': 0.5619555, 'loss': -0.5067807}\n",
      "--- Step : 2230 \n",
      "  ------- {'fairness_loss': 1.8393207, 'utility': 0.561963, 'loss': -0.5067834}\n",
      "--- Step : 2231 \n",
      "  ------- {'fairness_loss': 1.839458, 'utility': 0.5619701, 'loss': -0.50678635}\n",
      "--- Step : 2232 \n",
      "  ------- {'fairness_loss': 1.839577, 'utility': 0.5619761, 'loss': -0.5067888}\n",
      "--- Step : 2233 \n",
      "  ------- {'fairness_loss': 1.839773, 'utility': 0.5619848, 'loss': -0.5067916}\n",
      "--- Step : 2234 \n",
      "  ------- {'fairness_loss': 1.8400306, 'utility': 0.56199545, 'loss': -0.5067945}\n",
      "--- Step : 2235 \n",
      "  ------- {'fairness_loss': 1.84036, 'utility': 0.56200814, 'loss': -0.5067973}\n",
      "--- Step : 2236 \n",
      "  ------- {'fairness_loss': 1.8406485, 'utility': 0.5620194, 'loss': -0.50679994}\n",
      "--- Step : 2237 \n",
      "  ------- {'fairness_loss': 1.8409001, 'utility': 0.5620298, 'loss': -0.5068028}\n",
      "--- Step : 2238 \n",
      "  ------- {'fairness_loss': 1.8411149, 'utility': 0.56203884, 'loss': -0.5068054}\n",
      "--- Step : 2239 \n",
      "  ------- {'fairness_loss': 1.841301, 'utility': 0.5620473, 'loss': -0.5068083}\n",
      "--- Step : 2240 \n",
      "  ------- {'fairness_loss': 1.8414569, 'utility': 0.56205475, 'loss': -0.506811}\n",
      "--- Step : 2241 \n",
      "  ------- {'fairness_loss': 1.8415892, 'utility': 0.5620616, 'loss': -0.50681394}\n",
      "--- Step : 2242 \n",
      "  ------- {'fairness_loss': 1.8416994, 'utility': 0.5620676, 'loss': -0.5068166}\n",
      "--- Step : 2243 \n",
      "  ------- {'fairness_loss': 1.8418927, 'utility': 0.56207615, 'loss': -0.50681937}\n",
      "--- Step : 2244 \n",
      "  ------- {'fairness_loss': 1.8421525, 'utility': 0.56208676, 'loss': -0.50682217}\n",
      "--- Step : 2245 \n",
      "  ------- {'fairness_loss': 1.8423824, 'utility': 0.5620965, 'loss': -0.50682503}\n",
      "--- Step : 2246 \n",
      "  ------- {'fairness_loss': 1.8425792, 'utility': 0.5621051, 'loss': -0.5068277}\n",
      "--- Step : 2247 \n",
      "  ------- {'fairness_loss': 1.8427535, 'utility': 0.5621129, 'loss': -0.50683033}\n",
      "--- Step : 2248 \n",
      "  ------- {'fairness_loss': 1.8429941, 'utility': 0.56212324, 'loss': -0.50683343}\n",
      "--- Step : 2249 \n",
      "  ------- {'fairness_loss': 1.843206, 'utility': 0.5621321, 'loss': -0.50683594}\n",
      "--- Step : 2250 \n",
      "  ------- {'fairness_loss': 1.8433908, 'utility': 0.5621403, 'loss': -0.50683856}\n",
      "--- Step : 2251 \n",
      "  ------- {'fairness_loss': 1.8436445, 'utility': 0.5621507, 'loss': -0.50684136}\n",
      "--- Step : 2252 \n",
      "  ------- {'fairness_loss': 1.8438689, 'utility': 0.56216025, 'loss': -0.50684416}\n",
      "--- Step : 2253 \n",
      "  ------- {'fairness_loss': 1.8440576, 'utility': 0.56216866, 'loss': -0.5068469}\n",
      "--- Step : 2254 \n",
      "  ------- {'fairness_loss': 1.8442272, 'utility': 0.56217635, 'loss': -0.5068495}\n",
      "--- Step : 2255 \n",
      "  ------- {'fairness_loss': 1.8444653, 'utility': 0.5621863, 'loss': -0.5068523}\n",
      "--- Step : 2256 \n",
      "  ------- {'fairness_loss': 1.8447747, 'utility': 0.56219834, 'loss': -0.50685513}\n",
      "--- Step : 2257 \n",
      "  ------- {'fairness_loss': 1.8450475, 'utility': 0.56220937, 'loss': -0.50685793}\n",
      "--- Step : 2258 \n",
      "  ------- {'fairness_loss': 1.8452834, 'utility': 0.56221896, 'loss': -0.5068605}\n",
      "--- Step : 2259 \n",
      "  ------- {'fairness_loss': 1.845485, 'utility': 0.56222785, 'loss': -0.5068633}\n",
      "--- Step : 2260 \n",
      "  ------- {'fairness_loss': 1.8456588, 'utility': 0.5622359, 'loss': -0.50686616}\n",
      "--- Step : 2261 \n",
      "  ------- {'fairness_loss': 1.8458061, 'utility': 0.562243, 'loss': -0.5068688}\n",
      "--- Step : 2262 \n",
      "  ------- {'fairness_loss': 1.8459353, 'utility': 0.56224966, 'loss': -0.5068716}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2263 \n",
      "  ------- {'fairness_loss': 1.8461446, 'utility': 0.56225854, 'loss': -0.5068742}\n",
      "--- Step : 2264 \n",
      "  ------- {'fairness_loss': 1.8464202, 'utility': 0.5622696, 'loss': -0.506877}\n",
      "--- Step : 2265 \n",
      "  ------- {'fairness_loss': 1.8466643, 'utility': 0.56227964, 'loss': -0.5068797}\n",
      "--- Step : 2266 \n",
      "  ------- {'fairness_loss': 1.8468767, 'utility': 0.5622888, 'loss': -0.50688255}\n",
      "--- Step : 2267 \n",
      "  ------- {'fairness_loss': 1.8470575, 'utility': 0.562297, 'loss': -0.5068853}\n",
      "--- Step : 2268 \n",
      "  ------- {'fairness_loss': 1.8472191, 'utility': 0.5623045, 'loss': -0.5068879}\n",
      "--- Step : 2269 \n",
      "  ------- {'fairness_loss': 1.8474514, 'utility': 0.5623142, 'loss': -0.50689065}\n",
      "--- Step : 2270 \n",
      "  ------- {'fairness_loss': 1.8477558, 'utility': 0.5623261, 'loss': -0.5068934}\n",
      "--- Step : 2271 \n",
      "  ------- {'fairness_loss': 1.8480252, 'utility': 0.56233674, 'loss': -0.506896}\n",
      "--- Step : 2272 \n",
      "  ------- {'fairness_loss': 1.848261, 'utility': 0.5623466, 'loss': -0.50689876}\n",
      "--- Step : 2273 \n",
      "  ------- {'fairness_loss': 1.8484609, 'utility': 0.5623553, 'loss': -0.50690144}\n",
      "--- Step : 2274 \n",
      "  ------- {'fairness_loss': 1.8486334, 'utility': 0.56236327, 'loss': -0.50690424}\n",
      "--- Step : 2275 \n",
      "  ------- {'fairness_loss': 1.8487806, 'utility': 0.5623704, 'loss': -0.506907}\n",
      "--- Step : 2276 \n",
      "  ------- {'fairness_loss': 1.8489147, 'utility': 0.562377, 'loss': -0.50690955}\n",
      "--- Step : 2277 \n",
      "  ------- {'fairness_loss': 1.8491226, 'utility': 0.562386, 'loss': -0.5069123}\n",
      "--- Step : 2278 \n",
      "  ------- {'fairness_loss': 1.8493997, 'utility': 0.5623971, 'loss': -0.50691515}\n",
      "--- Step : 2279 \n",
      "  ------- {'fairness_loss': 1.8497515, 'utility': 0.5624103, 'loss': -0.5069178}\n",
      "--- Step : 2280 \n",
      "  ------- {'fairness_loss': 1.8500606, 'utility': 0.5624223, 'loss': -0.50692046}\n",
      "--- Step : 2281 \n",
      "  ------- {'fairness_loss': 1.8503319, 'utility': 0.5624329, 'loss': -0.50692296}\n",
      "--- Step : 2282 \n",
      "  ------- {'fairness_loss': 1.850568, 'utility': 0.5624427, 'loss': -0.5069257}\n",
      "--- Step : 2283 \n",
      "  ------- {'fairness_loss': 1.8507705, 'utility': 0.56245166, 'loss': -0.50692856}\n",
      "--- Step : 2284 \n",
      "  ------- {'fairness_loss': 1.8509448, 'utility': 0.56245947, 'loss': -0.5069311}\n",
      "--- Step : 2285 \n",
      "  ------- {'fairness_loss': 1.8510925, 'utility': 0.56246686, 'loss': -0.5069341}\n",
      "--- Step : 2286 \n",
      "  ------- {'fairness_loss': 1.8512197, 'utility': 0.5624734, 'loss': -0.50693685}\n",
      "--- Step : 2287 \n",
      "  ------- {'fairness_loss': 1.8513322, 'utility': 0.5624793, 'loss': -0.50693935}\n",
      "--- Step : 2288 \n",
      "  ------- {'fairness_loss': 1.8515297, 'utility': 0.5624878, 'loss': -0.5069419}\n",
      "--- Step : 2289 \n",
      "  ------- {'fairness_loss': 1.8517929, 'utility': 0.5624986, 'loss': -0.50694484}\n",
      "--- Step : 2290 \n",
      "  ------- {'fairness_loss': 1.8521296, 'utility': 0.56251156, 'loss': -0.5069477}\n",
      "--- Step : 2291 \n",
      "  ------- {'fairness_loss': 1.8524308, 'utility': 0.562523, 'loss': -0.5069501}\n",
      "--- Step : 2292 \n",
      "  ------- {'fairness_loss': 1.852693, 'utility': 0.5625338, 'loss': -0.506953}\n",
      "--- Step : 2293 \n",
      "  ------- {'fairness_loss': 1.8529212, 'utility': 0.5625432, 'loss': -0.50695556}\n",
      "--- Step : 2294 \n",
      "  ------- {'fairness_loss': 1.8531171, 'utility': 0.56255186, 'loss': -0.50695837}\n",
      "--- Step : 2295 \n",
      "  ------- {'fairness_loss': 1.8532882, 'utility': 0.5625596, 'loss': -0.506961}\n",
      "--- Step : 2296 \n",
      "  ------- {'fairness_loss': 1.8534329, 'utility': 0.5625669, 'loss': -0.5069639}\n",
      "--- Step : 2297 \n",
      "  ------- {'fairness_loss': 1.8535585, 'utility': 0.56257325, 'loss': -0.5069665}\n",
      "--- Step : 2298 \n",
      "  ------- {'fairness_loss': 1.8537673, 'utility': 0.56258225, 'loss': -0.5069692}\n",
      "--- Step : 2299 \n",
      "  ------- {'fairness_loss': 1.8540521, 'utility': 0.5625935, 'loss': -0.50697196}\n",
      "--- Step : 2300 \n",
      "  ------- {'fairness_loss': 1.854302, 'utility': 0.56260365, 'loss': -0.5069746}\n",
      "--- Step : 2301 \n",
      "  ------- {'fairness_loss': 1.85452, 'utility': 0.56261295, 'loss': -0.5069774}\n",
      "--- Step : 2302 \n",
      "  ------- {'fairness_loss': 1.8547093, 'utility': 0.5626212, 'loss': -0.5069799}\n",
      "--- Step : 2303 \n",
      "  ------- {'fairness_loss': 1.8548746, 'utility': 0.56262875, 'loss': -0.5069825}\n",
      "--- Step : 2304 \n",
      "  ------- {'fairness_loss': 1.8551173, 'utility': 0.5626388, 'loss': -0.5069853}\n",
      "--- Step : 2305 \n",
      "  ------- {'fairness_loss': 1.8554368, 'utility': 0.5626511, 'loss': -0.506988}\n",
      "--- Step : 2306 \n",
      "  ------- {'fairness_loss': 1.8557174, 'utility': 0.5626621, 'loss': -0.5069906}\n",
      "--- Step : 2307 \n",
      "  ------- {'fairness_loss': 1.8559625, 'utility': 0.5626722, 'loss': -0.5069933}\n",
      "--- Step : 2308 \n",
      "  ------- {'fairness_loss': 1.8561748, 'utility': 0.5626811, 'loss': -0.50699586}\n",
      "--- Step : 2309 \n",
      "  ------- {'fairness_loss': 1.8563594, 'utility': 0.56268954, 'loss': -0.5069988}\n",
      "--- Step : 2310 \n",
      "  ------- {'fairness_loss': 1.8565171, 'utility': 0.56269693, 'loss': -0.5070014}\n",
      "--- Step : 2311 \n",
      "  ------- {'fairness_loss': 1.8566544, 'utility': 0.5627038, 'loss': -0.50700414}\n",
      "--- Step : 2312 \n",
      "  ------- {'fairness_loss': 1.856877, 'utility': 0.562713, 'loss': -0.5070067}\n",
      "--- Step : 2313 \n",
      "  ------- {'fairness_loss': 1.8571763, 'utility': 0.5627246, 'loss': -0.5070093}\n",
      "--- Step : 2314 \n",
      "  ------- {'fairness_loss': 1.8574378, 'utility': 0.56273514, 'loss': -0.507012}\n",
      "--- Step : 2315 \n",
      "  ------- {'fairness_loss': 1.8576673, 'utility': 0.56274486, 'loss': -0.5070148}\n",
      "--- Step : 2316 \n",
      "  ------- {'fairness_loss': 1.8578649, 'utility': 0.5627533, 'loss': -0.5070174}\n",
      "--- Step : 2317 \n",
      "  ------- {'fairness_loss': 1.8580371, 'utility': 0.5627612, 'loss': -0.50702006}\n",
      "--- Step : 2318 \n",
      "  ------- {'fairness_loss': 1.8581885, 'utility': 0.5627684, 'loss': -0.50702274}\n",
      "--- Step : 2319 \n",
      "  ------- {'fairness_loss': 1.8584222, 'utility': 0.56277794, 'loss': -0.50702524}\n",
      "--- Step : 2320 \n",
      "  ------- {'fairness_loss': 1.8587269, 'utility': 0.56279004, 'loss': -0.5070282}\n",
      "--- Step : 2321 \n",
      "  ------- {'fairness_loss': 1.8590019, 'utility': 0.5628007, 'loss': -0.50703067}\n",
      "--- Step : 2322 \n",
      "  ------- {'fairness_loss': 1.8592395, 'utility': 0.5628106, 'loss': -0.5070334}\n",
      "--- Step : 2323 \n",
      "  ------- {'fairness_loss': 1.859448, 'utility': 0.5628195, 'loss': -0.50703603}\n",
      "--- Step : 2324 \n",
      "  ------- {'fairness_loss': 1.859628, 'utility': 0.56282747, 'loss': -0.50703865}\n",
      "--- Step : 2325 \n",
      "  ------- {'fairness_loss': 1.8597832, 'utility': 0.562835, 'loss': -0.50704145}\n",
      "--- Step : 2326 \n",
      "  ------- {'fairness_loss': 1.8600216, 'utility': 0.56284475, 'loss': -0.5070441}\n",
      "--- Step : 2327 \n",
      "  ------- {'fairness_loss': 1.86023, 'utility': 0.5628537, 'loss': -0.5070468}\n",
      "--- Step : 2328 \n",
      "  ------- {'fairness_loss': 1.8605205, 'utility': 0.562865, 'loss': -0.5070494}\n",
      "--- Step : 2329 \n",
      "  ------- {'fairness_loss': 1.8607748, 'utility': 0.5628754, 'loss': -0.5070521}\n",
      "--- Step : 2330 \n",
      "  ------- {'fairness_loss': 1.8609979, 'utility': 0.56288457, 'loss': -0.5070546}\n",
      "--- Step : 2331 \n",
      "  ------- {'fairness_loss': 1.8611897, 'utility': 0.562893, 'loss': -0.5070573}\n",
      "--- Step : 2332 \n",
      "  ------- {'fairness_loss': 1.8613575, 'utility': 0.5629008, 'loss': -0.50706005}\n",
      "--- Step : 2333 \n",
      "  ------- {'fairness_loss': 1.861608, 'utility': 0.56291085, 'loss': -0.5070626}\n",
      "--- Step : 2334 \n",
      "  ------- {'fairness_loss': 1.861829, 'utility': 0.56292033, 'loss': -0.5070655}\n",
      "--- Step : 2335 \n",
      "  ------- {'fairness_loss': 1.8620205, 'utility': 0.5629287, 'loss': -0.50706804}\n",
      "--- Step : 2336 \n",
      "  ------- {'fairness_loss': 1.8622941, 'utility': 0.56293947, 'loss': -0.50707066}\n",
      "--- Step : 2337 \n",
      "  ------- {'fairness_loss': 1.8625342, 'utility': 0.5629495, 'loss': -0.50707346}\n",
      "--- Step : 2338 \n",
      "  ------- {'fairness_loss': 1.8627435, 'utility': 0.56295824, 'loss': -0.5070759}\n",
      "--- Step : 2339 \n",
      "  ------- {'fairness_loss': 1.8629261, 'utility': 0.56296635, 'loss': -0.5070786}\n",
      "--- Step : 2340 \n",
      "  ------- {'fairness_loss': 1.8631936, 'utility': 0.5629771, 'loss': -0.5070813}\n",
      "--- Step : 2341 \n",
      "  ------- {'fairness_loss': 1.8634257, 'utility': 0.56298655, 'loss': -0.5070838}\n",
      "--- Step : 2342 \n",
      "  ------- {'fairness_loss': 1.8636292, 'utility': 0.56299525, 'loss': -0.5070864}\n",
      "--- Step : 2343 \n",
      "  ------- {'fairness_loss': 1.8638047, 'utility': 0.56300336, 'loss': -0.5070892}\n",
      "--- Step : 2344 \n",
      "  ------- {'fairness_loss': 1.8640664, 'utility': 0.56301385, 'loss': -0.5070919}\n",
      "--- Step : 2345 \n",
      "  ------- {'fairness_loss': 1.8642944, 'utility': 0.5630233, 'loss': -0.5070945}\n",
      "--- Step : 2346 \n",
      "  ------- {'fairness_loss': 1.8644944, 'utility': 0.5630321, 'loss': -0.50709724}\n",
      "--- Step : 2347 \n",
      "  ------- {'fairness_loss': 1.8647767, 'utility': 0.56304306, 'loss': -0.50709975}\n",
      "--- Step : 2348 \n",
      "  ------- {'fairness_loss': 1.8650244, 'utility': 0.56305313, 'loss': -0.5071024}\n",
      "--- Step : 2349 \n",
      "  ------- {'fairness_loss': 1.8652424, 'utility': 0.56306225, 'loss': -0.507105}\n",
      "--- Step : 2350 \n",
      "  ------- {'fairness_loss': 1.8654306, 'utility': 0.56307054, 'loss': -0.5071076}\n",
      "--- Step : 2351 \n",
      "  ------- {'fairness_loss': 1.8655976, 'utility': 0.5630781, 'loss': -0.5071102}\n",
      "--- Step : 2352 \n",
      "  ------- {'fairness_loss': 1.8658463, 'utility': 0.56308836, 'loss': -0.507113}\n",
      "--- Step : 2353 \n",
      "  ------- {'fairness_loss': 1.8660648, 'utility': 0.5630975, 'loss': -0.50711554}\n",
      "--- Step : 2354 \n",
      "  ------- {'fairness_loss': 1.8663665, 'utility': 0.563109, 'loss': -0.507118}\n",
      "--- Step : 2355 \n",
      "  ------- {'fairness_loss': 1.8666298, 'utility': 0.5631197, 'loss': -0.5071208}\n",
      "--- Step : 2356 \n",
      "  ------- {'fairness_loss': 1.8668637, 'utility': 0.56312925, 'loss': -0.50712335}\n",
      "--- Step : 2357 \n",
      "  ------- {'fairness_loss': 1.8670647, 'utility': 0.56313795, 'loss': -0.50712603}\n",
      "--- Step : 2358 \n",
      "  ------- {'fairness_loss': 1.8672428, 'utility': 0.56314594, 'loss': -0.50712866}\n",
      "--- Step : 2359 \n",
      "  ------- {'fairness_loss': 1.8673973, 'utility': 0.56315327, 'loss': -0.50713134}\n",
      "--- Step : 2360 \n",
      "  ------- {'fairness_loss': 1.8676374, 'utility': 0.563163, 'loss': -0.50713384}\n",
      "--- Step : 2361 \n",
      "  ------- {'fairness_loss': 1.8679574, 'utility': 0.563175, 'loss': -0.5071363}\n",
      "--- Step : 2362 \n",
      "  ------- {'fairness_loss': 1.8682406, 'utility': 0.56318635, 'loss': -0.50713915}\n",
      "--- Step : 2363 \n",
      "  ------- {'fairness_loss': 1.8684893, 'utility': 0.56319636, 'loss': -0.5071417}\n",
      "--- Step : 2364 \n",
      "  ------- {'fairness_loss': 1.868708, 'utility': 0.5632054, 'loss': -0.5071442}\n",
      "--- Step : 2365 \n",
      "  ------- {'fairness_loss': 1.8688962, 'utility': 0.5632139, 'loss': -0.507147}\n",
      "--- Step : 2366 \n",
      "  ------- {'fairness_loss': 1.8690602, 'utility': 0.56322145, 'loss': -0.50714964}\n",
      "--- Step : 2367 \n",
      "  ------- {'fairness_loss': 1.8692044, 'utility': 0.5632284, 'loss': -0.5071523}\n",
      "--- Step : 2368 \n",
      "  ------- {'fairness_loss': 1.8694382, 'utility': 0.5632379, 'loss': -0.50715476}\n",
      "--- Step : 2369 \n",
      "  ------- {'fairness_loss': 1.8697519, 'utility': 0.56325006, 'loss': -0.5071575}\n",
      "--- Step : 2370 \n",
      "  ------- {'fairness_loss': 1.8700305, 'utility': 0.5632609, 'loss': -0.50716}\n",
      "--- Step : 2371 \n",
      "  ------- {'fairness_loss': 1.8702731, 'utility': 0.56327075, 'loss': -0.5071626}\n",
      "--- Step : 2372 \n",
      "  ------- {'fairness_loss': 1.8704871, 'utility': 0.5632798, 'loss': -0.5071652}\n",
      "--- Step : 2373 \n",
      "  ------- {'fairness_loss': 1.8706735, 'utility': 0.56328815, 'loss': -0.50716794}\n",
      "--- Step : 2374 \n",
      "  ------- {'fairness_loss': 1.8708342, 'utility': 0.56329566, 'loss': -0.5071706}\n",
      "--- Step : 2375 \n",
      "  ------- {'fairness_loss': 1.8709775, 'utility': 0.5633024, 'loss': -0.50717306}\n",
      "--- Step : 2376 \n",
      "  ------- {'fairness_loss': 1.8712087, 'utility': 0.56331193, 'loss': -0.5071757}\n",
      "--- Step : 2377 \n",
      "  ------- {'fairness_loss': 1.8715197, 'utility': 0.5633239, 'loss': -0.5071783}\n",
      "--- Step : 2378 \n",
      "  ------- {'fairness_loss': 1.8717958, 'utility': 0.5633349, 'loss': -0.507181}\n",
      "--- Step : 2379 \n",
      "  ------- {'fairness_loss': 1.8720399, 'utility': 0.5633447, 'loss': -0.50718355}\n",
      "--- Step : 2380 \n",
      "  ------- {'fairness_loss': 1.8722512, 'utility': 0.56335366, 'loss': -0.5071861}\n",
      "--- Step : 2381 \n",
      "  ------- {'fairness_loss': 1.8724391, 'utility': 0.5633619, 'loss': -0.50718874}\n",
      "--- Step : 2382 \n",
      "  ------- {'fairness_loss': 1.8726001, 'utility': 0.5633693, 'loss': -0.5071913}\n",
      "--- Step : 2383 \n",
      "  ------- {'fairness_loss': 1.8727466, 'utility': 0.56337637, 'loss': -0.507194}\n",
      "--- Step : 2384 \n",
      "  ------- {'fairness_loss': 1.872978, 'utility': 0.56338584, 'loss': -0.5071965}\n",
      "--- Step : 2385 \n",
      "  ------- {'fairness_loss': 1.873288, 'utility': 0.5633979, 'loss': -0.5071992}\n",
      "--- Step : 2386 \n",
      "  ------- {'fairness_loss': 1.8735652, 'utility': 0.5634087, 'loss': -0.50720173}\n",
      "--- Step : 2387 \n",
      "  ------- {'fairness_loss': 1.8738105, 'utility': 0.5634187, 'loss': -0.50720435}\n",
      "--- Step : 2388 \n",
      "  ------- {'fairness_loss': 1.8740269, 'utility': 0.56342775, 'loss': -0.5072069}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2389 \n",
      "  ------- {'fairness_loss': 1.8742136, 'utility': 0.563436, 'loss': -0.50720954}\n",
      "--- Step : 2390 \n",
      "  ------- {'fairness_loss': 1.8743787, 'utility': 0.56344354, 'loss': -0.50721216}\n",
      "--- Step : 2391 \n",
      "  ------- {'fairness_loss': 1.87463, 'utility': 0.5634536, 'loss': -0.5072147}\n",
      "--- Step : 2392 \n",
      "  ------- {'fairness_loss': 1.8748531, 'utility': 0.5634629, 'loss': -0.50721735}\n",
      "--- Step : 2393 \n",
      "  ------- {'fairness_loss': 1.8750496, 'utility': 0.56347144, 'loss': -0.50722}\n",
      "--- Step : 2394 \n",
      "  ------- {'fairness_loss': 1.8753321, 'utility': 0.5634824, 'loss': -0.5072224}\n",
      "--- Step : 2395 \n",
      "  ------- {'fairness_loss': 1.8755794, 'utility': 0.5634926, 'loss': -0.5072252}\n",
      "--- Step : 2396 \n",
      "  ------- {'fairness_loss': 1.8757994, 'utility': 0.5635019, 'loss': -0.5072279}\n",
      "--- Step : 2397 \n",
      "  ------- {'fairness_loss': 1.8759915, 'utility': 0.5635101, 'loss': -0.5072304}\n",
      "--- Step : 2398 \n",
      "  ------- {'fairness_loss': 1.8761624, 'utility': 0.5635178, 'loss': -0.50723296}\n",
      "--- Step : 2399 \n",
      "  ------- {'fairness_loss': 1.8764176, 'utility': 0.5635278, 'loss': -0.5072353}\n",
      "--- Step : 2400 \n",
      "  ------- {'fairness_loss': 1.8766437, 'utility': 0.5635373, 'loss': -0.507238}\n",
      "--- Step : 2401 \n",
      "  ------- {'fairness_loss': 1.8768435, 'utility': 0.5635459, 'loss': -0.5072406}\n",
      "--- Step : 2402 \n",
      "  ------- {'fairness_loss': 1.8771273, 'utility': 0.563557, 'loss': -0.5072432}\n",
      "--- Step : 2403 \n",
      "  ------- {'fairness_loss': 1.8773817, 'utility': 0.5635672, 'loss': -0.5072458}\n",
      "--- Step : 2404 \n",
      "  ------- {'fairness_loss': 1.8776026, 'utility': 0.56357664, 'loss': -0.5072486}\n",
      "--- Step : 2405 \n",
      "  ------- {'fairness_loss': 1.8777989, 'utility': 0.563585, 'loss': -0.507251}\n",
      "--- Step : 2406 \n",
      "  ------- {'fairness_loss': 1.8779684, 'utility': 0.5635926, 'loss': -0.5072536}\n",
      "--- Step : 2407 \n",
      "  ------- {'fairness_loss': 1.8782299, 'utility': 0.5636029, 'loss': -0.50725603}\n",
      "--- Step : 2408 \n",
      "  ------- {'fairness_loss': 1.8784604, 'utility': 0.5636124, 'loss': -0.5072586}\n",
      "--- Step : 2409 \n",
      "  ------- {'fairness_loss': 1.8786635, 'utility': 0.56362116, 'loss': -0.5072613}\n",
      "--- Step : 2410 \n",
      "  ------- {'fairness_loss': 1.8788432, 'utility': 0.563629, 'loss': -0.50726366}\n",
      "--- Step : 2411 \n",
      "  ------- {'fairness_loss': 1.8791064, 'utility': 0.5636396, 'loss': -0.5072664}\n",
      "--- Step : 2412 \n",
      "  ------- {'fairness_loss': 1.8794553, 'utility': 0.5636526, 'loss': -0.5072689}\n",
      "--- Step : 2413 \n",
      "  ------- {'fairness_loss': 1.8797644, 'utility': 0.5636644, 'loss': -0.50727147}\n",
      "--- Step : 2414 \n",
      "  ------- {'fairness_loss': 1.8800379, 'utility': 0.5636751, 'loss': -0.507274}\n",
      "--- Step : 2415 \n",
      "  ------- {'fairness_loss': 1.8802785, 'utility': 0.5636848, 'loss': -0.5072765}\n",
      "--- Step : 2416 \n",
      "  ------- {'fairness_loss': 1.88049, 'utility': 0.5636938, 'loss': -0.5072791}\n",
      "--- Step : 2417 \n",
      "  ------- {'fairness_loss': 1.8806742, 'utility': 0.5637019, 'loss': -0.5072817}\n",
      "--- Step : 2418 \n",
      "  ------- {'fairness_loss': 1.8808377, 'utility': 0.5637093, 'loss': -0.50728416}\n",
      "--- Step : 2419 \n",
      "  ------- {'fairness_loss': 1.8809758, 'utility': 0.5637162, 'loss': -0.5072869}\n",
      "--- Step : 2420 \n",
      "  ------- {'fairness_loss': 1.8811003, 'utility': 0.5637223, 'loss': -0.5072893}\n",
      "--- Step : 2421 \n",
      "  ------- {'fairness_loss': 1.8813183, 'utility': 0.5637316, 'loss': -0.50729203}\n",
      "--- Step : 2422 \n",
      "  ------- {'fairness_loss': 1.8816226, 'utility': 0.56374323, 'loss': -0.50729454}\n",
      "--- Step : 2423 \n",
      "  ------- {'fairness_loss': 1.8818914, 'utility': 0.56375384, 'loss': -0.5072971}\n",
      "--- Step : 2424 \n",
      "  ------- {'fairness_loss': 1.8821297, 'utility': 0.5637636, 'loss': -0.5072997}\n",
      "--- Step : 2425 \n",
      "  ------- {'fairness_loss': 1.8823402, 'utility': 0.56377244, 'loss': -0.5073022}\n",
      "--- Step : 2426 \n",
      "  ------- {'fairness_loss': 1.8825234, 'utility': 0.56378055, 'loss': -0.50730485}\n",
      "--- Step : 2427 \n",
      "  ------- {'fairness_loss': 1.8826847, 'utility': 0.56378794, 'loss': -0.5073074}\n",
      "--- Step : 2428 \n",
      "  ------- {'fairness_loss': 1.882833, 'utility': 0.56379473, 'loss': -0.50730973}\n",
      "--- Step : 2429 \n",
      "  ------- {'fairness_loss': 1.8830687, 'utility': 0.5638044, 'loss': -0.5073123}\n",
      "--- Step : 2430 \n",
      "  ------- {'fairness_loss': 1.883385, 'utility': 0.56381655, 'loss': -0.507315}\n",
      "--- Step : 2431 \n",
      "  ------- {'fairness_loss': 1.8836704, 'utility': 0.5638276, 'loss': -0.5073175}\n",
      "--- Step : 2432 \n",
      "  ------- {'fairness_loss': 1.8839222, 'utility': 0.56383765, 'loss': -0.50732}\n",
      "--- Step : 2433 \n",
      "  ------- {'fairness_loss': 1.8841437, 'utility': 0.56384695, 'loss': -0.5073226}\n",
      "--- Step : 2434 \n",
      "  ------- {'fairness_loss': 1.8843379, 'utility': 0.5638553, 'loss': -0.5073252}\n",
      "--- Step : 2435 \n",
      "  ------- {'fairness_loss': 1.8845078, 'utility': 0.56386304, 'loss': -0.5073278}\n",
      "--- Step : 2436 \n",
      "  ------- {'fairness_loss': 1.8846601, 'utility': 0.5638701, 'loss': -0.5073303}\n",
      "--- Step : 2437 \n",
      "  ------- {'fairness_loss': 1.8849024, 'utility': 0.56388, 'loss': -0.507333}\n",
      "--- Step : 2438 \n",
      "  ------- {'fairness_loss': 1.8852334, 'utility': 0.5638923, 'loss': -0.5073353}\n",
      "--- Step : 2439 \n",
      "  ------- {'fairness_loss': 1.8855278, 'utility': 0.5639036, 'loss': -0.5073378}\n",
      "--- Step : 2440 \n",
      "  ------- {'fairness_loss': 1.8857876, 'utility': 0.563914, 'loss': -0.5073404}\n",
      "--- Step : 2441 \n",
      "  ------- {'fairness_loss': 1.886017, 'utility': 0.5639235, 'loss': -0.507343}\n",
      "--- Step : 2442 \n",
      "  ------- {'fairness_loss': 1.8862197, 'utility': 0.56393194, 'loss': -0.5073454}\n",
      "--- Step : 2443 \n",
      "  ------- {'fairness_loss': 1.886395, 'utility': 0.56393987, 'loss': -0.507348}\n",
      "--- Step : 2444 \n",
      "  ------- {'fairness_loss': 1.8865478, 'utility': 0.56394696, 'loss': -0.5073505}\n",
      "--- Step : 2445 \n",
      "  ------- {'fairness_loss': 1.8866817, 'utility': 0.5639537, 'loss': -0.50735325}\n",
      "--- Step : 2446 \n",
      "  ------- {'fairness_loss': 1.8869131, 'utility': 0.56396323, 'loss': -0.50735587}\n",
      "--- Step : 2447 \n",
      "  ------- {'fairness_loss': 1.8871192, 'utility': 0.5639718, 'loss': -0.50735825}\n",
      "--- Step : 2448 \n",
      "  ------- {'fairness_loss': 1.8874147, 'utility': 0.56398326, 'loss': -0.5073608}\n",
      "--- Step : 2449 \n",
      "  ------- {'fairness_loss': 1.8876736, 'utility': 0.5639935, 'loss': -0.5073633}\n",
      "--- Step : 2450 \n",
      "  ------- {'fairness_loss': 1.8879056, 'utility': 0.5640031, 'loss': -0.50736594}\n",
      "--- Step : 2451 \n",
      "  ------- {'fairness_loss': 1.8881088, 'utility': 0.5640117, 'loss': -0.50736845}\n",
      "--- Step : 2452 \n",
      "  ------- {'fairness_loss': 1.8882884, 'utility': 0.56401974, 'loss': -0.50737107}\n",
      "--- Step : 2453 \n",
      "  ------- {'fairness_loss': 1.8884443, 'utility': 0.5640269, 'loss': -0.5073736}\n",
      "--- Step : 2454 \n",
      "  ------- {'fairness_loss': 1.8886964, 'utility': 0.564037, 'loss': -0.50737613}\n",
      "--- Step : 2455 \n",
      "  ------- {'fairness_loss': 1.8889188, 'utility': 0.5640463, 'loss': -0.50737876}\n",
      "--- Step : 2456 \n",
      "  ------- {'fairness_loss': 1.8891134, 'utility': 0.5640544, 'loss': -0.507381}\n",
      "--- Step : 2457 \n",
      "  ------- {'fairness_loss': 1.8892926, 'utility': 0.5640623, 'loss': -0.5073835}\n",
      "--- Step : 2458 \n",
      "  ------- {'fairness_loss': 1.8895549, 'utility': 0.56407285, 'loss': -0.5073862}\n",
      "--- Step : 2459 \n",
      "  ------- {'fairness_loss': 1.8897907, 'utility': 0.5640824, 'loss': -0.50738865}\n",
      "--- Step : 2460 \n",
      "  ------- {'fairness_loss': 1.8899999, 'utility': 0.5640912, 'loss': -0.5073912}\n",
      "--- Step : 2461 \n",
      "  ------- {'fairness_loss': 1.890188, 'utility': 0.5640994, 'loss': -0.5073937}\n",
      "--- Step : 2462 \n",
      "  ------- {'fairness_loss': 1.8904616, 'utility': 0.5641101, 'loss': -0.5073963}\n",
      "--- Step : 2463 \n",
      "  ------- {'fairness_loss': 1.8907088, 'utility': 0.56412005, 'loss': -0.5073988}\n",
      "--- Step : 2464 \n",
      "  ------- {'fairness_loss': 1.8909256, 'utility': 0.56412905, 'loss': -0.5074013}\n",
      "--- Step : 2465 \n",
      "  ------- {'fairness_loss': 1.8911152, 'utility': 0.5641372, 'loss': -0.5074038}\n",
      "--- Step : 2466 \n",
      "  ------- {'fairness_loss': 1.8912848, 'utility': 0.56414473, 'loss': -0.5074062}\n",
      "--- Step : 2467 \n",
      "  ------- {'fairness_loss': 1.891547, 'utility': 0.5641553, 'loss': -0.50740886}\n",
      "--- Step : 2468 \n",
      "  ------- {'fairness_loss': 1.8917806, 'utility': 0.5641647, 'loss': -0.5074113}\n",
      "--- Step : 2469 \n",
      "  ------- {'fairness_loss': 1.8919855, 'utility': 0.5641734, 'loss': -0.50741386}\n",
      "--- Step : 2470 \n",
      "  ------- {'fairness_loss': 1.8921689, 'utility': 0.56418157, 'loss': -0.5074165}\n",
      "--- Step : 2471 \n",
      "  ------- {'fairness_loss': 1.8924433, 'utility': 0.5641921, 'loss': -0.5074188}\n",
      "--- Step : 2472 \n",
      "  ------- {'fairness_loss': 1.8926891, 'utility': 0.56420213, 'loss': -0.50742143}\n",
      "--- Step : 2473 \n",
      "  ------- {'fairness_loss': 1.8929077, 'utility': 0.56421113, 'loss': -0.5074239}\n",
      "--- Step : 2474 \n",
      "  ------- {'fairness_loss': 1.8930982, 'utility': 0.5642193, 'loss': -0.5074264}\n",
      "--- Step : 2475 \n",
      "  ------- {'fairness_loss': 1.8932664, 'utility': 0.56422687, 'loss': -0.5074289}\n",
      "--- Step : 2476 \n",
      "  ------- {'fairness_loss': 1.8935293, 'utility': 0.56423736, 'loss': -0.5074315}\n",
      "--- Step : 2477 \n",
      "  ------- {'fairness_loss': 1.893763, 'utility': 0.56424683, 'loss': -0.50743395}\n",
      "--- Step : 2478 \n",
      "  ------- {'fairness_loss': 1.8939697, 'utility': 0.5642557, 'loss': -0.50743663}\n",
      "--- Step : 2479 \n",
      "  ------- {'fairness_loss': 1.8941513, 'utility': 0.5642636, 'loss': -0.507439}\n",
      "--- Step : 2480 \n",
      "  ------- {'fairness_loss': 1.894431, 'utility': 0.56427443, 'loss': -0.5074415}\n",
      "--- Step : 2481 \n",
      "  ------- {'fairness_loss': 1.8946744, 'utility': 0.56428427, 'loss': -0.507444}\n",
      "--- Step : 2482 \n",
      "  ------- {'fairness_loss': 1.8948914, 'utility': 0.56429315, 'loss': -0.5074464}\n",
      "--- Step : 2483 \n",
      "  ------- {'fairness_loss': 1.8950872, 'utility': 0.5643016, 'loss': -0.507449}\n",
      "--- Step : 2484 \n",
      "  ------- {'fairness_loss': 1.8952535, 'utility': 0.56430924, 'loss': -0.50745165}\n",
      "--- Step : 2485 \n",
      "  ------- {'fairness_loss': 1.8954091, 'utility': 0.5643161, 'loss': -0.5074538}\n",
      "--- Step : 2486 \n",
      "  ------- {'fairness_loss': 1.8956536, 'utility': 0.5643261, 'loss': -0.5074565}\n",
      "--- Step : 2487 \n",
      "  ------- {'fairness_loss': 1.8959882, 'utility': 0.5643386, 'loss': -0.507459}\n",
      "--- Step : 2488 \n",
      "  ------- {'fairness_loss': 1.896289, 'utility': 0.5643501, 'loss': -0.5074614}\n",
      "--- Step : 2489 \n",
      "  ------- {'fairness_loss': 1.8965567, 'utility': 0.5643606, 'loss': -0.50746393}\n",
      "--- Step : 2490 \n",
      "  ------- {'fairness_loss': 1.8967911, 'utility': 0.56437016, 'loss': -0.50746644}\n",
      "--- Step : 2491 \n",
      "  ------- {'fairness_loss': 1.896999, 'utility': 0.56437904, 'loss': -0.50746906}\n",
      "--- Step : 2492 \n",
      "  ------- {'fairness_loss': 1.8971822, 'utility': 0.5643868, 'loss': -0.5074713}\n",
      "--- Step : 2493 \n",
      "  ------- {'fairness_loss': 1.8973446, 'utility': 0.5643943, 'loss': -0.50747395}\n",
      "--- Step : 2494 \n",
      "  ------- {'fairness_loss': 1.8974867, 'utility': 0.56440103, 'loss': -0.50747645}\n",
      "--- Step : 2495 \n",
      "  ------- {'fairness_loss': 1.897611, 'utility': 0.5644074, 'loss': -0.5074791}\n",
      "--- Step : 2496 \n",
      "  ------- {'fairness_loss': 1.8978395, 'utility': 0.56441665, 'loss': -0.50748146}\n",
      "--- Step : 2497 \n",
      "  ------- {'fairness_loss': 1.8981574, 'utility': 0.5644286, 'loss': -0.5074839}\n",
      "--- Step : 2498 \n",
      "  ------- {'fairness_loss': 1.8984425, 'utility': 0.5644397, 'loss': -0.50748646}\n",
      "--- Step : 2499 \n",
      "  ------- {'fairness_loss': 1.898693, 'utility': 0.5644497, 'loss': -0.50748897}\n",
      "--- Step : 2500 \n",
      "  ------- {'fairness_loss': 1.8989166, 'utility': 0.5644589, 'loss': -0.5074914}\n",
      "--- Step : 2501 \n",
      "  ------- {'fairness_loss': 1.8991123, 'utility': 0.5644672, 'loss': -0.50749385}\n",
      "--- Step : 2502 \n",
      "  ------- {'fairness_loss': 1.8992859, 'utility': 0.56447494, 'loss': -0.50749636}\n",
      "--- Step : 2503 \n",
      "  ------- {'fairness_loss': 1.8994372, 'utility': 0.56448215, 'loss': -0.50749904}\n",
      "--- Step : 2504 \n",
      "  ------- {'fairness_loss': 1.8995732, 'utility': 0.5644887, 'loss': -0.5075015}\n",
      "--- Step : 2505 \n",
      "  ------- {'fairness_loss': 1.899698, 'utility': 0.56449455, 'loss': -0.5075036}\n",
      "--- Step : 2506 \n",
      "  ------- {'fairness_loss': 1.8999186, 'utility': 0.5645037, 'loss': -0.5075062}\n",
      "--- Step : 2507 \n",
      "  ------- {'fairness_loss': 1.9002281, 'utility': 0.56451565, 'loss': -0.5075088}\n",
      "--- Step : 2508 \n",
      "  ------- {'fairness_loss': 1.9005075, 'utility': 0.5645266, 'loss': -0.5075114}\n",
      "--- Step : 2509 \n",
      "  ------- {'fairness_loss': 1.9007592, 'utility': 0.56453645, 'loss': -0.5075137}\n",
      "--- Step : 2510 \n",
      "  ------- {'fairness_loss': 1.9009784, 'utility': 0.5645455, 'loss': -0.50751615}\n",
      "--- Step : 2511 \n",
      "  ------- {'fairness_loss': 1.9011756, 'utility': 0.564554, 'loss': -0.5075187}\n",
      "--- Step : 2512 \n",
      "  ------- {'fairness_loss': 1.901347, 'utility': 0.5645614, 'loss': -0.50752103}\n",
      "--- Step : 2513 \n",
      "  ------- {'fairness_loss': 1.9014995, 'utility': 0.5645686, 'loss': -0.5075236}\n",
      "--- Step : 2514 \n",
      "  ------- {'fairness_loss': 1.9016367, 'utility': 0.56457514, 'loss': -0.50752604}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2515 \n",
      "  ------- {'fairness_loss': 1.9018717, 'utility': 0.56458485, 'loss': -0.5075287}\n",
      "--- Step : 2516 \n",
      "  ------- {'fairness_loss': 1.9021974, 'utility': 0.5645971, 'loss': -0.50753117}\n",
      "--- Step : 2517 \n",
      "  ------- {'fairness_loss': 1.9024892, 'utility': 0.56460834, 'loss': -0.50753367}\n",
      "--- Step : 2518 \n",
      "  ------- {'fairness_loss': 1.9027518, 'utility': 0.5646186, 'loss': -0.50753605}\n",
      "--- Step : 2519 \n",
      "  ------- {'fairness_loss': 1.9029834, 'utility': 0.56462795, 'loss': -0.50753844}\n",
      "--- Step : 2520 \n",
      "  ------- {'fairness_loss': 1.9031886, 'utility': 0.5646365, 'loss': -0.5075409}\n",
      "--- Step : 2521 \n",
      "  ------- {'fairness_loss': 1.9033706, 'utility': 0.5646447, 'loss': -0.50754356}\n",
      "--- Step : 2522 \n",
      "  ------- {'fairness_loss': 1.9035306, 'utility': 0.56465185, 'loss': -0.50754595}\n",
      "--- Step : 2523 \n",
      "  ------- {'fairness_loss': 1.903672, 'utility': 0.5646586, 'loss': -0.50754845}\n",
      "--- Step : 2524 \n",
      "  ------- {'fairness_loss': 1.9037989, 'utility': 0.56466484, 'loss': -0.5075509}\n",
      "--- Step : 2525 \n",
      "  ------- {'fairness_loss': 1.904026, 'utility': 0.5646742, 'loss': -0.5075534}\n",
      "--- Step : 2526 \n",
      "  ------- {'fairness_loss': 1.9043459, 'utility': 0.5646861, 'loss': -0.5075557}\n",
      "--- Step : 2527 \n",
      "  ------- {'fairness_loss': 1.9046342, 'utility': 0.5646973, 'loss': -0.5075583}\n",
      "--- Step : 2528 \n",
      "  ------- {'fairness_loss': 1.9048916, 'utility': 0.5647074, 'loss': -0.5075607}\n",
      "--- Step : 2529 \n",
      "  ------- {'fairness_loss': 1.9051188, 'utility': 0.5647167, 'loss': -0.5075631}\n",
      "--- Step : 2530 \n",
      "  ------- {'fairness_loss': 1.9053211, 'utility': 0.56472516, 'loss': -0.5075655}\n",
      "--- Step : 2531 \n",
      "  ------- {'fairness_loss': 1.905498, 'utility': 0.5647331, 'loss': -0.5075681}\n",
      "--- Step : 2532 \n",
      "  ------- {'fairness_loss': 1.9056566, 'utility': 0.5647401, 'loss': -0.50757045}\n",
      "--- Step : 2533 \n",
      "  ------- {'fairness_loss': 1.9057949, 'utility': 0.564747, 'loss': -0.5075731}\n",
      "--- Step : 2534 \n",
      "  ------- {'fairness_loss': 1.905921, 'utility': 0.564753, 'loss': -0.5075754}\n",
      "--- Step : 2535 \n",
      "  ------- {'fairness_loss': 1.9061464, 'utility': 0.56476223, 'loss': -0.50757784}\n",
      "--- Step : 2536 \n",
      "  ------- {'fairness_loss': 1.9064696, 'utility': 0.5647745, 'loss': -0.5075804}\n",
      "--- Step : 2537 \n",
      "  ------- {'fairness_loss': 1.9067591, 'utility': 0.5647855, 'loss': -0.5075827}\n",
      "--- Step : 2538 \n",
      "  ------- {'fairness_loss': 1.9070151, 'utility': 0.5647957, 'loss': -0.5075852}\n",
      "--- Step : 2539 \n",
      "  ------- {'fairness_loss': 1.9072427, 'utility': 0.56480503, 'loss': -0.50758773}\n",
      "--- Step : 2540 \n",
      "  ------- {'fairness_loss': 1.907444, 'utility': 0.5648136, 'loss': -0.5075903}\n",
      "--- Step : 2541 \n",
      "  ------- {'fairness_loss': 1.9076227, 'utility': 0.56482136, 'loss': -0.5075927}\n",
      "--- Step : 2542 \n",
      "  ------- {'fairness_loss': 1.9077835, 'utility': 0.5648286, 'loss': -0.50759506}\n",
      "--- Step : 2543 \n",
      "  ------- {'fairness_loss': 1.9079212, 'utility': 0.5648352, 'loss': -0.50759757}\n",
      "--- Step : 2544 \n",
      "  ------- {'fairness_loss': 1.9080445, 'utility': 0.56484145, 'loss': -0.5076001}\n",
      "--- Step : 2545 \n",
      "  ------- {'fairness_loss': 1.9082736, 'utility': 0.5648508, 'loss': -0.5076026}\n",
      "--- Step : 2546 \n",
      "  ------- {'fairness_loss': 1.9084785, 'utility': 0.5648594, 'loss': -0.507605}\n",
      "--- Step : 2547 \n",
      "  ------- {'fairness_loss': 1.9086628, 'utility': 0.5648672, 'loss': -0.50760734}\n",
      "--- Step : 2548 \n",
      "  ------- {'fairness_loss': 1.9089428, 'utility': 0.56487817, 'loss': -0.5076099}\n",
      "--- Step : 2549 \n",
      "  ------- {'fairness_loss': 1.909197, 'utility': 0.5648881, 'loss': -0.5076122}\n",
      "--- Step : 2550 \n",
      "  ------- {'fairness_loss': 1.9094177, 'utility': 0.56489724, 'loss': -0.50761473}\n",
      "--- Step : 2551 \n",
      "  ------- {'fairness_loss': 1.909616, 'utility': 0.5649057, 'loss': -0.50761724}\n",
      "--- Step : 2552 \n",
      "  ------- {'fairness_loss': 1.909794, 'utility': 0.56491345, 'loss': -0.5076196}\n",
      "--- Step : 2553 \n",
      "  ------- {'fairness_loss': 1.9099474, 'utility': 0.56492054, 'loss': -0.5076221}\n",
      "--- Step : 2554 \n",
      "  ------- {'fairness_loss': 1.9100918, 'utility': 0.56492716, 'loss': -0.5076244}\n",
      "--- Step : 2555 \n",
      "  ------- {'fairness_loss': 1.9103312, 'utility': 0.56493694, 'loss': -0.507627}\n",
      "--- Step : 2556 \n",
      "  ------- {'fairness_loss': 1.9106687, 'utility': 0.5649495, 'loss': -0.50762945}\n",
      "--- Step : 2557 \n",
      "  ------- {'fairness_loss': 1.9109725, 'utility': 0.56496096, 'loss': -0.5076318}\n",
      "--- Step : 2558 \n",
      "  ------- {'fairness_loss': 1.9112428, 'utility': 0.5649715, 'loss': -0.5076342}\n",
      "--- Step : 2559 \n",
      "  ------- {'fairness_loss': 1.911485, 'utility': 0.5649812, 'loss': -0.50763667}\n",
      "--- Step : 2560 \n",
      "  ------- {'fairness_loss': 1.9116988, 'utility': 0.56499004, 'loss': -0.50763905}\n",
      "--- Step : 2561 \n",
      "  ------- {'fairness_loss': 1.9118885, 'utility': 0.5649982, 'loss': -0.50764155}\n",
      "--- Step : 2562 \n",
      "  ------- {'fairness_loss': 1.9120579, 'utility': 0.56500554, 'loss': -0.5076438}\n",
      "--- Step : 2563 \n",
      "  ------- {'fairness_loss': 1.912207, 'utility': 0.56501263, 'loss': -0.50764644}\n",
      "--- Step : 2564 \n",
      "  ------- {'fairness_loss': 1.9123379, 'utility': 0.56501913, 'loss': -0.507649}\n",
      "--- Step : 2565 \n",
      "  ------- {'fairness_loss': 1.9124546, 'utility': 0.56502503, 'loss': -0.5076514}\n",
      "--- Step : 2566 \n",
      "  ------- {'fairness_loss': 1.9125634, 'utility': 0.5650307, 'loss': -0.5076538}\n",
      "--- Step : 2567 \n",
      "  ------- {'fairness_loss': 1.912776, 'utility': 0.5650393, 'loss': -0.507656}\n",
      "--- Step : 2568 \n",
      "  ------- {'fairness_loss': 1.9130832, 'utility': 0.5650512, 'loss': -0.5076587}\n",
      "--- Step : 2569 \n",
      "  ------- {'fairness_loss': 1.9133625, 'utility': 0.56506187, 'loss': -0.507661}\n",
      "--- Step : 2570 \n",
      "  ------- {'fairness_loss': 1.9136113, 'utility': 0.56507176, 'loss': -0.5076634}\n",
      "--- Step : 2571 \n",
      "  ------- {'fairness_loss': 1.9138339, 'utility': 0.5650807, 'loss': -0.5076657}\n",
      "--- Step : 2572 \n",
      "  ------- {'fairness_loss': 1.9140313, 'utility': 0.5650892, 'loss': -0.5076683}\n",
      "--- Step : 2573 \n",
      "  ------- {'fairness_loss': 1.9142067, 'utility': 0.5650969, 'loss': -0.5076707}\n",
      "--- Step : 2574 \n",
      "  ------- {'fairness_loss': 1.9143614, 'utility': 0.56510407, 'loss': -0.5076732}\n",
      "--- Step : 2575 \n",
      "  ------- {'fairness_loss': 1.9145004, 'utility': 0.5651106, 'loss': -0.5076756}\n",
      "--- Step : 2576 \n",
      "  ------- {'fairness_loss': 1.9146311, 'utility': 0.5651168, 'loss': -0.5076779}\n",
      "--- Step : 2577 \n",
      "  ------- {'fairness_loss': 1.9148577, 'utility': 0.56512606, 'loss': -0.50768036}\n",
      "--- Step : 2578 \n",
      "  ------- {'fairness_loss': 1.915184, 'utility': 0.5651384, 'loss': -0.50768286}\n",
      "--- Step : 2579 \n",
      "  ------- {'fairness_loss': 1.9154788, 'utility': 0.5651496, 'loss': -0.50768524}\n",
      "--- Step : 2580 \n",
      "  ------- {'fairness_loss': 1.9157438, 'utility': 0.5651599, 'loss': -0.5076876}\n",
      "--- Step : 2581 \n",
      "  ------- {'fairness_loss': 1.9159795, 'utility': 0.56516945, 'loss': -0.5076901}\n",
      "--- Step : 2582 \n",
      "  ------- {'fairness_loss': 1.9161878, 'utility': 0.56517816, 'loss': -0.5076925}\n",
      "--- Step : 2583 \n",
      "  ------- {'fairness_loss': 1.916374, 'utility': 0.56518614, 'loss': -0.5076949}\n",
      "--- Step : 2584 \n",
      "  ------- {'fairness_loss': 1.9165406, 'utility': 0.5651937, 'loss': -0.5076975}\n",
      "--- Step : 2585 \n",
      "  ------- {'fairness_loss': 1.9166892, 'utility': 0.5652005, 'loss': -0.50769985}\n",
      "--- Step : 2586 \n",
      "  ------- {'fairness_loss': 1.9168199, 'utility': 0.5652069, 'loss': -0.5077023}\n",
      "--- Step : 2587 \n",
      "  ------- {'fairness_loss': 1.9169348, 'utility': 0.5652127, 'loss': -0.5077047}\n",
      "--- Step : 2588 \n",
      "  ------- {'fairness_loss': 1.9171624, 'utility': 0.565222, 'loss': -0.5077072}\n",
      "--- Step : 2589 \n",
      "  ------- {'fairness_loss': 1.9173646, 'utility': 0.5652305, 'loss': -0.50770956}\n",
      "--- Step : 2590 \n",
      "  ------- {'fairness_loss': 1.9175448, 'utility': 0.56523836, 'loss': -0.507712}\n",
      "--- Step : 2591 \n",
      "  ------- {'fairness_loss': 1.9178307, 'utility': 0.56524926, 'loss': -0.50771433}\n",
      "--- Step : 2592 \n",
      "  ------- {'fairness_loss': 1.9180864, 'utility': 0.56525934, 'loss': -0.5077168}\n",
      "--- Step : 2593 \n",
      "  ------- {'fairness_loss': 1.9183137, 'utility': 0.56526846, 'loss': -0.50771904}\n",
      "--- Step : 2594 \n",
      "  ------- {'fairness_loss': 1.9185146, 'utility': 0.5652769, 'loss': -0.5077215}\n",
      "--- Step : 2595 \n",
      "  ------- {'fairness_loss': 1.9186954, 'utility': 0.56528497, 'loss': -0.5077241}\n",
      "--- Step : 2596 \n",
      "  ------- {'fairness_loss': 1.9188584, 'utility': 0.56529206, 'loss': -0.5077263}\n",
      "--- Step : 2597 \n",
      "  ------- {'fairness_loss': 1.9190006, 'utility': 0.56529886, 'loss': -0.5077288}\n",
      "--- Step : 2598 \n",
      "  ------- {'fairness_loss': 1.9191338, 'utility': 0.5653051, 'loss': -0.5077311}\n",
      "--- Step : 2599 \n",
      "  ------- {'fairness_loss': 1.9193687, 'utility': 0.56531477, 'loss': -0.5077337}\n",
      "--- Step : 2600 \n",
      "  ------- {'fairness_loss': 1.9197062, 'utility': 0.56532717, 'loss': -0.50773597}\n",
      "--- Step : 2601 \n",
      "  ------- {'fairness_loss': 1.9200066, 'utility': 0.5653386, 'loss': -0.5077384}\n",
      "--- Step : 2602 \n",
      "  ------- {'fairness_loss': 1.9202806, 'utility': 0.56534916, 'loss': -0.50774074}\n",
      "--- Step : 2603 \n",
      "  ------- {'fairness_loss': 1.9205233, 'utility': 0.5653589, 'loss': -0.5077432}\n",
      "--- Step : 2604 \n",
      "  ------- {'fairness_loss': 1.9207382, 'utility': 0.5653677, 'loss': -0.50774556}\n",
      "--- Step : 2605 \n",
      "  ------- {'fairness_loss': 1.9209324, 'utility': 0.56537575, 'loss': -0.50774777}\n",
      "--- Step : 2606 \n",
      "  ------- {'fairness_loss': 1.9211047, 'utility': 0.5653835, 'loss': -0.50775033}\n",
      "--- Step : 2607 \n",
      "  ------- {'fairness_loss': 1.9212588, 'utility': 0.5653905, 'loss': -0.5077528}\n",
      "--- Step : 2608 \n",
      "  ------- {'fairness_loss': 1.9213948, 'utility': 0.5653971, 'loss': -0.5077552}\n",
      "--- Step : 2609 \n",
      "  ------- {'fairness_loss': 1.9215143, 'utility': 0.56540316, 'loss': -0.5077577}\n",
      "--- Step : 2610 \n",
      "  ------- {'fairness_loss': 1.9216251, 'utility': 0.5654088, 'loss': -0.50776005}\n",
      "--- Step : 2611 \n",
      "  ------- {'fairness_loss': 1.9217268, 'utility': 0.56541413, 'loss': -0.5077623}\n",
      "--- Step : 2612 \n",
      "  ------- {'fairness_loss': 1.9219369, 'utility': 0.56542283, 'loss': -0.5077647}\n",
      "--- Step : 2613 \n",
      "  ------- {'fairness_loss': 1.922247, 'utility': 0.56543463, 'loss': -0.5077672}\n",
      "--- Step : 2614 \n",
      "  ------- {'fairness_loss': 1.9225274, 'utility': 0.5654455, 'loss': -0.50776964}\n",
      "--- Step : 2615 \n",
      "  ------- {'fairness_loss': 1.92278, 'utility': 0.5654554, 'loss': -0.50777197}\n",
      "--- Step : 2616 \n",
      "  ------- {'fairness_loss': 1.9230055, 'utility': 0.5654646, 'loss': -0.5077745}\n",
      "--- Step : 2617 \n",
      "  ------- {'fairness_loss': 1.9232085, 'utility': 0.5654729, 'loss': -0.5077766}\n",
      "--- Step : 2618 \n",
      "  ------- {'fairness_loss': 1.9233879, 'utility': 0.5654809, 'loss': -0.50777924}\n",
      "--- Step : 2619 \n",
      "  ------- {'fairness_loss': 1.9235501, 'utility': 0.5654881, 'loss': -0.5077816}\n",
      "--- Step : 2620 \n",
      "  ------- {'fairness_loss': 1.9236944, 'utility': 0.5654949, 'loss': -0.50778407}\n",
      "--- Step : 2621 \n",
      "  ------- {'fairness_loss': 1.9238225, 'utility': 0.56550115, 'loss': -0.50778645}\n",
      "--- Step : 2622 \n",
      "  ------- {'fairness_loss': 1.9239433, 'utility': 0.56550705, 'loss': -0.5077888}\n",
      "--- Step : 2623 \n",
      "  ------- {'fairness_loss': 1.9241694, 'utility': 0.5655162, 'loss': -0.5077911}\n",
      "--- Step : 2624 \n",
      "  ------- {'fairness_loss': 1.9244983, 'utility': 0.5655285, 'loss': -0.50779355}\n",
      "--- Step : 2625 \n",
      "  ------- {'fairness_loss': 1.9247966, 'utility': 0.5655398, 'loss': -0.5077959}\n",
      "--- Step : 2626 \n",
      "  ------- {'fairness_loss': 1.9250644, 'utility': 0.5655501, 'loss': -0.50779814}\n",
      "--- Step : 2627 \n",
      "  ------- {'fairness_loss': 1.9253002, 'utility': 0.56555974, 'loss': -0.50780076}\n",
      "--- Step : 2628 \n",
      "  ------- {'fairness_loss': 1.9255157, 'utility': 0.5655684, 'loss': -0.5078029}\n",
      "--- Step : 2629 \n",
      "  ------- {'fairness_loss': 1.9257072, 'utility': 0.5655767, 'loss': -0.50780547}\n",
      "--- Step : 2630 \n",
      "  ------- {'fairness_loss': 1.9258794, 'utility': 0.56558424, 'loss': -0.50780785}\n",
      "--- Step : 2631 \n",
      "  ------- {'fairness_loss': 1.9260335, 'utility': 0.5655912, 'loss': -0.50781024}\n",
      "--- Step : 2632 \n",
      "  ------- {'fairness_loss': 1.9261707, 'utility': 0.5655978, 'loss': -0.5078127}\n",
      "--- Step : 2633 \n",
      "  ------- {'fairness_loss': 1.9262936, 'utility': 0.56560385, 'loss': -0.50781506}\n",
      "--- Step : 2634 \n",
      "  ------- {'fairness_loss': 1.9264028, 'utility': 0.56560946, 'loss': -0.5078174}\n",
      "--- Step : 2635 \n",
      "  ------- {'fairness_loss': 1.9265071, 'utility': 0.56561476, 'loss': -0.50781953}\n",
      "--- Step : 2636 \n",
      "  ------- {'fairness_loss': 1.9267217, 'utility': 0.5656237, 'loss': -0.50782204}\n",
      "--- Step : 2637 \n",
      "  ------- {'fairness_loss': 1.9270355, 'utility': 0.56563556, 'loss': -0.5078245}\n",
      "--- Step : 2638 \n",
      "  ------- {'fairness_loss': 1.9273236, 'utility': 0.5656466, 'loss': -0.50782686}\n",
      "--- Step : 2639 \n",
      "  ------- {'fairness_loss': 1.927583, 'utility': 0.56565684, 'loss': -0.50782937}\n",
      "--- Step : 2640 \n",
      "  ------- {'fairness_loss': 1.9278138, 'utility': 0.565666, 'loss': -0.50783163}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2641 \n",
      "  ------- {'fairness_loss': 1.9280214, 'utility': 0.56567454, 'loss': -0.5078339}\n",
      "--- Step : 2642 \n",
      "  ------- {'fairness_loss': 1.9282085, 'utility': 0.56568265, 'loss': -0.5078364}\n",
      "--- Step : 2643 \n",
      "  ------- {'fairness_loss': 1.928376, 'utility': 0.56569004, 'loss': -0.5078388}\n",
      "--- Step : 2644 \n",
      "  ------- {'fairness_loss': 1.9285283, 'utility': 0.56569695, 'loss': -0.5078411}\n",
      "--- Step : 2645 \n",
      "  ------- {'fairness_loss': 1.9286603, 'utility': 0.56570345, 'loss': -0.5078436}\n",
      "--- Step : 2646 \n",
      "  ------- {'fairness_loss': 1.9287832, 'utility': 0.5657094, 'loss': -0.50784594}\n",
      "--- Step : 2647 \n",
      "  ------- {'fairness_loss': 1.9288933, 'utility': 0.565715, 'loss': -0.5078482}\n",
      "--- Step : 2648 \n",
      "  ------- {'fairness_loss': 1.9291162, 'utility': 0.56572413, 'loss': -0.50785065}\n",
      "--- Step : 2649 \n",
      "  ------- {'fairness_loss': 1.9294434, 'utility': 0.56573635, 'loss': -0.50785303}\n",
      "--- Step : 2650 \n",
      "  ------- {'fairness_loss': 1.9297402, 'utility': 0.5657475, 'loss': -0.5078553}\n",
      "--- Step : 2651 \n",
      "  ------- {'fairness_loss': 1.9300069, 'utility': 0.5657578, 'loss': -0.5078576}\n",
      "--- Step : 2652 \n",
      "  ------- {'fairness_loss': 1.9302472, 'utility': 0.5657676, 'loss': -0.5078602}\n",
      "--- Step : 2653 \n",
      "  ------- {'fairness_loss': 1.9304602, 'utility': 0.56577635, 'loss': -0.50786257}\n",
      "--- Step : 2654 \n",
      "  ------- {'fairness_loss': 1.9306556, 'utility': 0.5657845, 'loss': -0.50786483}\n",
      "--- Step : 2655 \n",
      "  ------- {'fairness_loss': 1.930829, 'utility': 0.56579196, 'loss': -0.5078671}\n",
      "--- Step : 2656 \n",
      "  ------- {'fairness_loss': 1.9309857, 'utility': 0.5657992, 'loss': -0.5078696}\n",
      "--- Step : 2657 \n",
      "  ------- {'fairness_loss': 1.9311266, 'utility': 0.56580573, 'loss': -0.5078719}\n",
      "--- Step : 2658 \n",
      "  ------- {'fairness_loss': 1.9312536, 'utility': 0.5658119, 'loss': -0.50787425}\n",
      "--- Step : 2659 \n",
      "  ------- {'fairness_loss': 1.9313688, 'utility': 0.56581765, 'loss': -0.5078766}\n",
      "--- Step : 2660 \n",
      "  ------- {'fairness_loss': 1.9314699, 'utility': 0.56582326, 'loss': -0.50787914}\n",
      "--- Step : 2661 \n",
      "  ------- {'fairness_loss': 1.9315711, 'utility': 0.5658284, 'loss': -0.5078812}\n",
      "--- Step : 2662 \n",
      "  ------- {'fairness_loss': 1.931781, 'utility': 0.5658371, 'loss': -0.50788367}\n",
      "--- Step : 2663 \n",
      "  ------- {'fairness_loss': 1.9320921, 'utility': 0.565849, 'loss': -0.50788623}\n",
      "--- Step : 2664 \n",
      "  ------- {'fairness_loss': 1.932378, 'utility': 0.56586, 'loss': -0.5078886}\n",
      "--- Step : 2665 \n",
      "  ------- {'fairness_loss': 1.9326394, 'utility': 0.5658701, 'loss': -0.50789094}\n",
      "--- Step : 2666 \n",
      "  ------- {'fairness_loss': 1.9328716, 'utility': 0.5658794, 'loss': -0.50789326}\n",
      "--- Step : 2667 \n",
      "  ------- {'fairness_loss': 1.9330814, 'utility': 0.56588805, 'loss': -0.5078956}\n",
      "--- Step : 2668 \n",
      "  ------- {'fairness_loss': 1.9332699, 'utility': 0.5658961, 'loss': -0.507898}\n",
      "--- Step : 2669 \n",
      "  ------- {'fairness_loss': 1.9334388, 'utility': 0.56590366, 'loss': -0.5079005}\n",
      "--- Step : 2670 \n",
      "  ------- {'fairness_loss': 1.9335941, 'utility': 0.5659106, 'loss': -0.50790274}\n",
      "--- Step : 2671 \n",
      "  ------- {'fairness_loss': 1.9337323, 'utility': 0.5659171, 'loss': -0.5079051}\n",
      "--- Step : 2672 \n",
      "  ------- {'fairness_loss': 1.933858, 'utility': 0.56592315, 'loss': -0.5079074}\n",
      "--- Step : 2673 \n",
      "  ------- {'fairness_loss': 1.9339746, 'utility': 0.56592894, 'loss': -0.5079097}\n",
      "--- Step : 2674 \n",
      "  ------- {'fairness_loss': 1.9342016, 'utility': 0.56593823, 'loss': -0.50791216}\n",
      "--- Step : 2675 \n",
      "  ------- {'fairness_loss': 1.9344132, 'utility': 0.5659469, 'loss': -0.5079145}\n",
      "--- Step : 2676 \n",
      "  ------- {'fairness_loss': 1.9345993, 'utility': 0.5659548, 'loss': -0.5079168}\n",
      "--- Step : 2677 \n",
      "  ------- {'fairness_loss': 1.9347676, 'utility': 0.56596226, 'loss': -0.50791925}\n",
      "--- Step : 2678 \n",
      "  ------- {'fairness_loss': 1.9349248, 'utility': 0.56596935, 'loss': -0.5079216}\n",
      "--- Step : 2679 \n",
      "  ------- {'fairness_loss': 1.9351891, 'utility': 0.5659797, 'loss': -0.507924}\n",
      "--- Step : 2680 \n",
      "  ------- {'fairness_loss': 1.935431, 'utility': 0.5659892, 'loss': -0.5079263}\n",
      "--- Step : 2681 \n",
      "  ------- {'fairness_loss': 1.9356494, 'utility': 0.565998, 'loss': -0.50792855}\n",
      "--- Step : 2682 \n",
      "  ------- {'fairness_loss': 1.9358467, 'utility': 0.56600636, 'loss': -0.507931}\n",
      "--- Step : 2683 \n",
      "  ------- {'fairness_loss': 1.936025, 'utility': 0.5660141, 'loss': -0.5079334}\n",
      "--- Step : 2684 \n",
      "  ------- {'fairness_loss': 1.9361875, 'utility': 0.56602126, 'loss': -0.50793564}\n",
      "--- Step : 2685 \n",
      "  ------- {'fairness_loss': 1.9363323, 'utility': 0.56602794, 'loss': -0.50793797}\n",
      "--- Step : 2686 \n",
      "  ------- {'fairness_loss': 1.9364674, 'utility': 0.5660342, 'loss': -0.5079402}\n",
      "--- Step : 2687 \n",
      "  ------- {'fairness_loss': 1.9367127, 'utility': 0.56604403, 'loss': -0.5079427}\n",
      "--- Step : 2688 \n",
      "  ------- {'fairness_loss': 1.9369388, 'utility': 0.56605315, 'loss': -0.507945}\n",
      "--- Step : 2689 \n",
      "  ------- {'fairness_loss': 1.9371414, 'utility': 0.5660616, 'loss': -0.5079474}\n",
      "--- Step : 2690 \n",
      "  ------- {'fairness_loss': 1.9373254, 'utility': 0.5660696, 'loss': -0.5079498}\n",
      "--- Step : 2691 \n",
      "  ------- {'fairness_loss': 1.9374933, 'utility': 0.5660769, 'loss': -0.5079521}\n",
      "--- Step : 2692 \n",
      "  ------- {'fairness_loss': 1.9376465, 'utility': 0.5660838, 'loss': -0.5079544}\n",
      "--- Step : 2693 \n",
      "  ------- {'fairness_loss': 1.937786, 'utility': 0.5660902, 'loss': -0.5079566}\n",
      "--- Step : 2694 \n",
      "  ------- {'fairness_loss': 1.9380364, 'utility': 0.5661002, 'loss': -0.50795907}\n",
      "--- Step : 2695 \n",
      "  ------- {'fairness_loss': 1.9382669, 'utility': 0.5661095, 'loss': -0.50796145}\n",
      "--- Step : 2696 \n",
      "  ------- {'fairness_loss': 1.9384749, 'utility': 0.56611806, 'loss': -0.50796384}\n",
      "--- Step : 2697 \n",
      "  ------- {'fairness_loss': 1.9386641, 'utility': 0.5661261, 'loss': -0.50796616}\n",
      "--- Step : 2698 \n",
      "  ------- {'fairness_loss': 1.9388334, 'utility': 0.56613356, 'loss': -0.50796854}\n",
      "--- Step : 2699 \n",
      "  ------- {'fairness_loss': 1.9389888, 'utility': 0.56614053, 'loss': -0.50797087}\n",
      "--- Step : 2700 \n",
      "  ------- {'fairness_loss': 1.9391338, 'utility': 0.566147, 'loss': -0.507973}\n",
      "--- Step : 2701 \n",
      "  ------- {'fairness_loss': 1.9393882, 'utility': 0.56615716, 'loss': -0.5079755}\n",
      "--- Step : 2702 \n",
      "  ------- {'fairness_loss': 1.9396234, 'utility': 0.5661666, 'loss': -0.5079779}\n",
      "--- Step : 2703 \n",
      "  ------- {'fairness_loss': 1.9398342, 'utility': 0.5661753, 'loss': -0.5079802}\n",
      "--- Step : 2704 \n",
      "  ------- {'fairness_loss': 1.9400249, 'utility': 0.5661834, 'loss': -0.5079827}\n",
      "--- Step : 2705 \n",
      "  ------- {'fairness_loss': 1.9402012, 'utility': 0.56619096, 'loss': -0.50798494}\n",
      "--- Step : 2706 \n",
      "  ------- {'fairness_loss': 1.9403571, 'utility': 0.56619793, 'loss': -0.5079872}\n",
      "--- Step : 2707 \n",
      "  ------- {'fairness_loss': 1.9405032, 'utility': 0.5662045, 'loss': -0.5079894}\n",
      "--- Step : 2708 \n",
      "  ------- {'fairness_loss': 1.9406408, 'utility': 0.5662109, 'loss': -0.5079917}\n",
      "--- Step : 2709 \n",
      "  ------- {'fairness_loss': 1.9408854, 'utility': 0.5662207, 'loss': -0.5079941}\n",
      "--- Step : 2710 \n",
      "  ------- {'fairness_loss': 1.9411106, 'utility': 0.5662298, 'loss': -0.5079965}\n",
      "--- Step : 2711 \n",
      "  ------- {'fairness_loss': 1.941319, 'utility': 0.56623846, 'loss': -0.5079989}\n",
      "--- Step : 2712 \n",
      "  ------- {'fairness_loss': 1.9415056, 'utility': 0.5662464, 'loss': -0.5080012}\n",
      "--- Step : 2713 \n",
      "  ------- {'fairness_loss': 1.9416761, 'utility': 0.56625384, 'loss': -0.50800353}\n",
      "--- Step : 2714 \n",
      "  ------- {'fairness_loss': 1.94183, 'utility': 0.5662608, 'loss': -0.5080059}\n",
      "--- Step : 2715 \n",
      "  ------- {'fairness_loss': 1.9419736, 'utility': 0.56626743, 'loss': -0.50800824}\n",
      "--- Step : 2716 \n",
      "  ------- {'fairness_loss': 1.94223, 'utility': 0.56627744, 'loss': -0.50801057}\n",
      "--- Step : 2717 \n",
      "  ------- {'fairness_loss': 1.9424663, 'utility': 0.56628686, 'loss': -0.5080129}\n",
      "--- Step : 2718 \n",
      "  ------- {'fairness_loss': 1.942679, 'utility': 0.56629556, 'loss': -0.5080152}\n",
      "--- Step : 2719 \n",
      "  ------- {'fairness_loss': 1.942876, 'utility': 0.56630355, 'loss': -0.5080173}\n",
      "--- Step : 2720 \n",
      "  ------- {'fairness_loss': 1.9430507, 'utility': 0.56631124, 'loss': -0.50801975}\n",
      "--- Step : 2721 \n",
      "  ------- {'fairness_loss': 1.943212, 'utility': 0.56631845, 'loss': -0.50802207}\n",
      "--- Step : 2722 \n",
      "  ------- {'fairness_loss': 1.943359, 'utility': 0.5663251, 'loss': -0.50802433}\n",
      "--- Step : 2723 \n",
      "  ------- {'fairness_loss': 1.9434952, 'utility': 0.56633157, 'loss': -0.5080267}\n",
      "--- Step : 2724 \n",
      "  ------- {'fairness_loss': 1.9437464, 'utility': 0.56634164, 'loss': -0.5080292}\n",
      "--- Step : 2725 \n",
      "  ------- {'fairness_loss': 1.9439793, 'utility': 0.56635094, 'loss': -0.50803155}\n",
      "--- Step : 2726 \n",
      "  ------- {'fairness_loss': 1.9441886, 'utility': 0.56635946, 'loss': -0.5080338}\n",
      "--- Step : 2727 \n",
      "  ------- {'fairness_loss': 1.9443791, 'utility': 0.56636757, 'loss': -0.5080362}\n",
      "--- Step : 2728 \n",
      "  ------- {'fairness_loss': 1.944555, 'utility': 0.56637514, 'loss': -0.50803846}\n",
      "--- Step : 2729 \n",
      "  ------- {'fairness_loss': 1.9447124, 'utility': 0.5663822, 'loss': -0.50804085}\n",
      "--- Step : 2730 \n",
      "  ------- {'fairness_loss': 1.9448584, 'utility': 0.56638885, 'loss': -0.5080431}\n",
      "--- Step : 2731 \n",
      "  ------- {'fairness_loss': 1.9449939, 'utility': 0.56639516, 'loss': -0.5080454}\n",
      "--- Step : 2732 \n",
      "  ------- {'fairness_loss': 1.9452474, 'utility': 0.56640506, 'loss': -0.50804764}\n",
      "--- Step : 2733 \n",
      "  ------- {'fairness_loss': 1.9454775, 'utility': 0.5664144, 'loss': -0.5080501}\n",
      "--- Step : 2734 \n",
      "  ------- {'fairness_loss': 1.9456881, 'utility': 0.56642294, 'loss': -0.5080523}\n",
      "--- Step : 2735 \n",
      "  ------- {'fairness_loss': 1.9458783, 'utility': 0.566431, 'loss': -0.5080546}\n",
      "--- Step : 2736 \n",
      "  ------- {'fairness_loss': 1.9460543, 'utility': 0.5664386, 'loss': -0.508057}\n",
      "--- Step : 2737 \n",
      "  ------- {'fairness_loss': 1.9462146, 'utility': 0.5664458, 'loss': -0.5080594}\n",
      "--- Step : 2738 \n",
      "  ------- {'fairness_loss': 1.9463617, 'utility': 0.5664524, 'loss': -0.5080615}\n",
      "--- Step : 2739 \n",
      "  ------- {'fairness_loss': 1.9464976, 'utility': 0.56645876, 'loss': -0.50806385}\n",
      "--- Step : 2740 \n",
      "  ------- {'fairness_loss': 1.9467503, 'utility': 0.5664687, 'loss': -0.5080662}\n",
      "--- Step : 2741 \n",
      "  ------- {'fairness_loss': 1.9469842, 'utility': 0.56647795, 'loss': -0.50806844}\n",
      "--- Step : 2742 \n",
      "  ------- {'fairness_loss': 1.9471956, 'utility': 0.5664867, 'loss': -0.5080708}\n",
      "--- Step : 2743 \n",
      "  ------- {'fairness_loss': 1.9473882, 'utility': 0.56649494, 'loss': -0.5080733}\n",
      "--- Step : 2744 \n",
      "  ------- {'fairness_loss': 1.9475677, 'utility': 0.5665025, 'loss': -0.5080755}\n",
      "--- Step : 2745 \n",
      "  ------- {'fairness_loss': 1.9477278, 'utility': 0.5665098, 'loss': -0.508078}\n",
      "--- Step : 2746 \n",
      "  ------- {'fairness_loss': 1.9478788, 'utility': 0.5665164, 'loss': -0.50808}\n",
      "--- Step : 2747 \n",
      "  ------- {'fairness_loss': 1.9480151, 'utility': 0.56652296, 'loss': -0.5080825}\n",
      "--- Step : 2748 \n",
      "  ------- {'fairness_loss': 1.9481448, 'utility': 0.56652904, 'loss': -0.5080847}\n",
      "--- Step : 2749 \n",
      "  ------- {'fairness_loss': 1.9483905, 'utility': 0.56653875, 'loss': -0.50808704}\n",
      "--- Step : 2750 \n",
      "  ------- {'fairness_loss': 1.9486165, 'utility': 0.566548, 'loss': -0.5080895}\n",
      "--- Step : 2751 \n",
      "  ------- {'fairness_loss': 1.9488257, 'utility': 0.56655645, 'loss': -0.5080917}\n",
      "--- Step : 2752 \n",
      "  ------- {'fairness_loss': 1.949012, 'utility': 0.56656456, 'loss': -0.5080942}\n",
      "--- Step : 2753 \n",
      "  ------- {'fairness_loss': 1.9491873, 'utility': 0.5665719, 'loss': -0.5080963}\n",
      "--- Step : 2754 \n",
      "  ------- {'fairness_loss': 1.9493488, 'utility': 0.566579, 'loss': -0.50809854}\n",
      "--- Step : 2755 \n",
      "  ------- {'fairness_loss': 1.9494947, 'utility': 0.5665857, 'loss': -0.50810087}\n",
      "--- Step : 2756 \n",
      "  ------- {'fairness_loss': 1.9496349, 'utility': 0.5665922, 'loss': -0.5081032}\n",
      "--- Step : 2757 \n",
      "  ------- {'fairness_loss': 1.949889, 'utility': 0.5666023, 'loss': -0.50810564}\n",
      "--- Step : 2758 \n",
      "  ------- {'fairness_loss': 1.9501246, 'utility': 0.5666115, 'loss': -0.5081078}\n",
      "--- Step : 2759 \n",
      "  ------- {'fairness_loss': 1.9503411, 'utility': 0.5666202, 'loss': -0.5081099}\n",
      "--- Step : 2760 \n",
      "  ------- {'fairness_loss': 1.9505365, 'utility': 0.5666285, 'loss': -0.50811243}\n",
      "--- Step : 2761 \n",
      "  ------- {'fairness_loss': 1.950719, 'utility': 0.5666362, 'loss': -0.50811464}\n",
      "--- Step : 2762 \n",
      "  ------- {'fairness_loss': 1.9508854, 'utility': 0.5666436, 'loss': -0.508117}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2763 \n",
      "  ------- {'fairness_loss': 1.9510368, 'utility': 0.56665057, 'loss': -0.50811946}\n",
      "--- Step : 2764 \n",
      "  ------- {'fairness_loss': 1.9511795, 'utility': 0.5666571, 'loss': -0.5081217}\n",
      "--- Step : 2765 \n",
      "  ------- {'fairness_loss': 1.9513102, 'utility': 0.56666327, 'loss': -0.50812393}\n",
      "--- Step : 2766 \n",
      "  ------- {'fairness_loss': 1.9515612, 'utility': 0.56667316, 'loss': -0.5081263}\n",
      "--- Step : 2767 \n",
      "  ------- {'fairness_loss': 1.9517978, 'utility': 0.56668246, 'loss': -0.5081285}\n",
      "--- Step : 2768 \n",
      "  ------- {'fairness_loss': 1.9520085, 'utility': 0.5666912, 'loss': -0.50813097}\n",
      "--- Step : 2769 \n",
      "  ------- {'fairness_loss': 1.9522028, 'utility': 0.5666993, 'loss': -0.50813323}\n",
      "--- Step : 2770 \n",
      "  ------- {'fairness_loss': 1.952382, 'utility': 0.56670696, 'loss': -0.5081355}\n",
      "--- Step : 2771 \n",
      "  ------- {'fairness_loss': 1.9525459, 'utility': 0.56671417, 'loss': -0.5081378}\n",
      "--- Step : 2772 \n",
      "  ------- {'fairness_loss': 1.9527005, 'utility': 0.56672114, 'loss': -0.50814015}\n",
      "--- Step : 2773 \n",
      "  ------- {'fairness_loss': 1.9528418, 'utility': 0.5667277, 'loss': -0.5081425}\n",
      "--- Step : 2774 \n",
      "  ------- {'fairness_loss': 1.9529737, 'utility': 0.5667339, 'loss': -0.5081447}\n",
      "--- Step : 2775 \n",
      "  ------- {'fairness_loss': 1.9532287, 'utility': 0.5667438, 'loss': -0.50814694}\n",
      "--- Step : 2776 \n",
      "  ------- {'fairness_loss': 1.9534615, 'utility': 0.5667531, 'loss': -0.50814927}\n",
      "--- Step : 2777 \n",
      "  ------- {'fairness_loss': 1.9536772, 'utility': 0.56676185, 'loss': -0.50815153}\n",
      "--- Step : 2778 \n",
      "  ------- {'fairness_loss': 1.9538754, 'utility': 0.56677, 'loss': -0.50815374}\n",
      "--- Step : 2779 \n",
      "  ------- {'fairness_loss': 1.9540571, 'utility': 0.5667778, 'loss': -0.5081561}\n",
      "--- Step : 2780 \n",
      "  ------- {'fairness_loss': 1.9542228, 'utility': 0.5667852, 'loss': -0.50815856}\n",
      "--- Step : 2781 \n",
      "  ------- {'fairness_loss': 1.9543792, 'utility': 0.5667921, 'loss': -0.5081607}\n",
      "--- Step : 2782 \n",
      "  ------- {'fairness_loss': 1.9545225, 'utility': 0.5667987, 'loss': -0.50816303}\n",
      "--- Step : 2783 \n",
      "  ------- {'fairness_loss': 1.9546548, 'utility': 0.5668048, 'loss': -0.5081652}\n",
      "--- Step : 2784 \n",
      "  ------- {'fairness_loss': 1.9547836, 'utility': 0.56681114, 'loss': -0.5081676}\n",
      "--- Step : 2785 \n",
      "  ------- {'fairness_loss': 1.95503, 'utility': 0.56682086, 'loss': -0.50816995}\n",
      "--- Step : 2786 \n",
      "  ------- {'fairness_loss': 1.9552583, 'utility': 0.56683, 'loss': -0.5081722}\n",
      "--- Step : 2787 \n",
      "  ------- {'fairness_loss': 1.9554703, 'utility': 0.56683856, 'loss': -0.5081745}\n",
      "--- Step : 2788 \n",
      "  ------- {'fairness_loss': 1.9556634, 'utility': 0.5668468, 'loss': -0.50817686}\n",
      "--- Step : 2789 \n",
      "  ------- {'fairness_loss': 1.9558434, 'utility': 0.5668545, 'loss': -0.5081792}\n",
      "--- Step : 2790 \n",
      "  ------- {'fairness_loss': 1.9560119, 'utility': 0.5668618, 'loss': -0.50818145}\n",
      "--- Step : 2791 \n",
      "  ------- {'fairness_loss': 1.9561651, 'utility': 0.56686854, 'loss': -0.5081836}\n",
      "--- Step : 2792 \n",
      "  ------- {'fairness_loss': 1.9563076, 'utility': 0.5668751, 'loss': -0.50818586}\n",
      "--- Step : 2793 \n",
      "  ------- {'fairness_loss': 1.9564433, 'utility': 0.56688154, 'loss': -0.50818825}\n",
      "--- Step : 2794 \n",
      "  ------- {'fairness_loss': 1.9566987, 'utility': 0.5668915, 'loss': -0.5081905}\n",
      "--- Step : 2795 \n",
      "  ------- {'fairness_loss': 1.9569368, 'utility': 0.56690085, 'loss': -0.5081927}\n",
      "--- Step : 2796 \n",
      "  ------- {'fairness_loss': 1.9571562, 'utility': 0.56690985, 'loss': -0.50819516}\n",
      "--- Step : 2797 \n",
      "  ------- {'fairness_loss': 1.9573567, 'utility': 0.5669182, 'loss': -0.5081975}\n",
      "--- Step : 2798 \n",
      "  ------- {'fairness_loss': 1.9575453, 'utility': 0.566926, 'loss': -0.50819963}\n",
      "--- Step : 2799 \n",
      "  ------- {'fairness_loss': 1.9577178, 'utility': 0.5669335, 'loss': -0.50820196}\n",
      "--- Step : 2800 \n",
      "  ------- {'fairness_loss': 1.9578773, 'utility': 0.5669406, 'loss': -0.5082043}\n",
      "--- Step : 2801 \n",
      "  ------- {'fairness_loss': 1.9580266, 'utility': 0.56694734, 'loss': -0.50820655}\n",
      "--- Step : 2802 \n",
      "  ------- {'fairness_loss': 1.958165, 'utility': 0.5669538, 'loss': -0.5082088}\n",
      "--- Step : 2803 \n",
      "  ------- {'fairness_loss': 1.9582962, 'utility': 0.56696016, 'loss': -0.50821126}\n",
      "--- Step : 2804 \n",
      "  ------- {'fairness_loss': 1.9584244, 'utility': 0.5669661, 'loss': -0.5082134}\n",
      "--- Step : 2805 \n",
      "  ------- {'fairness_loss': 1.9586711, 'utility': 0.5669758, 'loss': -0.50821567}\n",
      "--- Step : 2806 \n",
      "  ------- {'fairness_loss': 1.958899, 'utility': 0.56698495, 'loss': -0.508218}\n",
      "--- Step : 2807 \n",
      "  ------- {'fairness_loss': 1.9591129, 'utility': 0.5669937, 'loss': -0.5082203}\n",
      "--- Step : 2808 \n",
      "  ------- {'fairness_loss': 1.9593098, 'utility': 0.5670017, 'loss': -0.5082224}\n",
      "--- Step : 2809 \n",
      "  ------- {'fairness_loss': 1.9594905, 'utility': 0.56700957, 'loss': -0.50822484}\n",
      "--- Step : 2810 \n",
      "  ------- {'fairness_loss': 1.9596621, 'utility': 0.5670171, 'loss': -0.5082272}\n",
      "--- Step : 2811 \n",
      "  ------- {'fairness_loss': 1.9598199, 'utility': 0.56702393, 'loss': -0.5082293}\n",
      "--- Step : 2812 \n",
      "  ------- {'fairness_loss': 1.959966, 'utility': 0.5670305, 'loss': -0.5082315}\n",
      "--- Step : 2813 \n",
      "  ------- {'fairness_loss': 1.9601028, 'utility': 0.56703705, 'loss': -0.50823396}\n",
      "--- Step : 2814 \n",
      "  ------- {'fairness_loss': 1.9602369, 'utility': 0.5670433, 'loss': -0.50823617}\n",
      "--- Step : 2815 \n",
      "  ------- {'fairness_loss': 1.9604906, 'utility': 0.5670533, 'loss': -0.5082386}\n",
      "--- Step : 2816 \n",
      "  ------- {'fairness_loss': 1.9607288, 'utility': 0.5670627, 'loss': -0.5082408}\n",
      "--- Step : 2817 \n",
      "  ------- {'fairness_loss': 1.960947, 'utility': 0.56707144, 'loss': -0.508243}\n",
      "--- Step : 2818 \n",
      "  ------- {'fairness_loss': 1.9611505, 'utility': 0.5670797, 'loss': -0.5082452}\n",
      "--- Step : 2819 \n",
      "  ------- {'fairness_loss': 1.9613379, 'utility': 0.56708777, 'loss': -0.5082476}\n",
      "--- Step : 2820 \n",
      "  ------- {'fairness_loss': 1.9615133, 'utility': 0.5670954, 'loss': -0.50825}\n",
      "--- Step : 2821 \n",
      "  ------- {'fairness_loss': 1.9616774, 'utility': 0.56710243, 'loss': -0.5082521}\n",
      "--- Step : 2822 \n",
      "  ------- {'fairness_loss': 1.9618291, 'utility': 0.5671093, 'loss': -0.5082544}\n",
      "--- Step : 2823 \n",
      "  ------- {'fairness_loss': 1.9619738, 'utility': 0.56711584, 'loss': -0.5082566}\n",
      "--- Step : 2824 \n",
      "  ------- {'fairness_loss': 1.962108, 'utility': 0.5671223, 'loss': -0.50825906}\n",
      "--- Step : 2825 \n",
      "  ------- {'fairness_loss': 1.9622357, 'utility': 0.5671285, 'loss': -0.5082614}\n",
      "--- Step : 2826 \n",
      "  ------- {'fairness_loss': 1.9624921, 'utility': 0.5671384, 'loss': -0.5082636}\n",
      "--- Step : 2827 \n",
      "  ------- {'fairness_loss': 1.9627293, 'utility': 0.56714755, 'loss': -0.5082657}\n",
      "--- Step : 2828 \n",
      "  ------- {'fairness_loss': 1.9629486, 'utility': 0.5671565, 'loss': -0.50826806}\n",
      "--- Step : 2829 \n",
      "  ------- {'fairness_loss': 1.9631526, 'utility': 0.56716496, 'loss': -0.5082704}\n",
      "--- Step : 2830 \n",
      "  ------- {'fairness_loss': 1.9633408, 'utility': 0.56717294, 'loss': -0.5082727}\n",
      "--- Step : 2831 \n",
      "  ------- {'fairness_loss': 1.9635162, 'utility': 0.56718045, 'loss': -0.508275}\n",
      "--- Step : 2832 \n",
      "  ------- {'fairness_loss': 1.9636842, 'utility': 0.5671876, 'loss': -0.50827706}\n",
      "--- Step : 2833 \n",
      "  ------- {'fairness_loss': 1.9638386, 'utility': 0.56719464, 'loss': -0.5082795}\n",
      "--- Step : 2834 \n",
      "  ------- {'fairness_loss': 1.9639845, 'utility': 0.56720126, 'loss': -0.5082817}\n",
      "--- Step : 2835 \n",
      "  ------- {'fairness_loss': 1.964123, 'utility': 0.56720763, 'loss': -0.508284}\n",
      "--- Step : 2836 \n",
      "  ------- {'fairness_loss': 1.9642516, 'utility': 0.56721395, 'loss': -0.5082864}\n",
      "--- Step : 2837 \n",
      "  ------- {'fairness_loss': 1.9643779, 'utility': 0.5672197, 'loss': -0.5082883}\n",
      "--- Step : 2838 \n",
      "  ------- {'fairness_loss': 1.9646282, 'utility': 0.56722975, 'loss': -0.5082909}\n",
      "--- Step : 2839 \n",
      "  ------- {'fairness_loss': 1.9648634, 'utility': 0.567239, 'loss': -0.5082931}\n",
      "--- Step : 2840 \n",
      "  ------- {'fairness_loss': 1.965083, 'utility': 0.56724775, 'loss': -0.50829524}\n",
      "--- Step : 2841 \n",
      "  ------- {'fairness_loss': 1.9652867, 'utility': 0.5672561, 'loss': -0.5082975}\n",
      "--- Step : 2842 \n",
      "  ------- {'fairness_loss': 1.965475, 'utility': 0.56726414, 'loss': -0.5082999}\n",
      "--- Step : 2843 \n",
      "  ------- {'fairness_loss': 1.9656515, 'utility': 0.5672717, 'loss': -0.50830215}\n",
      "--- Step : 2844 \n",
      "  ------- {'fairness_loss': 1.9658182, 'utility': 0.56727886, 'loss': -0.5083043}\n",
      "--- Step : 2845 \n",
      "  ------- {'fairness_loss': 1.9659742, 'utility': 0.5672858, 'loss': -0.50830656}\n",
      "--- Step : 2846 \n",
      "  ------- {'fairness_loss': 1.9661211, 'utility': 0.56729275, 'loss': -0.5083091}\n",
      "--- Step : 2847 \n",
      "  ------- {'fairness_loss': 1.9662604, 'utility': 0.56729907, 'loss': -0.5083113}\n",
      "--- Step : 2848 \n",
      "  ------- {'fairness_loss': 1.9663942, 'utility': 0.56730515, 'loss': -0.5083133}\n",
      "--- Step : 2849 \n",
      "  ------- {'fairness_loss': 1.9665211, 'utility': 0.56731147, 'loss': -0.5083158}\n",
      "--- Step : 2850 \n",
      "  ------- {'fairness_loss': 1.9667785, 'utility': 0.5673213, 'loss': -0.50831795}\n",
      "--- Step : 2851 \n",
      "  ------- {'fairness_loss': 1.9670166, 'utility': 0.5673306, 'loss': -0.5083201}\n",
      "--- Step : 2852 \n",
      "  ------- {'fairness_loss': 1.967239, 'utility': 0.5673397, 'loss': -0.50832254}\n",
      "--- Step : 2853 \n",
      "  ------- {'fairness_loss': 1.9674443, 'utility': 0.5673481, 'loss': -0.5083248}\n",
      "--- Step : 2854 \n",
      "  ------- {'fairness_loss': 1.9676381, 'utility': 0.5673561, 'loss': -0.50832695}\n",
      "--- Step : 2855 \n",
      "  ------- {'fairness_loss': 1.9678185, 'utility': 0.5673639, 'loss': -0.5083294}\n",
      "--- Step : 2856 \n",
      "  ------- {'fairness_loss': 1.9679905, 'utility': 0.5673713, 'loss': -0.5083316}\n",
      "--- Step : 2857 \n",
      "  ------- {'fairness_loss': 1.9681504, 'utility': 0.5673783, 'loss': -0.5083338}\n",
      "--- Step : 2858 \n",
      "  ------- {'fairness_loss': 1.9683028, 'utility': 0.56738514, 'loss': -0.50833607}\n",
      "--- Step : 2859 \n",
      "  ------- {'fairness_loss': 1.9684476, 'utility': 0.5673919, 'loss': -0.50833845}\n",
      "--- Step : 2860 \n",
      "  ------- {'fairness_loss': 1.9685848, 'utility': 0.56739813, 'loss': -0.5083406}\n",
      "--- Step : 2861 \n",
      "  ------- {'fairness_loss': 1.9687167, 'utility': 0.56740427, 'loss': -0.50834274}\n",
      "--- Step : 2862 \n",
      "  ------- {'fairness_loss': 1.9688424, 'utility': 0.5674104, 'loss': -0.5083451}\n",
      "--- Step : 2863 \n",
      "  ------- {'fairness_loss': 1.9690971, 'utility': 0.5674204, 'loss': -0.5083475}\n",
      "--- Step : 2864 \n",
      "  ------- {'fairness_loss': 1.9693382, 'utility': 0.5674298, 'loss': -0.50834966}\n",
      "--- Step : 2865 \n",
      "  ------- {'fairness_loss': 1.9695631, 'utility': 0.5674388, 'loss': -0.50835186}\n",
      "--- Step : 2866 \n",
      "  ------- {'fairness_loss': 1.9697708, 'utility': 0.5674472, 'loss': -0.50835407}\n",
      "--- Step : 2867 \n",
      "  ------- {'fairness_loss': 1.9699658, 'utility': 0.5674555, 'loss': -0.5083565}\n",
      "--- Step : 2868 \n",
      "  ------- {'fairness_loss': 1.9701493, 'utility': 0.5674632, 'loss': -0.5083587}\n",
      "--- Step : 2869 \n",
      "  ------- {'fairness_loss': 1.9703226, 'utility': 0.5674705, 'loss': -0.5083608}\n",
      "--- Step : 2870 \n",
      "  ------- {'fairness_loss': 1.9704868, 'utility': 0.5674779, 'loss': -0.5083633}\n",
      "--- Step : 2871 \n",
      "  ------- {'fairness_loss': 1.9706444, 'utility': 0.5674847, 'loss': -0.50836533}\n",
      "--- Step : 2872 \n",
      "  ------- {'fairness_loss': 1.970791, 'utility': 0.56749135, 'loss': -0.5083676}\n",
      "--- Step : 2873 \n",
      "  ------- {'fairness_loss': 1.9709303, 'utility': 0.56749797, 'loss': -0.50837004}\n",
      "--- Step : 2874 \n",
      "  ------- {'fairness_loss': 1.9710686, 'utility': 0.5675041, 'loss': -0.50837207}\n",
      "--- Step : 2875 \n",
      "  ------- {'fairness_loss': 1.9711976, 'utility': 0.56751025, 'loss': -0.50837433}\n",
      "--- Step : 2876 \n",
      "  ------- {'fairness_loss': 1.971322, 'utility': 0.56751645, 'loss': -0.5083768}\n",
      "--- Step : 2877 \n",
      "  ------- {'fairness_loss': 1.9715798, 'utility': 0.5675262, 'loss': -0.5083788}\n",
      "--- Step : 2878 \n",
      "  ------- {'fairness_loss': 1.9718202, 'utility': 0.5675359, 'loss': -0.50838125}\n",
      "--- Step : 2879 \n",
      "  ------- {'fairness_loss': 1.972045, 'utility': 0.5675448, 'loss': -0.50838345}\n",
      "--- Step : 2880 \n",
      "  ------- {'fairness_loss': 1.972257, 'utility': 0.5675533, 'loss': -0.5083856}\n",
      "--- Step : 2881 \n",
      "  ------- {'fairness_loss': 1.9724541, 'utility': 0.5675617, 'loss': -0.50838804}\n",
      "--- Step : 2882 \n",
      "  ------- {'fairness_loss': 1.9726416, 'utility': 0.56756955, 'loss': -0.5083903}\n",
      "--- Step : 2883 \n",
      "  ------- {'fairness_loss': 1.972818, 'utility': 0.567577, 'loss': -0.50839245}\n",
      "--- Step : 2884 \n",
      "  ------- {'fairness_loss': 1.9729856, 'utility': 0.56758434, 'loss': -0.5083948}\n",
      "--- Step : 2885 \n",
      "  ------- {'fairness_loss': 1.9731437, 'utility': 0.5675913, 'loss': -0.508397}\n",
      "--- Step : 2886 \n",
      "  ------- {'fairness_loss': 1.973298, 'utility': 0.56759804, 'loss': -0.5083991}\n",
      "--- Step : 2887 \n",
      "  ------- {'fairness_loss': 1.9734434, 'utility': 0.5676048, 'loss': -0.50840145}\n",
      "--- Step : 2888 \n",
      "  ------- {'fairness_loss': 1.9735817, 'utility': 0.56761116, 'loss': -0.5084037}\n",
      "--- Step : 2889 \n",
      "  ------- {'fairness_loss': 1.9737172, 'utility': 0.5676174, 'loss': -0.5084059}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 2890 \n",
      "  ------- {'fairness_loss': 1.9738462, 'utility': 0.5676238, 'loss': -0.5084084}\n",
      "--- Step : 2891 \n",
      "  ------- {'fairness_loss': 1.9739722, 'utility': 0.5676296, 'loss': -0.5084104}\n",
      "--- Step : 2892 \n",
      "  ------- {'fairness_loss': 1.9740993, 'utility': 0.56763566, 'loss': -0.50841266}\n",
      "--- Step : 2893 \n",
      "  ------- {'fairness_loss': 1.9743519, 'utility': 0.5676455, 'loss': -0.5084149}\n",
      "--- Step : 2894 \n",
      "  ------- {'fairness_loss': 1.974593, 'utility': 0.567655, 'loss': -0.50841725}\n",
      "--- Step : 2895 \n",
      "  ------- {'fairness_loss': 1.974817, 'utility': 0.567664, 'loss': -0.5084195}\n",
      "--- Step : 2896 \n",
      "  ------- {'fairness_loss': 1.97503, 'utility': 0.5676726, 'loss': -0.5084217}\n",
      "--- Step : 2897 \n",
      "  ------- {'fairness_loss': 1.9752301, 'utility': 0.56768095, 'loss': -0.50842404}\n",
      "--- Step : 2898 \n",
      "  ------- {'fairness_loss': 1.9754181, 'utility': 0.5676889, 'loss': -0.50842637}\n",
      "--- Step : 2899 \n",
      "  ------- {'fairness_loss': 1.9755989, 'utility': 0.5676964, 'loss': -0.50842845}\n",
      "--- Step : 2900 \n",
      "  ------- {'fairness_loss': 1.9757714, 'utility': 0.56770396, 'loss': -0.50843084}\n",
      "--- Step : 2901 \n",
      "  ------- {'fairness_loss': 1.975933, 'utility': 0.56771094, 'loss': -0.5084329}\n",
      "--- Step : 2902 \n",
      "  ------- {'fairness_loss': 1.9760925, 'utility': 0.56771797, 'loss': -0.5084352}\n",
      "--- Step : 2903 \n",
      "  ------- {'fairness_loss': 1.9762414, 'utility': 0.5677246, 'loss': -0.50843734}\n",
      "--- Step : 2904 \n",
      "  ------- {'fairness_loss': 1.9763851, 'utility': 0.56773126, 'loss': -0.5084397}\n",
      "--- Step : 2905 \n",
      "  ------- {'fairness_loss': 1.9765252, 'utility': 0.5677378, 'loss': -0.50844204}\n",
      "--- Step : 2906 \n",
      "  ------- {'fairness_loss': 1.9766628, 'utility': 0.5677439, 'loss': -0.508444}\n",
      "--- Step : 2907 \n",
      "  ------- {'fairness_loss': 1.976792, 'utility': 0.56775033, 'loss': -0.5084466}\n",
      "--- Step : 2908 \n",
      "  ------- {'fairness_loss': 1.9769216, 'utility': 0.5677562, 'loss': -0.50844854}\n",
      "--- Step : 2909 \n",
      "  ------- {'fairness_loss': 1.9771852, 'utility': 0.56776655, 'loss': -0.508451}\n",
      "--- Step : 2910 \n",
      "  ------- {'fairness_loss': 1.9774323, 'utility': 0.5677762, 'loss': -0.50845325}\n",
      "--- Step : 2911 \n",
      "  ------- {'fairness_loss': 1.9776639, 'utility': 0.56778526, 'loss': -0.50845534}\n",
      "--- Step : 2912 \n",
      "  ------- {'fairness_loss': 1.9778821, 'utility': 0.5677942, 'loss': -0.5084577}\n",
      "--- Step : 2913 \n",
      "  ------- {'fairness_loss': 1.9780895, 'utility': 0.56780255, 'loss': -0.50845987}\n",
      "--- Step : 2914 \n",
      "  ------- {'fairness_loss': 1.9782864, 'utility': 0.5678107, 'loss': -0.50846213}\n",
      "--- Step : 2915 \n",
      "  ------- {'fairness_loss': 1.978472, 'utility': 0.5678186, 'loss': -0.5084644}\n",
      "--- Step : 2916 \n",
      "  ------- {'fairness_loss': 1.978651, 'utility': 0.56782603, 'loss': -0.5084665}\n",
      "--- Step : 2917 \n",
      "  ------- {'fairness_loss': 1.9788214, 'utility': 0.5678336, 'loss': -0.508469}\n",
      "--- Step : 2918 \n",
      "  ------- {'fairness_loss': 1.9789845, 'utility': 0.56784064, 'loss': -0.50847113}\n",
      "--- Step : 2919 \n",
      "  ------- {'fairness_loss': 1.9791435, 'utility': 0.56784755, 'loss': -0.5084733}\n",
      "--- Step : 2920 \n",
      "  ------- {'fairness_loss': 1.9792948, 'utility': 0.56785446, 'loss': -0.5084756}\n",
      "--- Step : 2921 \n",
      "  ------- {'fairness_loss': 1.9794424, 'utility': 0.567861, 'loss': -0.50847775}\n",
      "--- Step : 2922 \n",
      "  ------- {'fairness_loss': 1.9795849, 'utility': 0.5678675, 'loss': -0.50847995}\n",
      "--- Step : 2923 \n",
      "  ------- {'fairness_loss': 1.9797217, 'utility': 0.5678741, 'loss': -0.50848246}\n",
      "--- Step : 2924 \n",
      "  ------- {'fairness_loss': 1.9798576, 'utility': 0.5678802, 'loss': -0.5084845}\n",
      "--- Step : 2925 \n",
      "  ------- {'fairness_loss': 1.979992, 'utility': 0.56788653, 'loss': -0.50848675}\n",
      "--- Step : 2926 \n",
      "  ------- {'fairness_loss': 1.980118, 'utility': 0.5678925, 'loss': -0.50848895}\n",
      "--- Step : 2927 \n",
      "  ------- {'fairness_loss': 1.9802482, 'utility': 0.5678987, 'loss': -0.5084912}\n",
      "--- Step : 2928 \n",
      "  ------- {'fairness_loss': 1.980377, 'utility': 0.5679048, 'loss': -0.5084935}\n",
      "--- Step : 2929 \n",
      "  ------- {'fairness_loss': 1.9806358, 'utility': 0.5679149, 'loss': -0.5084958}\n",
      "--- Step : 2930 \n",
      "  ------- {'fairness_loss': 1.9808844, 'utility': 0.5679245, 'loss': -0.50849795}\n",
      "--- Step : 2931 \n",
      "  ------- {'fairness_loss': 1.9811206, 'utility': 0.5679337, 'loss': -0.50850004}\n",
      "--- Step : 2932 \n",
      "  ------- {'fairness_loss': 1.9813389, 'utility': 0.5679426, 'loss': -0.5085025}\n",
      "--- Step : 2933 \n",
      "  ------- {'fairness_loss': 1.9815495, 'utility': 0.56795114, 'loss': -0.5085046}\n",
      "--- Step : 2934 \n",
      "  ------- {'fairness_loss': 1.9817513, 'utility': 0.56795937, 'loss': -0.50850683}\n",
      "--- Step : 2935 \n",
      "  ------- {'fairness_loss': 1.9819411, 'utility': 0.56796736, 'loss': -0.5085091}\n",
      "--- Step : 2936 \n",
      "  ------- {'fairness_loss': 1.9821253, 'utility': 0.56797516, 'loss': -0.5085114}\n",
      "--- Step : 2937 \n",
      "  ------- {'fairness_loss': 1.9823017, 'utility': 0.56798244, 'loss': -0.5085134}\n",
      "--- Step : 2938 \n",
      "  ------- {'fairness_loss': 1.9824699, 'utility': 0.56798995, 'loss': -0.50851583}\n",
      "--- Step : 2939 \n",
      "  ------- {'fairness_loss': 1.9826331, 'utility': 0.56799704, 'loss': -0.50851804}\n",
      "--- Step : 2940 \n",
      "  ------- {'fairness_loss': 1.9827917, 'utility': 0.568004, 'loss': -0.50852025}\n",
      "--- Step : 2941 \n",
      "  ------- {'fairness_loss': 1.9829446, 'utility': 0.568011, 'loss': -0.5085226}\n",
      "--- Step : 2942 \n",
      "  ------- {'fairness_loss': 1.9830941, 'utility': 0.56801766, 'loss': -0.50852484}\n",
      "--- Step : 2943 \n",
      "  ------- {'fairness_loss': 1.9832416, 'utility': 0.5680243, 'loss': -0.50852704}\n",
      "--- Step : 2944 \n",
      "  ------- {'fairness_loss': 1.9833844, 'utility': 0.5680308, 'loss': -0.50852925}\n",
      "--- Step : 2945 \n",
      "  ------- {'fairness_loss': 1.9835234, 'utility': 0.5680371, 'loss': -0.5085314}\n",
      "--- Step : 2946 \n",
      "  ------- {'fairness_loss': 1.983661, 'utility': 0.5680437, 'loss': -0.5085339}\n",
      "--- Step : 2947 \n",
      "  ------- {'fairness_loss': 1.9837971, 'utility': 0.5680499, 'loss': -0.508536}\n",
      "--- Step : 2948 \n",
      "  ------- {'fairness_loss': 1.9839303, 'utility': 0.56805617, 'loss': -0.50853825}\n",
      "--- Step : 2949 \n",
      "  ------- {'fairness_loss': 1.984064, 'utility': 0.5680623, 'loss': -0.5085404}\n",
      "--- Step : 2950 \n",
      "  ------- {'fairness_loss': 1.9842, 'utility': 0.5680685, 'loss': -0.5085425}\n",
      "--- Step : 2951 \n",
      "  ------- {'fairness_loss': 1.9844671, 'utility': 0.56807876, 'loss': -0.50854474}\n",
      "--- Step : 2952 \n",
      "  ------- {'fairness_loss': 1.9847225, 'utility': 0.56808865, 'loss': -0.50854695}\n",
      "--- Step : 2953 \n",
      "  ------- {'fairness_loss': 1.984964, 'utility': 0.56809825, 'loss': -0.50854933}\n",
      "--- Step : 2954 \n",
      "  ------- {'fairness_loss': 1.9851947, 'utility': 0.56810725, 'loss': -0.5085514}\n",
      "--- Step : 2955 \n",
      "  ------- {'fairness_loss': 1.9854103, 'utility': 0.56811625, 'loss': -0.5085539}\n",
      "--- Step : 2956 \n",
      "  ------- {'fairness_loss': 1.9856207, 'utility': 0.56812453, 'loss': -0.5085559}\n",
      "--- Step : 2957 \n",
      "  ------- {'fairness_loss': 1.9858207, 'utility': 0.5681328, 'loss': -0.5085582}\n",
      "--- Step : 2958 \n",
      "  ------- {'fairness_loss': 1.986012, 'utility': 0.5681408, 'loss': -0.5085604}\n",
      "--- Step : 2959 \n",
      "  ------- {'fairness_loss': 1.9861976, 'utility': 0.5681486, 'loss': -0.5085627}\n",
      "--- Step : 2960 \n",
      "  ------- {'fairness_loss': 1.9863775, 'utility': 0.56815606, 'loss': -0.5085647}\n",
      "--- Step : 2961 \n",
      "  ------- {'fairness_loss': 1.9865496, 'utility': 0.5681637, 'loss': -0.5085672}\n",
      "--- Step : 2962 \n",
      "  ------- {'fairness_loss': 1.9867179, 'utility': 0.5681707, 'loss': -0.5085692}\n",
      "--- Step : 2963 \n",
      "  ------- {'fairness_loss': 1.9868823, 'utility': 0.5681781, 'loss': -0.5085716}\n",
      "--- Step : 2964 \n",
      "  ------- {'fairness_loss': 1.9870414, 'utility': 0.568185, 'loss': -0.5085737}\n",
      "--- Step : 2965 \n",
      "  ------- {'fairness_loss': 1.9871975, 'utility': 0.568192, 'loss': -0.5085761}\n",
      "--- Step : 2966 \n",
      "  ------- {'fairness_loss': 1.9873521, 'utility': 0.56819874, 'loss': -0.5085782}\n",
      "--- Step : 2967 \n",
      "  ------- {'fairness_loss': 1.9875, 'utility': 0.5682055, 'loss': -0.5085805}\n",
      "--- Step : 2968 \n",
      "  ------- {'fairness_loss': 1.9876487, 'utility': 0.5682122, 'loss': -0.5085828}\n",
      "--- Step : 2969 \n",
      "  ------- {'fairness_loss': 1.9877952, 'utility': 0.56821877, 'loss': -0.5085849}\n",
      "--- Step : 2970 \n",
      "  ------- {'fairness_loss': 1.9879396, 'utility': 0.56822544, 'loss': -0.50858724}\n",
      "--- Step : 2971 \n",
      "  ------- {'fairness_loss': 1.988081, 'utility': 0.5682319, 'loss': -0.50858945}\n",
      "--- Step : 2972 \n",
      "  ------- {'fairness_loss': 1.9882233, 'utility': 0.5682384, 'loss': -0.50859165}\n",
      "--- Step : 2973 \n",
      "  ------- {'fairness_loss': 1.9883626, 'utility': 0.5682448, 'loss': -0.5085939}\n",
      "--- Step : 2974 \n",
      "  ------- {'fairness_loss': 1.9885031, 'utility': 0.5682511, 'loss': -0.508596}\n",
      "--- Step : 2975 \n",
      "  ------- {'fairness_loss': 1.9886405, 'utility': 0.56825763, 'loss': -0.5085984}\n",
      "--- Step : 2976 \n",
      "  ------- {'fairness_loss': 1.9887812, 'utility': 0.5682638, 'loss': -0.5086004}\n",
      "--- Step : 2977 \n",
      "  ------- {'fairness_loss': 1.988916, 'utility': 0.5682702, 'loss': -0.50860274}\n",
      "--- Step : 2978 \n",
      "  ------- {'fairness_loss': 1.9890538, 'utility': 0.5682766, 'loss': -0.50860494}\n",
      "--- Step : 2979 \n",
      "  ------- {'fairness_loss': 1.9891914, 'utility': 0.568283, 'loss': -0.50860727}\n",
      "--- Step : 2980 \n",
      "  ------- {'fairness_loss': 1.9894681, 'utility': 0.5682934, 'loss': -0.50860935}\n",
      "--- Step : 2981 \n",
      "  ------- {'fairness_loss': 1.9897311, 'utility': 0.56830364, 'loss': -0.50861174}\n",
      "--- Step : 2982 \n",
      "  ------- {'fairness_loss': 1.9899814, 'utility': 0.5683134, 'loss': -0.508614}\n",
      "--- Step : 2983 \n",
      "  ------- {'fairness_loss': 1.9902221, 'utility': 0.5683228, 'loss': -0.5086161}\n",
      "--- Step : 2984 \n",
      "  ------- {'fairness_loss': 1.9904515, 'utility': 0.5683317, 'loss': -0.5086182}\n",
      "--- Step : 2985 \n",
      "  ------- {'fairness_loss': 1.9906698, 'utility': 0.5683407, 'loss': -0.5086206}\n",
      "--- Step : 2986 \n",
      "  ------- {'fairness_loss': 1.9908823, 'utility': 0.5683492, 'loss': -0.5086227}\n",
      "--- Step : 2987 \n",
      "  ------- {'fairness_loss': 1.9910862, 'utility': 0.5683576, 'loss': -0.50862503}\n",
      "--- Step : 2988 \n",
      "  ------- {'fairness_loss': 1.9912826, 'utility': 0.56836575, 'loss': -0.5086273}\n",
      "--- Step : 2989 \n",
      "  ------- {'fairness_loss': 1.9914742, 'utility': 0.5683737, 'loss': -0.50862944}\n",
      "--- Step : 2990 \n",
      "  ------- {'fairness_loss': 1.9916592, 'utility': 0.5683815, 'loss': -0.5086317}\n",
      "--- Step : 2991 \n",
      "  ------- {'fairness_loss': 1.9918392, 'utility': 0.56838906, 'loss': -0.5086339}\n",
      "--- Step : 2992 \n",
      "  ------- {'fairness_loss': 1.9920182, 'utility': 0.5683966, 'loss': -0.50863606}\n",
      "--- Step : 2993 \n",
      "  ------- {'fairness_loss': 1.9921912, 'utility': 0.5684042, 'loss': -0.50863844}\n",
      "--- Step : 2994 \n",
      "  ------- {'fairness_loss': 1.9923599, 'utility': 0.5684113, 'loss': -0.50864047}\n",
      "--- Step : 2995 \n",
      "  ------- {'fairness_loss': 1.9925269, 'utility': 0.5684186, 'loss': -0.5086428}\n",
      "--- Step : 2996 \n",
      "  ------- {'fairness_loss': 1.9926896, 'utility': 0.56842566, 'loss': -0.50864494}\n",
      "--- Step : 2997 \n",
      "  ------- {'fairness_loss': 1.9928508, 'utility': 0.5684328, 'loss': -0.50864726}\n",
      "--- Step : 2998 \n",
      "  ------- {'fairness_loss': 1.9930118, 'utility': 0.56843996, 'loss': -0.5086496}\n",
      "--- Step : 2999 \n",
      "  ------- {'fairness_loss': 1.9931716, 'utility': 0.5684468, 'loss': -0.5086517}\n",
      "--- Step : 3000 \n",
      "  ------- {'fairness_loss': 1.9933277, 'utility': 0.56845367, 'loss': -0.5086538}\n",
      "--- Step : 3001 \n",
      "  ------- {'fairness_loss': 1.9934822, 'utility': 0.5684606, 'loss': -0.50865614}\n",
      "--- Step : 3002 \n",
      "  ------- {'fairness_loss': 1.9936354, 'utility': 0.56846756, 'loss': -0.50865847}\n",
      "--- Step : 3003 \n",
      "  ------- {'fairness_loss': 1.9937893, 'utility': 0.5684743, 'loss': -0.5086606}\n",
      "--- Step : 3004 \n",
      "  ------- {'fairness_loss': 1.9939437, 'utility': 0.5684811, 'loss': -0.50866276}\n",
      "--- Step : 3005 \n",
      "  ------- {'fairness_loss': 1.9940952, 'utility': 0.56848776, 'loss': -0.5086649}\n",
      "--- Step : 3006 \n",
      "  ------- {'fairness_loss': 1.9942479, 'utility': 0.5684948, 'loss': -0.50866735}\n",
      "--- Step : 3007 \n",
      "  ------- {'fairness_loss': 1.9943981, 'utility': 0.5685014, 'loss': -0.5086695}\n",
      "--- Step : 3008 \n",
      "  ------- {'fairness_loss': 1.9945495, 'utility': 0.5685082, 'loss': -0.5086717}\n",
      "--- Step : 3009 \n",
      "  ------- {'fairness_loss': 1.9946994, 'utility': 0.5685149, 'loss': -0.5086739}\n",
      "--- Step : 3010 \n",
      "  ------- {'fairness_loss': 1.9948517, 'utility': 0.5685216, 'loss': -0.50867605}\n",
      "--- Step : 3011 \n",
      "  ------- {'fairness_loss': 1.9950032, 'utility': 0.5685284, 'loss': -0.5086783}\n",
      "--- Step : 3012 \n",
      "  ------- {'fairness_loss': 1.9951514, 'utility': 0.56853515, 'loss': -0.5086806}\n",
      "--- Step : 3013 \n",
      "  ------- {'fairness_loss': 1.9953022, 'utility': 0.5685419, 'loss': -0.50868285}\n",
      "--- Step : 3014 \n",
      "  ------- {'fairness_loss': 1.9954548, 'utility': 0.56854844, 'loss': -0.5086848}\n",
      "--- Step : 3015 \n",
      "  ------- {'fairness_loss': 1.9956045, 'utility': 0.5685554, 'loss': -0.50868726}\n",
      "--- Step : 3016 \n",
      "  ------- {'fairness_loss': 1.9957558, 'utility': 0.5685621, 'loss': -0.5086894}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3017 \n",
      "  ------- {'fairness_loss': 1.9959081, 'utility': 0.56856894, 'loss': -0.5086917}\n",
      "--- Step : 3018 \n",
      "  ------- {'fairness_loss': 1.9960612, 'utility': 0.56857574, 'loss': -0.50869393}\n",
      "--- Step : 3019 \n",
      "  ------- {'fairness_loss': 1.9962122, 'utility': 0.5685826, 'loss': -0.5086962}\n",
      "--- Step : 3020 \n",
      "  ------- {'fairness_loss': 1.9963669, 'utility': 0.5685892, 'loss': -0.5086982}\n",
      "--- Step : 3021 \n",
      "  ------- {'fairness_loss': 1.9965193, 'utility': 0.568596, 'loss': -0.50870043}\n",
      "--- Step : 3022 \n",
      "  ------- {'fairness_loss': 1.9966738, 'utility': 0.5686029, 'loss': -0.5087027}\n",
      "--- Step : 3023 \n",
      "  ------- {'fairness_loss': 1.9968303, 'utility': 0.5686098, 'loss': -0.50870484}\n",
      "--- Step : 3024 \n",
      "  ------- {'fairness_loss': 1.9969836, 'utility': 0.5686166, 'loss': -0.5087071}\n",
      "--- Step : 3025 \n",
      "  ------- {'fairness_loss': 1.997139, 'utility': 0.5686235, 'loss': -0.5087093}\n",
      "--- Step : 3026 \n",
      "  ------- {'fairness_loss': 1.997293, 'utility': 0.56863046, 'loss': -0.5087117}\n",
      "--- Step : 3027 \n",
      "  ------- {'fairness_loss': 1.9974518, 'utility': 0.5686373, 'loss': -0.5087138}\n",
      "--- Step : 3028 \n",
      "  ------- {'fairness_loss': 1.9976074, 'utility': 0.5686442, 'loss': -0.508716}\n",
      "--- Step : 3029 \n",
      "  ------- {'fairness_loss': 1.9977643, 'utility': 0.5686512, 'loss': -0.50871825}\n",
      "--- Step : 3030 \n",
      "  ------- {'fairness_loss': 1.9979222, 'utility': 0.5686582, 'loss': -0.5087205}\n",
      "--- Step : 3031 \n",
      "  ------- {'fairness_loss': 1.9980826, 'utility': 0.56866515, 'loss': -0.50872266}\n",
      "--- Step : 3032 \n",
      "  ------- {'fairness_loss': 1.9982399, 'utility': 0.5686721, 'loss': -0.5087249}\n",
      "--- Step : 3033 \n",
      "  ------- {'fairness_loss': 1.998401, 'utility': 0.5686792, 'loss': -0.5087272}\n",
      "--- Step : 3034 \n",
      "  ------- {'fairness_loss': 1.9985611, 'utility': 0.5686861, 'loss': -0.5087293}\n",
      "--- Step : 3035 \n",
      "  ------- {'fairness_loss': 1.998722, 'utility': 0.5686933, 'loss': -0.5087316}\n",
      "--- Step : 3036 \n",
      "  ------- {'fairness_loss': 1.9988846, 'utility': 0.56870025, 'loss': -0.50873375}\n",
      "--- Step : 3037 \n",
      "  ------- {'fairness_loss': 1.9991907, 'utility': 0.5687117, 'loss': -0.50873595}\n",
      "--- Step : 3038 \n",
      "  ------- {'fairness_loss': 1.9994836, 'utility': 0.5687226, 'loss': -0.5087381}\n",
      "--- Step : 3039 \n",
      "  ------- {'fairness_loss': 1.9997634, 'utility': 0.56873333, 'loss': -0.5087404}\n",
      "--- Step : 3040 \n",
      "  ------- {'fairness_loss': 2.0000315, 'utility': 0.5687434, 'loss': -0.50874245}\n",
      "--- Step : 3041 \n",
      "  ------- {'fairness_loss': 2.0002909, 'utility': 0.5687535, 'loss': -0.5087448}\n",
      "--- Step : 3042 \n",
      "  ------- {'fairness_loss': 2.0005398, 'utility': 0.5687632, 'loss': -0.508747}\n",
      "--- Step : 3043 \n",
      "  ------- {'fairness_loss': 2.0007799, 'utility': 0.56877273, 'loss': -0.50874937}\n",
      "--- Step : 3044 \n",
      "  ------- {'fairness_loss': 2.0010142, 'utility': 0.5687818, 'loss': -0.5087514}\n",
      "--- Step : 3045 \n",
      "  ------- {'fairness_loss': 2.0012414, 'utility': 0.56879085, 'loss': -0.5087536}\n",
      "--- Step : 3046 \n",
      "  ------- {'fairness_loss': 2.0014634, 'utility': 0.5687998, 'loss': -0.5087559}\n",
      "--- Step : 3047 \n",
      "  ------- {'fairness_loss': 2.0016801, 'utility': 0.5688084, 'loss': -0.50875795}\n",
      "--- Step : 3048 \n",
      "  ------- {'fairness_loss': 2.001892, 'utility': 0.5688171, 'loss': -0.50876033}\n",
      "--- Step : 3049 \n",
      "  ------- {'fairness_loss': 2.0021005, 'utility': 0.56882554, 'loss': -0.50876254}\n",
      "--- Step : 3050 \n",
      "  ------- {'fairness_loss': 2.0023046, 'utility': 0.568834, 'loss': -0.50876486}\n",
      "--- Step : 3051 \n",
      "  ------- {'fairness_loss': 2.0025048, 'utility': 0.56884205, 'loss': -0.5087669}\n",
      "--- Step : 3052 \n",
      "  ------- {'fairness_loss': 2.0027027, 'utility': 0.56885016, 'loss': -0.5087691}\n",
      "--- Step : 3053 \n",
      "  ------- {'fairness_loss': 2.002896, 'utility': 0.5688582, 'loss': -0.5087713}\n",
      "--- Step : 3054 \n",
      "  ------- {'fairness_loss': 2.003088, 'utility': 0.5688664, 'loss': -0.50877374}\n",
      "--- Step : 3055 \n",
      "  ------- {'fairness_loss': 2.0032806, 'utility': 0.5688741, 'loss': -0.5087757}\n",
      "--- Step : 3056 \n",
      "  ------- {'fairness_loss': 2.003469, 'utility': 0.5688821, 'loss': -0.50877804}\n",
      "--- Step : 3057 \n",
      "  ------- {'fairness_loss': 2.0036557, 'utility': 0.5688899, 'loss': -0.50878024}\n",
      "--- Step : 3058 \n",
      "  ------- {'fairness_loss': 2.0038419, 'utility': 0.5688978, 'loss': -0.5087825}\n",
      "--- Step : 3059 \n",
      "  ------- {'fairness_loss': 2.004027, 'utility': 0.5689054, 'loss': -0.5087846}\n",
      "--- Step : 3060 \n",
      "  ------- {'fairness_loss': 2.004211, 'utility': 0.56891316, 'loss': -0.50878686}\n",
      "--- Step : 3061 \n",
      "  ------- {'fairness_loss': 2.0043943, 'utility': 0.5689209, 'loss': -0.50878906}\n",
      "--- Step : 3062 \n",
      "  ------- {'fairness_loss': 2.0045767, 'utility': 0.56892866, 'loss': -0.5087914}\n",
      "--- Step : 3063 \n",
      "  ------- {'fairness_loss': 2.004758, 'utility': 0.56893635, 'loss': -0.5087936}\n",
      "--- Step : 3064 \n",
      "  ------- {'fairness_loss': 2.0049393, 'utility': 0.5689439, 'loss': -0.50879574}\n",
      "--- Step : 3065 \n",
      "  ------- {'fairness_loss': 2.0051208, 'utility': 0.5689514, 'loss': -0.5087978}\n",
      "--- Step : 3066 \n",
      "  ------- {'fairness_loss': 2.0053015, 'utility': 0.5689593, 'loss': -0.50880027}\n",
      "--- Step : 3067 \n",
      "  ------- {'fairness_loss': 2.0054817, 'utility': 0.56896687, 'loss': -0.5088024}\n",
      "--- Step : 3068 \n",
      "  ------- {'fairness_loss': 2.0056634, 'utility': 0.56897444, 'loss': -0.50880456}\n",
      "--- Step : 3069 \n",
      "  ------- {'fairness_loss': 2.0058436, 'utility': 0.5689821, 'loss': -0.5088068}\n",
      "--- Step : 3070 \n",
      "  ------- {'fairness_loss': 2.0060246, 'utility': 0.5689897, 'loss': -0.508809}\n",
      "--- Step : 3071 \n",
      "  ------- {'fairness_loss': 2.0062041, 'utility': 0.5689975, 'loss': -0.50881135}\n",
      "--- Step : 3072 \n",
      "  ------- {'fairness_loss': 2.006387, 'utility': 0.5690051, 'loss': -0.50881344}\n",
      "--- Step : 3073 \n",
      "  ------- {'fairness_loss': 2.006568, 'utility': 0.56901264, 'loss': -0.5088156}\n",
      "--- Step : 3074 \n",
      "  ------- {'fairness_loss': 2.0067494, 'utility': 0.5690203, 'loss': -0.5088178}\n",
      "--- Step : 3075 \n",
      "  ------- {'fairness_loss': 2.0069304, 'utility': 0.56902796, 'loss': -0.50882006}\n",
      "--- Step : 3076 \n",
      "  ------- {'fairness_loss': 2.007112, 'utility': 0.5690356, 'loss': -0.5088222}\n",
      "--- Step : 3077 \n",
      "  ------- {'fairness_loss': 2.007295, 'utility': 0.5690434, 'loss': -0.5088245}\n",
      "--- Step : 3078 \n",
      "  ------- {'fairness_loss': 2.0074751, 'utility': 0.56905097, 'loss': -0.50882673}\n",
      "--- Step : 3079 \n",
      "  ------- {'fairness_loss': 2.007659, 'utility': 0.56905866, 'loss': -0.5088289}\n",
      "--- Step : 3080 \n",
      "  ------- {'fairness_loss': 2.007841, 'utility': 0.56906635, 'loss': -0.50883114}\n",
      "--- Step : 3081 \n",
      "  ------- {'fairness_loss': 2.0080264, 'utility': 0.56907415, 'loss': -0.50883335}\n",
      "--- Step : 3082 \n",
      "  ------- {'fairness_loss': 2.0082107, 'utility': 0.56908196, 'loss': -0.5088357}\n",
      "--- Step : 3083 \n",
      "  ------- {'fairness_loss': 2.008395, 'utility': 0.56908953, 'loss': -0.5088377}\n",
      "--- Step : 3084 \n",
      "  ------- {'fairness_loss': 2.00858, 'utility': 0.5690972, 'loss': -0.50883985}\n",
      "--- Step : 3085 \n",
      "  ------- {'fairness_loss': 2.008764, 'utility': 0.5691051, 'loss': -0.5088422}\n",
      "--- Step : 3086 \n",
      "  ------- {'fairness_loss': 2.0089512, 'utility': 0.5691131, 'loss': -0.50884455}\n",
      "--- Step : 3087 \n",
      "  ------- {'fairness_loss': 2.0091367, 'utility': 0.56912076, 'loss': -0.50884664}\n",
      "--- Step : 3088 \n",
      "  ------- {'fairness_loss': 2.009322, 'utility': 0.56912863, 'loss': -0.50884897}\n",
      "--- Step : 3089 \n",
      "  ------- {'fairness_loss': 2.0095117, 'utility': 0.5691364, 'loss': -0.50885105}\n",
      "--- Step : 3090 \n",
      "  ------- {'fairness_loss': 2.009699, 'utility': 0.56914425, 'loss': -0.50885326}\n",
      "--- Step : 3091 \n",
      "  ------- {'fairness_loss': 2.0098863, 'utility': 0.5691522, 'loss': -0.5088556}\n",
      "--- Step : 3092 \n",
      "  ------- {'fairness_loss': 2.010076, 'utility': 0.5691601, 'loss': -0.50885785}\n",
      "--- Step : 3093 \n",
      "  ------- {'fairness_loss': 2.0102644, 'utility': 0.5691679, 'loss': -0.50886}\n",
      "--- Step : 3094 \n",
      "  ------- {'fairness_loss': 2.0104542, 'utility': 0.56917584, 'loss': -0.5088622}\n",
      "--- Step : 3095 \n",
      "  ------- {'fairness_loss': 2.0106452, 'utility': 0.56918365, 'loss': -0.5088643}\n",
      "--- Step : 3096 \n",
      "  ------- {'fairness_loss': 2.0108361, 'utility': 0.56919175, 'loss': -0.50886667}\n",
      "--- Step : 3097 \n",
      "  ------- {'fairness_loss': 2.011029, 'utility': 0.56919956, 'loss': -0.5088687}\n",
      "--- Step : 3098 \n",
      "  ------- {'fairness_loss': 2.011219, 'utility': 0.56920767, 'loss': -0.5088711}\n",
      "--- Step : 3099 \n",
      "  ------- {'fairness_loss': 2.0114112, 'utility': 0.5692157, 'loss': -0.5088734}\n",
      "--- Step : 3100 \n",
      "  ------- {'fairness_loss': 2.011606, 'utility': 0.5692237, 'loss': -0.50887555}\n",
      "--- Step : 3101 \n",
      "  ------- {'fairness_loss': 2.0117986, 'utility': 0.5692316, 'loss': -0.5088777}\n",
      "--- Step : 3102 \n",
      "  ------- {'fairness_loss': 2.0119934, 'utility': 0.5692397, 'loss': -0.5088799}\n",
      "--- Step : 3103 \n",
      "  ------- {'fairness_loss': 2.0121884, 'utility': 0.5692478, 'loss': -0.5088821}\n",
      "--- Step : 3104 \n",
      "  ------- {'fairness_loss': 2.0123832, 'utility': 0.56925577, 'loss': -0.50888425}\n",
      "--- Step : 3105 \n",
      "  ------- {'fairness_loss': 2.012579, 'utility': 0.56926405, 'loss': -0.5088867}\n",
      "--- Step : 3106 \n",
      "  ------- {'fairness_loss': 2.0127769, 'utility': 0.56927204, 'loss': -0.5088887}\n",
      "--- Step : 3107 \n",
      "  ------- {'fairness_loss': 2.012974, 'utility': 0.5692801, 'loss': -0.50889087}\n",
      "--- Step : 3108 \n",
      "  ------- {'fairness_loss': 2.0131705, 'utility': 0.5692883, 'loss': -0.5088932}\n",
      "--- Step : 3109 \n",
      "  ------- {'fairness_loss': 2.0133674, 'utility': 0.5692964, 'loss': -0.5088954}\n",
      "--- Step : 3110 \n",
      "  ------- {'fairness_loss': 2.0135674, 'utility': 0.56930465, 'loss': -0.5088976}\n",
      "--- Step : 3111 \n",
      "  ------- {'fairness_loss': 2.0137658, 'utility': 0.56931275, 'loss': -0.5088998}\n",
      "--- Step : 3112 \n",
      "  ------- {'fairness_loss': 2.0139668, 'utility': 0.56932116, 'loss': -0.50890213}\n",
      "--- Step : 3113 \n",
      "  ------- {'fairness_loss': 2.0141654, 'utility': 0.5693292, 'loss': -0.5089042}\n",
      "--- Step : 3114 \n",
      "  ------- {'fairness_loss': 2.0143661, 'utility': 0.5693375, 'loss': -0.5089065}\n",
      "--- Step : 3115 \n",
      "  ------- {'fairness_loss': 2.014568, 'utility': 0.5693458, 'loss': -0.50890875}\n",
      "--- Step : 3116 \n",
      "  ------- {'fairness_loss': 2.0147696, 'utility': 0.56935406, 'loss': -0.50891095}\n",
      "--- Step : 3117 \n",
      "  ------- {'fairness_loss': 2.0149717, 'utility': 0.5693623, 'loss': -0.50891316}\n",
      "--- Step : 3118 \n",
      "  ------- {'fairness_loss': 2.015175, 'utility': 0.5693707, 'loss': -0.5089154}\n",
      "--- Step : 3119 \n",
      "  ------- {'fairness_loss': 2.0153794, 'utility': 0.5693789, 'loss': -0.5089175}\n",
      "--- Step : 3120 \n",
      "  ------- {'fairness_loss': 2.015582, 'utility': 0.5693872, 'loss': -0.5089197}\n",
      "--- Step : 3121 \n",
      "  ------- {'fairness_loss': 2.0157862, 'utility': 0.56939566, 'loss': -0.5089221}\n",
      "--- Step : 3122 \n",
      "  ------- {'fairness_loss': 2.0159929, 'utility': 0.56940395, 'loss': -0.5089242}\n",
      "--- Step : 3123 \n",
      "  ------- {'fairness_loss': 2.0161982, 'utility': 0.5694123, 'loss': -0.50892633}\n",
      "--- Step : 3124 \n",
      "  ------- {'fairness_loss': 2.0164032, 'utility': 0.56942075, 'loss': -0.50892866}\n",
      "--- Step : 3125 \n",
      "  ------- {'fairness_loss': 2.0166104, 'utility': 0.5694292, 'loss': -0.5089309}\n",
      "--- Step : 3126 \n",
      "  ------- {'fairness_loss': 2.0168183, 'utility': 0.56943756, 'loss': -0.508933}\n",
      "--- Step : 3127 \n",
      "  ------- {'fairness_loss': 2.0170243, 'utility': 0.569446, 'loss': -0.5089353}\n",
      "--- Step : 3128 \n",
      "  ------- {'fairness_loss': 2.0172334, 'utility': 0.5694545, 'loss': -0.5089375}\n",
      "--- Step : 3129 \n",
      "  ------- {'fairness_loss': 2.0174434, 'utility': 0.5694629, 'loss': -0.5089396}\n",
      "--- Step : 3130 \n",
      "  ------- {'fairness_loss': 2.0176506, 'utility': 0.56947154, 'loss': -0.508942}\n",
      "--- Step : 3131 \n",
      "  ------- {'fairness_loss': 2.01786, 'utility': 0.5694801, 'loss': -0.50894433}\n",
      "--- Step : 3132 \n",
      "  ------- {'fairness_loss': 2.0180707, 'utility': 0.5694885, 'loss': -0.5089464}\n",
      "--- Step : 3133 \n",
      "  ------- {'fairness_loss': 2.0182817, 'utility': 0.5694971, 'loss': -0.5089487}\n",
      "--- Step : 3134 \n",
      "  ------- {'fairness_loss': 2.0184925, 'utility': 0.5695057, 'loss': -0.50895095}\n",
      "--- Step : 3135 \n",
      "  ------- {'fairness_loss': 2.0187037, 'utility': 0.5695143, 'loss': -0.50895315}\n",
      "--- Step : 3136 \n",
      "  ------- {'fairness_loss': 2.0189157, 'utility': 0.56952286, 'loss': -0.50895536}\n",
      "--- Step : 3137 \n",
      "  ------- {'fairness_loss': 2.0191288, 'utility': 0.56953144, 'loss': -0.50895756}\n",
      "--- Step : 3138 \n",
      "  ------- {'fairness_loss': 2.0193415, 'utility': 0.56954, 'loss': -0.5089598}\n",
      "--- Step : 3139 \n",
      "  ------- {'fairness_loss': 2.019556, 'utility': 0.56954867, 'loss': -0.508962}\n",
      "--- Step : 3140 \n",
      "  ------- {'fairness_loss': 2.019771, 'utility': 0.5695572, 'loss': -0.50896406}\n",
      "--- Step : 3141 \n",
      "  ------- {'fairness_loss': 2.019985, 'utility': 0.5695659, 'loss': -0.5089663}\n",
      "--- Step : 3142 \n",
      "  ------- {'fairness_loss': 2.0201998, 'utility': 0.56957465, 'loss': -0.50896865}\n",
      "--- Step : 3143 \n",
      "  ------- {'fairness_loss': 2.020416, 'utility': 0.5695834, 'loss': -0.5089709}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3144 \n",
      "  ------- {'fairness_loss': 2.0206325, 'utility': 0.5695922, 'loss': -0.5089732}\n",
      "--- Step : 3145 \n",
      "  ------- {'fairness_loss': 2.0208485, 'utility': 0.5696008, 'loss': -0.5089754}\n",
      "--- Step : 3146 \n",
      "  ------- {'fairness_loss': 2.0210657, 'utility': 0.56960964, 'loss': -0.50897765}\n",
      "--- Step : 3147 \n",
      "  ------- {'fairness_loss': 2.0212858, 'utility': 0.56961834, 'loss': -0.5089798}\n",
      "--- Step : 3148 \n",
      "  ------- {'fairness_loss': 2.021505, 'utility': 0.5696272, 'loss': -0.50898206}\n",
      "--- Step : 3149 \n",
      "  ------- {'fairness_loss': 2.021722, 'utility': 0.5696359, 'loss': -0.50898427}\n",
      "--- Step : 3150 \n",
      "  ------- {'fairness_loss': 2.0219407, 'utility': 0.56964463, 'loss': -0.5089864}\n",
      "--- Step : 3151 \n",
      "  ------- {'fairness_loss': 2.0221622, 'utility': 0.5696536, 'loss': -0.5089887}\n",
      "--- Step : 3152 \n",
      "  ------- {'fairness_loss': 2.0223815, 'utility': 0.56966233, 'loss': -0.5089909}\n",
      "--- Step : 3153 \n",
      "  ------- {'fairness_loss': 2.022602, 'utility': 0.56967115, 'loss': -0.5089931}\n",
      "--- Step : 3154 \n",
      "  ------- {'fairness_loss': 2.022823, 'utility': 0.56968, 'loss': -0.5089953}\n",
      "--- Step : 3155 \n",
      "  ------- {'fairness_loss': 2.0230472, 'utility': 0.56968904, 'loss': -0.5089976}\n",
      "--- Step : 3156 \n",
      "  ------- {'fairness_loss': 2.023268, 'utility': 0.56969786, 'loss': -0.5089998}\n",
      "--- Step : 3157 \n",
      "  ------- {'fairness_loss': 2.0234916, 'utility': 0.5697067, 'loss': -0.5090019}\n",
      "--- Step : 3158 \n",
      "  ------- {'fairness_loss': 2.0237138, 'utility': 0.5697156, 'loss': -0.50900424}\n",
      "--- Step : 3159 \n",
      "  ------- {'fairness_loss': 2.0239375, 'utility': 0.5697246, 'loss': -0.5090065}\n",
      "--- Step : 3160 \n",
      "  ------- {'fairness_loss': 2.0241623, 'utility': 0.5697336, 'loss': -0.50900877}\n",
      "--- Step : 3161 \n",
      "  ------- {'fairness_loss': 2.024386, 'utility': 0.56974256, 'loss': -0.509011}\n",
      "--- Step : 3162 \n",
      "  ------- {'fairness_loss': 2.0246108, 'utility': 0.56975156, 'loss': -0.50901324}\n",
      "--- Step : 3163 \n",
      "  ------- {'fairness_loss': 2.0248368, 'utility': 0.56976056, 'loss': -0.50901544}\n",
      "--- Step : 3164 \n",
      "  ------- {'fairness_loss': 2.025063, 'utility': 0.5697695, 'loss': -0.5090176}\n",
      "--- Step : 3165 \n",
      "  ------- {'fairness_loss': 2.0252903, 'utility': 0.56977856, 'loss': -0.50901985}\n",
      "--- Step : 3166 \n",
      "  ------- {'fairness_loss': 2.0255165, 'utility': 0.56978774, 'loss': -0.50902224}\n",
      "--- Step : 3167 \n",
      "  ------- {'fairness_loss': 2.025744, 'utility': 0.5697968, 'loss': -0.5090245}\n",
      "--- Step : 3168 \n",
      "  ------- {'fairness_loss': 2.0259721, 'utility': 0.5698058, 'loss': -0.50902665}\n",
      "--- Step : 3169 \n",
      "  ------- {'fairness_loss': 2.0262022, 'utility': 0.5698149, 'loss': -0.50902885}\n",
      "--- Step : 3170 \n",
      "  ------- {'fairness_loss': 2.026431, 'utility': 0.56982404, 'loss': -0.5090311}\n",
      "--- Step : 3171 \n",
      "  ------- {'fairness_loss': 2.0266607, 'utility': 0.5698331, 'loss': -0.50903326}\n",
      "--- Step : 3172 \n",
      "  ------- {'fairness_loss': 2.0268908, 'utility': 0.5698423, 'loss': -0.5090356}\n",
      "--- Step : 3173 \n",
      "  ------- {'fairness_loss': 2.0271208, 'utility': 0.5698514, 'loss': -0.5090378}\n",
      "--- Step : 3174 \n",
      "  ------- {'fairness_loss': 2.02735, 'utility': 0.5698606, 'loss': -0.50904006}\n",
      "--- Step : 3175 \n",
      "  ------- {'fairness_loss': 2.0275824, 'utility': 0.5698698, 'loss': -0.5090423}\n",
      "--- Step : 3176 \n",
      "  ------- {'fairness_loss': 2.0278125, 'utility': 0.56987894, 'loss': -0.5090446}\n",
      "--- Step : 3177 \n",
      "  ------- {'fairness_loss': 2.0280464, 'utility': 0.5698881, 'loss': -0.50904673}\n",
      "--- Step : 3178 \n",
      "  ------- {'fairness_loss': 2.0282784, 'utility': 0.56989735, 'loss': -0.509049}\n",
      "--- Step : 3179 \n",
      "  ------- {'fairness_loss': 2.0285113, 'utility': 0.5699067, 'loss': -0.5090514}\n",
      "--- Step : 3180 \n",
      "  ------- {'fairness_loss': 2.028745, 'utility': 0.56991583, 'loss': -0.50905347}\n",
      "--- Step : 3181 \n",
      "  ------- {'fairness_loss': 2.0289812, 'utility': 0.5699251, 'loss': -0.5090557}\n",
      "--- Step : 3182 \n",
      "  ------- {'fairness_loss': 2.0292153, 'utility': 0.56993455, 'loss': -0.5090581}\n",
      "--- Step : 3183 \n",
      "  ------- {'fairness_loss': 2.0294492, 'utility': 0.56994367, 'loss': -0.5090602}\n",
      "--- Step : 3184 \n",
      "  ------- {'fairness_loss': 2.0296857, 'utility': 0.569953, 'loss': -0.50906247}\n",
      "--- Step : 3185 \n",
      "  ------- {'fairness_loss': 2.0299225, 'utility': 0.5699623, 'loss': -0.5090647}\n",
      "--- Step : 3186 \n",
      "  ------- {'fairness_loss': 2.0301588, 'utility': 0.5699717, 'loss': -0.50906694}\n",
      "--- Step : 3187 \n",
      "  ------- {'fairness_loss': 2.030396, 'utility': 0.5699811, 'loss': -0.5090692}\n",
      "--- Step : 3188 \n",
      "  ------- {'fairness_loss': 2.0306323, 'utility': 0.5699906, 'loss': -0.5090716}\n",
      "--- Step : 3189 \n",
      "  ------- {'fairness_loss': 2.030872, 'utility': 0.56999975, 'loss': -0.5090736}\n",
      "--- Step : 3190 \n",
      "  ------- {'fairness_loss': 2.0311086, 'utility': 0.57000923, 'loss': -0.509076}\n",
      "--- Step : 3191 \n",
      "  ------- {'fairness_loss': 2.0313466, 'utility': 0.57001865, 'loss': -0.50907826}\n",
      "--- Step : 3192 \n",
      "  ------- {'fairness_loss': 2.031588, 'utility': 0.57002807, 'loss': -0.5090804}\n",
      "--- Step : 3193 \n",
      "  ------- {'fairness_loss': 2.0318286, 'utility': 0.57003754, 'loss': -0.5090827}\n",
      "--- Step : 3194 \n",
      "  ------- {'fairness_loss': 2.0320683, 'utility': 0.57004696, 'loss': -0.50908494}\n",
      "--- Step : 3195 \n",
      "  ------- {'fairness_loss': 2.03231, 'utility': 0.5700564, 'loss': -0.5090871}\n",
      "--- Step : 3196 \n",
      "  ------- {'fairness_loss': 2.0325503, 'utility': 0.5700659, 'loss': -0.5090894}\n",
      "--- Step : 3197 \n",
      "  ------- {'fairness_loss': 2.0327923, 'utility': 0.57007545, 'loss': -0.5090917}\n",
      "--- Step : 3198 \n",
      "  ------- {'fairness_loss': 2.033034, 'utility': 0.570085, 'loss': -0.50909394}\n",
      "--- Step : 3199 \n",
      "  ------- {'fairness_loss': 2.0332773, 'utility': 0.57009447, 'loss': -0.50909615}\n",
      "--- Step : 3200 \n",
      "  ------- {'fairness_loss': 2.0335207, 'utility': 0.5701041, 'loss': -0.50909853}\n",
      "--- Step : 3201 \n",
      "  ------- {'fairness_loss': 2.033764, 'utility': 0.5701136, 'loss': -0.5091007}\n",
      "--- Step : 3202 \n",
      "  ------- {'fairness_loss': 2.034008, 'utility': 0.5701229, 'loss': -0.50910264}\n",
      "--- Step : 3203 \n",
      "  ------- {'fairness_loss': 2.0342531, 'utility': 0.57013273, 'loss': -0.50910515}\n",
      "--- Step : 3204 \n",
      "  ------- {'fairness_loss': 2.0344977, 'utility': 0.5701423, 'loss': -0.5091074}\n",
      "--- Step : 3205 \n",
      "  ------- {'fairness_loss': 2.0347438, 'utility': 0.57015187, 'loss': -0.50910956}\n",
      "--- Step : 3206 \n",
      "  ------- {'fairness_loss': 2.0349896, 'utility': 0.5701615, 'loss': -0.5091118}\n",
      "--- Step : 3207 \n",
      "  ------- {'fairness_loss': 2.0352354, 'utility': 0.5701712, 'loss': -0.50911415}\n",
      "--- Step : 3208 \n",
      "  ------- {'fairness_loss': 2.0354826, 'utility': 0.5701809, 'loss': -0.5091164}\n",
      "--- Step : 3209 \n",
      "  ------- {'fairness_loss': 2.03573, 'utility': 0.5701906, 'loss': -0.50911874}\n",
      "--- Step : 3210 \n",
      "  ------- {'fairness_loss': 2.0359766, 'utility': 0.5702002, 'loss': -0.5091209}\n",
      "--- Step : 3211 \n",
      "  ------- {'fairness_loss': 2.0362253, 'utility': 0.57020986, 'loss': -0.5091231}\n",
      "--- Step : 3212 \n",
      "  ------- {'fairness_loss': 2.0364761, 'utility': 0.5702196, 'loss': -0.5091253}\n",
      "--- Step : 3213 \n",
      "  ------- {'fairness_loss': 2.036723, 'utility': 0.5702295, 'loss': -0.5091278}\n",
      "--- Step : 3214 \n",
      "  ------- {'fairness_loss': 2.0369716, 'utility': 0.5702392, 'loss': -0.50913006}\n",
      "--- Step : 3215 \n",
      "  ------- {'fairness_loss': 2.0372224, 'utility': 0.57024884, 'loss': -0.50913215}\n",
      "--- Step : 3216 \n",
      "  ------- {'fairness_loss': 2.0374734, 'utility': 0.57025874, 'loss': -0.50913453}\n",
      "--- Step : 3217 \n",
      "  ------- {'fairness_loss': 2.0377228, 'utility': 0.5702686, 'loss': -0.5091369}\n",
      "--- Step : 3218 \n",
      "  ------- {'fairness_loss': 2.0379746, 'utility': 0.5702784, 'loss': -0.5091392}\n",
      "--- Step : 3219 \n",
      "  ------- {'fairness_loss': 2.038227, 'utility': 0.57028806, 'loss': -0.50914127}\n",
      "--- Step : 3220 \n",
      "  ------- {'fairness_loss': 2.038479, 'utility': 0.57029796, 'loss': -0.5091436}\n",
      "--- Step : 3221 \n",
      "  ------- {'fairness_loss': 2.0387323, 'utility': 0.5703077, 'loss': -0.5091457}\n",
      "--- Step : 3222 \n",
      "  ------- {'fairness_loss': 2.038984, 'utility': 0.5703177, 'loss': -0.5091482}\n",
      "--- Step : 3223 \n",
      "  ------- {'fairness_loss': 2.039239, 'utility': 0.5703276, 'loss': -0.5091504}\n",
      "--- Step : 3224 \n",
      "  ------- {'fairness_loss': 2.0394938, 'utility': 0.5703373, 'loss': -0.5091525}\n",
      "--- Step : 3225 \n",
      "  ------- {'fairness_loss': 2.0397487, 'utility': 0.5703473, 'loss': -0.50915486}\n",
      "--- Step : 3226 \n",
      "  ------- {'fairness_loss': 2.0400026, 'utility': 0.57035726, 'loss': -0.5091572}\n",
      "--- Step : 3227 \n",
      "  ------- {'fairness_loss': 2.040259, 'utility': 0.5703673, 'loss': -0.5091595}\n",
      "--- Step : 3228 \n",
      "  ------- {'fairness_loss': 2.0405147, 'utility': 0.5703771, 'loss': -0.50916165}\n",
      "--- Step : 3229 \n",
      "  ------- {'fairness_loss': 2.0407717, 'utility': 0.5703871, 'loss': -0.509164}\n",
      "--- Step : 3230 \n",
      "  ------- {'fairness_loss': 2.0410283, 'utility': 0.5703971, 'loss': -0.50916624}\n",
      "--- Step : 3231 \n",
      "  ------- {'fairness_loss': 2.0412855, 'utility': 0.5704071, 'loss': -0.5091685}\n",
      "--- Step : 3232 \n",
      "  ------- {'fairness_loss': 2.0415447, 'utility': 0.57041717, 'loss': -0.50917083}\n",
      "--- Step : 3233 \n",
      "  ------- {'fairness_loss': 2.0418034, 'utility': 0.5704271, 'loss': -0.50917304}\n",
      "--- Step : 3234 \n",
      "  ------- {'fairness_loss': 2.0420606, 'utility': 0.5704371, 'loss': -0.50917524}\n",
      "--- Step : 3235 \n",
      "  ------- {'fairness_loss': 2.0423207, 'utility': 0.5704472, 'loss': -0.50917757}\n",
      "--- Step : 3236 \n",
      "  ------- {'fairness_loss': 2.0425806, 'utility': 0.5704571, 'loss': -0.5091797}\n",
      "--- Step : 3237 \n",
      "  ------- {'fairness_loss': 2.0428421, 'utility': 0.57046735, 'loss': -0.5091821}\n",
      "--- Step : 3238 \n",
      "  ------- {'fairness_loss': 2.0431025, 'utility': 0.57047755, 'loss': -0.5091845}\n",
      "--- Step : 3239 \n",
      "  ------- {'fairness_loss': 2.0433617, 'utility': 0.5704876, 'loss': -0.50918674}\n",
      "--- Step : 3240 \n",
      "  ------- {'fairness_loss': 2.043624, 'utility': 0.5704977, 'loss': -0.50918895}\n",
      "--- Step : 3241 \n",
      "  ------- {'fairness_loss': 2.043885, 'utility': 0.5705078, 'loss': -0.5091913}\n",
      "--- Step : 3242 \n",
      "  ------- {'fairness_loss': 2.0441477, 'utility': 0.57051814, 'loss': -0.5091937}\n",
      "--- Step : 3243 \n",
      "  ------- {'fairness_loss': 2.044411, 'utility': 0.57052827, 'loss': -0.5091959}\n",
      "--- Step : 3244 \n",
      "  ------- {'fairness_loss': 2.0446734, 'utility': 0.5705382, 'loss': -0.509198}\n",
      "--- Step : 3245 \n",
      "  ------- {'fairness_loss': 2.0449367, 'utility': 0.5705485, 'loss': -0.5092004}\n",
      "--- Step : 3246 \n",
      "  ------- {'fairness_loss': 2.0452025, 'utility': 0.57055885, 'loss': -0.5092028}\n",
      "--- Step : 3247 \n",
      "  ------- {'fairness_loss': 2.0454664, 'utility': 0.57056886, 'loss': -0.50920486}\n",
      "--- Step : 3248 \n",
      "  ------- {'fairness_loss': 2.0457304, 'utility': 0.5705793, 'loss': -0.50920737}\n",
      "--- Step : 3249 \n",
      "  ------- {'fairness_loss': 2.0459967, 'utility': 0.57058966, 'loss': -0.50920975}\n",
      "--- Step : 3250 \n",
      "  ------- {'fairness_loss': 2.0462646, 'utility': 0.57059985, 'loss': -0.5092119}\n",
      "--- Step : 3251 \n",
      "  ------- {'fairness_loss': 2.0465288, 'utility': 0.57061005, 'loss': -0.50921416}\n",
      "--- Step : 3252 \n",
      "  ------- {'fairness_loss': 2.0467956, 'utility': 0.5706203, 'loss': -0.5092164}\n",
      "--- Step : 3253 \n",
      "  ------- {'fairness_loss': 2.0470629, 'utility': 0.57063067, 'loss': -0.5092188}\n",
      "--- Step : 3254 \n",
      "  ------- {'fairness_loss': 2.0473323, 'utility': 0.570641, 'loss': -0.509221}\n",
      "--- Step : 3255 \n",
      "  ------- {'fairness_loss': 2.0475993, 'utility': 0.57065135, 'loss': -0.5092234}\n",
      "--- Step : 3256 \n",
      "  ------- {'fairness_loss': 2.0478694, 'utility': 0.5706618, 'loss': -0.5092257}\n",
      "--- Step : 3257 \n",
      "  ------- {'fairness_loss': 2.0481396, 'utility': 0.57067204, 'loss': -0.5092279}\n",
      "--- Step : 3258 \n",
      "  ------- {'fairness_loss': 2.0484087, 'utility': 0.5706825, 'loss': -0.50923026}\n",
      "--- Step : 3259 \n",
      "  ------- {'fairness_loss': 2.0486774, 'utility': 0.570693, 'loss': -0.5092327}\n",
      "--- Step : 3260 \n",
      "  ------- {'fairness_loss': 2.0489485, 'utility': 0.5707033, 'loss': -0.50923485}\n",
      "--- Step : 3261 \n",
      "  ------- {'fairness_loss': 2.04922, 'utility': 0.5707137, 'loss': -0.5092371}\n",
      "--- Step : 3262 \n",
      "  ------- {'fairness_loss': 2.0494914, 'utility': 0.5707242, 'loss': -0.50923944}\n",
      "--- Step : 3263 \n",
      "  ------- {'fairness_loss': 2.0497646, 'utility': 0.57073474, 'loss': -0.5092418}\n",
      "--- Step : 3264 \n",
      "  ------- {'fairness_loss': 2.0500371, 'utility': 0.5707451, 'loss': -0.509244}\n",
      "--- Step : 3265 \n",
      "  ------- {'fairness_loss': 2.050309, 'utility': 0.5707558, 'loss': -0.5092465}\n",
      "--- Step : 3266 \n",
      "  ------- {'fairness_loss': 2.0505831, 'utility': 0.57076627, 'loss': -0.5092488}\n",
      "--- Step : 3267 \n",
      "  ------- {'fairness_loss': 2.050855, 'utility': 0.5707767, 'loss': -0.50925106}\n",
      "--- Step : 3268 \n",
      "  ------- {'fairness_loss': 2.0511308, 'utility': 0.5707872, 'loss': -0.50925326}\n",
      "--- Step : 3269 \n",
      "  ------- {'fairness_loss': 2.0514054, 'utility': 0.57079774, 'loss': -0.5092556}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3270 \n",
      "  ------- {'fairness_loss': 2.0516803, 'utility': 0.5708083, 'loss': -0.5092579}\n",
      "--- Step : 3271 \n",
      "  ------- {'fairness_loss': 2.0519562, 'utility': 0.570819, 'loss': -0.50926036}\n",
      "--- Step : 3272 \n",
      "  ------- {'fairness_loss': 2.0522325, 'utility': 0.5708297, 'loss': -0.50926274}\n",
      "--- Step : 3273 \n",
      "  ------- {'fairness_loss': 2.0525084, 'utility': 0.57084024, 'loss': -0.509265}\n",
      "--- Step : 3274 \n",
      "  ------- {'fairness_loss': 2.052788, 'utility': 0.57085073, 'loss': -0.5092671}\n",
      "--- Step : 3275 \n",
      "  ------- {'fairness_loss': 2.0530653, 'utility': 0.5708614, 'loss': -0.5092694}\n",
      "--- Step : 3276 \n",
      "  ------- {'fairness_loss': 2.053342, 'utility': 0.57087207, 'loss': -0.5092718}\n",
      "--- Step : 3277 \n",
      "  ------- {'fairness_loss': 2.0536208, 'utility': 0.57088274, 'loss': -0.5092741}\n",
      "--- Step : 3278 \n",
      "  ------- {'fairness_loss': 2.0538998, 'utility': 0.5708936, 'loss': -0.50927657}\n",
      "--- Step : 3279 \n",
      "  ------- {'fairness_loss': 2.05418, 'utility': 0.57090414, 'loss': -0.5092787}\n",
      "--- Step : 3280 \n",
      "  ------- {'fairness_loss': 2.0544589, 'utility': 0.57091486, 'loss': -0.5092811}\n",
      "--- Step : 3281 \n",
      "  ------- {'fairness_loss': 2.05474, 'utility': 0.5709256, 'loss': -0.5092834}\n",
      "--- Step : 3282 \n",
      "  ------- {'fairness_loss': 2.05502, 'utility': 0.5709364, 'loss': -0.5092858}\n",
      "--- Step : 3283 \n",
      "  ------- {'fairness_loss': 2.0553021, 'utility': 0.5709472, 'loss': -0.50928813}\n",
      "--- Step : 3284 \n",
      "  ------- {'fairness_loss': 2.055582, 'utility': 0.5709579, 'loss': -0.50929046}\n",
      "--- Step : 3285 \n",
      "  ------- {'fairness_loss': 2.0558639, 'utility': 0.57096875, 'loss': -0.50929284}\n",
      "--- Step : 3286 \n",
      "  ------- {'fairness_loss': 2.0561478, 'utility': 0.5709796, 'loss': -0.50929517}\n",
      "--- Step : 3287 \n",
      "  ------- {'fairness_loss': 2.0564306, 'utility': 0.57099026, 'loss': -0.5092974}\n",
      "--- Step : 3288 \n",
      "  ------- {'fairness_loss': 2.0567133, 'utility': 0.57100123, 'loss': -0.5092998}\n",
      "--- Step : 3289 \n",
      "  ------- {'fairness_loss': 2.056998, 'utility': 0.571012, 'loss': -0.5093021}\n",
      "--- Step : 3290 \n",
      "  ------- {'fairness_loss': 2.057281, 'utility': 0.5710229, 'loss': -0.5093045}\n",
      "--- Step : 3291 \n",
      "  ------- {'fairness_loss': 2.0575666, 'utility': 0.5710338, 'loss': -0.5093068}\n",
      "--- Step : 3292 \n",
      "  ------- {'fairness_loss': 2.0578527, 'utility': 0.57104474, 'loss': -0.5093092}\n",
      "--- Step : 3293 \n",
      "  ------- {'fairness_loss': 2.058137, 'utility': 0.5710556, 'loss': -0.5093115}\n",
      "--- Step : 3294 \n",
      "  ------- {'fairness_loss': 2.0584242, 'utility': 0.5710667, 'loss': -0.50931394}\n",
      "--- Step : 3295 \n",
      "  ------- {'fairness_loss': 2.0587113, 'utility': 0.5710775, 'loss': -0.5093162}\n",
      "--- Step : 3296 \n",
      "  ------- {'fairness_loss': 2.059, 'utility': 0.5710885, 'loss': -0.5093185}\n",
      "--- Step : 3297 \n",
      "  ------- {'fairness_loss': 2.0592868, 'utility': 0.57109946, 'loss': -0.50932086}\n",
      "--- Step : 3298 \n",
      "  ------- {'fairness_loss': 2.0595748, 'utility': 0.5711104, 'loss': -0.5093232}\n",
      "--- Step : 3299 \n",
      "  ------- {'fairness_loss': 2.0598633, 'utility': 0.5711215, 'loss': -0.5093256}\n",
      "--- Step : 3300 \n",
      "  ------- {'fairness_loss': 2.060153, 'utility': 0.57113254, 'loss': -0.50932795}\n",
      "--- Step : 3301 \n",
      "  ------- {'fairness_loss': 2.060443, 'utility': 0.5711436, 'loss': -0.50933033}\n",
      "--- Step : 3302 \n",
      "  ------- {'fairness_loss': 2.0607328, 'utility': 0.5711546, 'loss': -0.5093326}\n",
      "--- Step : 3303 \n",
      "  ------- {'fairness_loss': 2.061024, 'utility': 0.5711656, 'loss': -0.5093349}\n",
      "--- Step : 3304 \n",
      "  ------- {'fairness_loss': 2.0613146, 'utility': 0.5711768, 'loss': -0.50933737}\n",
      "--- Step : 3305 \n",
      "  ------- {'fairness_loss': 2.0616066, 'utility': 0.5711878, 'loss': -0.5093396}\n",
      "--- Step : 3306 \n",
      "  ------- {'fairness_loss': 2.0619001, 'utility': 0.571199, 'loss': -0.509342}\n",
      "--- Step : 3307 \n",
      "  ------- {'fairness_loss': 2.0621917, 'utility': 0.57121015, 'loss': -0.5093444}\n",
      "--- Step : 3308 \n",
      "  ------- {'fairness_loss': 2.0624833, 'utility': 0.57122123, 'loss': -0.5093467}\n",
      "--- Step : 3309 \n",
      "  ------- {'fairness_loss': 2.062776, 'utility': 0.57123256, 'loss': -0.5093493}\n",
      "--- Step : 3310 \n",
      "  ------- {'fairness_loss': 2.0630713, 'utility': 0.57124364, 'loss': -0.5093515}\n",
      "--- Step : 3311 \n",
      "  ------- {'fairness_loss': 2.0633652, 'utility': 0.5712548, 'loss': -0.5093538}\n",
      "--- Step : 3312 \n",
      "  ------- {'fairness_loss': 2.0636594, 'utility': 0.57126606, 'loss': -0.50935626}\n",
      "--- Step : 3313 \n",
      "  ------- {'fairness_loss': 2.0639534, 'utility': 0.57127726, 'loss': -0.50935864}\n",
      "--- Step : 3314 \n",
      "  ------- {'fairness_loss': 2.064252, 'utility': 0.5712885, 'loss': -0.50936097}\n",
      "--- Step : 3315 \n",
      "  ------- {'fairness_loss': 2.0645463, 'utility': 0.5712998, 'loss': -0.5093634}\n",
      "--- Step : 3316 \n",
      "  ------- {'fairness_loss': 2.0648432, 'utility': 0.57131106, 'loss': -0.50936574}\n",
      "--- Step : 3317 \n",
      "  ------- {'fairness_loss': 2.0651393, 'utility': 0.57132226, 'loss': -0.50936806}\n",
      "--- Step : 3318 \n",
      "  ------- {'fairness_loss': 2.0654366, 'utility': 0.57133365, 'loss': -0.50937057}\n",
      "--- Step : 3319 \n",
      "  ------- {'fairness_loss': 2.0657349, 'utility': 0.571345, 'loss': -0.50937295}\n",
      "--- Step : 3320 \n",
      "  ------- {'fairness_loss': 2.0660315, 'utility': 0.57135624, 'loss': -0.5093753}\n",
      "--- Step : 3321 \n",
      "  ------- {'fairness_loss': 2.0663323, 'utility': 0.57136756, 'loss': -0.5093776}\n",
      "--- Step : 3322 \n",
      "  ------- {'fairness_loss': 2.0666325, 'utility': 0.57137895, 'loss': -0.50938}\n",
      "--- Step : 3323 \n",
      "  ------- {'fairness_loss': 2.0669317, 'utility': 0.5713904, 'loss': -0.5093824}\n",
      "--- Step : 3324 \n",
      "  ------- {'fairness_loss': 2.0672326, 'utility': 0.57140166, 'loss': -0.5093847}\n",
      "--- Step : 3325 \n",
      "  ------- {'fairness_loss': 2.067534, 'utility': 0.5714132, 'loss': -0.5093872}\n",
      "--- Step : 3326 \n",
      "  ------- {'fairness_loss': 2.0678349, 'utility': 0.57142454, 'loss': -0.5093895}\n",
      "--- Step : 3327 \n",
      "  ------- {'fairness_loss': 2.068135, 'utility': 0.5714361, 'loss': -0.5093921}\n",
      "--- Step : 3328 \n",
      "  ------- {'fairness_loss': 2.0684385, 'utility': 0.57144755, 'loss': -0.5093944}\n",
      "--- Step : 3329 \n",
      "  ------- {'fairness_loss': 2.0687408, 'utility': 0.5714589, 'loss': -0.5093967}\n",
      "--- Step : 3330 \n",
      "  ------- {'fairness_loss': 2.0690453, 'utility': 0.57147056, 'loss': -0.5093992}\n",
      "--- Step : 3331 \n",
      "  ------- {'fairness_loss': 2.0693486, 'utility': 0.5714819, 'loss': -0.50940144}\n",
      "--- Step : 3332 \n",
      "  ------- {'fairness_loss': 2.069654, 'utility': 0.5714935, 'loss': -0.5094039}\n",
      "--- Step : 3333 \n",
      "  ------- {'fairness_loss': 2.0699558, 'utility': 0.571505, 'loss': -0.5094063}\n",
      "--- Step : 3334 \n",
      "  ------- {'fairness_loss': 2.0702612, 'utility': 0.57151663, 'loss': -0.5094088}\n",
      "--- Step : 3335 \n",
      "  ------- {'fairness_loss': 2.0705676, 'utility': 0.57152826, 'loss': -0.5094112}\n",
      "--- Step : 3336 \n",
      "  ------- {'fairness_loss': 2.0708728, 'utility': 0.5715398, 'loss': -0.50941366}\n",
      "--- Step : 3337 \n",
      "  ------- {'fairness_loss': 2.071179, 'utility': 0.5715513, 'loss': -0.509416}\n",
      "--- Step : 3338 \n",
      "  ------- {'fairness_loss': 2.0714855, 'utility': 0.571563, 'loss': -0.5094184}\n",
      "--- Step : 3339 \n",
      "  ------- {'fairness_loss': 2.0717933, 'utility': 0.57157457, 'loss': -0.50942075}\n",
      "--- Step : 3340 \n",
      "  ------- {'fairness_loss': 2.0721028, 'utility': 0.5715862, 'loss': -0.50942314}\n",
      "--- Step : 3341 \n",
      "  ------- {'fairness_loss': 2.0724099, 'utility': 0.571598, 'loss': -0.5094257}\n",
      "--- Step : 3342 \n",
      "  ------- {'fairness_loss': 2.0727184, 'utility': 0.5716097, 'loss': -0.50942814}\n",
      "--- Step : 3343 \n",
      "  ------- {'fairness_loss': 2.073027, 'utility': 0.5716215, 'loss': -0.50943065}\n",
      "--- Step : 3344 \n",
      "  ------- {'fairness_loss': 2.0733373, 'utility': 0.57163304, 'loss': -0.5094329}\n",
      "--- Step : 3345 \n",
      "  ------- {'fairness_loss': 2.073649, 'utility': 0.5716448, 'loss': -0.5094353}\n",
      "--- Step : 3346 \n",
      "  ------- {'fairness_loss': 2.0739584, 'utility': 0.57165647, 'loss': -0.50943774}\n",
      "--- Step : 3347 \n",
      "  ------- {'fairness_loss': 2.0742695, 'utility': 0.5716684, 'loss': -0.5094403}\n",
      "--- Step : 3348 \n",
      "  ------- {'fairness_loss': 2.0745792, 'utility': 0.57167995, 'loss': -0.50944257}\n",
      "--- Step : 3349 \n",
      "  ------- {'fairness_loss': 2.0748923, 'utility': 0.5716919, 'loss': -0.50944513}\n",
      "--- Step : 3350 \n",
      "  ------- {'fairness_loss': 2.0752072, 'utility': 0.5717036, 'loss': -0.5094474}\n",
      "--- Step : 3351 \n",
      "  ------- {'fairness_loss': 2.0755188, 'utility': 0.5717155, 'loss': -0.5094499}\n",
      "--- Step : 3352 \n",
      "  ------- {'fairness_loss': 2.0758295, 'utility': 0.5717272, 'loss': -0.50945234}\n",
      "--- Step : 3353 \n",
      "  ------- {'fairness_loss': 2.0761447, 'utility': 0.5717392, 'loss': -0.50945485}\n",
      "--- Step : 3354 \n",
      "  ------- {'fairness_loss': 2.0764592, 'utility': 0.57175106, 'loss': -0.5094573}\n",
      "--- Step : 3355 \n",
      "  ------- {'fairness_loss': 2.076775, 'utility': 0.57176286, 'loss': -0.5094596}\n",
      "--- Step : 3356 \n",
      "  ------- {'fairness_loss': 2.0770898, 'utility': 0.5717747, 'loss': -0.509462}\n",
      "--- Step : 3357 \n",
      "  ------- {'fairness_loss': 2.0774055, 'utility': 0.5717868, 'loss': -0.5094647}\n",
      "--- Step : 3358 \n",
      "  ------- {'fairness_loss': 2.07772, 'utility': 0.5717986, 'loss': -0.509467}\n",
      "--- Step : 3359 \n",
      "  ------- {'fairness_loss': 2.0780356, 'utility': 0.5718105, 'loss': -0.5094694}\n",
      "--- Step : 3360 \n",
      "  ------- {'fairness_loss': 2.0783544, 'utility': 0.57182264, 'loss': -0.509472}\n",
      "--- Step : 3361 \n",
      "  ------- {'fairness_loss': 2.078672, 'utility': 0.57183456, 'loss': -0.5094744}\n",
      "--- Step : 3362 \n",
      "  ------- {'fairness_loss': 2.0789893, 'utility': 0.5718466, 'loss': -0.5094769}\n",
      "--- Step : 3363 \n",
      "  ------- {'fairness_loss': 2.0793076, 'utility': 0.5718585, 'loss': -0.5094793}\n",
      "--- Step : 3364 \n",
      "  ------- {'fairness_loss': 2.0796278, 'utility': 0.5718706, 'loss': -0.5094818}\n",
      "--- Step : 3365 \n",
      "  ------- {'fairness_loss': 2.0799465, 'utility': 0.57188267, 'loss': -0.5094843}\n",
      "--- Step : 3366 \n",
      "  ------- {'fairness_loss': 2.0802655, 'utility': 0.57189465, 'loss': -0.5094867}\n",
      "--- Step : 3367 \n",
      "  ------- {'fairness_loss': 2.0805838, 'utility': 0.5719067, 'loss': -0.5094892}\n",
      "--- Step : 3368 \n",
      "  ------- {'fairness_loss': 2.0809057, 'utility': 0.5719188, 'loss': -0.5094916}\n",
      "--- Step : 3369 \n",
      "  ------- {'fairness_loss': 2.0812256, 'utility': 0.5719308, 'loss': -0.50949407}\n",
      "--- Step : 3370 \n",
      "  ------- {'fairness_loss': 2.0815473, 'utility': 0.5719431, 'loss': -0.5094967}\n",
      "--- Step : 3371 \n",
      "  ------- {'fairness_loss': 2.0818694, 'utility': 0.57195514, 'loss': -0.5094991}\n",
      "--- Step : 3372 \n",
      "  ------- {'fairness_loss': 2.0821934, 'utility': 0.57196736, 'loss': -0.5095016}\n",
      "--- Step : 3373 \n",
      "  ------- {'fairness_loss': 2.0825145, 'utility': 0.57197946, 'loss': -0.509504}\n",
      "--- Step : 3374 \n",
      "  ------- {'fairness_loss': 2.082837, 'utility': 0.5719917, 'loss': -0.5095066}\n",
      "--- Step : 3375 \n",
      "  ------- {'fairness_loss': 2.0831618, 'utility': 0.57200384, 'loss': -0.50950897}\n",
      "--- Step : 3376 \n",
      "  ------- {'fairness_loss': 2.0834882, 'utility': 0.5720161, 'loss': -0.5095115}\n",
      "--- Step : 3377 \n",
      "  ------- {'fairness_loss': 2.0838118, 'utility': 0.5720284, 'loss': -0.50951403}\n",
      "--- Step : 3378 \n",
      "  ------- {'fairness_loss': 2.0841367, 'utility': 0.5720404, 'loss': -0.5095163}\n",
      "--- Step : 3379 \n",
      "  ------- {'fairness_loss': 2.0844631, 'utility': 0.5720528, 'loss': -0.50951886}\n",
      "--- Step : 3380 \n",
      "  ------- {'fairness_loss': 2.08479, 'utility': 0.5720651, 'loss': -0.5095214}\n",
      "--- Step : 3381 \n",
      "  ------- {'fairness_loss': 2.0851161, 'utility': 0.5720774, 'loss': -0.5095239}\n",
      "--- Step : 3382 \n",
      "  ------- {'fairness_loss': 2.085442, 'utility': 0.5720896, 'loss': -0.5095264}\n",
      "--- Step : 3383 \n",
      "  ------- {'fairness_loss': 2.0857687, 'utility': 0.5721019, 'loss': -0.5095288}\n",
      "--- Step : 3384 \n",
      "  ------- {'fairness_loss': 2.0860963, 'utility': 0.5721142, 'loss': -0.5095313}\n",
      "--- Step : 3385 \n",
      "  ------- {'fairness_loss': 2.0864248, 'utility': 0.57212657, 'loss': -0.5095338}\n",
      "--- Step : 3386 \n",
      "  ------- {'fairness_loss': 2.0867522, 'utility': 0.572139, 'loss': -0.50953645}\n",
      "--- Step : 3387 \n",
      "  ------- {'fairness_loss': 2.0870826, 'utility': 0.5721514, 'loss': -0.50953895}\n",
      "--- Step : 3388 \n",
      "  ------- {'fairness_loss': 2.0874116, 'utility': 0.5721639, 'loss': -0.5095415}\n",
      "--- Step : 3389 \n",
      "  ------- {'fairness_loss': 2.0877419, 'utility': 0.5721763, 'loss': -0.509544}\n",
      "--- Step : 3390 \n",
      "  ------- {'fairness_loss': 2.0880706, 'utility': 0.57218856, 'loss': -0.50954646}\n",
      "--- Step : 3391 \n",
      "  ------- {'fairness_loss': 2.0884008, 'utility': 0.5722011, 'loss': -0.509549}\n",
      "--- Step : 3392 \n",
      "  ------- {'fairness_loss': 2.0887315, 'utility': 0.5722136, 'loss': -0.50955164}\n",
      "--- Step : 3393 \n",
      "  ------- {'fairness_loss': 2.0890636, 'utility': 0.572226, 'loss': -0.5095541}\n",
      "--- Step : 3394 \n",
      "  ------- {'fairness_loss': 2.089395, 'utility': 0.5722385, 'loss': -0.50955665}\n",
      "--- Step : 3395 \n",
      "  ------- {'fairness_loss': 2.0897284, 'utility': 0.57225096, 'loss': -0.5095591}\n",
      "--- Step : 3396 \n",
      "  ------- {'fairness_loss': 2.0900612, 'utility': 0.57226354, 'loss': -0.5095617}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3397 \n",
      "  ------- {'fairness_loss': 2.090395, 'utility': 0.57227594, 'loss': -0.5095641}\n",
      "--- Step : 3398 \n",
      "  ------- {'fairness_loss': 2.0907288, 'utility': 0.57228863, 'loss': -0.5095668}\n",
      "--- Step : 3399 \n",
      "  ------- {'fairness_loss': 2.091062, 'utility': 0.5723011, 'loss': -0.5095692}\n",
      "--- Step : 3400 \n",
      "  ------- {'fairness_loss': 2.091395, 'utility': 0.5723137, 'loss': -0.5095719}\n",
      "--- Step : 3401 \n",
      "  ------- {'fairness_loss': 2.091731, 'utility': 0.57232624, 'loss': -0.5095743}\n",
      "--- Step : 3402 \n",
      "  ------- {'fairness_loss': 2.0920672, 'utility': 0.5723389, 'loss': -0.50957686}\n",
      "--- Step : 3403 \n",
      "  ------- {'fairness_loss': 2.092403, 'utility': 0.5723516, 'loss': -0.5095795}\n",
      "--- Step : 3404 \n",
      "  ------- {'fairness_loss': 2.0927365, 'utility': 0.57236403, 'loss': -0.5095819}\n",
      "--- Step : 3405 \n",
      "  ------- {'fairness_loss': 2.0930731, 'utility': 0.5723767, 'loss': -0.50958455}\n",
      "--- Step : 3406 \n",
      "  ------- {'fairness_loss': 2.0934114, 'utility': 0.5723895, 'loss': -0.50958717}\n",
      "--- Step : 3407 \n",
      "  ------- {'fairness_loss': 2.093749, 'utility': 0.5724021, 'loss': -0.5095897}\n",
      "--- Step : 3408 \n",
      "  ------- {'fairness_loss': 2.094084, 'utility': 0.5724147, 'loss': -0.5095922}\n",
      "--- Step : 3409 \n",
      "  ------- {'fairness_loss': 2.0944245, 'utility': 0.5724276, 'loss': -0.50959486}\n",
      "--- Step : 3410 \n",
      "  ------- {'fairness_loss': 2.0947652, 'utility': 0.57244015, 'loss': -0.5095972}\n",
      "--- Step : 3411 \n",
      "  ------- {'fairness_loss': 2.0951016, 'utility': 0.572453, 'loss': -0.5096}\n",
      "--- Step : 3412 \n",
      "  ------- {'fairness_loss': 2.09544, 'utility': 0.5724656, 'loss': -0.5096024}\n",
      "--- Step : 3413 \n",
      "  ------- {'fairness_loss': 2.0957797, 'utility': 0.5724784, 'loss': -0.50960505}\n",
      "--- Step : 3414 \n",
      "  ------- {'fairness_loss': 2.0961196, 'utility': 0.57249135, 'loss': -0.5096078}\n",
      "--- Step : 3415 \n",
      "  ------- {'fairness_loss': 2.0964599, 'utility': 0.57250404, 'loss': -0.50961024}\n",
      "--- Step : 3416 \n",
      "  ------- {'fairness_loss': 2.0967999, 'utility': 0.57251674, 'loss': -0.50961274}\n",
      "--- Step : 3417 \n",
      "  ------- {'fairness_loss': 2.097142, 'utility': 0.57252973, 'loss': -0.5096155}\n",
      "--- Step : 3418 \n",
      "  ------- {'fairness_loss': 2.0974844, 'utility': 0.57254237, 'loss': -0.50961787}\n",
      "--- Step : 3419 \n",
      "  ------- {'fairness_loss': 2.097825, 'utility': 0.57255536, 'loss': -0.5096206}\n",
      "--- Step : 3420 \n",
      "  ------- {'fairness_loss': 2.0981681, 'utility': 0.5725682, 'loss': -0.5096231}\n",
      "--- Step : 3421 \n",
      "  ------- {'fairness_loss': 2.0985124, 'utility': 0.572581, 'loss': -0.5096256}\n",
      "--- Step : 3422 \n",
      "  ------- {'fairness_loss': 2.098854, 'utility': 0.572594, 'loss': -0.50962836}\n",
      "--- Step : 3423 \n",
      "  ------- {'fairness_loss': 2.0991952, 'utility': 0.57260686, 'loss': -0.50963104}\n",
      "--- Step : 3424 \n",
      "  ------- {'fairness_loss': 2.099539, 'utility': 0.57261974, 'loss': -0.50963354}\n",
      "--- Step : 3425 \n",
      "  ------- {'fairness_loss': 2.0998828, 'utility': 0.57263273, 'loss': -0.5096362}\n",
      "--- Step : 3426 \n",
      "  ------- {'fairness_loss': 2.1002285, 'utility': 0.5726456, 'loss': -0.5096387}\n",
      "--- Step : 3427 \n",
      "  ------- {'fairness_loss': 2.1005738, 'utility': 0.5726584, 'loss': -0.50964123}\n",
      "--- Step : 3428 \n",
      "  ------- {'fairness_loss': 2.100918, 'utility': 0.5726714, 'loss': -0.50964385}\n",
      "--- Step : 3429 \n",
      "  ------- {'fairness_loss': 2.1012638, 'utility': 0.57268447, 'loss': -0.50964653}\n",
      "--- Step : 3430 \n",
      "  ------- {'fairness_loss': 2.1016095, 'utility': 0.5726974, 'loss': -0.5096491}\n",
      "--- Step : 3431 \n",
      "  ------- {'fairness_loss': 2.1019533, 'utility': 0.57271045, 'loss': -0.50965184}\n",
      "--- Step : 3432 \n",
      "  ------- {'fairness_loss': 2.1023014, 'utility': 0.5727235, 'loss': -0.50965446}\n",
      "--- Step : 3433 \n",
      "  ------- {'fairness_loss': 2.102649, 'utility': 0.5727364, 'loss': -0.5096569}\n",
      "--- Step : 3434 \n",
      "  ------- {'fairness_loss': 2.1029944, 'utility': 0.57274956, 'loss': -0.5096597}\n",
      "--- Step : 3435 \n",
      "  ------- {'fairness_loss': 2.103342, 'utility': 0.5727628, 'loss': -0.5096625}\n",
      "--- Step : 3436 \n",
      "  ------- {'fairness_loss': 2.1036918, 'utility': 0.57277554, 'loss': -0.5096648}\n",
      "--- Step : 3437 \n",
      "  ------- {'fairness_loss': 2.1040387, 'utility': 0.57278883, 'loss': -0.5096677}\n",
      "--- Step : 3438 \n",
      "  ------- {'fairness_loss': 2.1043873, 'utility': 0.5728018, 'loss': -0.5096702}\n",
      "--- Step : 3439 \n",
      "  ------- {'fairness_loss': 2.1047347, 'utility': 0.57281494, 'loss': -0.5096729}\n",
      "--- Step : 3440 \n",
      "  ------- {'fairness_loss': 2.1050847, 'utility': 0.57282805, 'loss': -0.5096755}\n",
      "--- Step : 3441 \n",
      "  ------- {'fairness_loss': 2.105436, 'utility': 0.5728411, 'loss': -0.509678}\n",
      "--- Step : 3442 \n",
      "  ------- {'fairness_loss': 2.1057844, 'utility': 0.5728542, 'loss': -0.5096807}\n",
      "--- Step : 3443 \n",
      "  ------- {'fairness_loss': 2.1061335, 'utility': 0.57286733, 'loss': -0.5096833}\n",
      "--- Step : 3444 \n",
      "  ------- {'fairness_loss': 2.1064847, 'utility': 0.5728806, 'loss': -0.5096861}\n",
      "--- Step : 3445 \n",
      "  ------- {'fairness_loss': 2.1068347, 'utility': 0.5728937, 'loss': -0.5096886}\n",
      "--- Step : 3446 \n",
      "  ------- {'fairness_loss': 2.1071868, 'utility': 0.572907, 'loss': -0.50969136}\n",
      "--- Step : 3447 \n",
      "  ------- {'fairness_loss': 2.1075377, 'utility': 0.5729203, 'loss': -0.5096942}\n",
      "--- Step : 3448 \n",
      "  ------- {'fairness_loss': 2.1078877, 'utility': 0.57293344, 'loss': -0.5096968}\n",
      "--- Step : 3449 \n",
      "  ------- {'fairness_loss': 2.1082406, 'utility': 0.57294667, 'loss': -0.50969946}\n",
      "--- Step : 3450 \n",
      "  ------- {'fairness_loss': 2.1085937, 'utility': 0.5729598, 'loss': -0.50970197}\n",
      "--- Step : 3451 \n",
      "  ------- {'fairness_loss': 2.108943, 'utility': 0.5729732, 'loss': -0.5097049}\n",
      "--- Step : 3452 \n",
      "  ------- {'fairness_loss': 2.1092968, 'utility': 0.5729865, 'loss': -0.50970757}\n",
      "--- Step : 3453 \n",
      "  ------- {'fairness_loss': 2.1096497, 'utility': 0.57299954, 'loss': -0.5097101}\n",
      "--- Step : 3454 \n",
      "  ------- {'fairness_loss': 2.1100028, 'utility': 0.57301295, 'loss': -0.5097129}\n",
      "--- Step : 3455 \n",
      "  ------- {'fairness_loss': 2.1103568, 'utility': 0.5730262, 'loss': -0.5097155}\n",
      "--- Step : 3456 \n",
      "  ------- {'fairness_loss': 2.1107104, 'utility': 0.57303953, 'loss': -0.50971824}\n",
      "--- Step : 3457 \n",
      "  ------- {'fairness_loss': 2.1110632, 'utility': 0.57305276, 'loss': -0.50972086}\n",
      "--- Step : 3458 \n",
      "  ------- {'fairness_loss': 2.1114173, 'utility': 0.5730662, 'loss': -0.50972366}\n",
      "--- Step : 3459 \n",
      "  ------- {'fairness_loss': 2.111772, 'utility': 0.5730795, 'loss': -0.50972635}\n",
      "--- Step : 3460 \n",
      "  ------- {'fairness_loss': 2.1121268, 'utility': 0.57309264, 'loss': -0.50972885}\n",
      "--- Step : 3461 \n",
      "  ------- {'fairness_loss': 2.1124825, 'utility': 0.5731061, 'loss': -0.50973165}\n",
      "--- Step : 3462 \n",
      "  ------- {'fairness_loss': 2.1128383, 'utility': 0.57311946, 'loss': -0.50973433}\n",
      "--- Step : 3463 \n",
      "  ------- {'fairness_loss': 2.1131933, 'utility': 0.5731329, 'loss': -0.5097371}\n",
      "--- Step : 3464 \n",
      "  ------- {'fairness_loss': 2.1135497, 'utility': 0.5731462, 'loss': -0.50973976}\n",
      "--- Step : 3465 \n",
      "  ------- {'fairness_loss': 2.1139047, 'utility': 0.57315975, 'loss': -0.5097426}\n",
      "--- Step : 3466 \n",
      "  ------- {'fairness_loss': 2.1142597, 'utility': 0.573173, 'loss': -0.5097452}\n",
      "--- Step : 3467 \n",
      "  ------- {'fairness_loss': 2.1146166, 'utility': 0.57318634, 'loss': -0.50974786}\n",
      "--- Step : 3468 \n",
      "  ------- {'fairness_loss': 2.1149735, 'utility': 0.5731999, 'loss': -0.5097507}\n",
      "--- Step : 3469 \n",
      "  ------- {'fairness_loss': 2.115329, 'utility': 0.5732133, 'loss': -0.5097534}\n",
      "--- Step : 3470 \n",
      "  ------- {'fairness_loss': 2.1156862, 'utility': 0.57322675, 'loss': -0.50975615}\n",
      "--- Step : 3471 \n",
      "  ------- {'fairness_loss': 2.1160438, 'utility': 0.5732401, 'loss': -0.5097588}\n",
      "--- Step : 3472 \n",
      "  ------- {'fairness_loss': 2.1164021, 'utility': 0.5732536, 'loss': -0.5097615}\n",
      "--- Step : 3473 \n",
      "  ------- {'fairness_loss': 2.1167605, 'utility': 0.573267, 'loss': -0.5097642}\n",
      "--- Step : 3474 \n",
      "  ------- {'fairness_loss': 2.1171165, 'utility': 0.5732806, 'loss': -0.50976706}\n",
      "--- Step : 3475 \n",
      "  ------- {'fairness_loss': 2.1174743, 'utility': 0.5732939, 'loss': -0.5097697}\n",
      "--- Step : 3476 \n",
      "  ------- {'fairness_loss': 2.1178331, 'utility': 0.57330745, 'loss': -0.5097725}\n",
      "--- Step : 3477 \n",
      "  ------- {'fairness_loss': 2.118191, 'utility': 0.5733211, 'loss': -0.5097754}\n",
      "--- Step : 3478 \n",
      "  ------- {'fairness_loss': 2.1185474, 'utility': 0.57333446, 'loss': -0.509778}\n",
      "--- Step : 3479 \n",
      "  ------- {'fairness_loss': 2.1189072, 'utility': 0.57334805, 'loss': -0.5097808}\n",
      "--- Step : 3480 \n",
      "  ------- {'fairness_loss': 2.1192658, 'utility': 0.5733614, 'loss': -0.50978345}\n",
      "--- Step : 3481 \n",
      "  ------- {'fairness_loss': 2.119626, 'utility': 0.5733751, 'loss': -0.5097863}\n",
      "--- Step : 3482 \n",
      "  ------- {'fairness_loss': 2.1199853, 'utility': 0.5733887, 'loss': -0.5097891}\n",
      "--- Step : 3483 \n",
      "  ------- {'fairness_loss': 2.1203454, 'utility': 0.5734023, 'loss': -0.5097919}\n",
      "--- Step : 3484 \n",
      "  ------- {'fairness_loss': 2.1207032, 'utility': 0.57341564, 'loss': -0.50979453}\n",
      "--- Step : 3485 \n",
      "  ------- {'fairness_loss': 2.1210642, 'utility': 0.5734292, 'loss': -0.50979733}\n",
      "--- Step : 3486 \n",
      "  ------- {'fairness_loss': 2.1214228, 'utility': 0.5734429, 'loss': -0.5098002}\n",
      "--- Step : 3487 \n",
      "  ------- {'fairness_loss': 2.1217828, 'utility': 0.57345647, 'loss': -0.509803}\n",
      "--- Step : 3488 \n",
      "  ------- {'fairness_loss': 2.1221416, 'utility': 0.5734699, 'loss': -0.5098056}\n",
      "--- Step : 3489 \n",
      "  ------- {'fairness_loss': 2.122504, 'utility': 0.57348347, 'loss': -0.50980836}\n",
      "--- Step : 3490 \n",
      "  ------- {'fairness_loss': 2.122862, 'utility': 0.5734972, 'loss': -0.5098113}\n",
      "--- Step : 3491 \n",
      "  ------- {'fairness_loss': 2.1232214, 'utility': 0.57351077, 'loss': -0.50981414}\n",
      "--- Step : 3492 \n",
      "  ------- {'fairness_loss': 2.1235838, 'utility': 0.57352436, 'loss': -0.5098168}\n",
      "--- Step : 3493 \n",
      "  ------- {'fairness_loss': 2.1239436, 'utility': 0.5735378, 'loss': -0.5098195}\n",
      "--- Step : 3494 \n",
      "  ------- {'fairness_loss': 2.124306, 'utility': 0.5735516, 'loss': -0.5098224}\n",
      "--- Step : 3495 \n",
      "  ------- {'fairness_loss': 2.1246674, 'utility': 0.573565, 'loss': -0.509825}\n",
      "--- Step : 3496 \n",
      "  ------- {'fairness_loss': 2.125028, 'utility': 0.57357883, 'loss': -0.509828}\n",
      "--- Step : 3497 \n",
      "  ------- {'fairness_loss': 2.1253884, 'utility': 0.57359236, 'loss': -0.5098307}\n",
      "--- Step : 3498 \n",
      "  ------- {'fairness_loss': 2.1257489, 'utility': 0.57360613, 'loss': -0.5098337}\n",
      "--- Step : 3499 \n",
      "  ------- {'fairness_loss': 2.1261122, 'utility': 0.5736196, 'loss': -0.50983626}\n",
      "--- Step : 3500 \n",
      "  ------- {'fairness_loss': 2.1264718, 'utility': 0.5736334, 'loss': -0.50983924}\n",
      "--- Step : 3501 \n",
      "  ------- {'fairness_loss': 2.126831, 'utility': 0.573647, 'loss': -0.5098421}\n",
      "--- Step : 3502 \n",
      "  ------- {'fairness_loss': 2.127191, 'utility': 0.5736607, 'loss': -0.50984496}\n",
      "--- Step : 3503 \n",
      "  ------- {'fairness_loss': 2.1275544, 'utility': 0.57367414, 'loss': -0.5098475}\n",
      "--- Step : 3504 \n",
      "  ------- {'fairness_loss': 2.1279151, 'utility': 0.573688, 'loss': -0.5098505}\n",
      "--- Step : 3505 \n",
      "  ------- {'fairness_loss': 2.128276, 'utility': 0.5737015, 'loss': -0.50985324}\n",
      "--- Step : 3506 \n",
      "  ------- {'fairness_loss': 2.1286385, 'utility': 0.5737153, 'loss': -0.50985616}\n",
      "--- Step : 3507 \n",
      "  ------- {'fairness_loss': 2.1290007, 'utility': 0.57372886, 'loss': -0.50985885}\n",
      "--- Step : 3508 \n",
      "  ------- {'fairness_loss': 2.1293619, 'utility': 0.57374257, 'loss': -0.5098617}\n",
      "--- Step : 3509 \n",
      "  ------- {'fairness_loss': 2.1297243, 'utility': 0.5737562, 'loss': -0.5098645}\n",
      "--- Step : 3510 \n",
      "  ------- {'fairness_loss': 2.1300855, 'utility': 0.57377005, 'loss': -0.5098675}\n",
      "--- Step : 3511 \n",
      "  ------- {'fairness_loss': 2.1304476, 'utility': 0.57378364, 'loss': -0.50987023}\n",
      "--- Step : 3512 \n",
      "  ------- {'fairness_loss': 2.1308103, 'utility': 0.57379735, 'loss': -0.50987303}\n",
      "--- Step : 3513 \n",
      "  ------- {'fairness_loss': 2.1311698, 'utility': 0.57381105, 'loss': -0.50987595}\n",
      "--- Step : 3514 \n",
      "  ------- {'fairness_loss': 2.131531, 'utility': 0.57382476, 'loss': -0.5098788}\n",
      "--- Step : 3515 \n",
      "  ------- {'fairness_loss': 2.1318934, 'utility': 0.5738385, 'loss': -0.5098817}\n",
      "--- Step : 3516 \n",
      "  ------- {'fairness_loss': 2.1322548, 'utility': 0.57385224, 'loss': -0.5098846}\n",
      "--- Step : 3517 \n",
      "  ------- {'fairness_loss': 2.1326182, 'utility': 0.57386583, 'loss': -0.5098873}\n",
      "--- Step : 3518 \n",
      "  ------- {'fairness_loss': 2.1329784, 'utility': 0.5738796, 'loss': -0.50989026}\n",
      "--- Step : 3519 \n",
      "  ------- {'fairness_loss': 2.1333392, 'utility': 0.57389337, 'loss': -0.5098932}\n",
      "--- Step : 3520 \n",
      "  ------- {'fairness_loss': 2.1337006, 'utility': 0.5739071, 'loss': -0.50989604}\n",
      "--- Step : 3521 \n",
      "  ------- {'fairness_loss': 2.1340647, 'utility': 0.57392067, 'loss': -0.5098987}\n",
      "--- Step : 3522 \n",
      "  ------- {'fairness_loss': 2.1344247, 'utility': 0.5739345, 'loss': -0.50990176}\n",
      "--- Step : 3523 \n",
      "  ------- {'fairness_loss': 2.1347864, 'utility': 0.57394814, 'loss': -0.50990456}\n",
      "--- Step : 3524 \n",
      "  ------- {'fairness_loss': 2.1351469, 'utility': 0.573962, 'loss': -0.50990754}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3525 \n",
      "  ------- {'fairness_loss': 2.1355085, 'utility': 0.57397556, 'loss': -0.5099103}\n",
      "--- Step : 3526 \n",
      "  ------- {'fairness_loss': 2.1358707, 'utility': 0.57398933, 'loss': -0.5099132}\n",
      "--- Step : 3527 \n",
      "  ------- {'fairness_loss': 2.1362329, 'utility': 0.57400304, 'loss': -0.50991607}\n",
      "--- Step : 3528 \n",
      "  ------- {'fairness_loss': 2.136594, 'utility': 0.57401675, 'loss': -0.5099189}\n",
      "--- Step : 3529 \n",
      "  ------- {'fairness_loss': 2.1369529, 'utility': 0.57403046, 'loss': -0.50992185}\n",
      "--- Step : 3530 \n",
      "  ------- {'fairness_loss': 2.1373134, 'utility': 0.57404417, 'loss': -0.50992477}\n",
      "--- Step : 3531 \n",
      "  ------- {'fairness_loss': 2.1376753, 'utility': 0.57405794, 'loss': -0.5099277}\n",
      "--- Step : 3532 \n",
      "  ------- {'fairness_loss': 2.1380372, 'utility': 0.57407176, 'loss': -0.5099307}\n",
      "--- Step : 3533 \n",
      "  ------- {'fairness_loss': 2.1383975, 'utility': 0.57408535, 'loss': -0.5099334}\n",
      "--- Step : 3534 \n",
      "  ------- {'fairness_loss': 2.1387582, 'utility': 0.5740991, 'loss': -0.5099364}\n",
      "--- Step : 3535 \n",
      "  ------- {'fairness_loss': 2.1391187, 'utility': 0.5741128, 'loss': -0.5099392}\n",
      "--- Step : 3536 \n",
      "  ------- {'fairness_loss': 2.1394792, 'utility': 0.5741267, 'loss': -0.50994235}\n",
      "--- Step : 3537 \n",
      "  ------- {'fairness_loss': 2.139839, 'utility': 0.5741402, 'loss': -0.50994503}\n",
      "--- Step : 3538 \n",
      "  ------- {'fairness_loss': 2.140199, 'utility': 0.5741541, 'loss': -0.50994813}\n",
      "--- Step : 3539 \n",
      "  ------- {'fairness_loss': 2.1405592, 'utility': 0.5741677, 'loss': -0.50995094}\n",
      "--- Step : 3540 \n",
      "  ------- {'fairness_loss': 2.140921, 'utility': 0.5741815, 'loss': -0.50995386}\n",
      "--- Step : 3541 \n",
      "  ------- {'fairness_loss': 2.1412792, 'utility': 0.57419515, 'loss': -0.5099568}\n",
      "--- Step : 3542 \n",
      "  ------- {'fairness_loss': 2.1416388, 'utility': 0.5742089, 'loss': -0.50995976}\n",
      "--- Step : 3543 \n",
      "  ------- {'fairness_loss': 2.1419992, 'utility': 0.57422256, 'loss': -0.50996256}\n",
      "--- Step : 3544 \n",
      "  ------- {'fairness_loss': 2.1423583, 'utility': 0.5742363, 'loss': -0.50996554}\n",
      "--- Step : 3545 \n",
      "  ------- {'fairness_loss': 2.1427174, 'utility': 0.5742499, 'loss': -0.5099684}\n",
      "--- Step : 3546 \n",
      "  ------- {'fairness_loss': 2.143076, 'utility': 0.5742638, 'loss': -0.50997156}\n",
      "--- Step : 3547 \n",
      "  ------- {'fairness_loss': 2.1434345, 'utility': 0.57427734, 'loss': -0.5099743}\n",
      "--- Step : 3548 \n",
      "  ------- {'fairness_loss': 2.1437917, 'utility': 0.574291, 'loss': -0.5099772}\n",
      "--- Step : 3549 \n",
      "  ------- {'fairness_loss': 2.1441517, 'utility': 0.5743049, 'loss': -0.5099803}\n",
      "--- Step : 3550 \n",
      "  ------- {'fairness_loss': 2.1445088, 'utility': 0.57431847, 'loss': -0.5099832}\n",
      "--- Step : 3551 \n",
      "  ------- {'fairness_loss': 2.1448662, 'utility': 0.5743322, 'loss': -0.50998616}\n",
      "--- Step : 3552 \n",
      "  ------- {'fairness_loss': 2.1452253, 'utility': 0.5743458, 'loss': -0.5099891}\n",
      "--- Step : 3553 \n",
      "  ------- {'fairness_loss': 2.145583, 'utility': 0.5743596, 'loss': -0.5099921}\n",
      "--- Step : 3554 \n",
      "  ------- {'fairness_loss': 2.1459408, 'utility': 0.5743732, 'loss': -0.509995}\n",
      "--- Step : 3555 \n",
      "  ------- {'fairness_loss': 2.146297, 'utility': 0.574387, 'loss': -0.5099981}\n",
      "--- Step : 3556 \n",
      "  ------- {'fairness_loss': 2.1466544, 'utility': 0.57440066, 'loss': -0.51000106}\n",
      "--- Step : 3557 \n",
      "  ------- {'fairness_loss': 2.147013, 'utility': 0.5744144, 'loss': -0.510004}\n",
      "--- Step : 3558 \n",
      "  ------- {'fairness_loss': 2.1473672, 'utility': 0.57442796, 'loss': -0.51000696}\n",
      "--- Step : 3559 \n",
      "  ------- {'fairness_loss': 2.1477263, 'utility': 0.5744417, 'loss': -0.5100099}\n",
      "--- Step : 3560 \n",
      "  ------- {'fairness_loss': 2.1480815, 'utility': 0.57445514, 'loss': -0.5100127}\n",
      "--- Step : 3561 \n",
      "  ------- {'fairness_loss': 2.1484373, 'utility': 0.57446873, 'loss': -0.5100156}\n",
      "--- Step : 3562 \n",
      "  ------- {'fairness_loss': 2.1487916, 'utility': 0.57448244, 'loss': -0.5100187}\n",
      "--- Step : 3563 \n",
      "  ------- {'fairness_loss': 2.1491497, 'utility': 0.5744961, 'loss': -0.5100216}\n",
      "--- Step : 3564 \n",
      "  ------- {'fairness_loss': 2.149506, 'utility': 0.5745098, 'loss': -0.5100246}\n",
      "--- Step : 3565 \n",
      "  ------- {'fairness_loss': 2.1498578, 'utility': 0.57452345, 'loss': -0.5100277}\n",
      "--- Step : 3566 \n",
      "  ------- {'fairness_loss': 2.1502144, 'utility': 0.5745371, 'loss': -0.5100307}\n",
      "--- Step : 3567 \n",
      "  ------- {'fairness_loss': 2.150568, 'utility': 0.5745507, 'loss': -0.51003367}\n",
      "--- Step : 3568 \n",
      "  ------- {'fairness_loss': 2.1509202, 'utility': 0.5745643, 'loss': -0.5100367}\n",
      "--- Step : 3569 \n",
      "  ------- {'fairness_loss': 2.1512744, 'utility': 0.57457787, 'loss': -0.5100396}\n",
      "--- Step : 3570 \n",
      "  ------- {'fairness_loss': 2.1516285, 'utility': 0.5745916, 'loss': -0.5100427}\n",
      "--- Step : 3571 \n",
      "  ------- {'fairness_loss': 2.151982, 'utility': 0.57460505, 'loss': -0.5100456}\n",
      "--- Step : 3572 \n",
      "  ------- {'fairness_loss': 2.152336, 'utility': 0.5746185, 'loss': -0.51004845}\n",
      "--- Step : 3573 \n",
      "  ------- {'fairness_loss': 2.1526878, 'utility': 0.5746322, 'loss': -0.5100516}\n",
      "--- Step : 3574 \n",
      "  ------- {'fairness_loss': 2.1530411, 'utility': 0.5746457, 'loss': -0.51005447}\n",
      "--- Step : 3575 \n",
      "  ------- {'fairness_loss': 2.1533947, 'utility': 0.5746593, 'loss': -0.51005745}\n",
      "--- Step : 3576 \n",
      "  ------- {'fairness_loss': 2.1537454, 'utility': 0.5746729, 'loss': -0.51006055}\n",
      "--- Step : 3577 \n",
      "  ------- {'fairness_loss': 2.154097, 'utility': 0.5746865, 'loss': -0.51006365}\n",
      "--- Step : 3578 \n",
      "  ------- {'fairness_loss': 2.1544478, 'utility': 0.57470006, 'loss': -0.5100666}\n",
      "--- Step : 3579 \n",
      "  ------- {'fairness_loss': 2.1548002, 'utility': 0.57471365, 'loss': -0.51006967}\n",
      "--- Step : 3580 \n",
      "  ------- {'fairness_loss': 2.1551507, 'utility': 0.5747271, 'loss': -0.5100726}\n",
      "--- Step : 3581 \n",
      "  ------- {'fairness_loss': 2.1554997, 'utility': 0.5747405, 'loss': -0.51007557}\n",
      "--- Step : 3582 \n",
      "  ------- {'fairness_loss': 2.155849, 'utility': 0.5747542, 'loss': -0.5100787}\n",
      "--- Step : 3583 \n",
      "  ------- {'fairness_loss': 2.1561975, 'utility': 0.57476765, 'loss': -0.5100817}\n",
      "--- Step : 3584 \n",
      "  ------- {'fairness_loss': 2.1565468, 'utility': 0.5747811, 'loss': -0.51008475}\n",
      "--- Step : 3585 \n",
      "  ------- {'fairness_loss': 2.156897, 'utility': 0.57479453, 'loss': -0.5100876}\n",
      "--- Step : 3586 \n",
      "  ------- {'fairness_loss': 2.1572454, 'utility': 0.574808, 'loss': -0.51009065}\n",
      "--- Step : 3587 \n",
      "  ------- {'fairness_loss': 2.157593, 'utility': 0.57482153, 'loss': -0.51009375}\n",
      "--- Step : 3588 \n",
      "  ------- {'fairness_loss': 2.1579409, 'utility': 0.57483494, 'loss': -0.5100967}\n",
      "--- Step : 3589 \n",
      "  ------- {'fairness_loss': 2.1582878, 'utility': 0.57484853, 'loss': -0.5100999}\n",
      "--- Step : 3590 \n",
      "  ------- {'fairness_loss': 2.1586356, 'utility': 0.57486194, 'loss': -0.51010287}\n",
      "--- Step : 3591 \n",
      "  ------- {'fairness_loss': 2.1589813, 'utility': 0.5748755, 'loss': -0.510106}\n",
      "--- Step : 3592 \n",
      "  ------- {'fairness_loss': 2.159329, 'utility': 0.5748888, 'loss': -0.51010895}\n",
      "--- Step : 3593 \n",
      "  ------- {'fairness_loss': 2.1596744, 'utility': 0.57490224, 'loss': -0.510112}\n",
      "--- Step : 3594 \n",
      "  ------- {'fairness_loss': 2.1600306, 'utility': 0.5749156, 'loss': -0.51011467}\n",
      "--- Step : 3595 \n",
      "  ------- {'fairness_loss': 2.1601646, 'utility': 0.5749226, 'loss': -0.5101177}\n",
      "--- Step : 3596 \n",
      "  ------- {'fairness_loss': 2.1600971, 'utility': 0.5749238, 'loss': -0.51012087}\n",
      "--- Step : 3597 \n",
      "  ------- {'fairness_loss': 2.159867, 'utility': 0.57491976, 'loss': -0.5101237}\n",
      "--- Step : 3598 \n",
      "  ------- {'fairness_loss': 2.159699, 'utility': 0.57491773, 'loss': -0.51012677}\n",
      "--- Step : 3599 \n",
      "  ------- {'fairness_loss': 2.159585, 'utility': 0.57491714, 'loss': -0.5101296}\n",
      "--- Step : 3600 \n",
      "  ------- {'fairness_loss': 2.1595173, 'utility': 0.574918, 'loss': -0.51013243}\n",
      "--- Step : 3601 \n",
      "  ------- {'fairness_loss': 2.1594937, 'utility': 0.5749203, 'loss': -0.5101355}\n",
      "--- Step : 3602 \n",
      "  ------- {'fairness_loss': 2.159512, 'utility': 0.5749237, 'loss': -0.51013833}\n",
      "--- Step : 3603 \n",
      "  ------- {'fairness_loss': 2.1595635, 'utility': 0.5749283, 'loss': -0.5101414}\n",
      "--- Step : 3604 \n",
      "  ------- {'fairness_loss': 2.1596494, 'utility': 0.5749338, 'loss': -0.51014435}\n",
      "--- Step : 3605 \n",
      "  ------- {'fairness_loss': 2.159766, 'utility': 0.57494026, 'loss': -0.5101473}\n",
      "--- Step : 3606 \n",
      "  ------- {'fairness_loss': 2.1599095, 'utility': 0.57494754, 'loss': -0.51015025}\n",
      "--- Step : 3607 \n",
      "  ------- {'fairness_loss': 2.1600761, 'utility': 0.57495564, 'loss': -0.51015335}\n",
      "--- Step : 3608 \n",
      "  ------- {'fairness_loss': 2.1602702, 'utility': 0.57496434, 'loss': -0.5101562}\n",
      "--- Step : 3609 \n",
      "  ------- {'fairness_loss': 2.1604812, 'utility': 0.5749737, 'loss': -0.51015925}\n",
      "--- Step : 3610 \n",
      "  ------- {'fairness_loss': 2.1607103, 'utility': 0.5749836, 'loss': -0.5101623}\n",
      "--- Step : 3611 \n",
      "  ------- {'fairness_loss': 2.1609554, 'utility': 0.5749939, 'loss': -0.5101652}\n",
      "--- Step : 3612 \n",
      "  ------- {'fairness_loss': 2.1612177, 'utility': 0.57500494, 'loss': -0.51016843}\n",
      "--- Step : 3613 \n",
      "  ------- {'fairness_loss': 2.1614935, 'utility': 0.57501614, 'loss': -0.51017135}\n",
      "--- Step : 3614 \n",
      "  ------- {'fairness_loss': 2.1617835, 'utility': 0.57502776, 'loss': -0.5101743}\n",
      "--- Step : 3615 \n",
      "  ------- {'fairness_loss': 2.1618721, 'utility': 0.57503355, 'loss': -0.5101774}\n",
      "--- Step : 3616 \n",
      "  ------- {'fairness_loss': 2.1617799, 'utility': 0.5750337, 'loss': -0.51018035}\n",
      "--- Step : 3617 \n",
      "  ------- {'fairness_loss': 2.1617393, 'utility': 0.57503545, 'loss': -0.5101833}\n",
      "--- Step : 3618 \n",
      "  ------- {'fairness_loss': 2.161747, 'utility': 0.5750387, 'loss': -0.51018625}\n",
      "--- Step : 3619 \n",
      "  ------- {'fairness_loss': 2.1617932, 'utility': 0.5750429, 'loss': -0.5101891}\n",
      "--- Step : 3620 \n",
      "  ------- {'fairness_loss': 2.161875, 'utility': 0.57504845, 'loss': -0.5101922}\n",
      "--- Step : 3621 \n",
      "  ------- {'fairness_loss': 2.1619935, 'utility': 0.5750551, 'loss': -0.5101953}\n",
      "--- Step : 3622 \n",
      "  ------- {'fairness_loss': 2.162143, 'utility': 0.57506233, 'loss': -0.51019806}\n",
      "--- Step : 3623 \n",
      "  ------- {'fairness_loss': 2.1623158, 'utility': 0.5750706, 'loss': -0.51020116}\n",
      "--- Step : 3624 \n",
      "  ------- {'fairness_loss': 2.1625178, 'utility': 0.57507974, 'loss': -0.5102042}\n",
      "--- Step : 3625 \n",
      "  ------- {'fairness_loss': 2.1627407, 'utility': 0.57508934, 'loss': -0.5102071}\n",
      "--- Step : 3626 \n",
      "  ------- {'fairness_loss': 2.1629844, 'utility': 0.5750998, 'loss': -0.5102103}\n",
      "--- Step : 3627 \n",
      "  ------- {'fairness_loss': 2.1630383, 'utility': 0.5751045, 'loss': -0.5102133}\n",
      "--- Step : 3628 \n",
      "  ------- {'fairness_loss': 2.1631303, 'utility': 0.5751102, 'loss': -0.5102163}\n",
      "--- Step : 3629 \n",
      "  ------- {'fairness_loss': 2.163257, 'utility': 0.5751171, 'loss': -0.5102194}\n",
      "--- Step : 3630 \n",
      "  ------- {'fairness_loss': 2.1634147, 'utility': 0.5751246, 'loss': -0.5102222}\n",
      "--- Step : 3631 \n",
      "  ------- {'fairness_loss': 2.1633892, 'utility': 0.5751269, 'loss': -0.51022524}\n",
      "--- Step : 3632 \n",
      "  ------- {'fairness_loss': 2.163414, 'utility': 0.5751305, 'loss': -0.5102281}\n",
      "--- Step : 3633 \n",
      "  ------- {'fairness_loss': 2.1634805, 'utility': 0.57513547, 'loss': -0.5102311}\n",
      "--- Step : 3634 \n",
      "  ------- {'fairness_loss': 2.1635842, 'utility': 0.5751416, 'loss': -0.51023406}\n",
      "--- Step : 3635 \n",
      "  ------- {'fairness_loss': 2.1637213, 'utility': 0.5751487, 'loss': -0.51023704}\n",
      "--- Step : 3636 \n",
      "  ------- {'fairness_loss': 2.1638932, 'utility': 0.575157, 'loss': -0.5102402}\n",
      "--- Step : 3637 \n",
      "  ------- {'fairness_loss': 2.1640913, 'utility': 0.57516587, 'loss': -0.5102431}\n",
      "--- Step : 3638 \n",
      "  ------- {'fairness_loss': 2.1643229, 'utility': 0.57517564, 'loss': -0.510246}\n",
      "--- Step : 3639 \n",
      "  ------- {'fairness_loss': 2.1643555, 'utility': 0.57517993, 'loss': -0.51024926}\n",
      "--- Step : 3640 \n",
      "  ------- {'fairness_loss': 2.1644366, 'utility': 0.57518524, 'loss': -0.5102521}\n",
      "--- Step : 3641 \n",
      "  ------- {'fairness_loss': 2.1645572, 'utility': 0.5751918, 'loss': -0.5102551}\n",
      "--- Step : 3642 \n",
      "  ------- {'fairness_loss': 2.1647136, 'utility': 0.5751996, 'loss': -0.5102582}\n",
      "--- Step : 3643 \n",
      "  ------- {'fairness_loss': 2.1646895, 'utility': 0.5752018, 'loss': -0.5102611}\n",
      "--- Step : 3644 \n",
      "  ------- {'fairness_loss': 2.1647186, 'utility': 0.5752056, 'loss': -0.51026404}\n",
      "--- Step : 3645 \n",
      "  ------- {'fairness_loss': 2.164789, 'utility': 0.5752107, 'loss': -0.510267}\n",
      "--- Step : 3646 \n",
      "  ------- {'fairness_loss': 2.1649013, 'utility': 0.57521707, 'loss': -0.51027}\n",
      "--- Step : 3647 \n",
      "  ------- {'fairness_loss': 2.1650515, 'utility': 0.5752245, 'loss': -0.510273}\n",
      "--- Step : 3648 \n",
      "  ------- {'fairness_loss': 2.165233, 'utility': 0.57523304, 'loss': -0.5102761}\n",
      "--- Step : 3649 \n",
      "  ------- {'fairness_loss': 2.1654444, 'utility': 0.57524246, 'loss': -0.5102791}\n",
      "--- Step : 3650 \n",
      "  ------- {'fairness_loss': 2.1656897, 'utility': 0.5752526, 'loss': -0.5102819}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3651 \n",
      "  ------- {'fairness_loss': 2.1657395, 'utility': 0.5752573, 'loss': -0.51028514}\n",
      "--- Step : 3652 \n",
      "  ------- {'fairness_loss': 2.16563, 'utility': 0.575257, 'loss': -0.5102881}\n",
      "--- Step : 3653 \n",
      "  ------- {'fairness_loss': 2.1655838, 'utility': 0.57525843, 'loss': -0.5102909}\n",
      "--- Step : 3654 \n",
      "  ------- {'fairness_loss': 2.1655881, 'utility': 0.57526153, 'loss': -0.5102939}\n",
      "--- Step : 3655 \n",
      "  ------- {'fairness_loss': 2.1656432, 'utility': 0.5752661, 'loss': -0.5102968}\n",
      "--- Step : 3656 \n",
      "  ------- {'fairness_loss': 2.1657445, 'utility': 0.57527226, 'loss': -0.5102999}\n",
      "--- Step : 3657 \n",
      "  ------- {'fairness_loss': 2.165886, 'utility': 0.5752795, 'loss': -0.5103029}\n",
      "--- Step : 3658 \n",
      "  ------- {'fairness_loss': 2.166062, 'utility': 0.5752877, 'loss': -0.5103058}\n",
      "--- Step : 3659 \n",
      "  ------- {'fairness_loss': 2.1662712, 'utility': 0.57529706, 'loss': -0.5103089}\n",
      "--- Step : 3660 \n",
      "  ------- {'fairness_loss': 2.1665094, 'utility': 0.5753072, 'loss': -0.5103119}\n",
      "--- Step : 3661 \n",
      "  ------- {'fairness_loss': 2.1667755, 'utility': 0.5753183, 'loss': -0.510315}\n",
      "--- Step : 3662 \n",
      "  ------- {'fairness_loss': 2.16707, 'utility': 0.5753302, 'loss': -0.5103181}\n",
      "--- Step : 3663 \n",
      "  ------- {'fairness_loss': 2.167174, 'utility': 0.5753364, 'loss': -0.5103212}\n",
      "--- Step : 3664 \n",
      "  ------- {'fairness_loss': 2.1671095, 'utility': 0.5753374, 'loss': -0.5103241}\n",
      "--- Step : 3665 \n",
      "  ------- {'fairness_loss': 2.1671069, 'utility': 0.5753402, 'loss': -0.510327}\n",
      "--- Step : 3666 \n",
      "  ------- {'fairness_loss': 2.1671553, 'utility': 0.5753446, 'loss': -0.51032996}\n",
      "--- Step : 3667 \n",
      "  ------- {'fairness_loss': 2.1672523, 'utility': 0.5753504, 'loss': -0.5103328}\n",
      "--- Step : 3668 \n",
      "  ------- {'fairness_loss': 2.1673894, 'utility': 0.57535756, 'loss': -0.51033586}\n",
      "--- Step : 3669 \n",
      "  ------- {'fairness_loss': 2.1675658, 'utility': 0.57536596, 'loss': -0.51033896}\n",
      "--- Step : 3670 \n",
      "  ------- {'fairness_loss': 2.167775, 'utility': 0.57537526, 'loss': -0.510342}\n",
      "--- Step : 3671 \n",
      "  ------- {'fairness_loss': 2.1680171, 'utility': 0.5753855, 'loss': -0.510345}\n",
      "--- Step : 3672 \n",
      "  ------- {'fairness_loss': 2.16829, 'utility': 0.5753967, 'loss': -0.510348}\n",
      "--- Step : 3673 \n",
      "  ------- {'fairness_loss': 2.1683793, 'utility': 0.5754026, 'loss': -0.51035124}\n",
      "--- Step : 3674 \n",
      "  ------- {'fairness_loss': 2.1685116, 'utility': 0.57540953, 'loss': -0.51035416}\n",
      "--- Step : 3675 \n",
      "  ------- {'fairness_loss': 2.1684785, 'utility': 0.57541144, 'loss': -0.5103571}\n",
      "--- Step : 3676 \n",
      "  ------- {'fairness_loss': 2.1685023, 'utility': 0.57541513, 'loss': -0.51036006}\n",
      "--- Step : 3677 \n",
      "  ------- {'fairness_loss': 2.1685786, 'utility': 0.57542044, 'loss': -0.5103631}\n",
      "--- Step : 3678 \n",
      "  ------- {'fairness_loss': 2.1686993, 'utility': 0.575427, 'loss': -0.510366}\n",
      "--- Step : 3679 \n",
      "  ------- {'fairness_loss': 2.168862, 'utility': 0.5754348, 'loss': -0.51036894}\n",
      "--- Step : 3680 \n",
      "  ------- {'fairness_loss': 2.1690624, 'utility': 0.57544386, 'loss': -0.510372}\n",
      "--- Step : 3681 \n",
      "  ------- {'fairness_loss': 2.1692958, 'utility': 0.5754542, 'loss': -0.5103753}\n",
      "--- Step : 3682 \n",
      "  ------- {'fairness_loss': 2.1695652, 'utility': 0.575465, 'loss': -0.51037806}\n",
      "--- Step : 3683 \n",
      "  ------- {'fairness_loss': 2.1696491, 'utility': 0.5754707, 'loss': -0.5103812}\n",
      "--- Step : 3684 \n",
      "  ------- {'fairness_loss': 2.1695745, 'utility': 0.57547116, 'loss': -0.5103839}\n",
      "--- Step : 3685 \n",
      "  ------- {'fairness_loss': 2.1695645, 'utility': 0.575474, 'loss': -0.51038706}\n",
      "--- Step : 3686 \n",
      "  ------- {'fairness_loss': 2.1696098, 'utility': 0.57547826, 'loss': -0.51039}\n",
      "--- Step : 3687 \n",
      "  ------- {'fairness_loss': 2.1697054, 'utility': 0.57548416, 'loss': -0.510393}\n",
      "--- Step : 3688 \n",
      "  ------- {'fairness_loss': 2.169847, 'utility': 0.5754914, 'loss': -0.510396}\n",
      "--- Step : 3689 \n",
      "  ------- {'fairness_loss': 2.1700306, 'utility': 0.5755, 'loss': -0.5103991}\n",
      "--- Step : 3690 \n",
      "  ------- {'fairness_loss': 2.1702497, 'utility': 0.57550967, 'loss': -0.5104022}\n",
      "--- Step : 3691 \n",
      "  ------- {'fairness_loss': 2.170505, 'utility': 0.57552034, 'loss': -0.5104052}\n",
      "--- Step : 3692 \n",
      "  ------- {'fairness_loss': 2.17079, 'utility': 0.575532, 'loss': -0.51040834}\n",
      "--- Step : 3693 \n",
      "  ------- {'fairness_loss': 2.1711152, 'utility': 0.5755444, 'loss': -0.51041096}\n",
      "--- Step : 3694 \n",
      "  ------- {'fairness_loss': 2.1712458, 'utility': 0.5755514, 'loss': -0.510414}\n",
      "--- Step : 3695 \n",
      "  ------- {'fairness_loss': 2.1712031, 'utility': 0.57555336, 'loss': -0.5104173}\n",
      "--- Step : 3696 \n",
      "  ------- {'fairness_loss': 2.1710234, 'utility': 0.57555073, 'loss': -0.51042}\n",
      "--- Step : 3697 \n",
      "  ------- {'fairness_loss': 2.1709216, 'utility': 0.5755507, 'loss': -0.510423}\n",
      "--- Step : 3698 \n",
      "  ------- {'fairness_loss': 2.1708858, 'utility': 0.57555246, 'loss': -0.51042587}\n",
      "--- Step : 3699 \n",
      "  ------- {'fairness_loss': 2.1709118, 'utility': 0.57555634, 'loss': -0.51042897}\n",
      "--- Step : 3700 \n",
      "  ------- {'fairness_loss': 2.1709914, 'utility': 0.5755616, 'loss': -0.5104318}\n",
      "--- Step : 3701 \n",
      "  ------- {'fairness_loss': 2.1711214, 'utility': 0.57556844, 'loss': -0.5104348}\n",
      "--- Step : 3702 \n",
      "  ------- {'fairness_loss': 2.1712966, 'utility': 0.57557684, 'loss': -0.51043797}\n",
      "--- Step : 3703 \n",
      "  ------- {'fairness_loss': 2.171513, 'utility': 0.57558644, 'loss': -0.51044106}\n",
      "--- Step : 3704 \n",
      "  ------- {'fairness_loss': 2.171766, 'utility': 0.575597, 'loss': -0.510444}\n",
      "--- Step : 3705 \n",
      "  ------- {'fairness_loss': 2.1720498, 'utility': 0.5756087, 'loss': -0.5104472}\n",
      "--- Step : 3706 \n",
      "  ------- {'fairness_loss': 2.1723654, 'utility': 0.5756213, 'loss': -0.51045036}\n",
      "--- Step : 3707 \n",
      "  ------- {'fairness_loss': 2.1727076, 'utility': 0.5756346, 'loss': -0.51045334}\n",
      "--- Step : 3708 \n",
      "  ------- {'fairness_loss': 2.1730886, 'utility': 0.5756486, 'loss': -0.51045597}\n",
      "--- Step : 3709 \n",
      "  ------- {'fairness_loss': 2.1732738, 'utility': 0.575657, 'loss': -0.5104588}\n",
      "--- Step : 3710 \n",
      "  ------- {'fairness_loss': 2.173281, 'utility': 0.5756607, 'loss': -0.5104623}\n",
      "--- Step : 3711 \n",
      "  ------- {'fairness_loss': 2.1731398, 'utility': 0.5756595, 'loss': -0.5104653}\n",
      "--- Step : 3712 \n",
      "  ------- {'fairness_loss': 2.1730797, 'utility': 0.5756606, 'loss': -0.5104682}\n",
      "--- Step : 3713 \n",
      "  ------- {'fairness_loss': 2.1731038, 'utility': 0.57566357, 'loss': -0.51047045}\n",
      "--- Step : 3714 \n",
      "  ------- {'fairness_loss': 2.1730797, 'utility': 0.5756652, 'loss': -0.5104728}\n",
      "--- Step : 3715 \n",
      "  ------- {'fairness_loss': 2.173006, 'utility': 0.5756652, 'loss': -0.510475}\n",
      "--- Step : 3716 \n",
      "  ------- {'fairness_loss': 2.1728876, 'utility': 0.5756639, 'loss': -0.5104773}\n",
      "--- Step : 3717 \n",
      "  ------- {'fairness_loss': 2.17273, 'utility': 0.57566166, 'loss': -0.51047975}\n",
      "--- Step : 3718 \n",
      "  ------- {'fairness_loss': 2.172536, 'utility': 0.57565826, 'loss': -0.5104822}\n",
      "--- Step : 3719 \n",
      "  ------- {'fairness_loss': 2.1723096, 'utility': 0.57565403, 'loss': -0.51048476}\n",
      "--- Step : 3720 \n",
      "  ------- {'fairness_loss': 2.1720574, 'utility': 0.57564896, 'loss': -0.51048726}\n",
      "--- Step : 3721 \n",
      "  ------- {'fairness_loss': 2.171779, 'utility': 0.5756435, 'loss': -0.5104901}\n",
      "--- Step : 3722 \n",
      "  ------- {'fairness_loss': 2.1714814, 'utility': 0.5756371, 'loss': -0.5104927}\n",
      "--- Step : 3723 \n",
      "  ------- {'fairness_loss': 2.1711633, 'utility': 0.57563037, 'loss': -0.5104955}\n",
      "--- Step : 3724 \n",
      "  ------- {'fairness_loss': 2.1708353, 'utility': 0.5756231, 'loss': -0.51049805}\n",
      "--- Step : 3725 \n",
      "  ------- {'fairness_loss': 2.1704898, 'utility': 0.5756157, 'loss': -0.510501}\n",
      "--- Step : 3726 \n",
      "  ------- {'fairness_loss': 2.17015, 'utility': 0.57560784, 'loss': -0.51050335}\n",
      "--- Step : 3727 \n",
      "  ------- {'fairness_loss': 2.1699195, 'utility': 0.5756031, 'loss': -0.51050556}\n",
      "--- Step : 3728 \n",
      "  ------- {'fairness_loss': 2.169777, 'utility': 0.57560146, 'loss': -0.5105082}\n",
      "--- Step : 3729 \n",
      "  ------- {'fairness_loss': 2.1697195, 'utility': 0.5756022, 'loss': -0.51051056}\n",
      "--- Step : 3730 \n",
      "  ------- {'fairness_loss': 2.169737, 'utility': 0.5756052, 'loss': -0.5105131}\n",
      "--- Step : 3731 \n",
      "  ------- {'fairness_loss': 2.1698236, 'utility': 0.5756105, 'loss': -0.5105158}\n",
      "--- Step : 3732 \n",
      "  ------- {'fairness_loss': 2.1699722, 'utility': 0.5756177, 'loss': -0.5105185}\n",
      "--- Step : 3733 \n",
      "  ------- {'fairness_loss': 2.1701772, 'utility': 0.5756266, 'loss': -0.5105213}\n",
      "--- Step : 3734 \n",
      "  ------- {'fairness_loss': 2.1704457, 'utility': 0.5756371, 'loss': -0.51052374}\n",
      "--- Step : 3735 \n",
      "  ------- {'fairness_loss': 2.1706452, 'utility': 0.57564557, 'loss': -0.5105262}\n",
      "--- Step : 3736 \n",
      "  ------- {'fairness_loss': 2.170801, 'utility': 0.5756523, 'loss': -0.51052827}\n",
      "--- Step : 3737 \n",
      "  ------- {'fairness_loss': 2.170684, 'utility': 0.5756512, 'loss': -0.5105307}\n",
      "--- Step : 3738 \n",
      "  ------- {'fairness_loss': 2.170323, 'utility': 0.5756433, 'loss': -0.51053363}\n",
      "--- Step : 3739 \n",
      "  ------- {'fairness_loss': 2.1699698, 'utility': 0.57563543, 'loss': -0.5105363}\n",
      "--- Step : 3740 \n",
      "  ------- {'fairness_loss': 2.1696112, 'utility': 0.5756272, 'loss': -0.5105389}\n",
      "--- Step : 3741 \n",
      "  ------- {'fairness_loss': 2.169265, 'utility': 0.5756191, 'loss': -0.51054114}\n",
      "--- Step : 3742 \n",
      "  ------- {'fairness_loss': 2.1690297, 'utility': 0.57561445, 'loss': -0.5105436}\n",
      "--- Step : 3743 \n",
      "  ------- {'fairness_loss': 2.1688952, 'utility': 0.5756127, 'loss': -0.51054585}\n",
      "--- Step : 3744 \n",
      "  ------- {'fairness_loss': 2.1688485, 'utility': 0.57561374, 'loss': -0.5105483}\n",
      "--- Step : 3745 \n",
      "  ------- {'fairness_loss': 2.1688812, 'utility': 0.5756176, 'loss': -0.51055115}\n",
      "--- Step : 3746 \n",
      "  ------- {'fairness_loss': 2.1689897, 'utility': 0.5756233, 'loss': -0.5105536}\n",
      "--- Step : 3747 \n",
      "  ------- {'fairness_loss': 2.1691706, 'utility': 0.5756313, 'loss': -0.5105562}\n",
      "--- Step : 3748 \n",
      "  ------- {'fairness_loss': 2.1693125, 'utility': 0.57563776, 'loss': -0.51055837}\n",
      "--- Step : 3749 \n",
      "  ------- {'fairness_loss': 2.169194, 'utility': 0.57563657, 'loss': -0.51056075}\n",
      "--- Step : 3750 \n",
      "  ------- {'fairness_loss': 2.168852, 'utility': 0.5756291, 'loss': -0.51056355}\n",
      "--- Step : 3751 \n",
      "  ------- {'fairness_loss': 2.1685147, 'utility': 0.5756215, 'loss': -0.51056606}\n",
      "--- Step : 3752 \n",
      "  ------- {'fairness_loss': 2.168188, 'utility': 0.5756139, 'loss': -0.51056826}\n",
      "--- Step : 3753 \n",
      "  ------- {'fairness_loss': 2.1679761, 'utility': 0.5756099, 'loss': -0.51057065}\n",
      "--- Step : 3754 \n",
      "  ------- {'fairness_loss': 2.1678648, 'utility': 0.57560885, 'loss': -0.5105729}\n",
      "--- Step : 3755 \n",
      "  ------- {'fairness_loss': 2.1678457, 'utility': 0.57561094, 'loss': -0.51057553}\n",
      "--- Step : 3756 \n",
      "  ------- {'fairness_loss': 2.1679142, 'utility': 0.5756156, 'loss': -0.51057816}\n",
      "--- Step : 3757 \n",
      "  ------- {'fairness_loss': 2.1679482, 'utility': 0.57561904, 'loss': -0.5105806}\n",
      "--- Step : 3758 \n",
      "  ------- {'fairness_loss': 2.1679516, 'utility': 0.5756214, 'loss': -0.51058286}\n",
      "--- Step : 3759 \n",
      "  ------- {'fairness_loss': 2.1679235, 'utility': 0.57562304, 'loss': -0.5105853}\n",
      "--- Step : 3760 \n",
      "  ------- {'fairness_loss': 2.1678681, 'utility': 0.57562387, 'loss': -0.5105878}\n",
      "--- Step : 3761 \n",
      "  ------- {'fairness_loss': 2.16779, 'utility': 0.57562417, 'loss': -0.5105905}\n",
      "--- Step : 3762 \n",
      "  ------- {'fairness_loss': 2.1676996, 'utility': 0.57562375, 'loss': -0.51059276}\n",
      "--- Step : 3763 \n",
      "  ------- {'fairness_loss': 2.1677074, 'utility': 0.5756262, 'loss': -0.51059496}\n",
      "--- Step : 3764 \n",
      "  ------- {'fairness_loss': 2.1675992, 'utility': 0.5756255, 'loss': -0.5105975}\n",
      "--- Step : 3765 \n",
      "  ------- {'fairness_loss': 2.1673903, 'utility': 0.5756218, 'loss': -0.5106001}\n",
      "--- Step : 3766 \n",
      "  ------- {'fairness_loss': 2.1672919, 'utility': 0.57562125, 'loss': -0.5106025}\n",
      "--- Step : 3767 \n",
      "  ------- {'fairness_loss': 2.1672897, 'utility': 0.5756236, 'loss': -0.51060486}\n",
      "--- Step : 3768 \n",
      "  ------- {'fairness_loss': 2.1672685, 'utility': 0.5756253, 'loss': -0.51060724}\n",
      "--- Step : 3769 \n",
      "  ------- {'fairness_loss': 2.1672263, 'utility': 0.5756265, 'loss': -0.5106097}\n",
      "--- Step : 3770 \n",
      "  ------- {'fairness_loss': 2.1671615, 'utility': 0.57562697, 'loss': -0.51061213}\n",
      "--- Step : 3771 \n",
      "  ------- {'fairness_loss': 2.1670768, 'utility': 0.57562685, 'loss': -0.5106145}\n",
      "--- Step : 3772 \n",
      "  ------- {'fairness_loss': 2.1669788, 'utility': 0.5756264, 'loss': -0.510617}\n",
      "--- Step : 3773 \n",
      "  ------- {'fairness_loss': 2.1669893, 'utility': 0.5756289, 'loss': -0.5106192}\n",
      "--- Step : 3774 \n",
      "  ------- {'fairness_loss': 2.1668854, 'utility': 0.5756284, 'loss': -0.51062185}\n",
      "--- Step : 3775 \n",
      "  ------- {'fairness_loss': 2.1666923, 'utility': 0.5756249, 'loss': -0.5106241}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3776 \n",
      "  ------- {'fairness_loss': 2.1666164, 'utility': 0.5756248, 'loss': -0.5106263}\n",
      "--- Step : 3777 \n",
      "  ------- {'fairness_loss': 2.1665254, 'utility': 0.5756245, 'loss': -0.51062876}\n",
      "--- Step : 3778 \n",
      "  ------- {'fairness_loss': 2.1664193, 'utility': 0.57562363, 'loss': -0.5106311}\n",
      "--- Step : 3779 \n",
      "  ------- {'fairness_loss': 2.1663039, 'utility': 0.57562256, 'loss': -0.51063347}\n",
      "--- Step : 3780 \n",
      "  ------- {'fairness_loss': 2.1661782, 'utility': 0.57562125, 'loss': -0.5106359}\n",
      "--- Step : 3781 \n",
      "  ------- {'fairness_loss': 2.1660502, 'utility': 0.5756198, 'loss': -0.5106383}\n",
      "--- Step : 3782 \n",
      "  ------- {'fairness_loss': 2.1660266, 'utility': 0.5756216, 'loss': -0.5106408}\n",
      "--- Step : 3783 \n",
      "  ------- {'fairness_loss': 2.1660986, 'utility': 0.57562613, 'loss': -0.5106432}\n",
      "--- Step : 3784 \n",
      "  ------- {'fairness_loss': 2.1662633, 'utility': 0.57563335, 'loss': -0.51064545}\n",
      "--- Step : 3785 \n",
      "  ------- {'fairness_loss': 2.166397, 'utility': 0.5756397, 'loss': -0.51064783}\n",
      "--- Step : 3786 \n",
      "  ------- {'fairness_loss': 2.1663, 'utility': 0.5756392, 'loss': -0.51065016}\n",
      "--- Step : 3787 \n",
      "  ------- {'fairness_loss': 2.1659985, 'utility': 0.57563263, 'loss': -0.51065266}\n",
      "--- Step : 3788 \n",
      "  ------- {'fairness_loss': 2.1657193, 'utility': 0.5756265, 'loss': -0.5106549}\n",
      "--- Step : 3789 \n",
      "  ------- {'fairness_loss': 2.165564, 'utility': 0.5756241, 'loss': -0.5106572}\n",
      "--- Step : 3790 \n",
      "  ------- {'fairness_loss': 2.1655192, 'utility': 0.5756251, 'loss': -0.5106596}\n",
      "--- Step : 3791 \n",
      "  ------- {'fairness_loss': 2.1655726, 'utility': 0.5756294, 'loss': -0.51066226}\n",
      "--- Step : 3792 \n",
      "  ------- {'fairness_loss': 2.1656127, 'utility': 0.57563287, 'loss': -0.51066446}\n",
      "--- Step : 3793 \n",
      "  ------- {'fairness_loss': 2.1656296, 'utility': 0.5756357, 'loss': -0.5106668}\n",
      "--- Step : 3794 \n",
      "  ------- {'fairness_loss': 2.1656306, 'utility': 0.5756382, 'loss': -0.51066923}\n",
      "--- Step : 3795 \n",
      "  ------- {'fairness_loss': 2.165612, 'utility': 0.57563996, 'loss': -0.5106716}\n",
      "--- Step : 3796 \n",
      "  ------- {'fairness_loss': 2.165595, 'utility': 0.5756416, 'loss': -0.5106737}\n",
      "--- Step : 3797 \n",
      "  ------- {'fairness_loss': 2.1654785, 'utility': 0.57564056, 'loss': -0.5106762}\n",
      "--- Step : 3798 \n",
      "  ------- {'fairness_loss': 2.1652834, 'utility': 0.575637, 'loss': -0.51067847}\n",
      "--- Step : 3799 \n",
      "  ------- {'fairness_loss': 2.16521, 'utility': 0.5756371, 'loss': -0.5106808}\n",
      "--- Step : 3800 \n",
      "  ------- {'fairness_loss': 2.165242, 'utility': 0.57564044, 'loss': -0.5106832}\n",
      "--- Step : 3801 \n",
      "  ------- {'fairness_loss': 2.1652627, 'utility': 0.57564354, 'loss': -0.5106857}\n",
      "--- Step : 3802 \n",
      "  ------- {'fairness_loss': 2.165269, 'utility': 0.5756461, 'loss': -0.51068807}\n",
      "--- Step : 3803 \n",
      "  ------- {'fairness_loss': 2.1652598, 'utility': 0.575648, 'loss': -0.5106902}\n",
      "--- Step : 3804 \n",
      "  ------- {'fairness_loss': 2.1652393, 'utility': 0.57565, 'loss': -0.5106928}\n",
      "--- Step : 3805 \n",
      "  ------- {'fairness_loss': 2.165209, 'utility': 0.57565135, 'loss': -0.5106951}\n",
      "--- Step : 3806 \n",
      "  ------- {'fairness_loss': 2.1649842, 'utility': 0.575647, 'loss': -0.5106975}\n",
      "--- Step : 3807 \n",
      "  ------- {'fairness_loss': 2.1648858, 'utility': 0.57564616, 'loss': -0.51069957}\n",
      "--- Step : 3808 \n",
      "  ------- {'fairness_loss': 2.1648974, 'utility': 0.57564884, 'loss': -0.5107019}\n",
      "--- Step : 3809 \n",
      "  ------- {'fairness_loss': 2.1650124, 'utility': 0.5756547, 'loss': -0.51070434}\n",
      "--- Step : 3810 \n",
      "  ------- {'fairness_loss': 2.1650338, 'utility': 0.57565755, 'loss': -0.51070654}\n",
      "--- Step : 3811 \n",
      "  ------- {'fairness_loss': 2.164853, 'utility': 0.57565445, 'loss': -0.51070887}\n",
      "--- Step : 3812 \n",
      "  ------- {'fairness_loss': 2.164682, 'utility': 0.5756517, 'loss': -0.51071125}\n",
      "--- Step : 3813 \n",
      "  ------- {'fairness_loss': 2.1645179, 'utility': 0.57564914, 'loss': -0.5107136}\n",
      "--- Step : 3814 \n",
      "  ------- {'fairness_loss': 2.1643643, 'utility': 0.57564676, 'loss': -0.51071584}\n",
      "--- Step : 3815 \n",
      "  ------- {'fairness_loss': 2.1643293, 'utility': 0.5756481, 'loss': -0.5107182}\n",
      "--- Step : 3816 \n",
      "  ------- {'fairness_loss': 2.1642919, 'utility': 0.57564926, 'loss': -0.5107205}\n",
      "--- Step : 3817 \n",
      "  ------- {'fairness_loss': 2.1643643, 'utility': 0.57565373, 'loss': -0.5107228}\n",
      "--- Step : 3818 \n",
      "  ------- {'fairness_loss': 2.1644242, 'utility': 0.5756577, 'loss': -0.510725}\n",
      "--- Step : 3819 \n",
      "  ------- {'fairness_loss': 2.1644661, 'utility': 0.57566154, 'loss': -0.5107275}\n",
      "--- Step : 3820 \n",
      "  ------- {'fairness_loss': 2.1644962, 'utility': 0.5756648, 'loss': -0.5107299}\n",
      "--- Step : 3821 \n",
      "  ------- {'fairness_loss': 2.1645217, 'utility': 0.57566786, 'loss': -0.51073223}\n",
      "--- Step : 3822 \n",
      "  ------- {'fairness_loss': 2.1644645, 'utility': 0.57566833, 'loss': -0.5107344}\n",
      "--- Step : 3823 \n",
      "  ------- {'fairness_loss': 2.1643317, 'utility': 0.5756667, 'loss': -0.51073676}\n",
      "--- Step : 3824 \n",
      "  ------- {'fairness_loss': 2.1643243, 'utility': 0.57566875, 'loss': -0.510739}\n",
      "--- Step : 3825 \n",
      "  ------- {'fairness_loss': 2.164428, 'utility': 0.57567394, 'loss': -0.5107411}\n",
      "--- Step : 3826 \n",
      "  ------- {'fairness_loss': 2.1645155, 'utility': 0.5756789, 'loss': -0.51074344}\n",
      "--- Step : 3827 \n",
      "  ------- {'fairness_loss': 2.16459, 'utility': 0.57568353, 'loss': -0.5107458}\n",
      "--- Step : 3828 \n",
      "  ------- {'fairness_loss': 2.1644616, 'utility': 0.575682, 'loss': -0.51074815}\n",
      "--- Step : 3829 \n",
      "  ------- {'fairness_loss': 2.1643403, 'utility': 0.57568055, 'loss': -0.51075035}\n",
      "--- Step : 3830 \n",
      "  ------- {'fairness_loss': 2.1642272, 'utility': 0.57567966, 'loss': -0.51075286}\n",
      "--- Step : 3831 \n",
      "  ------- {'fairness_loss': 2.164121, 'utility': 0.57567877, 'loss': -0.5107551}\n",
      "--- Step : 3832 \n",
      "  ------- {'fairness_loss': 2.1640246, 'utility': 0.5756782, 'loss': -0.5107575}\n",
      "--- Step : 3833 \n",
      "  ------- {'fairness_loss': 2.1640491, 'utility': 0.5756812, 'loss': -0.5107597}\n",
      "--- Step : 3834 \n",
      "  ------- {'fairness_loss': 2.1641846, 'utility': 0.5756874, 'loss': -0.51076186}\n",
      "--- Step : 3835 \n",
      "  ------- {'fairness_loss': 2.1642292, 'utility': 0.57569104, 'loss': -0.5107642}\n",
      "--- Step : 3836 \n",
      "  ------- {'fairness_loss': 2.164077, 'utility': 0.57568896, 'loss': -0.5107666}\n",
      "--- Step : 3837 \n",
      "  ------- {'fairness_loss': 2.163944, 'utility': 0.5756872, 'loss': -0.5107689}\n",
      "--- Step : 3838 \n",
      "  ------- {'fairness_loss': 2.1638248, 'utility': 0.5756859, 'loss': -0.51077116}\n",
      "--- Step : 3839 \n",
      "  ------- {'fairness_loss': 2.1638262, 'utility': 0.5756881, 'loss': -0.51077336}\n",
      "--- Step : 3840 \n",
      "  ------- {'fairness_loss': 2.1639414, 'utility': 0.57569385, 'loss': -0.5107756}\n",
      "--- Step : 3841 \n",
      "  ------- {'fairness_loss': 2.1640449, 'utility': 0.5756992, 'loss': -0.5107779}\n",
      "--- Step : 3842 \n",
      "  ------- {'fairness_loss': 2.1641448, 'utility': 0.5757043, 'loss': -0.5107799}\n",
      "--- Step : 3843 \n",
      "  ------- {'fairness_loss': 2.1640332, 'utility': 0.57570356, 'loss': -0.5107826}\n",
      "--- Step : 3844 \n",
      "  ------- {'fairness_loss': 2.1637526, 'utility': 0.5756974, 'loss': -0.51078486}\n",
      "--- Step : 3845 \n",
      "  ------- {'fairness_loss': 2.1636214, 'utility': 0.5756956, 'loss': -0.51078695}\n",
      "--- Step : 3846 \n",
      "  ------- {'fairness_loss': 2.1636155, 'utility': 0.5756978, 'loss': -0.51078933}\n",
      "--- Step : 3847 \n",
      "  ------- {'fairness_loss': 2.1636102, 'utility': 0.5756999, 'loss': -0.5107916}\n",
      "--- Step : 3848 \n",
      "  ------- {'fairness_loss': 2.163603, 'utility': 0.575702, 'loss': -0.5107939}\n",
      "--- Step : 3849 \n",
      "  ------- {'fairness_loss': 2.1636012, 'utility': 0.57570416, 'loss': -0.5107961}\n",
      "--- Step : 3850 \n",
      "  ------- {'fairness_loss': 2.1635983, 'utility': 0.57570654, 'loss': -0.5107986}\n",
      "--- Step : 3851 \n",
      "  ------- {'fairness_loss': 2.1637104, 'utility': 0.5757121, 'loss': -0.5108008}\n",
      "--- Step : 3852 \n",
      "  ------- {'fairness_loss': 2.163943, 'utility': 0.5757209, 'loss': -0.5108026}\n",
      "--- Step : 3853 \n",
      "  ------- {'fairness_loss': 2.1639605, 'utility': 0.57572365, 'loss': -0.51080483}\n",
      "--- Step : 3854 \n",
      "  ------- {'fairness_loss': 2.1637826, 'utility': 0.57572097, 'loss': -0.5108075}\n",
      "--- Step : 3855 \n",
      "  ------- {'fairness_loss': 2.1634557, 'utility': 0.5757132, 'loss': -0.51080954}\n",
      "--- Step : 3856 \n",
      "  ------- {'fairness_loss': 2.1632771, 'utility': 0.57571006, 'loss': -0.51081175}\n",
      "--- Step : 3857 \n",
      "  ------- {'fairness_loss': 2.163231, 'utility': 0.5757111, 'loss': -0.51081413}\n",
      "--- Step : 3858 \n",
      "  ------- {'fairness_loss': 2.1633122, 'utility': 0.5757157, 'loss': -0.51081634}\n",
      "--- Step : 3859 \n",
      "  ------- {'fairness_loss': 2.163389, 'utility': 0.5757203, 'loss': -0.51081866}\n",
      "--- Step : 3860 \n",
      "  ------- {'fairness_loss': 2.1634579, 'utility': 0.57572436, 'loss': -0.5108206}\n",
      "--- Step : 3861 \n",
      "  ------- {'fairness_loss': 2.163525, 'utility': 0.5757288, 'loss': -0.510823}\n",
      "--- Step : 3862 \n",
      "  ------- {'fairness_loss': 2.1635847, 'utility': 0.57573277, 'loss': -0.5108252}\n",
      "--- Step : 3863 \n",
      "  ------- {'fairness_loss': 2.163648, 'utility': 0.57573706, 'loss': -0.5108276}\n",
      "--- Step : 3864 \n",
      "  ------- {'fairness_loss': 2.1637058, 'utility': 0.5757411, 'loss': -0.5108299}\n",
      "--- Step : 3865 \n",
      "  ------- {'fairness_loss': 2.1635737, 'utility': 0.5757397, 'loss': -0.5108325}\n",
      "--- Step : 3866 \n",
      "  ------- {'fairness_loss': 2.1634693, 'utility': 0.57573855, 'loss': -0.51083446}\n",
      "--- Step : 3867 \n",
      "  ------- {'fairness_loss': 2.1634965, 'utility': 0.5757417, 'loss': -0.51083684}\n",
      "--- Step : 3868 \n",
      "  ------- {'fairness_loss': 2.1634567, 'utility': 0.5757428, 'loss': -0.5108391}\n",
      "--- Step : 3869 \n",
      "  ------- {'fairness_loss': 2.163358, 'utility': 0.5757419, 'loss': -0.51084113}\n",
      "--- Step : 3870 \n",
      "  ------- {'fairness_loss': 2.1633942, 'utility': 0.5757452, 'loss': -0.5108434}\n",
      "--- Step : 3871 \n",
      "  ------- {'fairness_loss': 2.1634338, 'utility': 0.5757485, 'loss': -0.5108455}\n",
      "--- Step : 3872 \n",
      "  ------- {'fairness_loss': 2.1634731, 'utility': 0.575752, 'loss': -0.5108478}\n",
      "--- Step : 3873 \n",
      "  ------- {'fairness_loss': 2.1635144, 'utility': 0.5757555, 'loss': -0.5108501}\n",
      "--- Step : 3874 \n",
      "  ------- {'fairness_loss': 2.1635556, 'utility': 0.57575893, 'loss': -0.5108523}\n",
      "--- Step : 3875 \n",
      "  ------- {'fairness_loss': 2.1636038, 'utility': 0.5757626, 'loss': -0.51085454}\n",
      "--- Step : 3876 \n",
      "  ------- {'fairness_loss': 2.1634648, 'utility': 0.57576084, 'loss': -0.51085687}\n",
      "--- Step : 3877 \n",
      "  ------- {'fairness_loss': 2.1633527, 'utility': 0.5757597, 'loss': -0.51085913}\n",
      "--- Step : 3878 \n",
      "  ------- {'fairness_loss': 2.1633747, 'utility': 0.57576245, 'loss': -0.5108612}\n",
      "--- Step : 3879 \n",
      "  ------- {'fairness_loss': 2.1633356, 'utility': 0.57576364, 'loss': -0.5108636}\n",
      "--- Step : 3880 \n",
      "  ------- {'fairness_loss': 2.1634262, 'utility': 0.5757685, 'loss': -0.5108657}\n",
      "--- Step : 3881 \n",
      "  ------- {'fairness_loss': 2.1635163, 'utility': 0.57577336, 'loss': -0.5108679}\n",
      "--- Step : 3882 \n",
      "  ------- {'fairness_loss': 2.1634238, 'utility': 0.5757727, 'loss': -0.51087}\n",
      "--- Step : 3883 \n",
      "  ------- {'fairness_loss': 2.1633482, 'utility': 0.5757727, 'loss': -0.51087224}\n",
      "--- Step : 3884 \n",
      "  ------- {'fairness_loss': 2.163289, 'utility': 0.5757733, 'loss': -0.5108746}\n",
      "--- Step : 3885 \n",
      "  ------- {'fairness_loss': 2.1632428, 'utility': 0.5757742, 'loss': -0.5108769}\n",
      "--- Step : 3886 \n",
      "  ------- {'fairness_loss': 2.1632168, 'utility': 0.5757756, 'loss': -0.5108791}\n",
      "--- Step : 3887 \n",
      "  ------- {'fairness_loss': 2.1633148, 'utility': 0.5757807, 'loss': -0.51088125}\n",
      "--- Step : 3888 \n",
      "  ------- {'fairness_loss': 2.1633456, 'utility': 0.57578367, 'loss': -0.51088333}\n",
      "--- Step : 3889 \n",
      "  ------- {'fairness_loss': 2.1633189, 'utility': 0.57578534, 'loss': -0.5108858}\n",
      "--- Step : 3890 \n",
      "  ------- {'fairness_loss': 2.1633093, 'utility': 0.5757871, 'loss': -0.51088786}\n",
      "--- Step : 3891 \n",
      "  ------- {'fairness_loss': 2.1633117, 'utility': 0.5757894, 'loss': -0.51089007}\n",
      "--- Step : 3892 \n",
      "  ------- {'fairness_loss': 2.1633184, 'utility': 0.57579184, 'loss': -0.5108923}\n",
      "--- Step : 3893 \n",
      "  ------- {'fairness_loss': 2.163337, 'utility': 0.5757946, 'loss': -0.5108945}\n",
      "--- Step : 3894 \n",
      "  ------- {'fairness_loss': 2.163365, 'utility': 0.5757977, 'loss': -0.51089674}\n",
      "--- Step : 3895 \n",
      "  ------- {'fairness_loss': 2.1632211, 'utility': 0.57579553, 'loss': -0.5108989}\n",
      "--- Step : 3896 \n",
      "  ------- {'fairness_loss': 2.1632206, 'utility': 0.5757977, 'loss': -0.51090103}\n",
      "--- Step : 3897 \n",
      "  ------- {'fairness_loss': 2.1633465, 'utility': 0.57580364, 'loss': -0.51090324}\n",
      "--- Step : 3898 \n",
      "  ------- {'fairness_loss': 2.1632903, 'utility': 0.5758042, 'loss': -0.51090544}\n",
      "--- Step : 3899 \n",
      "  ------- {'fairness_loss': 2.1632538, 'utility': 0.5758053, 'loss': -0.5109077}\n",
      "--- Step : 3900 \n",
      "  ------- {'fairness_loss': 2.1632335, 'utility': 0.575807, 'loss': -0.51091}\n",
      "--- Step : 3901 \n",
      "  ------- {'fairness_loss': 2.1633437, 'utility': 0.57581234, 'loss': -0.51091206}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 3902 \n",
      "  ------- {'fairness_loss': 2.163272, 'utility': 0.57581264, 'loss': -0.5109145}\n",
      "--- Step : 3903 \n",
      "  ------- {'fairness_loss': 2.1631627, 'utility': 0.5758113, 'loss': -0.5109165}\n",
      "--- Step : 3904 \n",
      "  ------- {'fairness_loss': 2.1630766, 'utility': 0.57581085, 'loss': -0.51091856}\n",
      "--- Step : 3905 \n",
      "  ------- {'fairness_loss': 2.1630123, 'utility': 0.575811, 'loss': -0.51092064}\n",
      "--- Step : 3906 \n",
      "  ------- {'fairness_loss': 2.1630845, 'utility': 0.5758154, 'loss': -0.51092285}\n",
      "--- Step : 3907 \n",
      "  ------- {'fairness_loss': 2.163162, 'utility': 0.5758199, 'loss': -0.51092505}\n",
      "--- Step : 3908 \n",
      "  ------- {'fairness_loss': 2.1632426, 'utility': 0.57582456, 'loss': -0.51092726}\n",
      "--- Step : 3909 \n",
      "  ------- {'fairness_loss': 2.1633291, 'utility': 0.57582945, 'loss': -0.5109296}\n",
      "--- Step : 3910 \n",
      "  ------- {'fairness_loss': 2.1634283, 'utility': 0.57583445, 'loss': -0.5109316}\n",
      "--- Step : 3911 \n",
      "  ------- {'fairness_loss': 2.1633449, 'utility': 0.57583416, 'loss': -0.5109338}\n",
      "--- Step : 3912 \n",
      "  ------- {'fairness_loss': 2.1632214, 'utility': 0.5758326, 'loss': -0.51093596}\n",
      "--- Step : 3913 \n",
      "  ------- {'fairness_loss': 2.1630707, 'utility': 0.5758302, 'loss': -0.5109381}\n",
      "--- Step : 3914 \n",
      "  ------- {'fairness_loss': 2.1630614, 'utility': 0.5758321, 'loss': -0.5109403}\n",
      "--- Step : 3915 \n",
      "  ------- {'fairness_loss': 2.1630723, 'utility': 0.5758347, 'loss': -0.5109425}\n",
      "--- Step : 3916 \n",
      "  ------- {'fairness_loss': 2.163097, 'utility': 0.57583743, 'loss': -0.51094455}\n",
      "--- Step : 3917 \n",
      "  ------- {'fairness_loss': 2.1631308, 'utility': 0.57584065, 'loss': -0.51094675}\n",
      "--- Step : 3918 \n",
      "  ------- {'fairness_loss': 2.1631749, 'utility': 0.5758442, 'loss': -0.510949}\n",
      "--- Step : 3919 \n",
      "  ------- {'fairness_loss': 2.1632302, 'utility': 0.57584816, 'loss': -0.5109513}\n",
      "--- Step : 3920 \n",
      "  ------- {'fairness_loss': 2.1632965, 'utility': 0.5758524, 'loss': -0.5109535}\n",
      "--- Step : 3921 \n",
      "  ------- {'fairness_loss': 2.1633801, 'utility': 0.57585704, 'loss': -0.51095563}\n",
      "--- Step : 3922 \n",
      "  ------- {'fairness_loss': 2.1632912, 'utility': 0.57585627, 'loss': -0.51095754}\n",
      "--- Step : 3923 \n",
      "  ------- {'fairness_loss': 2.1631613, 'utility': 0.5758546, 'loss': -0.51095974}\n",
      "--- Step : 3924 \n",
      "  ------- {'fairness_loss': 2.1630101, 'utility': 0.57585204, 'loss': -0.5109617}\n",
      "--- Step : 3925 \n",
      "  ------- {'fairness_loss': 2.1629975, 'utility': 0.575854, 'loss': -0.5109641}\n",
      "--- Step : 3926 \n",
      "  ------- {'fairness_loss': 2.1631184, 'utility': 0.57586, 'loss': -0.5109665}\n",
      "--- Step : 3927 \n",
      "  ------- {'fairness_loss': 2.1632512, 'utility': 0.57586604, 'loss': -0.5109685}\n",
      "--- Step : 3928 \n",
      "  ------- {'fairness_loss': 2.163386, 'utility': 0.5758721, 'loss': -0.51097053}\n",
      "--- Step : 3929 \n",
      "  ------- {'fairness_loss': 2.1635227, 'utility': 0.57587856, 'loss': -0.51097286}\n",
      "--- Step : 3930 \n",
      "  ------- {'fairness_loss': 2.1636722, 'utility': 0.57588494, 'loss': -0.51097476}\n",
      "--- Step : 3931 \n",
      "  ------- {'fairness_loss': 2.163642, 'utility': 0.57588613, 'loss': -0.51097685}\n",
      "--- Step : 3932 \n",
      "  ------- {'fairness_loss': 2.1634462, 'utility': 0.5758827, 'loss': -0.5109793}\n",
      "--- Step : 3933 \n",
      "  ------- {'fairness_loss': 2.1632948, 'utility': 0.5758803, 'loss': -0.51098144}\n",
      "--- Step : 3934 \n",
      "  ------- {'fairness_loss': 2.1631794, 'utility': 0.57587886, 'loss': -0.51098347}\n",
      "--- Step : 3935 \n",
      "  ------- {'fairness_loss': 2.1630933, 'utility': 0.57587844, 'loss': -0.5109856}\n",
      "--- Step : 3936 \n",
      "  ------- {'fairness_loss': 2.163149, 'utility': 0.57588243, 'loss': -0.51098794}\n",
      "--- Step : 3937 \n",
      "  ------- {'fairness_loss': 2.163331, 'utility': 0.5758901, 'loss': -0.5109902}\n",
      "--- Step : 3938 \n",
      "  ------- {'fairness_loss': 2.163343, 'utility': 0.57589275, 'loss': -0.51099247}\n",
      "--- Step : 3939 \n",
      "  ------- {'fairness_loss': 2.1632009, 'utility': 0.5758905, 'loss': -0.51099443}\n",
      "--- Step : 3940 \n",
      "  ------- {'fairness_loss': 2.1632035, 'utility': 0.57589275, 'loss': -0.51099664}\n",
      "--- Step : 3941 \n",
      "  ------- {'fairness_loss': 2.1633458, 'utility': 0.57589906, 'loss': -0.51099867}\n",
      "--- Step : 3942 \n",
      "  ------- {'fairness_loss': 2.1634917, 'utility': 0.5759056, 'loss': -0.5110009}\n",
      "--- Step : 3943 \n",
      "  ------- {'fairness_loss': 2.1636517, 'utility': 0.57591236, 'loss': -0.5110028}\n",
      "--- Step : 3944 \n",
      "  ------- {'fairness_loss': 2.1636274, 'utility': 0.57591385, 'loss': -0.51100504}\n",
      "--- Step : 3945 \n",
      "  ------- {'fairness_loss': 2.163451, 'utility': 0.5759108, 'loss': -0.5110073}\n",
      "--- Step : 3946 \n",
      "  ------- {'fairness_loss': 2.1633165, 'utility': 0.5759088, 'loss': -0.5110093}\n",
      "--- Step : 3947 \n",
      "  ------- {'fairness_loss': 2.1632159, 'utility': 0.5759079, 'loss': -0.5110114}\n",
      "--- Step : 3948 \n",
      "  ------- {'fairness_loss': 2.1631467, 'utility': 0.5759079, 'loss': -0.5110135}\n",
      "--- Step : 3949 \n",
      "  ------- {'fairness_loss': 2.163218, 'utility': 0.5759122, 'loss': -0.51101565}\n",
      "--- Step : 3950 \n",
      "  ------- {'fairness_loss': 2.1634195, 'utility': 0.5759206, 'loss': -0.511018}\n",
      "--- Step : 3951 \n",
      "  ------- {'fairness_loss': 2.163637, 'utility': 0.5759288, 'loss': -0.5110197}\n",
      "--- Step : 3952 \n",
      "  ------- {'fairness_loss': 2.1636696, 'utility': 0.57593185, 'loss': -0.51102173}\n",
      "--- Step : 3953 \n",
      "  ------- {'fairness_loss': 2.1635349, 'utility': 0.57593024, 'loss': -0.5110242}\n",
      "--- Step : 3954 \n",
      "  ------- {'fairness_loss': 2.1632695, 'utility': 0.5759244, 'loss': -0.5110263}\n",
      "--- Step : 3955 \n",
      "  ------- {'fairness_loss': 2.163174, 'utility': 0.57592356, 'loss': -0.51102835}\n",
      "--- Step : 3956 \n",
      "  ------- {'fairness_loss': 2.1632216, 'utility': 0.57592714, 'loss': -0.5110305}\n",
      "--- Step : 3957 \n",
      "  ------- {'fairness_loss': 2.1632888, 'utility': 0.57593125, 'loss': -0.5110326}\n",
      "--- Step : 3958 \n",
      "  ------- {'fairness_loss': 2.1633732, 'utility': 0.5759358, 'loss': -0.5110346}\n",
      "--- Step : 3959 \n",
      "  ------- {'fairness_loss': 2.1634662, 'utility': 0.5759409, 'loss': -0.51103693}\n",
      "--- Step : 3960 \n",
      "  ------- {'fairness_loss': 2.1635747, 'utility': 0.5759464, 'loss': -0.51103914}\n",
      "--- Step : 3961 \n",
      "  ------- {'fairness_loss': 2.1635199, 'utility': 0.5759469, 'loss': -0.51104134}\n",
      "--- Step : 3962 \n",
      "  ------- {'fairness_loss': 2.1634953, 'utility': 0.5759482, 'loss': -0.5110433}\n",
      "--- Step : 3963 \n",
      "  ------- {'fairness_loss': 2.1633284, 'utility': 0.57594526, 'loss': -0.5110454}\n",
      "--- Step : 3964 \n",
      "  ------- {'fairness_loss': 2.163316, 'utility': 0.5759469, 'loss': -0.5110474}\n",
      "--- Step : 3965 \n",
      "  ------- {'fairness_loss': 2.1634371, 'utility': 0.5759529, 'loss': -0.51104975}\n",
      "--- Step : 3966 \n",
      "  ------- {'fairness_loss': 2.1636975, 'utility': 0.57596266, 'loss': -0.5110517}\n",
      "--- Step : 3967 \n",
      "  ------- {'fairness_loss': 2.1637802, 'utility': 0.57596695, 'loss': -0.51105356}\n",
      "--- Step : 3968 \n",
      "  ------- {'fairness_loss': 2.163699, 'utility': 0.5759668, 'loss': -0.5110558}\n",
      "--- Step : 3969 \n",
      "  ------- {'fairness_loss': 2.16348, 'utility': 0.5759623, 'loss': -0.5110579}\n",
      "--- Step : 3970 \n",
      "  ------- {'fairness_loss': 2.1633098, 'utility': 0.5759592, 'loss': -0.5110599}\n",
      "--- Step : 3971 \n",
      "  ------- {'fairness_loss': 2.16318, 'utility': 0.57595736, 'loss': -0.51106197}\n",
      "--- Step : 3972 \n",
      "  ------- {'fairness_loss': 2.163088, 'utility': 0.57595676, 'loss': -0.5110641}\n",
      "--- Step : 3973 \n",
      "  ------- {'fairness_loss': 2.1631439, 'utility': 0.5759605, 'loss': -0.5110662}\n",
      "--- Step : 3974 \n",
      "  ------- {'fairness_loss': 2.163338, 'utility': 0.5759686, 'loss': -0.51106846}\n",
      "--- Step : 3975 \n",
      "  ------- {'fairness_loss': 2.1635385, 'utility': 0.5759767, 'loss': -0.5110706}\n",
      "--- Step : 3976 \n",
      "  ------- {'fairness_loss': 2.1637428, 'utility': 0.57598484, 'loss': -0.5110726}\n",
      "--- Step : 3977 \n",
      "  ------- {'fairness_loss': 2.1639585, 'utility': 0.57599324, 'loss': -0.5110745}\n",
      "--- Step : 3978 \n",
      "  ------- {'fairness_loss': 2.1640022, 'utility': 0.5759967, 'loss': -0.5110766}\n",
      "--- Step : 3979 \n",
      "  ------- {'fairness_loss': 2.163886, 'utility': 0.57599556, 'loss': -0.51107895}\n",
      "--- Step : 3980 \n",
      "  ------- {'fairness_loss': 2.1636333, 'utility': 0.5759902, 'loss': -0.5110812}\n",
      "--- Step : 3981 \n",
      "  ------- {'fairness_loss': 2.1634421, 'utility': 0.5759863, 'loss': -0.51108307}\n",
      "--- Step : 3982 \n",
      "  ------- {'fairness_loss': 2.163411, 'utility': 0.57598746, 'loss': -0.51108515}\n",
      "--- Step : 3983 \n",
      "  ------- {'fairness_loss': 2.1635225, 'utility': 0.5759931, 'loss': -0.5110874}\n",
      "--- Step : 3984 \n",
      "  ------- {'fairness_loss': 2.1636508, 'utility': 0.5759992, 'loss': -0.5110897}\n",
      "--- Step : 3985 \n",
      "  ------- {'fairness_loss': 2.1637943, 'utility': 0.5760055, 'loss': -0.5110917}\n",
      "--- Step : 3986 \n",
      "  ------- {'fairness_loss': 2.1637747, 'utility': 0.57600695, 'loss': -0.51109374}\n",
      "--- Step : 3987 \n",
      "  ------- {'fairness_loss': 2.163617, 'utility': 0.5760043, 'loss': -0.5110958}\n",
      "--- Step : 3988 \n",
      "  ------- {'fairness_loss': 2.1635072, 'utility': 0.5760029, 'loss': -0.51109767}\n",
      "--- Step : 3989 \n",
      "  ------- {'fairness_loss': 2.163544, 'utility': 0.5760062, 'loss': -0.5110999}\n",
      "--- Step : 3990 \n",
      "  ------- {'fairness_loss': 2.163719, 'utility': 0.5760137, 'loss': -0.51110214}\n",
      "--- Step : 3991 \n",
      "  ------- {'fairness_loss': 2.1639135, 'utility': 0.5760215, 'loss': -0.5111041}\n",
      "--- Step : 3992 \n",
      "  ------- {'fairness_loss': 2.1639395, 'utility': 0.5760244, 'loss': -0.51110625}\n",
      "--- Step : 3993 \n",
      "  ------- {'fairness_loss': 2.1638155, 'utility': 0.5760227, 'loss': -0.5111082}\n",
      "--- Step : 3994 \n",
      "  ------- {'fairness_loss': 2.1637363, 'utility': 0.5760224, 'loss': -0.5111103}\n",
      "--- Step : 3995 \n",
      "  ------- {'fairness_loss': 2.1636922, 'utility': 0.57602316, 'loss': -0.5111124}\n",
      "--- Step : 3996 \n",
      "  ------- {'fairness_loss': 2.1636837, 'utility': 0.576025, 'loss': -0.5111145}\n",
      "--- Step : 3997 \n",
      "  ------- {'fairness_loss': 2.163815, 'utility': 0.5760311, 'loss': -0.5111166}\n",
      "--- Step : 3998 \n",
      "  ------- {'fairness_loss': 2.1639128, 'utility': 0.5760361, 'loss': -0.5111187}\n",
      "--- Step : 3999 \n",
      "  ------- {'fairness_loss': 2.163858, 'utility': 0.57603633, 'loss': -0.5111206}\n",
      "--- Step : 4000 \n",
      "  ------- {'fairness_loss': 2.1638372, 'utility': 0.5760378, 'loss': -0.5111227}\n"
     ]
    }
   ],
   "source": [
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "utility_tracker = tf.keras.metrics.Mean(name=\"utility\")\n",
    "fairness_tracker = tf.keras.metrics.Mean(name=\"fairness\")\n",
    "\n",
    "# train data\n",
    "train_model = get_models_from_data(train_data)\n",
    "Py, Pz_y, Py_x, Pz_yx = train_model\n",
    "\n",
    "x = tf.convert_to_tensor(train_data[X_atr].values)\n",
    "y = tf.reshape(tf.convert_to_tensor(train_data[Y_atr].values),(-1,1))\n",
    "\n",
    "# test data\n",
    "test_model = get_models_from_data(test_data)\n",
    "test_tf_Py, test_tf_Pz_y, test_tf_Py_x, test_tf_Pz_yx = (tf.convert_to_tensor(p, dtype=\"float32\") for p in test_model)\n",
    "test_x = tf.convert_to_tensor(test_data[X_atr].values)\n",
    "test_y = tf.reshape(tf.convert_to_tensor(test_data[Y_atr].values),(-1,1))\n",
    "test_data_list = (test_x, test_y, test_tf_Py, test_tf_Pz_y, test_tf_Py_x, test_tf_Pz_yx)\n",
    "\n",
    "\n",
    "# loop\n",
    "history = []\n",
    "eval_history = []\n",
    "for epoch in range(epochs):\n",
    "    tf_Py, tf_Pz_y, tf_Py_x, tf_Pz_yx = (tf.convert_to_tensor(p, dtype=\"float32\") for p in train_model)\n",
    "    \n",
    "    # training step\n",
    "    step_results = train_step(policy = policy_model,\n",
    "                              data = (x, y, tf_Py, tf_Pz_y, tf_Py_x, tf_Pz_yx),\n",
    "                              lamba_parameter = 0.03,\n",
    "                              optimizer = optimizer)\n",
    "    step_results = {key:step_results[key].numpy() for key in step_results.keys()}\n",
    "    history += [step_results]\n",
    "    \n",
    "    # evaluation step\n",
    "    \n",
    "    eval_results = eval_step(policy = policy_model,\n",
    "                             data = test_data_list,\n",
    "                             lamba_parameter = 0.03)\n",
    "    \n",
    "    eval_history +=[eval_results]\n",
    "    \n",
    "    \n",
    "    reset_trackers([loss_tracker, utility_tracker, fairness_tracker,\n",
    "                    eval_loss_tracker, eval_utility_tracker, eval_fairness_tracker])\n",
    "    print(f\"--- Step : {epoch + 1} \\n  ------- {step_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.9081547 ],\n",
       "        [ 0.88394874],\n",
       "        [ 2.5878675 ],\n",
       "        [ 1.8557146 ],\n",
       "        [-0.11674024],\n",
       "        [ 0.24436349]], dtype=float32),\n",
       " -1.456088]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "eval_history_df = pd.DataFrame(eval_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_df[\"utility\"],label=\"utility\")\n",
    "plt.plot(eval_history_df[\"utility\"],label=\"eval utility\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df[\"fairness_loss\"],label=\"fairness_loss\")\n",
    "plt.plot(eval_history_df[\"fairness_loss\"],label=\"eval_fairness_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(eval_history_df[\"loss\"],label=\"eval_fairness_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# empirical fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_fairness_cont_v11(datas, p_a_x, Pz_y, Py, model_y_x, model_z_yx):\n",
    "    Z = n_z\n",
    "\n",
    "    Py_x = model_y_x.predict_proba(datas[X_atr]).T\n",
    "    EF = 0\n",
    "    for y in range(2):\n",
    "        tmp_data = datas[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "        print(Pz_yx.shape)\n",
    "        for z in range(Z):\n",
    "            c = 0\n",
    "            for i in range(tmp_data.shape[0]):\n",
    "                delta = (Pz_yx[z, i] - Pz_y[z, y] ) * (Py_x[y, i]/Py[y])\n",
    "                c += p_a_x[:, i] * delta\n",
    "            c = c/tmp_data.shape[0]\n",
    "            c = np.linalg.norm(c, 1)\n",
    "            EF += c\n",
    "    return EF\n",
    "\n",
    "\n",
    "def empirical_fairness_cont_v12(datas, p_a_x, Pz_y, Py,model_y_x, model_z_yx):\n",
    "    Z = n_z\n",
    "\n",
    "    Py_x = model_y_x.predict_proba(datas[X_atr]).T\n",
    "    EF = 0\n",
    "    for y in range(2):\n",
    "        tmp_data = datas[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "        for z in range(Z):\n",
    "            c = 0\n",
    "            j= 0 \n",
    "            for i in range(tmp_data.shape[0]):\n",
    "                j = j + 1\n",
    "                delta = (Pz_yx[z, i] / Pz_y[z, y] - 1 ) * (Py_x[y, i] / (Py[y]) )\n",
    "                c += p_a_x[:, i] * delta\n",
    "            c = c/datas.shape[0]\n",
    "            c = np.linalg.norm(c, 1)\n",
    "            EF += c\n",
    "    return EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas= test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 317us/step\n"
     ]
    }
   ],
   "source": [
    "p_a1 = policy_model.predict(datas[X_atr].astype(\"float32\"))\n",
    "p_a0 = 1 - p_a1\n",
    "p_a_x = np.concatenate([p_a0, p_a1],axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "(12, 1214)\n",
      "(12, 1214)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10304854295827681"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py, Pz_y, model_y_x, model_z_yx = get_models(datas)\n",
    "empirical_fairness_cont_v11(datas = datas,\n",
    "                            p_a_x = p_a_x,\n",
    "                            Pz_y=Pz_y,\n",
    "                            Py=Py,\n",
    "                            model_y_x = model_y_x,\n",
    "                            model_z_yx = model_z_yx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.199497670866549"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py, Pz_y, model_y_x, model_z_yx = get_models(datas)\n",
    "empirical_fairness_cont_v12(datas = datas,\n",
    "                            p_a_x = p_a_x,\n",
    "                            Pz_y = Pz_y,\n",
    "                            Py = Py,\n",
    "                            model_y_x = model_y_x, \n",
    "                            model_z_yx = model_z_yx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function dependence = Fairness(policy, model, model_delta)\n",
    "  A = rows(policy);\n",
    "  X = columns(policy);\n",
    "  dependence = 0;\n",
    "  for y=1:model.Y\n",
    "\tfor z=1:model.Z\n",
    "\t  delta = policy * model_delta(:, y, z);\n",
    "\t  dependence += norm(delta, 1);\n",
    "\tend\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = get_models_from_data(train_data)\n",
    "Py, Pz_y, Py_x, Pz_yx = train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), (12, 2), (2, 6000), (12, 2, 6000))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py.shape, Pz_y.shape, Py_x.shape, Pz_yx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=10\n",
    "y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 253us/step\n"
     ]
    }
   ],
   "source": [
    "Pa1 = policy_model.predict(train_data[X_atr])\n",
    "p_a0 = 1 - Pa1\n",
    "P_a_x = np.concatenate([p_a0, Pa1],axis=1).T\n",
    "tf_P_a_x = tf.convert_to_tensor(P_a_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), (12, 2), (2, 6000), (12, 2, 6000), (2, 6000))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py.shape, Pz_y.shape, Py_x.shape, Pz_yx.shape, P_a_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rshaped = np.reshape(Pz_yx\n",
    "n1 = (Pz_yx / np.expand_dims(Pz_y,axis=-1) - 1)# ok\n",
    "\n",
    "n2 = Py_x / np.expand_dims(Py,axis=-1) # ok\n",
    "delta_v = n1 * np.expand_dims(n2,axis=0) # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf delta ok\n",
    "n1_tf = (tf_Pz_yx / tf.expand_dims(tf_Pz_y, axis=-1)) - 1 # ok\n",
    "n2_tf = tf_Py_x / tf.expand_dims(tf_Py,axis=-1) # ok\n",
    "delta_tf = n1_tf * tf.expand_dims(n2_tf, axis=0) # ok\n",
    "np.all(delta_tf.numpy() == delta_v)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([12, 2, 6000]), TensorShape([2, 6000]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tf.shape, tf_P_a_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_P_a_x = tf.cast(tf_P_a_x,\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-2616.8071  ],\n",
       "       [  -20.924694]], dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.matmul(tf_P_a_x, tf.expand_dims(delta_tf[z,y,:],axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1, 2, 6000), (12, 2, 6000, 1))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(tf_P_a_x,axis=[0,1]).shape, np.expand_dims(delta_tf,axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.linalg.matmul(np.expand_dims(tf_P_a_x,axis=[0,1]), np.expand_dims(delta_tf,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.6916529494858994>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness = tf.norm(c, ord=1, axis=None, keepdims=None, name=None) / 6000\n",
    "fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_fairness(Pa_x, Py, Pz_y, Py_x, Pz_yx):\n",
    "    # compute delta\n",
    "    term_1 = (tf_Pz_yx / tf.expand_dims(tf_Pz_y, axis=-1)) - 1 # ok\n",
    "    term_2 = tf_Py_x / tf.expand_dims(tf_Py,axis=-1) # ok\n",
    "    delta = term_1 * tf.expand_dims(term_2, axis=0) # ok\n",
    "    \n",
    "    # compute c\n",
    "    c = tf.linalg.matmul(tf.expand_dims(tf.expand_dims(Pa_x, axis=0),axis=0),\n",
    "                         tf.expand_dims(delta, axis=-1))\n",
    "    \n",
    "    # compute fairness\n",
    "    fairness = tf.norm(c, ord=1, axis=None, keepdims=None, name=None) / 6000\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.691653>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_fairness(tf_P_a_x, tf_Py, tf_Pz_y, tf_Py_x, tf_Pz_yx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_P_a_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6000,), dtype=float64, numpy=\n",
       "array([ 0.07801016, -0.20923758, -1.08256027, ...,  0.12042848,\n",
       "       -0.55555947,  0.09868941])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tf[z,y,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_P_a_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_tf\u001b[49m\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "tf.expand_dims(tf_P_a_x, axis=0) * delta_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 6000), dtype=float32, numpy=\n",
       "array([[[0.98514897, 0.93615055, 0.11145234, ..., 0.9365855 ,\n",
       "         0.2046777 , 0.9690408 ],\n",
       "        [0.01485102, 0.06384946, 0.88854766, ..., 0.06341453,\n",
       "         0.7953223 , 0.03095921]]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(tf_P_a_x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([12, 2, 6000]), (12, 2, 6000))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tf.shape, delta_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 2, 6000), dtype=float64, numpy=\n",
       "array([[[ 0.20852164,  0.23392911, -0.43141843, ...,  0.06829575,\n",
       "         -0.24835348,  0.13897109],\n",
       "        [ 0.44608432,  0.47697199, -0.36121218, ...,  0.26005756,\n",
       "         -0.12074918,  0.35260648]],\n",
       "\n",
       "       [[-0.3533575 , -0.08558822,  0.58436664, ..., -0.2334473 ,\n",
       "          0.13374523, -0.29426304],\n",
       "        [-0.47147072, -0.25236525,  0.21586443, ..., -0.38240109,\n",
       "         -0.09410009, -0.42751087]],\n",
       "\n",
       "       [[ 0.39891276,  0.00713987, -0.30089692, ...,  0.37403473,\n",
       "         -0.09849992,  0.38974112],\n",
       "        [ 0.71618753,  0.23596668, -0.19473285, ...,  0.66161926,\n",
       "          0.08118453,  0.69210611]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.00322377,  0.01688301, -0.52548693, ..., -0.1753816 ,\n",
       "         -0.09818587, -0.09120677],\n",
       "        [ 0.3501312 ,  0.37781896, -0.39653631, ...,  0.10100938,\n",
       "          0.19414009,  0.22169546]],\n",
       "\n",
       "       [[ 0.41411424, -0.14322807, -0.62292095, ...,  0.4823729 ,\n",
       "         -0.41744152,  0.45131177],\n",
       "        [ 0.18134784, -0.28401918, -0.70423256, ...,  0.22070426,\n",
       "         -0.5242347 ,  0.20329909]],\n",
       "\n",
       "       [[ 0.2837893 , -0.41779317, -0.74033004, ...,  0.59912785,\n",
       "          0.00393157,  0.43624393],\n",
       "        [-0.17894392, -0.6275232 , -0.84407152, ...,  0.00814258,\n",
       "         -0.37231302, -0.0883527 ]]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 == n1_tf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(delta_tf.numpy() == delta_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness(policy, model_delta):\n",
    "    (Z, Y, X) = model_delta.shape\n",
    "    fairness = 0\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            c = np.matmul(policy, model_delta[z, y, :])\n",
    "            fairness += np.linalg.norm(c, 1) / X\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.379389364101258"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fairness(P_a_x, delta_v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values_1 = p_a_x*delta_v[z, y, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.58822407e-02, -4.34017986e-01, -1.67581003e-01, ...,\n",
       "         4.16570901e-03, -7.54972318e-02, -4.16011503e-02],\n",
       "       [-1.09382713e-03, -2.82798060e-02, -1.12994250e+00, ...,\n",
       "         2.77331954e-04, -3.19062733e-01, -1.28873914e-03]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= 1\n",
    "z= 11\n",
    "delta = (Pz_yx[z, y, :] / Pz_y[z, y] - 1 ) * (Py_x[y, :] / (Py[y]) )\n",
    "p_a_x*delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all((delta == delta_v[z,y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12,2,6000) (6000,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mn1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12,2,6000) (6000,2) "
     ]
    }
   ],
   "source": [
    "n1*n2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82105608, 0.3724768 , 0.15592848, ..., 1.00814258, 0.62768698,\n",
       "       0.9116473 ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pz_yx[z, y, :] / Pz_y[z, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(Pz_y,axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Pz_yx[z, \u001b[43mi\u001b[49m] \u001b[38;5;241m/\u001b[39m Pz_y[z, y]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "Pz_yx[z, y, :] / Pz_y[z, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = (Pz_yx[z, i] / Pz_y[z, y] - 1 ) * (Py_x[y, i] / (Py[y]) ) # (6000, 2, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.1231055>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [1, 1, 1]]) # x.dtype is tf.int32\n",
    "tf.math.reduce_euclidean_norm(x)  # returns 4 as dtype is tf.int32\n",
    "y = tf.constant([[1, 2, 3], [1, 1, 1]], dtype = tf.float32)\n",
    "tf.math.reduce_euclidean_norm(y)  # returns 4.1231055 which is sqrt(17)\n",
    "tf.math.reduce_euclidean_norm(y, 0)  # [sqrt(2), sqrt(5), sqrt(10)]\n",
    "tf.math.reduce_euclidean_norm(y, 1)  # [sqrt(14), sqrt(3)]\n",
    "tf.math.reduce_euclidean_norm(y, 1, keepdims=True)  # [[sqrt(14)], [sqrt(3)]]\n",
    "tf.math.reduce_euclidean_norm(y, [0, 1])  # sqrt(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pa_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_fairness_loss(\u001b[43mPa_x\u001b[49m, Py, Pz_y, Py_x, Pz_yx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pa_x' is not defined"
     ]
    }
   ],
   "source": [
    "get_fairness_loss(Pa_x, Py, Pz_y, Py_x, Pz_yx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fairness_loss': 0.0, 'utility': 0.53295857, 'loss': -0.53295857}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_results = {key:step_results[key].numpy() for key in step_results.keys()}\n",
    "step_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.90640097e-02, 3.75925926e-02],\n",
       "       [3.50694444e-01, 5.08703704e-01],\n",
       "       [2.79438406e-01, 2.41666667e-01],\n",
       "       [8.52958937e-02, 6.01851852e-02],\n",
       "       [6.49154589e-03, 2.40740741e-03],\n",
       "       [2.26449275e-03, 2.40740741e-03],\n",
       "       [1.25301932e-02, 4.62962963e-03],\n",
       "       [1.03411836e-01, 6.98148148e-02],\n",
       "       [9.31461353e-02, 6.16666667e-02],\n",
       "       [1.67572464e-02, 9.44444444e-03],\n",
       "       [4.52898551e-04, 5.55555556e-04],\n",
       "       [4.52898551e-04, 9.25925926e-04]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def empirical_fairness_cont_v12(datas, p_a_x, Pz_y, Py,model_y_x, model_z_yx):\n",
    "    Z = n_z\n",
    "\n",
    "    Py_x = model_y_x.predict_proba(datas[X_atr]).T\n",
    "    EF = 0\n",
    "    for y in range(2):\n",
    "        tmp_data = datas[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "        for z in range(Z):\n",
    "            c = 0\n",
    "            j= 0 \n",
    "            for i in range(tmp_data.shape[0]):\n",
    "                j = j + 1\n",
    "                delta = (Pz_yx[z, i] / Pz_y[z, y] - 1 ) * (Py_x[y, i] / (Py[y]) )\n",
    "                c += p_a_x[:, i] * delta\n",
    "            c = c/datas.shape[0]\n",
    "            c = np.linalg.norm(c, 1)\n",
    "            EF += c\n",
    "    return EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Pz_yx[z, i] / Pz_y[z, y] - 1 ) * (Py_x[y, i] / (Py[y]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Py = [Py[y] for y in train_data[Y_atr].values]\n",
    "data_Pz_y = [Pz_y[z, y] for z, y in train_data[[Z_atr,Y_atr]].values]\n",
    "\n",
    "predicted_proba_Py_x = model_y_x.predict_proba(train_data[X_atr])\n",
    "data_Py_z = np.zeros(train_data.shape[0])\n",
    "for i, (ind, datum) in enumerate(train_data.iterrows()):\n",
    "    data_Py_z[i] = predicted_proba_Py_x[i][datum[Y_atr]]\n",
    "    \n",
    "predicted_proba_Pz_yx = model_z_yx.predict_proba(train_data[[Y_atr] + X_atr])\n",
    "data_Pz_yx = np.zeros(train_data.shape[0])\n",
    "for i, (ind, datum) in enumerate(train_data.iterrows()):\n",
    "    data_Pz_yx[i] = predicted_proba_Pz_yx[i][datum[Z_atr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age_cat  race  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "0       0        2     0              0               0                0   \n",
       "1       0        1     1              0               0                0   \n",
       "2       0        0     1              0               0                1   \n",
       "3       0        0     1              0               1                0   \n",
       "4       0        1     0              0               0                0   \n",
       "...   ...      ...   ...            ...             ...              ...   \n",
       "5995    0        1     1              0               0                0   \n",
       "5996    1        1     0              0               0                0   \n",
       "5997    0        2     2              0               0                0   \n",
       "5998    0        1     1              0               0                0   \n",
       "5999    1        2     2              0               0                0   \n",
       "\n",
       "      priors_count  c_charge_degree  two_year_recid  z  \n",
       "0                0                1               0  0  \n",
       "1                0                1               1  1  \n",
       "2                4                1               1  1  \n",
       "3                1                1               0  1  \n",
       "4                2                1               0  0  \n",
       "...            ...              ...             ... ..  \n",
       "5995            22                1               1  1  \n",
       "5996             0                1               1  6  \n",
       "5997             2                1               1  2  \n",
       "5998             5                0               0  1  \n",
       "5999             1                1               0  8  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = LogisticRegresionTF(input_dim=len(X_atr), l = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "policy_model.compile(optimizer=optimizer,\n",
    "               metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = train_data[X_atr].astype(\"float32\")\n",
    "in_df[\"Py\"] = data_Py\n",
    "in_df[\"Pz_y\"] = data_Pz_y\n",
    "in_df[\"Py_z\"] = data_Py_z\n",
    "in_df[\"Pz_yx\"] = data_Pz_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_cat</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>Py</th>\n",
       "      <th>Pz_y</th>\n",
       "      <th>Py_z</th>\n",
       "      <th>Pz_yx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.806851</td>\n",
       "      <td>0.059295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.508704</td>\n",
       "      <td>0.330786</td>\n",
       "      <td>0.380325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.508704</td>\n",
       "      <td>0.690225</td>\n",
       "      <td>0.618515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>0.436171</td>\n",
       "      <td>0.478386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.052283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.508704</td>\n",
       "      <td>0.933514</td>\n",
       "      <td>0.837547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.330786</td>\n",
       "      <td>0.011815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449008</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.245004</td>\n",
       "      <td>0.401558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>0.524162</td>\n",
       "      <td>0.397598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550992</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.782034</td>\n",
       "      <td>0.112245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_cat  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0         2.0            0.0             0.0              0.0           0.0   \n",
       "1         1.0            0.0             0.0              0.0           0.0   \n",
       "2         0.0            0.0             0.0              1.0           4.0   \n",
       "3         0.0            0.0             1.0              0.0           1.0   \n",
       "4         1.0            0.0             0.0              0.0           2.0   \n",
       "...       ...            ...             ...              ...           ...   \n",
       "5995      1.0            0.0             0.0              0.0          22.0   \n",
       "5996      1.0            0.0             0.0              0.0           0.0   \n",
       "5997      2.0            0.0             0.0              0.0           2.0   \n",
       "5998      1.0            0.0             0.0              0.0           5.0   \n",
       "5999      2.0            0.0             0.0              0.0           1.0   \n",
       "\n",
       "      c_charge_degree        Py      Pz_y      Py_z     Pz_yx  \n",
       "0                 1.0  0.550992  0.049064  0.806851  0.059295  \n",
       "1                 1.0  0.449008  0.508704  0.330786  0.380325  \n",
       "2                 1.0  0.449008  0.508704  0.690225  0.618515  \n",
       "3                 1.0  0.550992  0.350694  0.436171  0.478386  \n",
       "4                 1.0  0.550992  0.049064  0.598783  0.052283  \n",
       "...               ...       ...       ...       ...       ...  \n",
       "5995              1.0  0.449008  0.508704  0.933514  0.837547  \n",
       "5996              1.0  0.449008  0.004630  0.330786  0.011815  \n",
       "5997              1.0  0.449008  0.241667  0.245004  0.401558  \n",
       "5998              0.0  0.550992  0.350694  0.524162  0.397598  \n",
       "5999              1.0  0.550992  0.093146  0.782034  0.112245  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset element_spec=((TensorSpec(shape=(None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset = tf.data.Dataset.from_tensor_slices((train_data[X_atr].astype(\"float64\").values,\n",
    "           data_Py,\n",
    "           data_Pz_y,\n",
    "           data_Py_z,\n",
    "           data_Pz_yx)\n",
    ")\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(train_data[Y_atr].values)\n",
    "tf_train_dataset2 = tf.data.Dataset.zip((input_dataset, labels_dataset))\n",
    "tf_train_dataset2.batch(batch_size = 64).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dataset.batch(batch_size= 12).repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = dataset.batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3]), array([ 0, -1, -2, -3])]\n",
      "[array([4, 5, 6, 7]), array([-4, -5, -6, -7])]\n",
      "[array([ 8,  9, 10, 11]), array([ -8,  -9, -10, -11])]\n",
      "[array([12, 13, 14, 15]), array([-12, -13, -14, -15])]\n"
     ]
    }
   ],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "for batch in batched_dataset.take(4):\n",
    "    print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "for batch in labels_dataset:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(6,), dtype=float64, numpy=array([2., 0., 0., 0., 0., 1.])>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5509915014164306>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.04906400966183575>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8068506063452929>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.05929491746587499>),\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(6,), dtype=float64, numpy=array([2., 0., 0., 0., 0., 1.])>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5509915014164306>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.04906400966183575>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8068506063452929>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.05929491746587499>),\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([2., 0., 0., 0., 0., 1.]),\n",
       "  0.5509915014164306,\n",
       "  0.04906400966183575,\n",
       "  0.8068506063452929,\n",
       "  0.05929491746587499),\n",
       " 0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf_train_dataset.as_numpy_iterator())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.80685060634529293, 0.059294917465874987)\n",
      "y shape:  []\n",
      "   1/6000 [..............................] - ETA: 31s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 4 1], 0.44900849858356939, 0.50870370370370366, 0.69022477735140764, 0.61851474034758691)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.43617055785508485, 0.4783860760271495)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.049064009661835752, 0.59878322752647029, 0.052283340602521572)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.24166666666666667, 0.80612420023422637, 0.15060182777681641)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.049064009661835752, 0.56175301303022862, 0.048225670322543282)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.54302447329801817, 0.18748927511481114)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.580318713100382, 0.517169767438791)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.21796646133876016, 0.10270049503810663)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.51398552192672631, 0.2507991349732705)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.633639285531326, 0.58413670975926879)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "  23/6000 [..............................] - ETA: 13s - fake: 0.0000e+00x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.49489857775297585, 0.063552082879970578)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.060185185185185182, 0.54302447329801817, 0.065813702507060867)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.09314613526570048, 0.56175301303022862, 0.073695505369088116)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 5 1], 0.44900849858356939, 0.50870370370370366, 0.55681556048428993, 0.52142400715712467)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.24166666666666667, 0.66025466709305991, 0.20519887738304279)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.037592592592592594, 0.40978663283753697, 0.0315526393782322)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 6 0], 0.55099150141643061, 0.27943840579710144, 0.40131749504613867, 0.33686130487804611)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.061666666666666668, 0.43810892255869566, 0.086906792572812641)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.50496122855418268, 0.19526459018337491)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 1 3 21 1], 0.44900849858356939, 0.50870370370370366, 0.96804472988024148, 0.89476532537796449)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.41954470314293846, 0.15774307304511689)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.78212912125246448, 0.2291733837310295)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.55099150141643061, 0.10341183574879227, 0.590213367162463, 0.075743839162455043)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.44900849858356939, 0.24166666666666667, 0.62521669996197893, 0.2185847224967678)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 4 13 1], 0.44900849858356939, 0.50870370370370366, 0.89303082113634025, 0.71185266121046631)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.66921440779625541, 0.020159677430391355)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.44900849858356939, 0.24166666666666667, 0.83378431759443994, 0.17224376674378497)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.016757246376811596, 0.78203353866123981, 0.015228872027597207)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 15 1], 0.55099150141643061, 0.35069444444444442, 0.14811915921705143, 0.69853407781892318)\n",
      "y shape:  []\n",
      "  55/6000 [..............................] - ETA: 11s - fake: 0.0000e+00x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.72589237637055337, 0.27026858591291786)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.5529826798509343, 0.33163906293229189)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 0], 0.44900849858356939, 0.50870370370370366, 0.48471176313269765, 0.46251203807947228)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 2 15 1], 0.44900849858356939, 0.50870370370370366, 0.89714782270260507, 0.81634007711567314)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.24166666666666667, 0.43810892255869566, 0.27098504005233026)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.58535988567697483, 0.54344180584191792)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 2 2 1], 0.44900849858356939, 0.50870370370370366, 0.67992328839931782, 0.63105612242723086)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.57255146474959462, 0.5830748457563657)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.82953758203903372, 0.065703137160179323)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.44900849858356939, 0.060185185185185182, 0.3735620396901918, 0.060513517581417015)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.45697552670198183, 0.0792848333283901)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 1 1], 0.44900849858356939, 0.24166666666666667, 0.4060727297381026, 0.3425321175414302)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.36528088984000795, 0.075271345209806967)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.588951387994036, 0.53694896693687166)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.19314939365470704, 0.054362058872582823)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 6 1 14 1], 0.44900849858356939, 0.50870370370370366, 0.90572227885719625, 0.89922834703433052)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.50510142224702415, 0.051425137887974919)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.61884665809761863, 0.60823904690430941)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 2 0], 0.44900849858356939, 0.50870370370370366, 0.58522375766564283, 0.51770222550880041)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "  89/6000 [..............................] - ETA: 10s - fake: 0.0000e+00x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.58908715161315817, 0.22818060869557721)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.54302447329801817, 0.046889874691886969)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.24166666666666667, 0.66025466709305991, 0.20519887738304279)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 0], 0.55099150141643061, 0.35069444444444442, 0.4395313423778261, 0.45774739810179915)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.49489857775297585, 0.063552082879970578)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.016757246376811596, 0.70209897371195851, 0.025807969413354771)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 2 8 1], 0.44900849858356939, 0.24166666666666667, 0.84105892937696358, 0.14572014637181405)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.6681832471057898, 0.6075366265557407)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.24166666666666667, 0.47583825790053685, 0.26128626159962504)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.71110182650329723, 0.67508944598885245)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 12 2 28 1], 0.44900849858356939, 0.50870370370370366, 0.99267844198598554, 0.98430237944564269)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.012530193236714976, 0.634719110159992, 0.013458031161759225)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.24166666666666667, 0.78123910465141932, 0.16093988771217441)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.5529826798509343, 0.40819234633391749)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.75509979173874053, 0.37450505361135167)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 19 1], 0.44900849858356939, 0.50870370370370366, 0.89894989841286588, 0.79856375836397331)\n",
      "y shape:  []\n",
      " 125/6000 [..............................] - ETA: 9s - fake: 0.0000e+00 x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.09314613526570048, 0.78212912125246448, 0.14372933804048768)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.65223523926262439, 0.16232980628344057)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.44816816104346935, 0.23572955437306012)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.59878322752647029, 0.079489603080120985)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.012530193236714976, 0.63484912955790884, 0.00950199490714618)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.44900849858356939, 0.061666666666666668, 0.71110182650329723, 0.027416988709803098)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.0094444444444444445, 0.47597814027541679, 0.0080876247571386815)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.09314613526570048, 0.694491423092075, 0.092902296075552476)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.41762331549294407, 0.11790321736354094)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.71272101396711984, 0.70679518251250217)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.72485344640802429, 0.65404856562659264)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.588951387994036, 0.53694896693687166)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.33078559220374454, 0.0748024584113431)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.069814814814814816, 0.58908715161315817, 0.071951565534841569)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.21796646133876016, 0.047869660377945739)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 1], 0.44900849858356939, 0.037592592592592594, 0.633639285531326, 0.017535246670826534)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.47597814027541679, 0.074757389322255161)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.012530193236714976, 0.78203353866123981, 0.011698357802909341)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.069814814814814816, 0.36515087044209121, 0.075827790329001374)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.75509979173874053, 0.24934523282883264)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.63301702939583337, 0.29898203581886329)\n",
      "y shape:  []\n",
      " 161/6000 [..............................] - ETA: 9s - fake: 0.0000e+00x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.061666666666666668, 0.43824698696977132, 0.066359149049251623)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.3735620396901918, 0.36050765846685567)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.09314613526570048, 0.62643796030980825, 0.080405637751305228)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.10341183574879227, 0.48601447807327369, 0.11221739162659708)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.085295893719806767, 0.78212912125246448, 0.094255388347237054)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.5529826798509343, 0.40819234633391749)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.09314613526570048, 0.44816816104346935, 0.05735764167147598)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.060185185185185182, 0.62534810521876572, 0.050234822487375687)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.51384542263649469, 0.4864837315119559)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.085295893719806767, 0.754996065631608, 0.085018950405766777)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.80685060634529293, 0.088344721017677527)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.19306200718740246, 0.40536007500734533)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.49489857775297585, 0.056075649854353135)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 2 1 22 1], 0.44900849858356939, 0.50870370370370366, 0.96452031220007706, 0.9267184940186256)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 23 0], 0.44900849858356939, 0.50870370370370366, 0.87173242339227164, 0.74888366568649134)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.40121677247352971, 0.072095735172724565)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 0], 0.44900849858356939, 0.24166666666666667, 0.409650996113323, 0.34642216010364485)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.0046296296296296294, 0.17046241796096631, 0.010551165711479635)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.78123910465141932, 0.69575136844445884)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.36515087044209121, 0.38345126452251183)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      " 196/6000 [..............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.49503877144581732, 0.15951472160614869)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.037592592592592594, 0.36515087044209121, 0.042711140784851886)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.5618910774413044, 0.25956855149884556)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 23 1], 0.44900849858356939, 0.069814814814814816, 0.94676210334096234, 0.039728691605748052)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.037592592592592594, 0.68589498751677958, 0.031127060356021873)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.24166666666666667, 0.72485344640802429, 0.18259560349794374)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.061666666666666668, 0.58908715161315817, 0.046001058549654091)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.40978663283753697, 0.34810985830817814)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 15 1], 0.55099150141643061, 0.35069444444444442, 0.17120115985380169, 0.6776343922527116)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.061666666666666668, 0.17046241796096631, 0.14845655767491439)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.037592592592592594, 0.33066145467639146, 0.046151043189944077)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.10341183574879227, 0.52416174209946309, 0.11336600927631808)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.72485344640802429, 0.65404856562659264)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.037592592592592594, 0.47597814027541679, 0.039399471906153352)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.43939318983316167, 0.48193974798640155)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.41954470314293846, 0.46487397466205538)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.069814814814814816, 0.40121677247352971, 0.075397622308301063)\n",
      "y shape:  []\n",
      " 232/6000 [>.............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.24166666666666667, 0.78123910465141932, 0.16093988771217441)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 11 0], 0.44900849858356939, 0.50870370370370366, 0.76143614756496691, 0.61506289122377567)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.52402185972458315, 0.077752351907200021)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 14 1], 0.55099150141643061, 0.35069444444444442, 0.18105531195278091, 0.69637512938298152)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.5410689070627277, 0.41776271459989378)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 25 1], 0.44900849858356939, 0.50870370370370366, 0.9568233845330707, 0.86914465229468274)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 0], 0.44900849858356939, 0.24166666666666667, 0.588951387994036, 0.229614033148943)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.44900849858356939, 0.24166666666666667, 0.54788699961025222, 0.23672950204151813)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.70209897371195851, 0.021163437796037379)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.012530193236714976, 0.56175301303022862, 0.0059042671316591007)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.24166666666666667, 0.62534810521876572, 0.21668449877452822)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.52402185972458315, 0.25423917870164192)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.580318713100382, 0.517169767438791)\n",
      "y shape:  []\n",
      " 256/6000 [>.............................] - ETA: 9s - fake: 0.0000e+00x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.50496122855418268, 0.077146509428868082)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.016757246376811596, 0.70209897371195851, 0.025807969413354771)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.44900849858356939, 0.060185185185185182, 0.58535988567697483, 0.06465778212789354)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 4 5 1], 0.44900849858356939, 0.061666666666666668, 0.81308209223861883, 0.027445471837602396)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.53302001810037081, 0.094657826601827991)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.55099150141643061, 0.085295893719806767, 0.45197408231262648, 0.0842982955459353)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.50510142224702415, 0.10800705557451334)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.44701732014906564, 0.46093091201993919)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.72485344640802429, 0.65404856562659264)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 3 0], 0.44900849858356939, 0.50870370370370366, 0.64119788850312021, 0.59324845942116733)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.45697552670198183, 0.058803105443603843)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.10341183574879227, 0.63484912955790884, 0.11100551470537433)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.66921440779625541, 0.020159677430391355)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 24 0], 0.55099150141643061, 0.35069444444444442, 0.057675205433984522, 0.7876192270015473)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.27421922789890879, 0.33767490728032107)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      " 289/6000 [>.............................] - ETA: 9s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.3735620396901918, 0.36050765846685567)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.060185185185185182, 0.43824698696977132, 0.06638829248546177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.27943840579710144, 0.52416174209946309, 0.25191374631096036)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.35069444444444442, 0.52416174209946309, 0.39759815226808476)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.49489857775297585, 0.056075649854353135)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 4 0], 0.44900849858356939, 0.50870370370370366, 0.65667041723085673, 0.56878157574645316)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 1 4 0], 0.44900849858356939, 0.50870370370370366, 0.52085387818409123, 0.5148611624926922)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.27943840579710144, 0.48601447807327369, 0.24523720643083349)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.037592592592592594, 0.40121677247352971, 0.04715797206380385)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.10341183574879227, 0.48601447807327369, 0.11221739162659708)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.40108204471537817, 0.28003070341004432)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 9 1], 0.44900849858356939, 0.037592592592592594, 0.8136136092726034, 0.023950469039236474)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      " 325/6000 [>.............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.62643796030980825, 0.35292774658953335)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.37465189478123428, 0.21572006930544979)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.60080888423479628, 0.58239636221322111)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 36 1], 0.44900849858356939, 0.24166666666666667, 0.98281829329541126, 0.047733688062230696)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 3 1], 0.55099150141643061, 0.085295893719806767, 0.36332657696128012, 0.058003586032815191)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.061666666666666668, 0.36515087044209121, 0.10167978747093329)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.016757246376811596, 0.49503877144581732, 0.02191420137457787)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.50510142224702415, 0.10800705557451334)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.36528088984000795, 0.051287053144881974)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.80693799281259748, 0.095749556349074769)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.049064009661835752, 0.56175301303022862, 0.048225670322543282)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 12 1], 0.44900849858356939, 0.50870370370370366, 0.76940909775271293, 0.71577849206257327)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.55099150141643061, 0.35069444444444442, 0.41464011432302517, 0.47832291672099375)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.0094444444444444445, 0.36528088984000795, 0.011628157898719019)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.62082007807803641, 0.61627042536386867)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.55099150141643061, 0.09314613526570048, 0.40975238711585082, 0.062277245379417027)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.41954470314293846, 0.1721041402523949)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 6 0], 0.44900849858356939, 0.50870370370370366, 0.55667715855582545, 0.49651102890444238)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.50510142224702415, 0.10800705557451334)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      " 361/6000 [>.............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([1 0 0 1 2 0], 0.55099150141643061, 0.35069444444444442, 0.5940625231820641, 0.34149323837644896)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([0 2 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.68928675913557569, 0.67323022727021542)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.36515087044209121, 0.079983175897264433)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 1 1], 0.55099150141643061, 0.012530193236714976, 0.41762331549294407, 0.014608651057671743)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.43617055785508485, 0.4783860760271495)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.54288530021098935, 0.18796781752853275)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 18 1], 0.55099150141643061, 0.35069444444444442, 0.21274596059147433, 0.64512269280230206)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.65223523926262439, 0.59135589692414836)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.19306200718740246, 0.14040437838096034)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.49503877144581732, 0.18288589080090278)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.61118160895848239, 0.64149162092030654)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.65223523926262439, 0.59135589692414836)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.41968128689961803, 0.17156502619019842)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 23 1], 0.44900849858356939, 0.50870370370370366, 0.94235526751486243, 0.8488537055611044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.754996065631608, 0.26882577192122248)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 0 23 1], 0.44900849858356939, 0.24166666666666667, 0.90282857670370387, 0.12654614326298025)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 12 1], 0.44900849858356939, 0.50870370370370366, 0.75413406854057818, 0.67534079777960154)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.016757246376811596, 0.66921440779625541, 0.0170401592110622)\n",
      "y shape:  []\n",
      " 397/6000 [>.............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([2 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.3387020227126683, 0.37218820205717057)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.55980845962395653, 0.43889318677531242)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 0], 0.44900849858356939, 0.50870370370370366, 0.51000335404847119, 0.46411683111875435)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 6 1], 0.55099150141643061, 0.35069444444444442, 0.36524806177508862, 0.4957126144278548)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.66129797728733175, 0.33636401471991234)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.305508576907925, 0.38302007706260693)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.049064009661835752, 0.694491423092075, 0.045549951811855519)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.49503877144581732, 0.0915141725382425)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.36528088984000795, 0.075271345209806967)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.43939318983316167, 0.48193974798640155)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.53302001810037081, 0.094657826601827991)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.09314613526570048, 0.78212912125246448, 0.14372933804048768)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.44900849858356939, 0.50870370370370366, 0.551693133733535, 0.51189107807450518)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.54302447329801817, 0.18748927511481114)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.37465189478123428, 0.52151660280027978)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 21 0], 0.44900849858356939, 0.50870370370370366, 0.83370657850285079, 0.71329433625803829)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.38301729166873721, 0.49046932957993689)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.060185185185185182, 0.19306200718740246, 0.080607759122322334)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.21796646133876016, 0.29122734165409342)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      " 433/6000 [=>............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([0 0 1 1 3 1], 0.44900849858356939, 0.24166666666666667, 0.67551720210162491, 0.17218519076826624)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.61698270833126279, 0.10447179311882435)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.44900849858356939, 0.24166666666666667, 0.58535988567697483, 0.22670743772625485)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.49489857775297585, 0.063552082879970578)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.060185185185185182, 0.40121677247352971, 0.069481144049873877)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.6235934774048022, 0.60677477184728534)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.36515087044209121, 0.079983175897264433)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.694491423092075, 0.37075515534738879)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.72578077210109115, 0.073253174445946825)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.53302001810037081, 0.18724593671112882)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 16 1], 0.55099150141643061, 0.35069444444444442, 0.26811333291770056, 0.6011128060037515)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.069814814814814816, 0.24500393436839196, 0.048580263381685647)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.037592592592592594, 0.54802591768737352, 0.036078198759457863)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 0], 0.44900849858356939, 0.50870370370370366, 0.75403006664516636, 0.65353926963756537)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 16 1], 0.55099150141643061, 0.10341183574879227, 0.26811333291770056, 0.068426986589605679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.3735620396901918, 0.36050765846685567)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.000925925925925926, 0.47597814027541679, 0.00048595502007214668)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.3387020227126683, 0.38609287862076652)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.74283468451895107, 0.72661397127474991)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 2 2 6 1], 0.55099150141643061, 0.35069444444444442, 0.16713094239805393, 0.758653156295704)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 28 1], 0.44900849858356939, 0.50870370370370366, 0.94425632768560064, 0.84796271941160528)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 8 1], 0.44900849858356939, 0.50870370370370366, 0.66476515110947831, 0.59565305661915036)\n",
      "y shape:  []\n",
      " 469/6000 [=>............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([0 1 0 0 6 1], 0.44900849858356939, 0.069814814814814816, 0.74897035626861208, 0.068512617579337631)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.78212912125246448, 0.2291733837310295)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 0], 0.44900849858356939, 0.50870370370370366, 0.5604686576221739, 0.512539420380599)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.44900849858356939, 0.24166666666666667, 0.54788699961025222, 0.23672950204151813)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.060185185185185182, 0.47597814027541679, 0.063197559445460266)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.006491545893719807, 0.66921440779625541, 0.008323506077618727)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.085295893719806767, 0.63484912955790884, 0.095666846965124258)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 6 1], 0.44900849858356939, 0.061666666666666668, 0.75127178183378152, 0.031552785849578324)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 4 2 0], 0.44900849858356939, 0.24166666666666667, 0.70289650231619738, 0.33807041223927758)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.44900849858356939, 0.0024074074074074076, 0.3387020227126683, 0.0026689068398422951)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.0094444444444444445, 0.58045529685706154, 0.0093269793562978914)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.060185185185185182, 0.58908715161315817, 0.053443111322205215)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.55099150141643061, 0.085295893719806767, 0.16621568240556006, 0.033232938864816618)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 33 1], 0.44900849858356939, 0.50870370370370366, 0.97314874899346715, 0.89363118731365954)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      " 505/6000 [=>............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.72589237637055337, 0.36950203562898171)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 12 0], 0.55099150141643061, 0.10341183574879227, 0.2752584204632047, 0.1055440081793466)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 1], 0.55099150141643061, 0.049064009661835752, 0.40233549073682651, 0.022767141117627124)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.55099150141643061, 0.085295893719806767, 0.448306866266465, 0.07837708064975786)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.049064009661835752, 0.63484912955790884, 0.046685302906980766)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.10341183574879227, 0.44816816104346935, 0.11147652913603139)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.52286079276698294, 0.51102266493922754)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.17046241796096631, 0.22933156190003251)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.72589237637055337, 0.27026858591291786)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.53302001810037081, 0.18724593671112882)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 3 6 1], 0.55099150141643061, 0.27943840579710144, 0.30807319688168877, 0.31995627896319978)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.34955381681062303, 0.40450513372273739)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.57255146474959462, 0.5830748457563657)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 0 20 1], 0.55099150141643061, 0.085295893719806767, 0.070310079596039077, 0.017857297397061121)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 9 0], 0.44900849858356939, 0.24166666666666667, 0.8036211343682963, 0.15503845324632057)\n",
      "y shape:  []\n",
      " 540/6000 [=>............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([0 1 0 4 6 1], 0.44900849858356939, 0.24166666666666667, 0.85597986688384609, 0.23944077666059735)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.50510142224702415, 0.069177312081953782)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.36515087044209121, 0.079983175897264433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.24500393436839196, 0.40155798880175059)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.41954470314293846, 0.1721041402523949)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.016757246376811596, 0.78203353866123981, 0.015228872027597207)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.37465189478123428, 0.52151660280027978)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.62643796030980825, 0.3599268844225193)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 3 1], 0.55099150141643061, 0.35069444444444442, 0.51898793428497192, 0.41600929364500155)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.80685060634529293, 0.017326632556585436)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.655916389713406, 0.640112302568515)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.63667342303871988, 0.60694328054479108)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.75509979173874053, 0.24934523282883264)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 8 0 1 16 1], 0.44900849858356939, 0.50870370370370366, 0.96013794436921274, 0.89841526265567884)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.27943840579710144, 0.48601447807327369, 0.24523720643083349)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 8 1], 0.55099150141643061, 0.085295893719806767, 0.22489730807386543, 0.053003731890485829)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 0], 0.55099150141643061, 0.27943840579710144, 0.30661625104279266, 0.19621845435438792)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.069814814814814816, 0.55183183895653065, 0.073102614788650766)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 15 1], 0.55099150141643061, 0.35069444444444442, 0.17120115985380169, 0.6776343922527116)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.52402185972458315, 0.077752351907200021)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.45697552670198183, 0.17836107409797464)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      " 576/6000 [=>............................] - ETA: 8s - fake: 0.0000e+00x shape:  ([2 0 0 0 2 0], 0.44900849858356939, 0.061666666666666668, 0.2178708787475355, 0.13225869945189483)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.3387020227126683, 0.37218820205717057)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.24166666666666667, 0.62534810521876572, 0.21668449877452822)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.17046241796096631, 0.40868663081907958)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 5 1], 0.44900849858356939, 0.50870370370370366, 0.55681556048428993, 0.52142400715712467)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.49503877144581732, 0.18288589080090278)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.037592592592592594, 0.29790102628804155, 0.049635128371995338)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.845743717781446, 0.77151211429928779)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([0 4 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.78055973047589977, 0.73934262902717729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.49489857775297585, 0.063552082879970578)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.46697998189962925, 0.080582342501612128)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.55099150141643061, 0.09314613526570048, 0.45197408231262648, 0.064471027577452808)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.41762331549294407, 0.5112630032854012)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 17 1], 0.44900849858356939, 0.50870370370370366, 0.76066595557373518, 0.6735863718902152)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.84471092676542014, 0.73725032543301838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.060185185185185182, 0.33066145467639146, 0.082830438863511921)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.50870370370370366, 0.54802591768737352, 0.51671918964209307)\n",
      "y shape:  []\n",
      " 612/6000 [==>...........................] - ETA: 8s - fake: 0.0000e+00x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.060185185185185182, 0.55183183895653065, 0.05669124075972435)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.55099150141643061, 0.35069444444444442, 0.30649702965721171, 0.56925936918763809)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.55099150141643061, 0.35069444444444442, 0.48615457736350531, 0.422378431006825)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 0], 0.44900849858356939, 0.50870370370370366, 0.44687869072757952, 0.43741936813377447)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.55099150141643061, 0.09314613526570048, 0.38301729166873721, 0.049544360184617713)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.58045529685706154, 0.048998811502905817)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 15 1], 0.44900849858356939, 0.50870370370370366, 0.70100700723143594, 0.63029474048897749)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.65223523926262439, 0.59135589692414836)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 4 1], 0.44900849858356939, 0.50870370370370366, 0.7079325917837811, 0.66345811893422013)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.43824698696977132, 0.27210380471688639)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.27943840579710144, 0.52416174209946309, 0.25191374631096036)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.655916389713406, 0.11676904417474469)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 1 18 1], 0.44900849858356939, 0.50870370370370366, 0.91483645361746124, 0.85438047769463943)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.49489857775297585, 0.056075649854353135)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.305508576907925, 0.049490782586540105)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.061666666666666668, 0.17046241796096631, 0.14845655767491439)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.55099150141643061, 0.35069444444444442, 0.45197408231262648, 0.4511214938808959)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.54302447329801817, 0.18748927511481114)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.58045529685706154, 0.17937979485979097)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.43824698696977132, 0.27210380471688639)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.55099150141643061, 0.10341183574879227, 0.30649702965721171, 0.10524795908565389)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      " 648/6000 [==>...........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([0 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.34776476073737561, 0.51537665116514364)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.069814814814814816, 0.66025466709305991, 0.069107897637623525)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.78123910465141932, 0.69575136844445884)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 23 1], 0.44900849858356939, 0.50870370370370366, 0.94235526751486243, 0.8488537055611044)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.55099150141643061, 0.35069444444444442, 0.16621568240556006, 0.68613194575082792)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.36332657696128012, 0.529276177462947)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 1 0], 0.44900849858356939, 0.50870370370370366, 0.369839929802896, 0.36839186450007694)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.54288530021098935, 0.073520006732131382)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.2178708787475355, 0.27120515235276155)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.80685060634529293, 0.088344721017677527)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.27514655359197571, 0.59232870696776374)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.037592592592592594, 0.43810892255869566, 0.036135062140190938)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.27943840579710144, 0.48601447807327369, 0.24523720643083349)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.80685060634529293, 0.059294917465874987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.754996065631608, 0.10581850128555505)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 17 1], 0.44900849858356939, 0.50870370370370366, 0.76066595557373518, 0.6735863718902152)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 3 1], 0.55099150141643061, 0.35069444444444442, 0.34320315194883722, 0.530563497515719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 15 1], 0.44900849858356939, 0.061666666666666668, 0.85188084078294857, 0.018163941603358449)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.060185185185185182, 0.58908715161315817, 0.053443111322205215)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 2 0], 0.44900849858356939, 0.50870370370370366, 0.58522375766564283, 0.51770222550880041)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.0024074074074074076, 0.54802591768737352, 0.0028259169102202815)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.27421922789890879, 0.39286224540502784)\n",
      "y shape:  []\n",
      " 684/6000 [==>...........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 15 1], 0.44900849858356939, 0.50870370370370366, 0.82879884014619831, 0.73380495573648064)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.5410689070627277, 0.41776271459989378)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.38115334190238137, 0.53807234477308874)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.24500393436839196, 0.40155798880175059)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.44900849858356939, 0.50870370370370366, 0.83378431759443994, 0.732154791939904)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.49503877144581732, 0.3892330546574016)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 0], 0.44900849858356939, 0.50870370370370366, 0.66012885092623619, 0.58559897249171111)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.71110182650329723, 0.67508944598885245)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 1], 0.44900849858356939, 0.061666666666666668, 0.48485184113758911, 0.0552040436735101)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.35514369190290229, 0.56589806738389448)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.53302001810037081, 0.094657826601827991)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.754996065631608, 0.10581850128555505)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      " 712/6000 [==>...........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 1 1 0], 0.55099150141643061, 0.35069444444444442, 0.630160070197104, 0.31726006041165905)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 18 1], 0.44900849858356939, 0.50870370370370366, 0.78725403940852567, 0.6940001612982728)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.45697552670198183, 0.0792848333283901)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.53302001810037081, 0.18724593671112882)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.45697552670198183, 0.17836107409797464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.016757246376811596, 0.634719110159992, 0.01536131069909156)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.24166666666666667, 0.72485344640802429, 0.18259560349794374)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 1 1], 0.44900849858356939, 0.24166666666666667, 0.60563719047184228, 0.19194584687545843)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.19314939365470704, 0.26886480002960117)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.47597814027541679, 0.074757389322255161)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.754996065631608, 0.26882577192122248)\n",
      "y shape:  []\n",
      " 733/6000 [==>...........................] - ETA: 8s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 6 1], 0.44900849858356939, 0.50870370370370366, 0.75127178183378152, 0.664124206653872)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.43939318983316167, 0.48193974798640155)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.71110182650329723, 0.67508944598885245)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 22 1], 0.44900849858356939, 0.24166666666666667, 0.93351404700176543, 0.08311906518493957)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.80685060634529293, 0.11849310494168314)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.45697552670198183, 0.17836107409797464)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 7 0], 0.44900849858356939, 0.50870370370370366, 0.6139624782153088, 0.57635851746377342)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.5529826798509343, 0.40819234633391749)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 4 0 10 0], 0.55099150141643061, 0.35069444444444442, 0.26881481457722534, 0.67015744080446216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.44900849858356939, 0.50870370370370366, 0.59024761288414918, 0.527427844161124)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.085295893719806767, 0.48601447807327369, 0.074237176692171308)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 19 1], 0.44900849858356939, 0.069814814814814816, 0.81161989517768574, 0.039041516588930368)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.54302447329801817, 0.046889874691886969)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.53302001810037081, 0.022864525189208989)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.54302447329801817, 0.053710318618841464)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.0022644927536231885, 0.59891795528462177, 0.0033685073187855251)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 18 1], 0.44900849858356939, 0.24166666666666667, 0.78725403940852567, 0.19704747345622872)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      " 765/6000 [==>...........................] - ETA: 8s - fake: 0.0000e+00x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 5 1], 0.44900849858356939, 0.50870370370370366, 0.55681556048428993, 0.52142400715712467)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.55099150141643061, 0.049064009661835752, 0.45711469978901065, 0.043181930122977885)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.36528088984000795, 0.051287053144881974)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.10341183574879227, 0.52402185972458315, 0.11256948850025975)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.50496122855418268, 0.19526459018337491)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 1 2 1], 0.44900849858356939, 0.24166666666666667, 0.66045484984021008, 0.15087712516129984)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.43939318983316167, 0.48193974798640155)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.56382944214491515, 0.55690301385190577)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 22 1], 0.44900849858356939, 0.50870370370370366, 0.94344138287190371, 0.84608390129464939)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.53302001810037081, 0.022864525189208989)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.55099150141643061, 0.27943840579710144, 0.40975238711585082, 0.2765189850959836)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.069814814814814816, 0.50496122855418268, 0.10988554822697814)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      " 801/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.049064009661835752, 0.59891795528462177, 0.043336181614318729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 17 1], 0.44900849858356939, 0.50870370370370366, 0.86776892958946927, 0.76807098483026626)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 1 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.56563222395496493, 0.017163708039715439)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.55099150141643061, 0.085295893719806767, 0.27514655359197571, 0.052613647555998691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.55099150141643061, 0.35069444444444442, 0.45197408231262648, 0.4511214938808959)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.37465189478123428, 0.21572006930544979)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 0], 0.55099150141643061, 0.35069444444444442, 0.62656919312517556, 0.33716977104471774)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.33066145467639146, 0.10930983831953528)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 16 1], 0.55099150141643061, 0.35069444444444442, 0.14022164499392475, 0.73312078086532873)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.0046296296296296294, 0.29790102628804155, 0.0125789940265891)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.45697552670198183, 0.15818433184860833)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.78123910465141932, 0.69575136844445884)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.50510142224702415, 0.051425137887974919)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 20 1], 0.55099150141643061, 0.35069444444444442, 0.076016622254013844, 0.811261387826465)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 3 1], 0.44900849858356939, 0.50870370370370366, 0.502051391266691, 0.52342672416220826)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 0 25 1], 0.44900849858356939, 0.50870370370370366, 0.92644302947016943, 0.84395670839780623)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.44900849858356939, 0.50870370370370366, 0.54788699961025222, 0.49120254132289431)\n",
      "y shape:  []\n",
      " 835/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 1 0 0 9 0], 0.44900849858356939, 0.50870370370370366, 0.48668386775970984, 0.50546728505379324)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.51398552192672631, 0.2507991349732705)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.27410762362944663, 0.31600081081482551)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.5618910774413044, 0.37291445460398787)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.72589237637055337, 0.36950203562898171)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.46697998189962925, 0.10991764061204658)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.049064009661835752, 0.56175301303022862, 0.048225670322543282)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.44900849858356939, 0.50870370370370366, 0.54788699961025222, 0.49120254132289431)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.24166666666666667, 0.43810892255869566, 0.27098504005233026)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.33066145467639146, 0.10930983831953528)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.55099150141643061, 0.35069444444444442, 0.41464011432302517, 0.47832291672099375)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.60563719047184228, 0.5915923687542014)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.655916389713406, 0.11676904417474469)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.4589310929372723, 0.48386430574285705)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.70374407406244743, 0.65315706331990042)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.016757246376811596, 0.66933854532360848, 0.023416886797905608)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 7 0], 0.55099150141643061, 0.35069444444444442, 0.23343072283819288, 0.62303000629318317)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.55099150141643061, 0.35069444444444442, 0.37478330003802107, 0.49638442311538278)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.45697552670198183, 0.058803105443603843)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 3 0 25 0], 0.44900849858356939, 0.50870370370370366, 0.96076733083458965, 0.90479332350072728)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.78123910465141932, 0.69575136844445884)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.80685060634529293, 0.059294917465874987)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.30538959652539016, 0.3393784149708492)\n",
      "y shape:  []\n",
      " 871/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.10341183574879227, 0.52402185972458315, 0.11256948850025975)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 3 1], 0.55099150141643061, 0.35069444444444442, 0.30808972079953156, 0.5980081119659032)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.56382944214491515, 0.15764433928874244)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 3 1 6 1], 0.44900849858356939, 0.50870370370370366, 0.79543255689886427, 0.77036609122244171)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.037592592592592594, 0.47597814027541679, 0.039399471906153352)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.09314613526570048, 0.5618910774413044, 0.09580305626224693)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 25 0], 0.44900849858356939, 0.0024074074074074076, 0.95762639782106918, 0.015847337159276831)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.060185185185185182, 0.61698270833126279, 0.058791685441465548)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.50496122855418268, 0.19526459018337491)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.36528088984000795, 0.0780093162298684)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.016757246376811596, 0.80693799281259748, 0.022690698692107894)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.17046241796096631, 0.082103614861541288)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.5618910774413044, 0.25956855149884556)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 3 0], 0.55099150141643061, 0.09314613526570048, 0.55691901409179057, 0.10023428452541285)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      " 907/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 6 0], 0.44900849858356939, 0.50870370370370366, 0.55667715855582545, 0.49651102890444238)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.24500393436839196, 0.31417485123041378)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.21796646133876016, 0.10270049503810663)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.27421922789890879, 0.33767490728032107)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 19 1], 0.44900849858356939, 0.50870370370370366, 0.89894989841286588, 0.79856375836397331)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.75509979173874053, 0.24934523282883264)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 0], 0.44900849858356939, 0.50870370370370366, 0.66012885092623619, 0.58559897249171111)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.016757246376811596, 0.82953758203903372, 0.024744462124346802)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.0094444444444444445, 0.29790102628804155, 0.01998757407163625)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.305508576907925, 0.38302007706260693)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.41954470314293846, 0.46487397466205538)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.36515087044209121, 0.38345126452251183)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 1 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.7644659977880941, 0.73002392013446671)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      " 942/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.19314939365470704, 0.26886480002960117)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.27943840579710144, 0.48601447807327369, 0.24523720643083349)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.53302001810037081, 0.18724593671112882)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 0 0], 0.44900849858356939, 0.061666666666666668, 0.48798264034773214, 0.069813827049002866)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.69350297034278829, 0.6319194307746071)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.53302001810037081, 0.18724593671112882)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.0094444444444444445, 0.46697998189962925, 0.018963326125962788)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.0094444444444444445, 0.58045529685706154, 0.0093269793562978914)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 10 1], 0.44900849858356939, 0.50870370370370366, 0.72885850345593139, 0.64212093483134669)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.27410762362944663, 0.31600081081482551)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.54288530021098935, 0.18796781752853275)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.33857641736335942, 0.36330928512409821)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 6 0], 0.55099150141643061, 0.10341183574879227, 0.3142258523428314, 0.15530731749252832)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.24166666666666667, 0.62534810521876572, 0.21668449877452822)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.49686793819261338, 0.509938911712172)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.33797661079330632, 0.21227660740881032)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      " 978/6000 [===>..........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.50870370370370366, 0.54802591768737352, 0.51671918964209307)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.061666666666666668, 0.47597814027541679, 0.0608522039560748)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.085295893719806767, 0.754996065631608, 0.085018950405766777)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.78212912125246448, 0.2291733837310295)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 17 0], 0.55099150141643061, 0.35069444444444442, 0.26822339840644149, 0.57784797244402764)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.44900849858356939, 0.060185185185185182, 0.83378431759443994, 0.02505981270641337)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.060185185185185182, 0.54302447329801817, 0.065813702507060867)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.41954470314293846, 0.1721041402523949)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.45711469978901065, 0.415193408692939)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.012530193236714976, 0.63484912955790884, 0.00950199490714618)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 8 0], 0.44900849858356939, 0.069814814814814816, 0.609170324204211, 0.0758087355903358)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.44900849858356939, 0.060185185185185182, 0.58535988567697483, 0.06465778212789354)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.80693799281259748, 0.095749556349074769)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.060185185185185182, 0.50496122855418268, 0.077158096451933389)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.44816816104346935, 0.23572955437306012)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 17 0], 0.44900849858356939, 0.50870370370370366, 0.859710727769743, 0.76936745701269849)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 0], 0.44900849858356939, 0.50870370370370366, 0.69338374895720734, 0.60899871653364135)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.6235934774048022, 0.60677477184728534)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.19314939365470704, 0.074017638527552734)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.634719110159992, 0.0871736733474773)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 1 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.61305608450305926, 0.6535278333432939)\n",
      "y shape:  []\n",
      "1014/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 3 0], 0.55099150141643061, 0.10341183574879227, 0.55691901409179057, 0.064008519092822638)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 2 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.34243028439315792, 0.12126846250355766)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.060185185185185182, 0.21796646133876016, 0.072237399794743876)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.55099150141643061, 0.10341183574879227, 0.66129797728733175, 0.074992572125573781)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 16 1], 0.44900849858356939, 0.50870370370370366, 0.84931727947733682, 0.75141374888029211)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.5529826798509343, 0.40819234633391749)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.33078559220374454, 0.0555232063669804)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.069814814814814816, 0.47583825790053685, 0.075865458034076974)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.49503877144581732, 0.3892330546574016)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 1 13 0], 0.44900849858356939, 0.50870370370370366, 0.81038708722185093, 0.71707741531495006)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.78212912125246448, 0.2291733837310295)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 0], 0.55099150141643061, 0.27943840579710144, 0.69461040347460989, 0.36328097395053965)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 17 1], 0.44900849858356939, 0.50870370370370366, 0.76066595557373518, 0.6735863718902152)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.53302001810037081, 0.094657826601827991)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.47597814027541679, 0.074757389322255161)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 30 0], 0.44900849858356939, 0.061666666666666668, 0.95171713296505323, 0.0078033188074658408)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.694491423092075, 0.31328888594922055)\n",
      "y shape:  []\n",
      "1050/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.754996065631608, 0.26882577192122248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 19 1], 0.55099150141643061, 0.35069444444444442, 0.18838010482231426, 0.66602960098859487)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.45697552670198183, 0.15818433184860833)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.09314613526570048, 0.694491423092075, 0.092902296075552476)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.52286079276698294, 0.51102266493922754)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.085295893719806767, 0.63484912955790884, 0.095666846965124258)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.54302447329801817, 0.10728433957883819)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.21796646133876016, 0.29122734165409342)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.55099150141643061, 0.27943840579710144, 0.48615457736350531, 0.24359809888069844)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 1 0], 0.44900849858356939, 0.50870370370370366, 0.59011196589781378, 0.50102284589288537)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.016757246376811596, 0.82953758203903372, 0.024744462124346802)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 9 1], 0.44900849858356939, 0.50870370370370366, 0.69777409766615173, 0.61924621271264624)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.016757246376811596, 0.66933854532360848, 0.023416886797905608)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "1086/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.24500393436839196, 0.0961628190630497)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.46697998189962925, 0.20185797228830529)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 0 0 18 0], 0.55099150141643061, 0.35069444444444442, 0.099675100261016558, 0.79058260180226081)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.061666666666666668, 0.51398552192672631, 0.055610100094629626)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.44900849858356939, 0.24166666666666667, 0.551693133733535, 0.24047964550554285)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.5529826798509343, 0.33163906293229189)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.590213367162463, 0.38389998824150912)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.069814814814814816, 0.43810892255869566, 0.076133751690832849)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.41954470314293846, 0.054103109413926986)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.50510142224702415, 0.069177312081953782)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.61698270833126279, 0.10447179311882435)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.61685016670238713, 0.54254398881434041)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.24490020826125952, 0.394155153651305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 4 0], 0.55099150141643061, 0.27943840579710144, 0.47608270878125691, 0.36095081105602728)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.55099150141643061, 0.016757246376811596, 0.30649702965721171, 0.0050072700832305339)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 16 1], 0.44900849858356939, 0.50870370370370366, 0.84931727947733682, 0.75141374888029211)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.061666666666666668, 0.17046241796096631, 0.14845655767491439)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.55099150141643061, 0.35069444444444442, 0.30649702965721171, 0.56925936918763809)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 12 0], 0.44900849858356939, 0.50870370370370366, 0.75775236110537192, 0.6415097453666202)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "1122/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.55099150141643061, 0.27943840579710144, 0.27514655359197571, 0.18479029211783526)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.74132362450394873, 0.69591162563938413)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.21796646133876016, 0.29122734165409342)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.016757246376811596, 0.66921440779625541, 0.0170401592110622)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.78203353866123981, 0.070459488590010125)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.44900849858356939, 0.24166666666666667, 0.551693133733535, 0.24047964550554285)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.66129797728733175, 0.33636401471991234)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 0], 0.55099150141643061, 0.09314613526570048, 0.66142358263664058, 0.11184604631640667)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.55099150141643061, 0.10341183574879227, 0.19387579976577363, 0.095195807706988156)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.037592592592592594, 0.46697998189962925, 0.047130932892219507)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "1143/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.80685060634529293, 0.11849310494168314)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.21796646133876016, 0.10270049503810663)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 17 0], 0.44900849858356939, 0.24166666666666667, 0.84924549162864937, 0.13430237158900485)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.47401357170914893, 0.43012219017109055)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.50510142224702415, 0.069177312081953782)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.50299185917565636, 0.0641814761888338)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.47401357170914893, 0.15718307069083637)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 2 2 3 1], 0.55099150141643061, 0.10341183574879227, 0.24053577622919853, 0.037535587527751095)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 1 0 9 0], 0.55099150141643061, 0.35069444444444442, 0.28577968536140042, 0.6606218072337301)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.060185185185185182, 0.58045529685706154, 0.06232717539926174)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.0022644927536231885, 0.41091284838684183, 0.0023087465366224045)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.016757246376811596, 0.49489857775297585, 0.015770020448378511)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.43824698696977132, 0.075216609534322992)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.72589237637055337, 0.27026858591291786)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 4 1], 0.44900849858356939, 0.50870370370370366, 0.5190232816549355, 0.49585291734312037)\n",
      "y shape:  []\n",
      "1179/6000 [====>.........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.40121677247352971, 0.072095735172724565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.037592592592592594, 0.33066145467639146, 0.046151043189944077)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.0022644927536231885, 0.70209897371195851, 0.00240336257552514)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.44900849858356939, 0.061666666666666668, 0.72485344640802429, 0.030430024709655067)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.069814814814814816, 0.55183183895653065, 0.073102614788650766)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.55099150141643061, 0.049064009661835752, 0.31410501248322042, 0.035320080565841724)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.09314613526570048, 0.59891795528462177, 0.10312224892370808)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.006491545893719807, 0.49489857775297585, 0.0053519411040053311)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 1], 0.55099150141643061, 0.09314613526570048, 0.40233549073682651, 0.048369640029316034)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.29790102628804155, 0.085378507070208776)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.44900849858356939, 0.24166666666666667, 0.44701732014906564, 0.33512019858043424)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.45697552670198183, 0.17836107409797464)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.54302447329801817, 0.18748927511481114)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "1215/6000 [=====>........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 1 3 1], 0.44900849858356939, 0.50870370370370366, 0.481012065715028, 0.47003525386899714)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.069814814814814816, 0.40121677247352971, 0.075397622308301063)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.09314613526570048, 0.75509979173874053, 0.13573057690447934)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.54288530021098935, 0.49111637020436416)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 8 1 8 1], 0.44900849858356939, 0.037592592592592594, 0.88925897289612488, 0.060767278073982016)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.29790102628804155, 0.074253201347627612)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 1 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.81480787835945678, 0.76631536546211521)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 1], 0.55099150141643061, 0.35069444444444442, 0.40233549073682651, 0.5064404404788625)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.55099150141643061, 0.35069444444444442, 0.48615457736350531, 0.422378431006825)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.36515087044209121, 0.38345126452251183)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.38314983329761287, 0.16504300526234436)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 1 1 4 1], 0.44900849858356939, 0.50870370370370366, 0.57940633300964683, 0.60667104083686463)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.24166666666666667, 0.6235934774048022, 0.22046221344373035)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.24166666666666667, 0.69350297034278829, 0.19381053285050492)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.46697998189962925, 0.20185797228830529)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "1251/6000 [=====>........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.27421922789890879, 0.39286224540502784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 22 1], 0.44900849858356939, 0.069814814814814816, 0.93351404700176543, 0.042943364630522125)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.44900849858356939, 0.24166666666666667, 0.62521669996197893, 0.2185847224967678)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 0], 0.55099150141643061, 0.09314613526570048, 0.69461040347460989, 0.11970825894866545)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.34776476073737561, 0.068154141970466264)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.29790102628804155, 0.085378507070208776)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.694491423092075, 0.37075515534738879)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.36528088984000795, 0.051287053144881974)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.060185185185185182, 0.33066145467639146, 0.082830438863511921)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.069814814814814816, 0.51398552192672631, 0.074045106214334341)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "1287/6000 [=====>........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.66921440779625541, 0.060541509912510942)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.006491545893719807, 0.59878322752647029, 0.0056656045555742727)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.71770689014104894, 0.14504367493895037)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.006491545893719807, 0.82953758203903372, 0.010967378674499173)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.50510142224702415, 0.10800705557451334)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.72589237637055337, 0.36950203562898171)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.40978663283753697, 0.43582908099946466)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.44900849858356939, 0.24166666666666667, 0.551693133733535, 0.24047964550554285)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.40978663283753697, 0.34810985830817814)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 0], 0.55099150141643061, 0.27943840579710144, 0.4395313423778261, 0.29496084846767207)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 3 1 6 1], 0.44900849858356939, 0.50870370370370366, 0.79543255689886427, 0.77036609122244171)\n",
      "y shape:  []\n",
      "x shape:  ([0 2 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.65580808394600365, 0.64942650263190616)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 0], 0.55099150141643061, 0.085295893719806767, 0.30661625104279266, 0.062889367413786229)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.82953758203903372, 0.051123226728045944)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.55099150141643061, 0.09314613526570048, 0.66129797728733175, 0.086573776776831562)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.78203353866123981, 0.070459488590010125)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 2 0 17 1], 0.44900849858356939, 0.50870370370370366, 0.90112391418145721, 0.85948397600281146)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "1323/6000 [=====>........................] - ETA: 7s - fake: 0.0000e+00x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.049064009661835752, 0.52402185972458315, 0.0442975617590515)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.085295893719806767, 0.56175301303022862, 0.081126539663148589)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.10341183574879227, 0.694491423092075, 0.074249488098820926)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.55099150141643061, 0.09314613526570048, 0.45211300038974778, 0.08413476821847278)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.51384542263649469, 0.4864837315119559)\n",
      "y shape:  []\n",
      "x shape:  ([0 2 0 1 2 1], 0.44900849858356939, 0.50870370370370366, 0.6935906813603625, 0.66980974857808318)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.36528088984000795, 0.075271345209806967)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.28229310985895106, 0.56317309029680374)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 3 1 15 1], 0.44900849858356939, 0.50870370370370366, 0.88100808505119976, 0.84259071600557467)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.50870370370370366, 0.54802591768737352, 0.51671918964209307)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 1 1], 0.55099150141643061, 0.085295893719806767, 0.37352890536949757, 0.07804348837675916)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.44701732014906564, 0.46093091201993919)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.44816816104346935, 0.23572955437306012)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 0], 0.44900849858356939, 0.50870370370370366, 0.69338374895720734, 0.60899871653364135)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.82953758203903372, 0.051123226728045944)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.59891795528462177, 0.34839956690285356)\n",
      "y shape:  []\n",
      "x shape:  ([0 3 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.690975079731082, 0.67623213002940874)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "1359/6000 [=====>........................] - ETA: 6s - fake: 0.0000e+00x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 15 1], 0.55099150141643061, 0.35069444444444442, 0.29899299276856406, 0.57814666518123436)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 17 1], 0.44900849858356939, 0.24166666666666667, 0.76066595557373518, 0.21010671770234743)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.24166666666666667, 0.69350297034278829, 0.19381053285050492)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 2 1], 0.44900849858356939, 0.50870370370370366, 0.44321938124560839, 0.44406673459069368)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 1], 0.55099150141643061, 0.049064009661835752, 0.51514815886241094, 0.030208612299290786)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.085295893719806767, 0.78203353866123981, 0.08687361760949136)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 3 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.32533901979651458, 0.5876109391046922)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 2 1], 0.44900849858356939, 0.50870370370370366, 0.6413269049627095, 0.61652317582683591)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 4 1], 0.55099150141643061, 0.10341183574879227, 0.4809767183450645, 0.0639220253353072)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.55099150141643061, 0.27943840579710144, 0.448306866266465, 0.23475120068511293)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.68589498751677958, 0.15366518506178267)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 16 0], 0.44900849858356939, 0.50870370370370366, 0.82871924833917943, 0.71383069380149244)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.55099150141643061, 0.35069444444444442, 0.40975238711585082, 0.47106787410821149)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.2178708787475355, 0.40045511387520555)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.44900849858356939, 0.037592592592592594, 0.305508576907925, 0.04066267299442633)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.037592592592592594, 0.68589498751677958, 0.031127060356021873)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.4551561708329197, 0.46930241919978238)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 1 19 1], 0.44900849858356939, 0.50870370370370366, 0.92596441725875944, 0.86548345429944118)\n",
      "y shape:  []\n",
      "1395/6000 [=====>........................] - ETA: 6s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.33078559220374454, 0.29869194676478933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.6235934774048022, 0.60677477184728534)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.069814814814814816, 0.80612420023422637, 0.059794454998106539)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.49489857775297585, 0.056075649854353135)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 15 1], 0.55099150141643061, 0.27943840579710144, 0.29899299276856406, 0.2432155944313843)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.069814814814814816, 0.50496122855418268, 0.10988554822697814)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 0 1], 0.55099150141643061, 0.27943840579710144, 0.63002935417637163, 0.34186051117087773)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.17046241796096631, 0.22933156190003251)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.069814814814814816, 0.62534810521876572, 0.0706130468284331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 0], 0.55099150141643061, 0.35069444444444442, 0.55312130927242054, 0.38452830853328823)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.36528088984000795, 0.051287053144881974)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 0 0 20 1], 0.44900849858356939, 0.50870370370370366, 0.93448736584501535, 0.87195846937315047)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.36528088984000795, 0.075271345209806967)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 5 0], 0.44900849858356939, 0.24166666666666667, 0.7232464375806773, 0.19009532962598441)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.085295893719806767, 0.59891795528462177, 0.092657580450807339)\n",
      "y shape:  []\n",
      "1431/6000 [======>.......................] - ETA: 6s - fake: 0.0000e+00x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.061666666666666668, 0.55183183895653065, 0.050655354431366886)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.10341183574879227, 0.63484912955790884, 0.11100551470537433)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.72589237637055337, 0.27026858591291786)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.62719594344444252, 0.62296024645604486)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.754996065631608, 0.10581850128555505)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.48485184113758911, 0.48603492957574607)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 3 1], 0.44900849858356939, 0.060185185185185182, 0.481012065715028, 0.063259083764911822)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.43824698696977132, 0.075216609534322992)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 15 0], 0.44900849858356939, 0.50870370370370366, 0.66805889094853232, 0.58536155976949689)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.24490020826125952, 0.394155153651305)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.75509979173874053, 0.24934523282883264)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.049064009661835752, 0.754996065631608, 0.052414873016427783)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.45697552670198183, 0.058803105443603843)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.40297998955972375, 0.29938911881499031)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.655916389713406, 0.640112302568515)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 5 0 12 0], 0.44900849858356939, 0.50870370370370366, 0.89226750531112653, 0.83188765412519494)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.61698270833126279, 0.1709416766712136)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.085295893719806767, 0.72578077210109115, 0.082853668075833414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.44816816104346935, 0.23572955437306012)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 4 1], 0.55099150141643061, 0.35069444444444442, 0.30977522264859236, 0.55562857702843116)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 0], 0.55099150141643061, 0.09314613526570048, 0.448306866266465, 0.075115106202620546)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.17046241796096631, 0.40868663081907958)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      "1466/6000 [======>.......................] - ETA: 6s - fake: 0.0000e+00x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 3 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.66554723853989561, 0.66784881046309985)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.45697552670198183, 0.15818433184860833)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 2 15 1], 0.44900849858356939, 0.50870370370370366, 0.8891150996166759, 0.77873486817327642)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.049064009661835752, 0.66933854532360848, 0.050052147462847293)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.50510142224702415, 0.05860550231055419)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.78203353866123981, 0.070459488590010125)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.0022644927536231885, 0.59878322752647029, 0.0014467530826473747)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.09314613526570048, 0.48601447807327369, 0.0625796150412866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.45697552670198183, 0.058803105443603843)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 17 1], 0.44900849858356939, 0.060185185185185182, 0.87713432237513633, 0.020071393798904595)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.29790102628804155, 0.074253201347627612)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.060185185185185182, 0.24500393436839196, 0.070215025660194774)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 0], 0.44900849858356939, 0.50870370370370366, 0.66012885092623619, 0.58559897249171111)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 8 1], 0.44900849858356939, 0.060185185185185182, 0.6832604703518238, 0.038564894498464765)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.085295893719806767, 0.59878322752647029, 0.084294448717661757)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.24500393436839196, 0.31417485123041378)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 12 0], 0.44900849858356939, 0.50870370370370366, 0.75775236110537192, 0.6415097453666202)\n",
      "y shape:  []\n",
      "2621/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.27943840579710144, 0.5618910774413044, 0.25956855149884556)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.580318713100382, 0.517169767438791)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 7 0], 0.44900849858356939, 0.24166666666666667, 0.6139624782153088, 0.2413760941084388)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 11 1], 0.44900849858356939, 0.50870370370370366, 0.75559496751518684, 0.7088510963007385)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.52402185972458315, 0.25423917870164192)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.037592592592592594, 0.40121677247352971, 0.04715797206380385)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 2 1], 0.55099150141643061, 0.09314613526570048, 0.3586730950372905, 0.044985275422313536)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.069814814814814816, 0.40121677247352971, 0.075397622308301063)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.0094444444444444445, 0.58908715161315817, 0.0054512078038608889)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.29790102628804155, 0.085378507070208776)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.82953758203903372, 0.19109194414008407)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 2 0], 0.55099150141643061, 0.27943840579710144, 0.5940625231820641, 0.32881604652498364)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.54092964189736881, 0.44081821176985836)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.580318713100382, 0.18017597065060753)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 19 1], 0.44900849858356939, 0.24166666666666667, 0.81161989517768574, 0.18441234606383375)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.21796646133876016, 0.10270049503810663)\n",
      "y shape:  []\n",
      "2653/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.49503877144581732, 0.15951472160614869)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.43824698696977132, 0.27210380471688639)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 4 4 1], 0.44900849858356939, 0.24166666666666667, 0.78885616154573124, 0.28924022879119832)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.59891795528462177, 0.34839956690285356)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.59878322752647029, 0.079489603080120985)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 3 1], 0.44900849858356939, 0.24166666666666667, 0.65679684805116278, 0.20543977447462183)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 3 0], 0.44900849858356939, 0.24166666666666667, 0.44308098590820943, 0.32897323665575018)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 3 1], 0.44900849858356939, 0.24166666666666667, 0.69452146471395237, 0.23909961727279688)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 1], 0.55099150141643061, 0.35069444444444442, 0.21876089534858068, 0.63649318200831007)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.17046241796096631, 0.082103614861541288)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.55099150141643061, 0.049064009661835752, 0.45711469978901065, 0.043181930122977885)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.55099150141643061, 0.35069444444444442, 0.28889817349670277, 0.61243666296075006)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 13 0], 0.44900849858356939, 0.50870370370370366, 0.75403006664516636, 0.65353926963756537)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 6 0], 0.55099150141643061, 0.10341183574879227, 0.46515911941020205, 0.11871789530787354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.49503877144581732, 0.3892330546574016)\n",
      "y shape:  []\n",
      "2686/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.580318713100382, 0.18017597065060753)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.6290211773770007, 0.62822153289792)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.39919111576520372, 0.50418696824612175)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.19314939365470704, 0.26886480002960117)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.58908715161315817, 0.22818060869557721)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 25 1], 0.44900849858356939, 0.50870370370370366, 0.9568233845330707, 0.86914465229468274)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 0], 0.55099150141643061, 0.35069444444444442, 0.55312130927242054, 0.38452830853328823)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.40978663283753697, 0.34810985830817814)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.46697998189962925, 0.10991764061204658)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.409650996113323, 0.41244100811683876)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 0 1], 0.55099150141643061, 0.35069444444444442, 0.58905287642943871, 0.34511731108219773)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.580318713100382, 0.18017597065060753)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 14 0], 0.44900849858356939, 0.50870370370370366, 0.79519596460660913, 0.71661304835551021)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.80685060634529293, 0.22677393157066067)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.55099150141643061, 0.35069444444444442, 0.45197408231262648, 0.4511214938808959)\n",
      "y shape:  []\n",
      "x shape:  ([0 3 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.72248065303114073, 0.69999359411018258)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "2719/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 1 1 0], 0.55099150141643061, 0.085295893719806767, 0.630160070197104, 0.096790754076349628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.80693799281259748, 0.2097603708059112)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.6235934774048022, 0.60677477184728534)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.33066145467639146, 0.10930983831953528)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.17046241796096631, 0.22933156190003251)\n",
      "y shape:  []\n",
      "x shape:  ([1 4 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.87135066170876829, 0.82172389031877724)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.061666666666666668, 0.29790102628804155, 0.11696371406817208)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.09314613526570048, 0.52402185972458315, 0.0680390560175085)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.55099150141643061, 0.27943840579710144, 0.47713920723301706, 0.30785969308308792)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.24166666666666667, 0.58908715161315817, 0.22818060869557721)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.0046296296296296294, 0.55183183895653065, 0.0009338565918842204)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 20 1], 0.44900849858356939, 0.0094444444444444445, 0.91195390873297832, 0.00076168917278676956)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 0 0 26 1], 0.44900849858356939, 0.50870370370370366, 0.972627545591561, 0.920375258635214)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 19 1], 0.44900849858356939, 0.24166666666666667, 0.89894989841286588, 0.10507687271902071)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.037592592592592594, 0.46697998189962925, 0.047130932892219507)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.061666666666666668, 0.36528088984000795, 0.0780093162298684)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 9 0], 0.44900849858356939, 0.50870370370370366, 0.68313908518001187, 0.6246281502206672)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.67887862634423246, 0.6533442829651912)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.59878322752647029, 0.079489603080120985)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 3 0], 0.44900849858356939, 0.50870370370370366, 0.46394434880578367, 0.47343664169454441)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "2752/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.29790102628804155, 0.074253201347627612)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 22 1], 0.44900849858356939, 0.50870370370370366, 0.93351404700176543, 0.83754692594191826)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.38115334190238137, 0.17349648476222826)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.588951387994036, 0.53694896693687166)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.3906961601632829, 0.541711552388214)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.33078559220374454, 0.084022874353729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.69350297034278829, 0.6319194307746071)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.049064009661835752, 0.80685060634529293, 0.059294917465874987)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 0], 0.44900849858356939, 0.0024074074074074076, 0.55287904504388508, 0.0069880773677393248)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.54302447329801817, 0.046889874691886969)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.069814814814814816, 0.66025466709305991, 0.069107897637623525)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 16 1], 0.44900849858356939, 0.50870370370370366, 0.84931727947733682, 0.75141374888029211)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.43824698696977132, 0.27210380471688639)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.29790102628804155, 0.085378507070208776)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 4 1], 0.44900849858356939, 0.24166666666666667, 0.53999530921074013, 0.26396547418757366)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 2 1], 0.44900849858356939, 0.24166666666666667, 0.6413269049627095, 0.18208334218776642)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.48485184113758911, 0.48603492957574607)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 0 1], 0.55099150141643061, 0.085295893719806767, 0.63002935417637163, 0.08848690836254379)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.50510142224702415, 0.069177312081953782)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.40108204471537817, 0.28003070341004432)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 3 0], 0.55099150141643061, 0.35069444444444442, 0.51409024868563669, 0.37011477759368416)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.060185185185185182, 0.62534810521876572, 0.050234822487375687)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.66921440779625541, 0.10923749342168131)\n",
      "y shape:  []\n",
      "2785/6000 [============>.................] - ETA: 4s - fake: 0.0000e+00x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 0], 0.55099150141643061, 0.35069444444444442, 0.4395313423778261, 0.45774739810179915)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.50870370370370366, 0.43810892255869566, 0.435049337737686)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 5 0], 0.55099150141643061, 0.35069444444444442, 0.50313206180738668, 0.44317543994954423)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 9 1], 0.55099150141643061, 0.35069444444444442, 0.51514815886241094, 0.43270269426368368)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.037592592592592594, 0.17046241796096631, 0.047443565138489491)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 12 1], 0.44900849858356939, 0.50870370370370366, 0.75413406854057818, 0.67534079777960154)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.5618910774413044, 0.37291445460398787)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.53302001810037081, 0.094657826601827991)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.069814814814814816, 0.54288530021098935, 0.10931913271277283)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 0], 0.44900849858356939, 0.037592592592592594, 0.27410762362944663, 0.036351327782513265)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.49489857775297585, 0.021278366261565238)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 9 2 1], 0.44900849858356939, 0.037592592592592594, 0.87647436040312343, 0.0011244708567281706)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.085295893719806767, 0.48601447807327369, 0.074237176692171308)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.016757246376811596, 0.78212912125246448, 0.020709870906173645)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 14 1], 0.55099150141643061, 0.09314613526570048, 0.3318167528942102, 0.039907383409404147)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "2817/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([0 0 1 1 3 1], 0.44900849858356939, 0.50870370370370366, 0.67551720210162491, 0.640487021228591)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.54302447329801817, 0.18748927511481114)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.59276845752310148, 0.60437753741275291)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 14 0], 0.44900849858356939, 0.50870370370370366, 0.79519596460660913, 0.71661304835551021)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.33857641736335942, 0.36330928512409821)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.40978663283753697, 0.43582908099946466)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.754996065631608, 0.38395807520928138)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 22 1], 0.55099150141643061, 0.35069444444444442, 0.066485952998234565, 0.79446667523751058)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.085295893719806767, 0.41091284838684183, 0.066986274978263746)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.55099150141643061, 0.27943840579710144, 0.40975238711585082, 0.2765189850959836)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.55099150141643061, 0.35069444444444442, 0.5618910774413044, 0.37291445460398787)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 2 24 0], 0.44900849858356939, 0.50870370370370366, 0.91781815319165649, 0.754495453281686)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 1], 0.44900849858356939, 0.24166666666666667, 0.59766450926317349, 0.27961080733591376)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 0], 0.44900849858356939, 0.037592592592592594, 0.43810892255869566, 0.036135062140190938)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.62458861385019193, 0.398235993987209)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 19 1], 0.44900849858356939, 0.060185185185185182, 0.89894989841286588, 0.021771506605906005)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.037592592592592594, 0.62534810521876572, 0.026424016558773203)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.21796646133876016, 0.40892564307432566)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 5 0], 0.44900849858356939, 0.24166666666666667, 0.49686793819261338, 0.22487078841680702)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.80685060634529293, 0.017326632556585436)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "2851/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.037592592592592594, 0.47597814027541679, 0.039399471906153352)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.069814814814814816, 0.40108204471537817, 0.076127571003478223)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.060185185185185182, 0.54302447329801817, 0.065813702507060867)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 2 1 0], 0.44900849858356939, 0.50870370370370366, 0.61031158746988423, 0.556724093346639)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.33066145467639146, 0.29549015713518784)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.53302001810037081, 0.022864525189208989)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.44900849858356939, 0.24166666666666667, 0.62521669996197893, 0.2185847224967678)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 18 0], 0.44900849858356939, 0.50870370370370366, 0.76056383943392736, 0.65297227720980222)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.40108204471537817, 0.40922626528414108)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.57255146474959462, 0.5830748457563657)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.59891795528462177, 0.34839956690285356)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 18 0], 0.44900849858356939, 0.24166666666666667, 0.76056383943392736, 0.21418304975084085)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.54288530021098935, 0.49111637020436416)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.44816816104346935, 0.47219450514043826)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.33078559220374454, 0.0748024584113431)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.17046241796096631, 0.40868663081907958)\n",
      "y shape:  []\n",
      "2883/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 11 1], 0.44900849858356939, 0.24166666666666667, 0.75559496751518684, 0.17235713176564246)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.19306200718740246, 0.24989048303498015)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.49489857775297585, 0.063552082879970578)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.44900849858356939, 0.069814814814814816, 0.52286079276698294, 0.048463032074883367)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.049064009661835752, 0.66933854532360848, 0.050052147462847293)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.36515087044209121, 0.079983175897264433)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.19306200718740246, 0.40536007500734533)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 3 0 0], 0.55099150141643061, 0.27943840579710144, 0.40501756503962028, 0.32787332452248624)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.016757246376811596, 0.66933854532360848, 0.023416886797905608)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.44900849858356939, 0.24166666666666667, 0.62521669996197893, 0.2185847224967678)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.80685060634529293, 0.017326632556585436)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.65223523926262439, 0.59135589692414836)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.82953758203903372, 0.159086333482353)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.55099150141643061, 0.09314613526570048, 0.45711469978901065, 0.076988877204031525)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.80693799281259748, 0.15156862579369812)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 6 1], 0.55099150141643061, 0.27943840579710144, 0.24945836281854861, 0.097038119691549879)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.59878322752647029, 0.079489603080120985)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.45697552670198183, 0.15818433184860833)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "2915/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.6093038398367171, 0.60727485638296341)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 1 0], 0.44900849858356939, 0.060185185185185182, 0.369839929802896, 0.0794222716608305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.27943840579710144, 0.5529826798509343, 0.33163906293229189)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 1 0 7 1], 0.44900849858356939, 0.061666666666666668, 0.430293543941146, 0.055762551136379832)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.59891795528462177, 0.34839956690285356)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.36528088984000795, 0.075271345209806967)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.694491423092075, 0.0804353932429937)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 0 0], 0.55099150141643061, 0.35069444444444442, 0.625446322309686, 0.29872628749881613)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 19 1], 0.44900849858356939, 0.50870370370370366, 0.81161989517768574, 0.71353296246830411)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 24 1], 0.55099150141643061, 0.35069444444444442, 0.097866241164258683, 0.7578497864676218)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 9 1], 0.44900849858356939, 0.24166666666666667, 0.67887862634423246, 0.17121292270795652)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 15 1], 0.55099150141643061, 0.35069444444444442, 0.29899299276856406, 0.57814666518123436)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.60080888423479628, 0.15006593517586611)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.060185185185185182, 0.61698270833126279, 0.058791685441465548)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 4 9 1], 0.55099150141643061, 0.35069444444444442, 0.20528330594184541, 0.54449900749206)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.80685060634529293, 0.068627885581908452)\n",
      "y shape:  []\n",
      "2944/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.24166666666666667, 0.69350297034278829, 0.19381053285050492)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.58237668450705593, 0.077591043340122873)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.80693799281259748, 0.38023382572511455)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([0 3 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.690975079731082, 0.67623213002940874)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.49489857775297585, 0.18380627342959327)\n",
      "y shape:  []\n",
      "x shape:  ([1 3 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.2704481035634021, 0.66658438975805345)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.78212912125246448, 0.37814306256804969)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.50870370370370366, 0.54802591768737352, 0.51671918964209307)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.037592592592592594, 0.54302447329801817, 0.046889874691886969)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.55099150141643061, 0.35069444444444442, 0.16621568240556006, 0.68613194575082792)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.19306200718740246, 0.40536007500734533)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.68589498751677958, 0.61498070766128654)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.43824698696977132, 0.075216609534322992)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 0 1], 0.55099150141643061, 0.27943840579710144, 0.40975238711585082, 0.2765189850959836)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.33078559220374454, 0.075142962218066836)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.51398552192672631, 0.2507991349732705)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.70209897371195851, 0.053365002433000824)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.049064009661835752, 0.59878322752647029, 0.052283340602521572)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 3 1], 0.44900849858356939, 0.24166666666666667, 0.65679684805116278, 0.20543977447462183)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.37465189478123428, 0.52151660280027978)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.36515087044209121, 0.38345126452251183)\n",
      "y shape:  []\n",
      "2977/6000 [=============>................] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 24 0], 0.44900849858356939, 0.50870370370370366, 0.95478286666904222, 0.86904261538932859)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.45697552670198183, 0.43853942951870828)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.085295893719806767, 0.63484912955790884, 0.095666846965124258)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.10341183574879227, 0.59891795528462177, 0.11225239469277583)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.36515087044209121, 0.38345126452251183)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.55099150141643061, 0.35069444444444442, 0.37478330003802107, 0.49638442311538278)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.33078559220374454, 0.0748024584113431)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 14 1], 0.44900849858356939, 0.037592592592592594, 0.6681832471057898, 0.015748873453025922)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.10341183574879227, 0.66933854532360848, 0.10924623817225901)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.82953758203903372, 0.065703137160179323)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.27943840579710144, 0.52416174209946309, 0.25191374631096036)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.24166666666666667, 0.66025466709305991, 0.20519887738304279)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.19314939365470704, 0.26886480002960117)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 5 1], 0.44900849858356939, 0.50870370370370366, 0.55681556048428993, 0.52142400715712467)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.55099150141643061, 0.35069444444444442, 0.47713920723301706, 0.45732264245375065)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 0], 0.55099150141643061, 0.10341183574879227, 0.62656919312517556, 0.075581252544856023)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.75509979173874053, 0.37450505361135167)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.44900849858356939, 0.037592592592592594, 0.52286079276698294, 0.023823117696067733)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 2 1], 0.44900849858356939, 0.50870370370370366, 0.62173855213634233, 0.56931940291833727)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.060185185185185182, 0.40108204471537817, 0.076909617646825371)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 1 9 1], 0.55099150141643061, 0.27943840579710144, 0.26793822888370944, 0.17248185822173104)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 0], 0.44900849858356939, 0.50870370370370366, 0.51000335404847119, 0.46411683111875435)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.006491545893719807, 0.70209897371195851, 0.00794740000884191)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.17046241796096631, 0.22933156190003251)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.633639285531326, 0.58413670975926879)\n",
      "y shape:  []\n",
      "3012/6000 [==============>...............] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.59878322752647029, 0.37138253810909627)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.80693799281259748, 0.095749556349074769)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.037592592592592594, 0.40108204471537817, 0.039361727070170952)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.60563719047184228, 0.5915923687542014)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.24166666666666667, 0.47597814027541679, 0.26168534030385177)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 0], 0.55099150141643061, 0.10341183574879227, 0.45711469978901065, 0.16006698056045068)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.65223523926262439, 0.59135589692414836)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 1 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.3615023063029732, 0.57404609894395509)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.27943840579710144, 0.48601447807327369, 0.24523720643083349)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.45697552670198183, 0.058803105443603843)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.17046241796096631, 0.40868663081907958)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.17046241796096631, 0.40868663081907958)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.62719594344444252, 0.62296024645604486)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.54302447329801817, 0.10728433957883819)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 10 1], 0.44900849858356939, 0.0094444444444444445, 0.76153800832051477, 0.0021243944122197904)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 10 1], 0.44900849858356939, 0.50870370370370366, 0.74517322278559506, 0.69011974208760063)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.66933854532360848, 0.11789434961682078)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 3 12 0], 0.44900849858356939, 0.50870370370370366, 0.8276656396241534, 0.68100880551867671)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.82953758203903372, 0.051123226728045944)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 0], 0.55099150141643061, 0.27943840579710144, 0.45211300038974778, 0.22926953009588658)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.49489857775297585, 0.0825441576190239)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "3047/6000 [==============>...............] - ETA: 4s - fake: 0.0000e+00x shape:  ([1 0 0 0 10 0], 0.55099150141643061, 0.27943840579710144, 0.33987114907376381, 0.20612917330776562)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.55099150141643061, 0.35069444444444442, 0.52416174209946309, 0.39759815226808476)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 0], 0.55099150141643061, 0.35069444444444442, 0.411048612005964, 0.47187097042646492)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.44900849858356939, 0.24166666666666667, 0.3387020227126683, 0.37218820205717057)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.78203353866123981, 0.11224501918057049)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.037592592592592594, 0.55183183895653065, 0.032464445502990713)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 20 1], 0.44900849858356939, 0.24166666666666667, 0.83378431759443994, 0.17224376674378497)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 1 0], 0.55099150141643061, 0.35069444444444442, 0.630160070197104, 0.31726006041165905)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.44900849858356939, 0.037592592592592594, 0.40978663283753697, 0.0315526393782322)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.55099150141643061, 0.049064009661835752, 0.48615457736350531, 0.033830912688248088)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.62643796030980825, 0.3599268844225193)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.66921440779625541, 0.089658367662572083)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 0], 0.44900849858356939, 0.50870370370370366, 0.62521669996197893, 0.56155168642466646)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.82953758203903372, 0.065703137160179323)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.060185185185185182, 0.62534810521876572, 0.050234822487375687)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.085295893719806767, 0.80685060634529293, 0.088344721017677527)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "3080/6000 [==============>...............] - ETA: 3s - fake: 0.0000e+00x shape:  ([2 0 0 0 10 1], 0.55099150141643061, 0.35069444444444442, 0.47713920723301706, 0.45732264245375065)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 1 1], 0.44900849858356939, 0.50870370370370366, 0.6235934774048022, 0.60677477184728534)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 17 1], 0.55099150141643061, 0.27943840579710144, 0.13223107041053073, 0.126960237583614)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.060185185185185182, 0.33078559220374454, 0.075142962218066836)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.44900849858356939, 0.50870370370370366, 0.24490020826125952, 0.293255825727316)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.061666666666666668, 0.19314939365470704, 0.10923931333794747)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.35069444444444442, 0.52402185972458315, 0.42196718297431696)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.061666666666666668, 0.66025466709305991, 0.037611921442307759)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.634719110159992, 0.11089138561396715)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.62643796030980825, 0.3599268844225193)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 12 1], 0.44900849858356939, 0.50870370370370366, 0.75413406854057818, 0.67534079777960154)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.09314613526570048, 0.56175301303022862, 0.073695505369088116)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.58045529685706154, 0.54144393137074487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.069814814814814816, 0.19306200718740246, 0.046667459091447178)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 0 10 1], 0.55099150141643061, 0.10341183574879227, 0.43744940727436787, 0.054733026707278677)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.80685060634529293, 0.017326632556585436)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 1 1], 0.44900849858356939, 0.24166666666666667, 0.62647109463050243, 0.26465872893813108)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 13 1 21 1], 0.44900849858356939, 0.50870370370370366, 0.97717164902589393, 0.95082976881688874)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.085295893719806767, 0.48601447807327369, 0.074237176692171308)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 12 1], 0.55099150141643061, 0.35069444444444442, 0.24586593145942182, 0.61476194713625154)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.52402185972458315, 0.25423917870164192)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "3113/6000 [==============>...............] - ETA: 3s - fake: 0.0000e+00x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 33 1], 0.44900849858356939, 0.50870370370370366, 0.986813207691342, 0.92486641309938755)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.44900849858356939, 0.24166666666666667, 0.56060681016683833, 0.29379379288653568)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.060185185185185182, 0.36515087044209121, 0.079983175897264433)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 2 1 1], 0.55099150141643061, 0.27943840579710144, 0.37352890536949757, 0.26596001714941575)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.41954470314293846, 0.15774307304511689)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.56175301303022862, 0.26257654110564338)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 1 1], 0.55099150141643061, 0.35069444444444442, 0.41464011432302517, 0.47832291672099375)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.43824698696977132, 0.27210380471688639)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.19314939365470704, 0.41474532009444004)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.41954470314293846, 0.1721041402523949)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 15 1], 0.55099150141643061, 0.35069444444444442, 0.1496751368918976, 0.734138125073732)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.69350297034278829, 0.6319194307746071)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 3 0], 0.55099150141643061, 0.10341183574879227, 0.3993256318454278, 0.16496497233410051)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.44900849858356939, 0.24166666666666667, 0.51384542263649469, 0.25107555511899593)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.35069444444444442, 0.754996065631608, 0.26882577192122248)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 0], 0.55099150141643061, 0.049064009661835752, 0.34789198189668413, 0.03283684323933396)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.55099150141643061, 0.27943840579710144, 0.33974533290694009, 0.20543950031900446)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 3 2 10 1], 0.44900849858356939, 0.069814814814814816, 0.8043507357757419, 0.020543878037194752)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 5 1], 0.55099150141643061, 0.049064009661835752, 0.46501959503548551, 0.051724608123661732)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 7 1], 0.55099150141643061, 0.27943840579710144, 0.590213367162463, 0.34265278645434949)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.085295893719806767, 0.754996065631608, 0.085018950405766777)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "3146/6000 [==============>...............] - ETA: 3s - fake: 0.0000e+00x shape:  ([2 0 0 0 23 1], 0.44900849858356939, 0.50870370370370366, 0.88785771029183413, 0.78241587218816933)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.061666666666666668, 0.62534810521876572, 0.041653131682397364)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.27943840579710144, 0.72578077210109115, 0.37802087074167462)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.53302001810037081, 0.089288052136909768)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.38488068593633629, 0.43104336776579716)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.44900849858356939, 0.24166666666666667, 0.36515087044209121, 0.28826218385935853)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 1], 0.44900849858356939, 0.50870370370370366, 0.633639285531326, 0.58413670975926879)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.65210801810331587, 0.56720693957951074)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.55099150141643061, 0.35069444444444442, 0.48615457736350531, 0.422378431006825)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.060185185185185182, 0.62534810521876572, 0.050234822487375687)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.78203353866123981, 0.070459488590010125)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 10 0], 0.55099150141643061, 0.27943840579710144, 0.33987114907376381, 0.20612917330776562)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.27943840579710144, 0.59878322752647029, 0.27005733304426321)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 5 1], 0.55099150141643061, 0.35069444444444442, 0.44318443951571007, 0.46699324808446618)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.060185185185185182, 0.33066145467639146, 0.082830438863511921)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.45697552670198183, 0.15818433184860833)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.44900849858356939, 0.24166666666666667, 0.24490020826125952, 0.394155153651305)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.19306200718740246, 0.14040437838096034)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.069814814814814816, 0.33078559220374454, 0.0748024584113431)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 0], 0.44900849858356939, 0.037592592592592594, 0.580318713100382, 0.035917159797545228)\n",
      "y shape:  []\n",
      "3179/6000 [==============>...............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 0 1 0 4 1], 0.55099150141643061, 0.10341183574879227, 0.50299185917565636, 0.11756865893541867)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.016757246376811596, 0.70209897371195851, 0.025807969413354771)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.50870370370370366, 0.80612420023422637, 0.7152468683948201)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.49503877144581732, 0.18288589080090278)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.24166666666666667, 0.27421922789890879, 0.39286224540502784)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.47597814027541679, 0.074757389322255161)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 5 1], 0.55099150141643061, 0.049064009661835752, 0.66129797728733175, 0.042231072355261592)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.58045529685706154, 0.17937979485979097)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.24166666666666667, 0.55183183895653065, 0.23958906437393163)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.72578077210109115, 0.29076238387652575)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.50496122855418268, 0.46439662928823161)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.70209897371195851, 0.021163437796037379)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.24166666666666667, 0.66025466709305991, 0.20519887738304279)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.012530193236714976, 0.66921440779625541, 0.020159677430391355)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 0], 0.55099150141643061, 0.085295893719806767, 0.75509979173874053, 0.092399955311754683)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.82953758203903372, 0.051123226728045944)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 1 9 0], 0.44900849858356939, 0.50870370370370366, 0.82765458280185566, 0.73891828076446464)\n",
      "y shape:  []\n",
      "x shape:  ([1 2 1 1 16 1], 0.44900849858356939, 0.50870370370370366, 0.90935359326585263, 0.85473125005720141)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "3206/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.46697998189962925, 0.20185797228830529)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 6 0], 0.55099150141643061, 0.085295893719806767, 0.3142258523428314, 0.071816077536694486)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.763041495185154, 0.69542524428245689)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.016757246376811596, 0.754996065631608, 0.013818333676257432)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.82953758203903372, 0.096811517013817433)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.085295893719806767, 0.70209897371195851, 0.10044764212068741)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.037592592592592594, 0.61698270833126279, 0.038475174013174587)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 19 1], 0.55099150141643061, 0.35069444444444442, 0.18838010482231426, 0.66602960098859487)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.069814814814814816, 0.47597814027541679, 0.074757389322255161)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.049064009661835752, 0.634719110159992, 0.056415537980855912)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.80693799281259748, 0.2097603708059112)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.19314939365470704, 0.41474532009444004)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.27421922789890879, 0.33767490728032107)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.55099150141643061, 0.35069444444444442, 0.19387579976577363, 0.657466063805964)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 0 21 1], 0.55099150141643061, 0.35069444444444442, 0.0654832634358169, 0.832773938468318)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.43824698696977132, 0.075216609534322992)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.049064009661835752, 0.694491423092075, 0.045549951811855519)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.56382944214491515, 0.55690301385190577)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 1 9 1], 0.44900849858356939, 0.50870370370370366, 0.5675085369365821, 0.53937889720845034)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.50870370370370366, 0.54802591768737352, 0.51671918964209307)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.40121677247352971, 0.072095735172724565)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 1 3 0], 0.44900849858356939, 0.50870370370370366, 0.64119788850312021, 0.59324845942116733)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.694491423092075, 0.37075515534738879)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.49489857775297585, 0.41137088525240756)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 0], 0.55099150141643061, 0.016757246376811596, 0.78212912125246448, 0.020709870906173645)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.409650996113323, 0.41244100811683876)\n",
      "y shape:  []\n",
      "3239/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 0 0 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.47597814027541679, 0.48534621339960937)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.67107980437064907, 0.63053534884662354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.35069444444444442, 0.48601447807327369, 0.44715481022193915)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.46697998189962925, 0.20185797228830529)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 0], 0.44900849858356939, 0.060185185185185182, 0.48471176313269765, 0.058385944187434355)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.33066145467639146, 0.10930983831953528)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.33078559220374454, 0.0555232063669804)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.049064009661835752, 0.82953758203903372, 0.051123226728045944)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 3 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.7444312658026101, 0.74189256017519223)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.78203353866123981, 0.24749803259550943)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.49503877144581732, 0.3892330546574016)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.60080888423479628, 0.58239636221322111)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.085295893719806767, 0.694491423092075, 0.0804353932429937)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.71770689014104894, 0.63770548213203515)\n",
      "y shape:  []\n",
      "x shape:  ([1 6 1 0 17 1], 0.44900849858356939, 0.24166666666666667, 0.94909978028759256, 0.048701296479396854)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.27943840579710144, 0.66933854532360848, 0.27692226400483022)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 2 1 10 1], 0.44900849858356939, 0.24166666666666667, 0.760828406132897, 0.1555809230043807)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 4 0], 0.44900849858356939, 0.24166666666666667, 0.61685016670238713, 0.17205343604692613)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.52286079276698294, 0.51102266493922754)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 9 1], 0.44900849858356939, 0.50870370370370366, 0.66025466709305991, 0.6090093599955565)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 3 1], 0.55099150141643061, 0.085295893719806767, 0.72578077210109115, 0.082853668075833414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.24166666666666667, 0.36528088984000795, 0.2908316893806987)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.634719110159992, 0.27644349518453182)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.40121677247352971, 0.43318724723151691)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.46697998189962925, 0.43699465382941394)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 4 1], 0.44900849858356939, 0.50870370370370366, 0.49700814082434358, 0.53273005046553656)\n",
      "y shape:  []\n",
      "3272/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.33078559220374454, 0.38032456470478188)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 14 1], 0.44900849858356939, 0.060185185185185182, 0.80612420023422637, 0.032839114922836719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 19 1], 0.44900849858356939, 0.50870370370370366, 0.89894989841286588, 0.79856375836397331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.70209897371195851, 0.28009585844435503)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 2 2 1], 0.44900849858356939, 0.061666666666666668, 0.48604984896380615, 0.0629081418092972)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 8 1], 0.55099150141643061, 0.35069444444444442, 0.5529826798509343, 0.40819234633391749)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.24166666666666667, 0.50496122855418268, 0.19526459018337491)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 0], 0.44900849858356939, 0.069814814814814816, 0.51384542263649469, 0.075340332796735243)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 6 1], 0.44900849858356939, 0.50870370370370366, 0.55183183895653065, 0.536302643109513)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 4 1], 0.55099150141643061, 0.27943840579710144, 0.52402185972458315, 0.25423917870164192)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 2 1], 0.55099150141643061, 0.09314613526570048, 0.37826144786365767, 0.054347070734978145)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 0], 0.44900849858356939, 0.50870370370370366, 0.59752964340018477, 0.53722619876144828)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 1 0 1], 0.44900849858356939, 0.24166666666666667, 0.54802591768737352, 0.23681143052653383)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.55099150141643061, 0.09314613526570048, 0.48601447807327369, 0.0625796150412866)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.55099150141643061, 0.10341183574879227, 0.49489857775297585, 0.15773501877595966)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.35069444444444442, 0.56175301303022862, 0.39669504482461243)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.069814814814814816, 0.51398552192672631, 0.074045106214334341)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 1 3 1], 0.55099150141643061, 0.27943840579710144, 0.49794860873330904, 0.27562416471091788)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.53302001810037081, 0.36274928712903803)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.10341183574879227, 0.78203353866123981, 0.070459488590010125)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.61698270833126279, 0.56684363430829265)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.54302447329801817, 0.51513499050298406)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 1], 0.44900849858356939, 0.069814814814814816, 0.54302447329801817, 0.10728433957883819)\n",
      "y shape:  []\n",
      "3305/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.061666666666666668, 0.58908715161315817, 0.046001058549654091)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.44900849858356939, 0.069814814814814816, 0.50496122855418268, 0.10988554822697814)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.24166666666666667, 0.40121677247352971, 0.28188638831470664)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.27943840579710144, 0.63484912955790884, 0.27227034619459461)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 2 0 7 1], 0.44900849858356939, 0.037592592592592594, 0.77792608994971757, 0.036812020014405714)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 2 1], 0.44900849858356939, 0.069814814814814816, 0.58045529685706154, 0.10607890273811454)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 2 0], 0.44900849858356939, 0.50870370370370366, 0.58224027607493845, 0.56804160386915392)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 12 1], 0.55099150141643061, 0.35069444444444442, 0.40233549073682651, 0.5064404404788625)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 3 0 24 0], 0.44900849858356939, 0.50870370370370366, 0.9610638364102575, 0.91993064189920137)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.27943840579710144, 0.59891795528462177, 0.26641324329949906)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.060185185185185182, 0.46697998189962925, 0.080582342501612128)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.80685060634529293, 0.39090995277488216)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.061666666666666668, 0.33066145467639146, 0.10930983831953528)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.53302001810037081, 0.15802921280677359)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.70209897371195851, 0.10692018740732268)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.58908715161315817, 0.56112165203269726)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 1], 0.55099150141643061, 0.35069444444444442, 0.62643796030980825, 0.3599268844225193)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.44900849858356939, 0.061666666666666668, 0.40121677247352971, 0.072095735172724565)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 0], 0.44900849858356939, 0.50870370370370366, 0.47583825790053685, 0.46083464157557719)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.085295893719806767, 0.41091284838684183, 0.066986274978263746)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 6 0], 0.44900849858356939, 0.24166666666666667, 0.55667715855582545, 0.29371244861101736)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 8 1], 0.44900849858356939, 0.50870370370370366, 0.62534810521876572, 0.5853848569551573)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.27943840579710144, 0.82953758203903372, 0.38054413516470331)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 26 1], 0.44900849858356939, 0.24166666666666667, 0.92590320706969631, 0.11031761162457498)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 1 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.71110182650329723, 0.67508944598885245)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 1 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.60080888423479628, 0.58239636221322111)\n",
      "y shape:  []\n",
      "3339/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 1 0 0 9 0], 0.44900849858356939, 0.0024074074074074076, 0.66189789262948773, 0.0040746024998502481)\n",
      "y shape:  []\n",
      "x shape:  ([1 5 0 0 10 1], 0.44900849858356939, 0.50870370370370366, 0.83432744647167933, 0.78513549354817247)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 0 0], 0.55099150141643061, 0.10341183574879227, 0.82953758203903372, 0.065703137160179323)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.35069444444444442, 0.70209897371195851, 0.27626282146345305)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 4 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.80565317857500551, 0.76604309723366493)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.50870370370370366, 0.43824698696977132, 0.45937940296973928)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.09314613526570048, 0.70209897371195851, 0.12505788522745853)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.085295893719806767, 0.66933854532360848, 0.098300326821173414)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.50870370370370366, 0.50510142224702415, 0.48786211198156576)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 0], 0.55099150141643061, 0.35069444444444442, 0.63484912955790884, 0.32410579279402679)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.50870370370370366, 0.33066145467639146, 0.35779162755747429)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 18 1], 0.44900849858356939, 0.24166666666666667, 0.900767718811232, 0.13141930069767974)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.060185185185185182, 0.36528088984000795, 0.07242200645223397)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.44900849858356939, 0.069814814814814816, 0.43824698696977132, 0.075216609534322992)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.24166666666666667, 0.50510142224702415, 0.19506880266482729)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.50870370370370366, 0.29790102628804155, 0.33229013600000123)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 6 0], 0.44900849858356939, 0.50870370370370366, 0.33857641736335942, 0.36330928512409821)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 4 1], 0.55099150141643061, 0.10341183574879227, 0.694491423092075, 0.074249488098820926)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.09314613526570048, 0.49503877144581732, 0.083155671112200347)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 2 1], 0.44900849858356939, 0.50870370370370366, 0.44019154037604341, 0.49860784215206644)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.50510142224702415, 0.051425137887974919)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.24166666666666667, 0.29790102628804155, 0.3014849531829118)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 5 1], 0.44900849858356939, 0.50870370370370366, 0.51398552192672631, 0.51101498194161377)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.66933854532360848, 0.30006060201625628)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 2 1], 0.55099150141643061, 0.09314613526570048, 0.754996065631608, 0.10581850128555505)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.44900849858356939, 0.50870370370370366, 0.36528088984000795, 0.40682528420845704)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 8 5 23 1], 0.44900849858356939, 0.50870370370370366, 0.98889403001703469, 0.97469841131797486)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 2 1 25 0], 0.44900849858356939, 0.50870370370370366, 0.96395651037583652, 0.89998282356200388)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 18 1], 0.44900849858356939, 0.50870370370370366, 0.88426899141066972, 0.78378302238379638)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.80693799281259748, 0.2097603708059112)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.27514655359197571, 0.59232870696776374)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 2 1], 0.55099150141643061, 0.10341183574879227, 0.59878322752647029, 0.11195487334037044)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.09314613526570048, 0.66921440779625541, 0.091110575590685569)\n",
      "y shape:  []\n",
      "3374/6000 [===============>..............] - ETA: 3s - fake: 0.0000e+00x shape:  ([1 0 0 1 9 1], 0.44900849858356939, 0.060185185185185182, 0.69777409766615173, 0.04458901867581283)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 9 1], 0.55099150141643061, 0.27943840579710144, 0.3048214874092684, 0.20079354665358809)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 1 8 0], 0.55099150141643061, 0.27943840579710144, 0.37006837221096311, 0.26914106995101988)\n",
      "y shape:  []\n",
      "x shape:  ([0 1 0 0 7 1], 0.44900849858356939, 0.50870370370370366, 0.77647592743920357, 0.71825971011414236)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 1], 0.44900849858356939, 0.037592592592592594, 0.50510142224702415, 0.051425137887974919)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.27943840579710144, 0.66921440779625541, 0.28143356045024)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 7 1], 0.55099150141643061, 0.35069444444444442, 0.41091284838684183, 0.49700976835904292)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.44900849858356939, 0.069814814814814816, 0.29790102628804155, 0.074253201347627612)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.35069444444444442, 0.634719110159992, 0.34604815152643875)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.55099150141643061, 0.35069444444444442, 0.59891795528462177, 0.34839956690285356)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 0], 0.44900849858356939, 0.060185185185185182, 0.40108204471537817, 0.076909617646825371)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 3 1], 0.55099150141643061, 0.10341183574879227, 0.56175301303022862, 0.11249637939613719)\n",
      "y shape:  []\n",
      "x shape:  ([1 1 0 0 26 1], 0.44900849858356939, 0.50870370370370366, 0.96802956258311756, 0.90319563250497348)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 0], 0.55099150141643061, 0.012530193236714976, 0.70209897371195851, 0.021163437796037379)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 1 1], 0.55099150141643061, 0.27943840579710144, 0.78203353866123981, 0.38834704278901289)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 1 0], 0.55099150141643061, 0.35069444444444442, 0.49503877144581732, 0.3892330546574016)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 0 1], 0.55099150141643061, 0.35069444444444442, 0.66921440779625541, 0.32067912979086838)\n",
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 11 1], 0.55099150141643061, 0.35069444444444442, 0.43939318983316167, 0.48193974798640155)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  []\n",
      "x shape:  ([2 0 0 0 13 1], 0.55099150141643061, 0.27943840579710144, 0.366360714468674, 0.2694533591056143)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 4 4 9 1], 0.44900849858356939, 0.50870370370370366, 0.844272845465937, 0.78609154144445581)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 1], 0.55099150141643061, 0.09314613526570048, 0.634719110159992, 0.085335552548774354)\n",
      "y shape:  []\n",
      "x shape:  ([1 0 0 0 1 0], 0.44900849858356939, 0.037592592592592594, 0.33066145467639146, 0.046151043189944077)\n",
      "y shape:  []\n",
      "x shape:  ([0 0 0 0 0 0], 0.44900849858356939, 0.037592592592592594, 0.46697998189962925, 0.047130932892219507)\n",
      "y shape:  []\n",
      "x shape:  ([2 1 0 0 8 0], 0.44900849858356939, 0.50870370370370366, 0.44883094307293403, 0.48078062748076178)\n",
      "y shape:  []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf_train_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;43;03m#                            y = train_data[Y_atr].astype(\"float32\"),\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;43;03m#                            batch_size=train_data[Y_atr].shape[0],\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Phd/projects/bayesian_fairness/envs/bayesian-fairness/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = policy_model.fit(x = tf_train_dataset,\n",
    "#                            y = train_data[Y_atr].astype(\"float32\"),\n",
    "                           epochs=400,\n",
    "#                            batch_size=train_data[Y_atr].shape[0],\n",
    "                           shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'utility'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutility\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutility\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# plt.plot(history[\"val_loss\"],label=\"val_loss\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'utility'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history[\"utility\"],label=\"utility\")\n",
    "# plt.plot(history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"accuracy\"],label=\"accuracy\")\n",
    "# plt.plot(history[\"val_accuracy\"],label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pd.DataFrame(history[\"fairness_loss\"]).rolling(10).mean(),label=\"fairness\")\n",
    "# plt.plot(history[\"val_accuracy\"],label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6852293610572815,\n",
       " 0.7108128666877747,\n",
       " 0.7290276885032654,\n",
       " 0.7421558499336243,\n",
       " 0.7518123388290405,\n",
       " 0.7590493559837341,\n",
       " 0.7645506262779236,\n",
       " 0.7687697410583496,\n",
       " 0.772016167640686,\n",
       " 0.7745072245597839,\n",
       " 0.7763996124267578,\n",
       " 0.7778087258338928,\n",
       " 0.7788220047950745,\n",
       " 0.7795062065124512,\n",
       " 0.7799137830734253,\n",
       " 0.7800867557525635,\n",
       " 0.780057966709137,\n",
       " 0.7798552513122559,\n",
       " 0.7795007228851318,\n",
       " 0.7790135741233826,\n",
       " 0.7784093618392944,\n",
       " 0.777701735496521,\n",
       " 0.7769018411636353,\n",
       " 0.7760199308395386,\n",
       " 0.7750645279884338,\n",
       " 0.774043083190918,\n",
       " 0.7729622721672058,\n",
       " 0.7718280553817749,\n",
       " 0.7706454992294312,\n",
       " 0.7694196701049805,\n",
       " 0.7681543827056885,\n",
       " 0.7668534517288208,\n",
       " 0.765520453453064,\n",
       " 0.7641586661338806,\n",
       " 0.7627707123756409,\n",
       " 0.7613593339920044,\n",
       " 0.7599269151687622,\n",
       " 0.7584758996963501,\n",
       " 0.7570080757141113,\n",
       " 0.7555255889892578,\n",
       " 0.7540299892425537,\n",
       " 0.7525231838226318,\n",
       " 0.7510067224502563,\n",
       " 0.7494818568229675,\n",
       " 0.7479501366615295,\n",
       " 0.7464127540588379,\n",
       " 0.7448708415031433,\n",
       " 0.7433258295059204,\n",
       " 0.741778552532196,\n",
       " 0.7402299642562866,\n",
       " 0.7386810779571533,\n",
       " 0.7371329665184021,\n",
       " 0.7355862259864807,\n",
       " 0.7340418696403503,\n",
       " 0.732500433921814,\n",
       " 0.7309627532958984,\n",
       " 0.7294294238090515,\n",
       " 0.7279011011123657,\n",
       " 0.7263785004615784,\n",
       " 0.7248619794845581,\n",
       " 0.723352313041687,\n",
       " 0.7218495607376099,\n",
       " 0.7203548550605774,\n",
       " 0.7188680768013,\n",
       " 0.7173898220062256,\n",
       " 0.715920627117157,\n",
       " 0.714460551738739,\n",
       " 0.7130101323127747,\n",
       " 0.7115694880485535,\n",
       " 0.7101392149925232,\n",
       " 0.7087194323539734,\n",
       " 0.7073103189468384,\n",
       " 0.705912172794342,\n",
       " 0.7045252323150635,\n",
       " 0.7031497955322266,\n",
       " 0.7017857432365417,\n",
       " 0.7004335522651672,\n",
       " 0.6990930438041687,\n",
       " 0.6977646350860596,\n",
       " 0.6964483857154846,\n",
       " 0.6951441764831543,\n",
       " 0.6938523650169373,\n",
       " 0.692573070526123,\n",
       " 0.6913058757781982,\n",
       " 0.6900513768196106,\n",
       " 0.6888093948364258,\n",
       " 0.6875800490379333,\n",
       " 0.6863633394241333,\n",
       " 0.6851590275764465,\n",
       " 0.6839675903320312,\n",
       " 0.6827884912490845,\n",
       " 0.6816221475601196,\n",
       " 0.6804683208465576,\n",
       " 0.6793269515037537,\n",
       " 0.6781982779502869,\n",
       " 0.6770818829536438,\n",
       " 0.6759780645370483,\n",
       " 0.6748864650726318,\n",
       " 0.6738072633743286,\n",
       " 0.6727402210235596,\n",
       " 0.6716852784156799,\n",
       " 0.670642614364624,\n",
       " 0.6696119904518127,\n",
       " 0.6685933470726013,\n",
       " 0.6675863862037659,\n",
       " 0.6665912866592407,\n",
       " 0.6656076908111572,\n",
       " 0.664635956287384,\n",
       " 0.6636755466461182,\n",
       " 0.6627267003059387,\n",
       " 0.661789059638977,\n",
       " 0.6608625650405884,\n",
       " 0.6599470376968384,\n",
       " 0.6590427160263062,\n",
       " 0.6581491827964783,\n",
       " 0.6572663187980652,\n",
       " 0.6563941240310669,\n",
       " 0.6555325984954834,\n",
       " 0.654681384563446,\n",
       " 0.6538406014442444,\n",
       " 0.6530099511146545,\n",
       " 0.652189314365387,\n",
       " 0.6513787508010864,\n",
       " 0.6505780220031738,\n",
       " 0.6497871279716492,\n",
       " 0.649005651473999,\n",
       " 0.6482338309288025,\n",
       " 0.6474713087081909,\n",
       " 0.6467182040214539,\n",
       " 0.6459742784500122,\n",
       " 0.6452394127845764,\n",
       " 0.6445133686065674,\n",
       " 0.6437962651252747,\n",
       " 0.6430878639221191,\n",
       " 0.642387866973877,\n",
       " 0.6416966915130615,\n",
       " 0.6410138607025146,\n",
       " 0.6403391361236572,\n",
       " 0.6396727561950684,\n",
       " 0.6390143036842346,\n",
       " 0.6383638978004456,\n",
       " 0.6377213001251221,\n",
       " 0.6370863914489746,\n",
       " 0.636459231376648,\n",
       " 0.6358396410942078,\n",
       " 0.6352275013923645,\n",
       " 0.6346225738525391,\n",
       " 0.634024977684021,\n",
       " 0.6334344148635864,\n",
       " 0.6328511238098145,\n",
       " 0.6322744488716125,\n",
       " 0.6317048668861389,\n",
       " 0.6311421990394592,\n",
       " 0.6305858492851257,\n",
       " 0.6300362348556519,\n",
       " 0.629492998123169,\n",
       " 0.6289563179016113,\n",
       " 0.6284257769584656,\n",
       " 0.6279014945030212,\n",
       " 0.6273833513259888,\n",
       " 0.6268712878227234,\n",
       " 0.6263651847839355,\n",
       " 0.6258649230003357,\n",
       " 0.6253705024719238,\n",
       " 0.6248816847801208,\n",
       " 0.6243986487388611,\n",
       " 0.6239210367202759,\n",
       " 0.6234490275382996,\n",
       " 0.6229822635650635,\n",
       " 0.6225210428237915,\n",
       " 0.6220648288726807,\n",
       " 0.6216138601303101,\n",
       " 0.6211681365966797,\n",
       " 0.6207273006439209,\n",
       " 0.6202913522720337,\n",
       " 0.6198606491088867,\n",
       " 0.6194344162940979,\n",
       " 0.6190130114555359,\n",
       " 0.6185963153839111,\n",
       " 0.6181843876838684,\n",
       " 0.6177768111228943,\n",
       " 0.6173739433288574,\n",
       " 0.6169753670692444,\n",
       " 0.6165812015533447,\n",
       " 0.6161912083625793,\n",
       " 0.6158057451248169,\n",
       " 0.6154242753982544,\n",
       " 0.6150469779968262,\n",
       " 0.6146738529205322,\n",
       " 0.6143046021461487,\n",
       " 0.6139393448829651,\n",
       " 0.613578200340271,\n",
       " 0.6132206916809082,\n",
       " 0.6128671169281006,\n",
       " 0.612517237663269,\n",
       " 0.6121711134910583,\n",
       " 0.611828625202179,\n",
       " 0.6114897131919861,\n",
       " 0.611154317855835,\n",
       " 0.6108224987983704,\n",
       " 0.610494077205658,\n",
       " 0.6101692914962769,\n",
       " 0.6098475456237793,\n",
       " 0.6095293164253235,\n",
       " 0.6092143654823303,\n",
       " 0.6089025735855103,\n",
       " 0.6085939407348633,\n",
       " 0.6082884669303894,\n",
       " 0.6079862713813782,\n",
       " 0.6076871156692505,\n",
       " 0.6073906421661377,\n",
       " 0.6070975065231323,\n",
       " 0.6068072319030762,\n",
       " 0.6065196990966797,\n",
       " 0.6062353253364563,\n",
       " 0.605953574180603,\n",
       " 0.6056746244430542,\n",
       " 0.6053985953330994,\n",
       " 0.6051251888275146,\n",
       " 0.6048543453216553,\n",
       " 0.6045863628387451,\n",
       " 0.6043209433555603,\n",
       " 0.6040579676628113,\n",
       " 0.6037976145744324,\n",
       " 0.6035398244857788,\n",
       " 0.6032845973968506,\n",
       " 0.6030316352844238,\n",
       " 0.6027812361717224,\n",
       " 0.6025331020355225,\n",
       " 0.6022874116897583,\n",
       " 0.6020440459251404,\n",
       " 0.6018030047416687,\n",
       " 0.6015642285346985,\n",
       " 0.6013277173042297,\n",
       " 0.6010933518409729,\n",
       " 0.6008611917495728,\n",
       " 0.6006311774253845,\n",
       " 0.6004033088684082,\n",
       " 0.6001777052879333,\n",
       " 0.5999541282653809,\n",
       " 0.5997323989868164,\n",
       " 0.5995128154754639,\n",
       " 0.5992953777313232,\n",
       " 0.5990798473358154,\n",
       " 0.5988662838935852,\n",
       " 0.5986545085906982,\n",
       " 0.5984448194503784,\n",
       " 0.5982368588447571,\n",
       " 0.5980308055877686,\n",
       " 0.5978266596794128,\n",
       " 0.5976243019104004,\n",
       " 0.597423791885376,\n",
       " 0.5972251296043396,\n",
       " 0.5970280766487122,\n",
       " 0.5968327522277832,\n",
       " 0.5966392159461975,\n",
       " 0.5964474081993103,\n",
       " 0.5962570905685425,\n",
       " 0.5960686206817627,\n",
       " 0.5958816409111023,\n",
       " 0.5956964492797852,\n",
       " 0.5955128073692322,\n",
       " 0.5953306555747986,\n",
       " 0.5951501131057739,\n",
       " 0.5949711203575134,\n",
       " 0.5947936177253723,\n",
       " 0.5946177244186401,\n",
       " 0.5944432616233826,\n",
       " 0.5942702889442444,\n",
       " 0.594098687171936,\n",
       " 0.5939286947250366,\n",
       " 0.5937598943710327,\n",
       " 0.593592643737793,\n",
       " 0.5934268236160278,\n",
       " 0.593262255191803,\n",
       " 0.5930991172790527,\n",
       " 0.5929372310638428,\n",
       " 0.592776894569397,\n",
       " 0.5926178097724915,\n",
       " 0.5924599170684814,\n",
       " 0.5923033356666565,\n",
       " 0.5921481251716614,\n",
       " 0.5919939875602722,\n",
       " 0.5918412208557129,\n",
       " 0.5916897654533386,\n",
       " 0.5915393829345703,\n",
       " 0.5913902521133423,\n",
       " 0.5912423729896545,\n",
       " 0.5910955667495728,\n",
       " 0.5909500122070312,\n",
       " 0.5908055901527405,\n",
       " 0.5906623005867004,\n",
       " 0.5905201435089111,\n",
       " 0.5903791189193726,\n",
       " 0.5902392268180847,\n",
       " 0.5901003479957581,\n",
       " 0.5899625420570374,\n",
       " 0.5898258686065674,\n",
       " 0.5896902084350586,\n",
       " 0.5895557403564453,\n",
       " 0.5894221067428589,\n",
       " 0.5892895460128784,\n",
       " 0.5891580581665039,\n",
       " 0.5890275835990906,\n",
       " 0.5888981223106384,\n",
       " 0.5887696146965027,\n",
       " 0.5886421799659729,\n",
       " 0.5885155200958252,\n",
       " 0.5883899927139282,\n",
       " 0.5882651805877686,\n",
       " 0.5881415605545044,\n",
       " 0.5880186557769775,\n",
       " 0.5878968238830566,\n",
       " 0.5877757668495178,\n",
       " 0.587655782699585,\n",
       " 0.5875365138053894,\n",
       " 0.5874181985855103,\n",
       " 0.587300717830658,\n",
       " 0.5871841311454773,\n",
       " 0.5870683789253235,\n",
       " 0.5869535207748413,\n",
       " 0.5868393778800964,\n",
       " 0.586726188659668,\n",
       " 0.5866138935089111,\n",
       " 0.5865023136138916,\n",
       " 0.5863914489746094,\n",
       " 0.5862815380096436,\n",
       " 0.5861724019050598,\n",
       " 0.5860639214515686,\n",
       " 0.5859562158584595,\n",
       " 0.585849404335022,\n",
       " 0.5857433080673218,\n",
       " 0.5856378674507141,\n",
       " 0.5855333209037781,\n",
       " 0.5854294896125793,\n",
       " 0.5853261947631836,\n",
       " 0.5852237939834595,\n",
       " 0.5851221084594727,\n",
       " 0.5850211381912231,\n",
       " 0.5849207639694214,\n",
       " 0.5848211646080017,\n",
       " 0.5847223997116089,\n",
       " 0.5846240520477295,\n",
       " 0.5845265984535217,\n",
       " 0.5844297409057617,\n",
       " 0.5843334197998047,\n",
       " 0.5842378735542297,\n",
       " 0.5841430425643921,\n",
       " 0.5840486884117126,\n",
       " 0.5839551687240601,\n",
       " 0.5838621258735657,\n",
       " 0.5837697982788086,\n",
       " 0.5836780667304993,\n",
       " 0.5835870504379272,\n",
       " 0.5834965109825134,\n",
       " 0.5834065675735474,\n",
       " 0.5833171606063843,\n",
       " 0.5832286477088928,\n",
       " 0.5831405520439148,\n",
       " 0.5830529928207397,\n",
       " 0.5829660892486572,\n",
       " 0.5828795433044434,\n",
       " 0.5827937722206116,\n",
       " 0.5827085375785828,\n",
       " 0.5826238989830017,\n",
       " 0.5825397968292236,\n",
       " 0.5824562311172485,\n",
       " 0.5823732018470764,\n",
       " 0.5822907090187073,\n",
       " 0.5822087526321411,\n",
       " 0.5821273326873779,\n",
       " 0.582046389579773,\n",
       " 0.5819661021232605,\n",
       " 0.5818861722946167,\n",
       " 0.5818067789077759,\n",
       " 0.581727921962738,\n",
       " 0.5816496014595032,\n",
       " 0.5815717577934265,\n",
       " 0.5814943909645081,\n",
       " 0.5814176201820374,\n",
       " 0.5813412070274353,\n",
       " 0.5812653303146362,\n",
       " 0.5811898708343506,\n",
       " 0.5811149477958679,\n",
       " 0.5810405015945435,\n",
       " 0.5809665322303772,\n",
       " 0.5808929204940796,\n",
       " 0.580819845199585,\n",
       " 0.5807472467422485,\n",
       " 0.5806750655174255,\n",
       " 0.5806033611297607,\n",
       " 0.5805320739746094,\n",
       " 0.5804611444473267,\n",
       " 0.5803907513618469,\n",
       " 0.5803208947181702,\n",
       " 0.580251157283783,\n",
       " 0.5801820755004883,\n",
       " 0.580113410949707,\n",
       " 0.5800451040267944,\n",
       " 0.57997727394104]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[\"fairness_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# empirical utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 265us/step\n"
     ]
    }
   ],
   "source": [
    "p_a1 = policy_model.predict(in_df[X_atr])\n",
    "p_a0 = 1 - p_a1\n",
    "p_a_x = np.concatenate([p_a0, p_a1],axis=1).T\n",
    "ys = train_data[[Y_atr]].values.ravel()\n",
    "a_pred = np.argmax(p_a_x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true =  ys, y_pred=a_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_utility_v1(p_a_x, ys, utility):\n",
    "    EU = 0\n",
    "    for x, y in enumerate(ys):\n",
    "        for a in range(2):\n",
    "            EU += utility[a,y]* p_a_x[a, x]\n",
    "    EU = EU / ys.shape[0]\n",
    "    return EU\n",
    "\n",
    "def empirical_utility_v2(p_a_x, ys, a, utility):\n",
    "    EU = 0\n",
    "    for x, (y, a) in enumerate(zip(ys, a)):\n",
    "        EU += utility[a, y]* p_a_x[a, x]\n",
    "    EU = EU / ys.shape[0]\n",
    "    return EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6346671340760465"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_utility_v1(p_a_x, ys, utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5674012770354748"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_utility_v2(p_a_x, ys, a_pred, utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9847291 , 0.9366156 , 0.11858833, ..., 0.934572  , 0.20011991,\n",
       "        0.9681015 ],\n",
       "       [0.01527089, 0.06338441, 0.8814117 , ..., 0.06542804, 0.7998801 ,\n",
       "        0.0318985 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_a_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# empirical fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_fairness_v21(datas, model, policy):\n",
    "    \n",
    "    Z = 11\n",
    "\n",
    "    EF = 0\n",
    "    for z in range(Z):\n",
    "        c = 0\n",
    "        for i,(x, y) in datas.iterrows():\n",
    "            delta = (model.Pz_yx[z, y, x]/model.Pz_y[z, y] - 1 )/(model.Py[y])\n",
    "            c += policy[:, x] * delta\n",
    "        c = c/datas.shape[0]\n",
    "        c = np.linalg.norm(c, 1)\n",
    "        EF += c\n",
    "    return EF"
   ]
  },
  {
   "attachments": {
    "Screenshot%202023-01-20%20at%203.01.34%20PM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot%202023-01-20%20at%203.01.34%20PM.png](attachment:Screenshot%202023-01-20%20at%203.01.34%20PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5509915, 0.4490085]),\n",
       " array([[4.90640097e-02, 3.75925926e-02],\n",
       "        [3.50694444e-01, 5.08703704e-01],\n",
       "        [2.79438406e-01, 2.41666667e-01],\n",
       "        [8.52958937e-02, 6.01851852e-02],\n",
       "        [6.49154589e-03, 2.40740741e-03],\n",
       "        [2.26449275e-03, 2.40740741e-03],\n",
       "        [1.25301932e-02, 4.62962963e-03],\n",
       "        [1.03411836e-01, 6.98148148e-02],\n",
       "        [9.31461353e-02, 6.16666667e-02],\n",
       "        [1.67572464e-02, 9.44444444e-03],\n",
       "        [4.52898551e-04, 5.55555556e-04],\n",
       "        [4.52898551e-04, 9.25925926e-04]]),\n",
       " LogisticRegression(max_iter=1000),\n",
       " LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py, Pz_y, model_y_x, model_z_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_fairness_cont_v11(datas, p_a_x, Pz_y, Py, model_y_x, model_z_yx):\n",
    "    Z = n_z\n",
    "\n",
    "    Py_x = model_y_x.predict_proba(datas[X_atr]).T\n",
    "    EF = 0\n",
    "    for y in range(2):\n",
    "        tmp_data = datas[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "        print(Pz_yx.shape)\n",
    "        for z in range(Z):\n",
    "            c = 0\n",
    "            for i in range(tmp_data.shape[0]):\n",
    "                delta = (Pz_yx[z, i] - Pz_y[z, y] ) * (Py_x[y, i]/Py[y])\n",
    "                c += p_a_x[:, i] * delta\n",
    "            c = c/tmp_data.shape[0]\n",
    "            c = np.linalg.norm(c, 1)\n",
    "            EF += c\n",
    "    return EF\n",
    "\n",
    "\n",
    "def empirical_fairness_cont_v12(datas, p_a_x, Pz_y, Py,model_y_x, model_z_yx):\n",
    "    Z = n_z\n",
    "\n",
    "    Py_x = model_y_x.predict_proba(datas[X_atr]).T\n",
    "    EF = 0\n",
    "    for y in range(2):\n",
    "        tmp_data = datas[[Y_atr] + X_atr].copy()\n",
    "        tmp_data[Y_atr] = y\n",
    "        Pz_yx = model_z_yx.predict_proba(tmp_data[[Y_atr] + X_atr]).T\n",
    "        for z in range(Z):\n",
    "            c = 0\n",
    "            j= 0 \n",
    "            for i in range(tmp_data.shape[0]):\n",
    "                j = j + 1\n",
    "                delta = (Pz_yx[z, i] / Pz_y[z, y] - 1 ) * (Py_x[y, i] / (Py[y]) )\n",
    "                c += p_a_x[:, i] * delta\n",
    "            c = c/datas.shape[0]\n",
    "            c = np.linalg.norm(c, 1)\n",
    "            EF += c\n",
    "    return EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = train_data\n",
    "datas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 262us/step\n"
     ]
    }
   ],
   "source": [
    "p_a1 = policy_model.predict(datas[X_atr].astype(\"float32\"))\n",
    "p_a0 = 1 - p_a1\n",
    "p_a_x = np.concatenate([p_a0, p_a1],axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6000)\n",
      "(12, 6000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29246787279407727"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py, Pz_y, model_y_x, model_z_yx = get_models(datas)\n",
    "empirical_fairness_cont_v11(datas = datas, p_a_x = p_a_x, Pz_y=Pz_y, Py=Py, model_y_x = model_y_x, model_z_yx = model_z_yx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.384358033537865"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py, Pz_y, model_y_x, model_z_yx = get_models(datas)\n",
    "empirical_fairness_cont_v12(datas = datas,\n",
    "                            p_a_x = p_a_x,\n",
    "                            Pz_y = Pz_y,\n",
    "                            Py = Py,\n",
    "                            model_y_x = model_y_x, \n",
    "                            model_z_yx = model_z_yx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness(policy, model_delta):\n",
    "    (X, Y, Z) = model_delta.shape\n",
    "    fairness = 0\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            delta = np.matmul(policy, model_delta[:, y , z ])\n",
    "            fairness += np.linalg.norm(delta, 1)\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Calculate expected utility\n",
    "    Todo: vectorize operation - minor\n",
    "    \"\"\"\n",
    "    A, X = policy.shape\n",
    "    Y = A\n",
    "    Eu = 0\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            for a in range(A):\n",
    "                Eu += utility[a,y] * policy[a,x] * model.Pxy[x, y]\n",
    "                \n",
    "    return Eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Py = [Py[y] for y in train_data[Y_atr].values]\n",
    "data_Pz_y = [Pz_y[z, y] for z, y in train_data[[Z_atr,Y_atr]].values]\n",
    "\n",
    "predicted_proba_Py_x = model_y_x.predict_proba(train_data[X_atr])\n",
    "data_Py_z = np.zeros(train_data.shape[0])\n",
    "for i, datum in train_data.iterrows():\n",
    "    data_Py_z[i] = predicted_proba_Py_x[i][datum[Y_atr]]\n",
    "    \n",
    "predicted_proba_Pz_yx = model_z_yx.predict_proba(train_data[[Y_atr] + X_atr])\n",
    "data_Pz_yx = np.zeros(train_data.shape[0])\n",
    "for i, datum in train_data.iterrows():\n",
    "    data_Pz_yx[i] = predicted_proba_Pz_yx[i][datum[Z_atr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_columns\n",
    "p_a_x = p_a_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "for i, (py, pz_y, py_z, pz_yx) in enumerate(in_df[prob_columns].values): \n",
    "    delta =  (pz_yx - pz_y) * (py_z / py)\n",
    "    for a in range(2):\n",
    "        C += p_a_x[a,i] * np.abs(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C / 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_x[a,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_columns = ['Py', 'Pz_y', 'Py_z', 'Pz_yx']\n",
    "in_df[prob_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Py_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Py, Pz_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba_Py_x = model_y_x.predict_proba(train_data[X_atr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba_Py_x = predicted_proba_Py_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba_Pz_yx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pz_y[z,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "for y in range(len(unique_y)):\n",
    "    train_data[Y_atr] = y\n",
    "    pz_yix = model_z_yx.predict_proba(train_data[[Y_atr] + X_atr]).T\n",
    "    for z in range(len(unique_y)):\n",
    "        c = 0 \n",
    "        for x, p_a in enumerate(p_a_x):\n",
    "            delta = (pz_yix[z, x] - Pz_y[z,y])*(predicted_proba_Py_x[y, x] / Py[y])\n",
    "            delta = np.abs(delta)\n",
    "            for a in range(2):\n",
    "                c += p_a[a] * np.abs(delta)\n",
    "        c = c\n",
    "        C += c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c/(6000*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enumerate(p_a_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_yx[z,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ldelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a1 = policy.predict(in_df[X_atr])\n",
    "p_a0 = 1 - p_a1\n",
    "p_a_x = np.concatenate([p_a0,p_a1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EF = 0 \n",
    "for p_a, y in zip(p_a_x, train_data[Y_atr].values):\n",
    "    for a in range(2):\n",
    "        EU += utility[a,y] * p_a[a]\n",
    "EU = EU/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empirical_fairness(policy, y_array, utility):\n",
    "    EF = 0 \n",
    "    for p_a, y in zip(policy, y_array):\n",
    "        for a in range(2):\n",
    "            EU += utility[a,y] * p_a[a]\n",
    "    EU = EU/train_data.shape[0]\n",
    "    return EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empirical_utility2(policy, y_array, utility):\n",
    "    EU = 0 \n",
    "    for p_a in policy:\n",
    "        for y in range(2):\n",
    "            for a in range(2):\n",
    "                EU += utility[a, y] * p_a[a]\n",
    "    EU = EU/train_data.shape[0]\n",
    "    return EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empirical_utility(policy, y_array, utility):\n",
    "    EU = 0 \n",
    "    for p_a, y in zip(policy, y_array):\n",
    "        for a in range(2):\n",
    "            EU += utility[a,y] * p_a[a]\n",
    "    EU = EU/train_data.shape[0]\n",
    "    return EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_empirical_utility(p_a_x,train_data[Y_atr].values,utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_empirical_utility2(p_a_x, train_data[Y_atr].values,utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argmax(p_a_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU = 0 \n",
    "for p_a,y in zip(p_a_x, train_data[Y_atr].values):\n",
    "    for a in range(2):\n",
    "        EU += utility[a,y] * p_a[a]\n",
    "EU = EU/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_x[x, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[Y_atr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.evaluate(test_data[X_atr].astype(\"float32\"),\n",
    "                test_data[Y_atr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(train_data[X_atr].astype(\"float32\"), policy.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.predict(train_data[X_atr].astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fairness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### opt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_model, true_model_delta, policy, utility, l):\n",
    "    \"\"\"\n",
    "    Evaluate policy on true model\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    results[\"fairness\"] = np.round(get_fairness(policy, true_model_delta),4)\n",
    "    results[\"utility\"] = get_utility(policy, true_model, utility)\n",
    "    results[\"total\"] = (1 - l) * results[\"utility\"] - l * results[\"fairness\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, model, utility, l, lr, n_iter):\n",
    "    \"\"\"\n",
    "    Marginal Policy Dirichlet\n",
    "    \"\"\"\n",
    "    model.get_marginal_model()\n",
    "    model_delta = get_delta(model.Px_y, model.Px_yz)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        fairness_gradient = get_fairness_gradient(policy, model_delta)\n",
    "        utility_gradient = get_utility_gradient(policy, model, utility)\n",
    "        gradient = (1 - l) * utility_gradient #+ l * fairness_gradient # minus on the gradient calc.\n",
    "        gradient = project_gradient(gradient)\n",
    "        policy = policy + lr * gradient # maximize Utility & minimize fairness constrain.\n",
    "        policy = normilize_policy(policy)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy_bayesian(policy, model, utility, l, lr, n_iter, n_model):\n",
    "    \"\"\"\n",
    "    Marginal Policy Dirichlet\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    model_delta = []\n",
    "    for m in range(n_model):\n",
    "        models += [model.sample_model()]\n",
    "        model_delta += [get_delta(model.Px_y, model.Px_yz)]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        tmp_index = i%n_model\n",
    "        tmp_model = models[tmp_index]\n",
    "        tmp_delta = model_delta[tmp_index]\n",
    "        fairness_gradient = get_fairness_gradient(policy, tmp_delta)\n",
    "        utility_gradient = get_utility_gradient(policy, tmp_model, utility)\n",
    "        gradient = (1 - l) * utility_gradient + l * fairness_gradient # minus on the gradient calc.\n",
    "        gradient = project_gradient(gradient)\n",
    "        policy = policy + lr * gradient # maximize Utility & minimize fairness constrain.\n",
    "        policy = normilize_policy(policy)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce results\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_org_policy(org_path_results):\n",
    "    file = pd.read_csv(org_path_results + \"/policy.csv\")\n",
    "    p_1 = file.iloc[4].values\n",
    "    p_2 = file.iloc[5].values\n",
    "    p_1 = [float(x) for x in p_1[0].split(\" \")[1:]]\n",
    "    p_2 = [float(x) for x in p_2[0].split(\" \")[1:]]\n",
    "    return np.array([p_1, p_2])\n",
    "# [float(x) for x in p_1[0].split(\" \")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path_results = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/org_code/bayesian-fairness/src/octave\"\n",
    "policy = load_org_policy(org_path_results)\n",
    "policy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = horizon // update_policy_period\n",
    "\n",
    "results = []\n",
    "for step in range(steps):    \n",
    "    # update policy step\n",
    "    policy = update_policy_bayesian(policy, belief, utility, l, lr, n_iter, n_model= n_samples) # SDG to update policy\n",
    "    \n",
    "    # evaluation step\n",
    "    step_results = evaluate(true_dirichlet_model, true_model_delta, policy, utility, l)\n",
    "    results += [step_results]\n",
    "    \n",
    "    # update belief step\n",
    "    data_start_index = step * update_policy_period\n",
    "    data_stop_index = min(data_start_index + update_policy_period, horizon)\n",
    "    belief.update_posterior_belief(train_data.iloc[data_start_index : data_stop_index])\n",
    "    \n",
    "    print(f\"--- Step : {data_start_index + 1} \\n  ------- {step_results}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls[[\"utility\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org = pd.read_csv(org_path_results + \"/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_results(r):\n",
    "    new_r = [float(sr.split(\" \")[1]) for sr in r]\n",
    "    return new_r\n",
    "\n",
    "r1 = fix_results(org.iloc[9: 64 + 9 - 3][\"# Created by Octave 6.2.0\"].values)\n",
    "r2 = fix_results(org.iloc[74: 64 + 74 - 3][\"# Created by Octave 6.2.0\"].values)\n",
    "r3 = fix_results(org.iloc[139: 64 + 139 - 3][\"# Created by Octave 6.2.0\"].values)\n",
    "# r4 = fix_results(org.iloc[204: 64 + 204][\"# Created by Octave 6.2.0\"].values)\n",
    "\n",
    "org_pd = pd.DataFrame([r1,r2,r3]).T\n",
    "org_pd.columns = [\"utility\",\"total\",\"fairness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "org_pd[\"utility\"].plot()\n",
    "pd_resutls[\"utility\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"fairness\"].plot()\n",
    "pd_resutls[\"fairness\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"total\"].plot()\n",
    "pd_resutls[\"total\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. ProjectPolicyGradient ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
