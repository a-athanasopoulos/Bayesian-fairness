{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"exp_compass\"\n",
    "exp_number = \"exp_1\"\n",
    "base_path = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/\"\n",
    "data_path = base_path + \"/my_code/Bayesian-fairness/data\"\n",
    "save_path = base_path + f\"/my_code/Bayesian-fairness/results/{exp_name}/{exp_number}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set atributes\n",
    "Z_atr = [\"sex\", \"race\"]\n",
    "X_atr = ['age_cat', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree']\n",
    "Y_atr = ['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compas_dataset(path, clip_features, clip_value):\n",
    "    raw_data = pd.read_csv(path + \"/compas.csv\")\n",
    "    raw_data[raw_data[clip_features] > 2] = 2\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_features = [\"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\"]\n",
    "data = load_compas_dataset(path = data_path, clip_features = clip_features, clip_value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct values\n",
    "unique_z = np.unique(data[Z_atr].values, axis=0)\n",
    "n_z = len(unique_z)\n",
    "\n",
    "unique_x = np.unique(data[X_atr].values, axis=0)\n",
    "n_x = len(unique_x)\n",
    "\n",
    "unique_y = np.unique(data[Y_atr].values, axis=0)\n",
    "n_y = len(unique_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Z values: 12\n",
      "Unique X values: 141\n",
      "Unique Y values: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Z values:\", n_z)\n",
    "print(\"Unique X values:\", n_x)\n",
    "print(\"Unique Y values:\", n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data,unique_values):\n",
    "    encoded_value = np.array([])\n",
    "    for i, d in data.iterrows():\n",
    "        # encode feature to an index represents the unique value.\n",
    "        index = np.argmax((d.values == unique_values).all(axis=1))\n",
    "        encoded_value = np.append(encoded_value, index)\n",
    "    return encoded_value.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compact_dataset():\n",
    "    # encode z\n",
    "    encoded_z = encode_data(data[Z_atr], unique_z)\n",
    "    assert (int(max(encoded_z))+1) == len(unique_z)\n",
    "    \n",
    "    # encode x\n",
    "    encoded_x = encode_data(data[X_atr], unique_x)\n",
    "    assert (int(max(encoded_x))+1) == len(unique_x)\n",
    "    \n",
    "    # encode y\n",
    "    encoded_y = encode_data(data[Y_atr], unique_y)\n",
    "    assert (int(max(encoded_y))+1) == len(unique_y)\n",
    "\n",
    "    return np.stack([encoded_x, encoded_z, encoded_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_compact_dataset()\n",
    "dataset = pd.DataFrame(dataset,columns = [\"x\",\"z\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>z</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x  z  y\n",
       "0  124  0  0\n",
       "1   64  1  1\n",
       "2   11  1  1\n",
       "3   20  1  0\n",
       "4   68  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.iloc[0:6000]\n",
    "test_data = dataset.iloc[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (6000, 3)\n",
      "testing size: (1214, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"training size:\", train_data.shape)\n",
    "print(\"testing size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirichletModel:\n",
    "    def __init__(self, n_x, n_z, n_y, prior):\n",
    "        self.X = n_x\n",
    "        self.Y = n_y\n",
    "        self.Z = n_z\n",
    "        \n",
    "        # why we have this fractoriazation?\n",
    "        self.N_x = prior + np.zeros(shape = (n_x, 1) )\n",
    "        self.N_y_x = prior + np.zeros(shape = (n_y, n_x) )\n",
    "        self.N_z_yx = prior + np.zeros(shape = (n_z, n_y, n_x) )\n",
    "        \n",
    "        # prop\n",
    "        self.Px = np.zeros(shape = (n_x, 1) )\n",
    "        self.Py_x = np.zeros(shape = (n_y, n_x) )\n",
    "        self.Pz_yx = np.zeros(shape = (n_z, n_y, n_x) )\n",
    "    \n",
    "    def update_posterior_belief(self, data):\n",
    "        for i , datum in data.iterrows():\n",
    "            self.N_x[datum[\"x\"]] += 1\n",
    "            self.N_y_x[datum[\"y\"], datum[\"x\"]] += 1\n",
    "            self.N_z_yx[datum[\"z\"], datum[\"y\"], datum[\"x\"]] += 1\n",
    "        \n",
    "    def calculate_marginal_propabilities(self):\n",
    "        # calculate Prop\n",
    "        self.Pxyz =  np.zeros(shape = (self.X, self.Y, self.Z) )\n",
    "        self.Pxy = np.zeros(shape = (self.X, self.Y) )\n",
    "        self.Pyz = np.zeros(shape = (self.Y, self.Z) )\n",
    "        self.Px_yz = np.zeros(shape = (self.X, self.Y, self.Z) )\n",
    "        \n",
    "        # calculate Pxyz\n",
    "        for x in range(self.X):\n",
    "            for y in range(self.Y):\n",
    "                for z in range(self.Z):\n",
    "                    # calculate Pxyz\n",
    "                    self.Pxyz[x, y, z] = self.Pz_yx[z, y, x] * self.Py_x[y, x] * self.Px[x]\n",
    "        \n",
    "        # calculate Px_yz \n",
    "        for y in range(self.Y):\n",
    "            for z in range(self.Z):\n",
    "                self.Pyz[y, z] = np.sum(self.Pxyz[:, y, z])    \n",
    "                for x in range(self.X):\n",
    "                    self.Pxy[x, y] = np.sum(self.Pxyz[x, y, :])\n",
    "                    self.Px_yz[x, y, z] = self.Pxyz[x, y, z] / self.Pyz[y, z]\n",
    "        \n",
    "        # calculate Px_y\n",
    "        self.Py = np.zeros(shape = (self.Y, 1) )\n",
    "        self.Px_y = np.zeros(shape = (self.X, self.Y) )\n",
    "        for y in range(self.Y):\n",
    "            self.Py[y] = np.sum(self.Pxyz[:, y, :])\n",
    "            for x in range(self.X):\n",
    "                self.Px_y[x,y] = self.Pxy[x,y] / self.Py[y]\n",
    "        \n",
    "        # calculate Pz_y\n",
    "        self.Pz_y = np.zeros(shape = (self.Z, self.Y) )\n",
    "        for y in range(self.Y):\n",
    "            self.Pz_y[:,y] = self.Pyz[y,:] / self.Py[y]\n",
    "                \n",
    "    def get_marginal_model(self):\n",
    "        self.Px = self.N_x / np.sum(self.N_x)\n",
    "        self.Py_x = self.N_y_x / np.sum(self.N_y_x, axis=0)\n",
    "        self.Pz_yx = self.N_z_yx / np.sum(self.N_z_yx, axis=0)\n",
    "        self.calculate_marginal_propabilities()\n",
    "        \n",
    "    def sample_model(self):\n",
    "        self.Px = np.random.dirichlet( np.ravel(dirichlet_model.N_x) ).reshape((-1,1))\n",
    "        \n",
    "        for y in range(self.Y):\n",
    "            self.Py_x[y, :] = np.random.dirichlet(self.N_y_x[y,:])\n",
    "        \n",
    "        for y in range(self.Y):\n",
    "            for z in range(self.Z):\n",
    "                self.Pz_yx[z, y, :] = np.random.dirichlet(self.N_z_yx[z, y, :])\n",
    "        \n",
    "        self.calculate_marginal_propabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_prior = 0.5\n",
    "true_dirichlet_model = DirichletModel(n_x = n_x, n_z = n_z, n_y = n_y, prior = dirichlet_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dirichlet_model.update_posterior_belief(data=test_data)\n",
    "true_dirichlet_model.get_marginal_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_policy(size):\n",
    "    a = np.ones(shape=size[0])\n",
    "    policy = np.random.dirichlet(a, size= size[1])\n",
    "    return np.transpose(policy)\n",
    "\n",
    "def get_random_policy_2(size):\n",
    "    policy = np.random.random(size = size)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = get_random_policy(size = (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normilize_policy(policy):\n",
    "    policy[policy < 0] = 0\n",
    "    policy[policy > 1] = 1\n",
    "    for x in range(policy.shape[-1]):\n",
    "        policy[:, x] /= np.sum(policy[:, x])\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(Px_y, Px_yz):\n",
    "    delta = np.zeros(Px_yz.shape)\n",
    "    for z in range(Px_yz.shape[-1]):\n",
    "        delta[:, :, z] = Px_y - Px_yz[:,:,z]\n",
    "    return delta\n",
    "\n",
    "def get_delta(Px_y, Px_yz, Pz_y):\n",
    "    delta = np.zeros(Px_yz.shape)\n",
    "    for z in range(Px_yz.shape[-1]):\n",
    "        delta[:, :, z] = (Px_y - Px_yz[:,:,z]) * Pz_y[z,:]\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_1 = get_delta(true_dirichlet_model.Px_y, true_dirichlet_model.Px_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_2 = get_delta2(true_dirichlet_model.Px_y, true_dirichlet_model.Px_yz, true_dirichlet_model.Pz_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_utility(size):\n",
    "    return np.eye(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- data parameters\n",
    "horizon = train_data.shape[0]\n",
    "\n",
    "num_X = n_x # number of features\n",
    "num_Y = n_y # number of outcomes\n",
    "num_Z = n_z # number of sensitive features\n",
    "num_A = 2 # number of actions\n",
    "\n",
    "# --- SGD parameters\n",
    "n_iter = 400 # number of itteration for SGD\n",
    "lr = 1.0 # learning rate\n",
    "\n",
    "# --- Algorithm parameters\n",
    "update_policy_period = 100 # period to update policy\n",
    "l = 0.5 # lambda\n",
    "n_samples = 16 # number of sample for bayssian policy\n",
    "\n",
    "# --- Utility\n",
    "utility = get_eye_utility(size=num_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. initializition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize belief\n",
    "belief = DirichletModel(n_x = num_X, n_y=num_Y, n_z=num_Z, prior = 0.5)\n",
    "\n",
    "# initialize policy\n",
    "policy = get_random_policy(size = (num_A, num_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true model delta to avoid computations\n",
    "true_model_delta = get_delta(true_dirichlet_model.Px_y,\n",
    "                             true_dirichlet_model.Px_yz,\n",
    "                             true_dirichlet_model.Pz_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fairness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness(policy, model_delta):\n",
    "    (X, Y, Z) = model_delta.shape\n",
    "    fairness = 0\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            delta = np.matmul(policy, model_delta[:, y , z ])\n",
    "            fairness += np.linalg.norm(delta, 1)\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_gradient(policy, model_delta):\n",
    "    \"\"\"\n",
    "    Todo: vectorize operation\n",
    "    \"\"\"\n",
    "    fairness_gradient = np.zeros(policy.shape)\n",
    "    \n",
    "    (X, Y, Z) = model_delta.shape\n",
    "    for y in range(Y):\n",
    "        for z in range(Z):\n",
    "            dyz = model_delta[:,y,z].reshape((-1,1))\n",
    "            c = np.matmul(policy, dyz)\n",
    "            fairness_gradient -= np.matmul(c, dyz.T)\n",
    "    \n",
    "    return fairness_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Calculate expected utility\n",
    "    Todo: vectorize operation - minor\n",
    "    \"\"\"\n",
    "    A, X = policy.shape\n",
    "    Y = A\n",
    "    Eu = 0\n",
    "    for x in range(X):\n",
    "        for y in range(Y):\n",
    "            for a in range(A):\n",
    "                Eu += utility[a,y] * policy[a,x] * model.Pxy[x,y]\n",
    "                \n",
    "    return Eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_gradient(policy, model, utility):\n",
    "    \"\"\"\n",
    "    Todo: vectorize operation\n",
    "    \"\"\"\n",
    "    utility_gradient = np.matmul(utility, model.Pxy.T )\n",
    "    \n",
    "    \n",
    "    return utility_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_gradient(grad):\n",
    "    proj_grad = grad - np.mean(grad,axis=0)\n",
    "    return proj_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### opt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_model, true_model_delta, policy, utility, l):\n",
    "    \"\"\"\n",
    "    Evaluate policy on true model\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    results[\"fairness\"] = np.round(get_fairness(policy, true_model_delta),4)\n",
    "    results[\"utility\"] = get_utility(policy, true_model, utility)\n",
    "    results[\"total\"] = (1 - l) * results[\"utility\"] - l * results[\"fairness\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(policy, model, utility, l, lr, n_iter):\n",
    "    \"\"\"\n",
    "    Marginal Policy Dirichlet\n",
    "    \"\"\"\n",
    "    model.get_marginal_model()\n",
    "    model_delta = get_delta(model.Px_y, model.Px_yz, model.Pz_y)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        fairness_gradient = get_fairness_gradient(policy, model_delta)\n",
    "        utility_gradient = get_utility_gradient(policy, model, utility)\n",
    "        gradient = (1 - l) * utility_gradient + l * fairness_gradient # minus on the gradient calc.\n",
    "        gradient = project_gradient(gradient)\n",
    "        policy = policy + lr * gradient # maximize Utility & minimize fairness constrain.\n",
    "        policy = normilize_policy(policy)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# reproduce results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "# reproduce results\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_org_policy(org_path_results):\n",
    "    file = pd.read_csv(org_path_results + \"/policy.csv\")\n",
    "    p_1 = file.iloc[4].values\n",
    "    p_2 = file.iloc[5].values\n",
    "    p_1 = [float(x) for x in p_1[0].split(\" \")[1:]]\n",
    "    p_2 = [float(x) for x in p_2[0].split(\" \")[1:]]\n",
    "    return np.array([p_1, p_2])\n",
    "# [float(x) for x in p_1[0].split(\" \")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 141)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_path_results = \"/Users/andreasathanasopoulos/Phd/projects/bayesian_fairness/org_code/bayesian-fairness/src/octave\"\n",
    "policy = load_org_policy(org_path_results)\n",
    "policy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step : 1 \n",
      "  ------- {'fairness': 0.1363, 'utility': 0.5650138598478441, 'total': -0.0661686140152156}\n",
      "--- Step : 101 \n",
      "  ------- {'fairness': 0.2254, 'utility': 0.6068819276375023, 'total': -0.14217180723624978}\n",
      "--- Step : 201 \n",
      "  ------- {'fairness': 0.2441, 'utility': 0.621656288469007, 'total': -0.15752437115309934}\n",
      "--- Step : 301 \n",
      "  ------- {'fairness': 0.237, 'utility': 0.6282174714982683, 'total': -0.1504782528501732}\n",
      "--- Step : 401 \n",
      "  ------- {'fairness': 0.2311, 'utility': 0.6317311497537531, 'total': -0.1448168850246247}\n",
      "--- Step : 501 \n",
      "  ------- {'fairness': 0.2294, 'utility': 0.6328487039216448, 'total': -0.14317512960783552}\n",
      "--- Step : 601 \n",
      "  ------- {'fairness': 0.2274, 'utility': 0.6331077483098082, 'total': -0.1413492251690192}\n",
      "--- Step : 701 \n",
      "  ------- {'fairness': 0.2255, 'utility': 0.6333730935359196, 'total': -0.13961269064640808}\n",
      "--- Step : 801 \n",
      "  ------- {'fairness': 0.2252, 'utility': 0.6336972200556763, 'total': -0.1393102779944324}\n",
      "--- Step : 901 \n",
      "  ------- {'fairness': 0.2255, 'utility': 0.6340466135820823, 'total': -0.1395453386417918}\n",
      "--- Step : 1001 \n",
      "  ------- {'fairness': 0.2261, 'utility': 0.6343836365611125, 'total': -0.14005163634388879}\n",
      "--- Step : 1101 \n",
      "  ------- {'fairness': 0.2268, 'utility': 0.6347237786802603, 'total': -0.14064762213197396}\n",
      "--- Step : 1201 \n",
      "  ------- {'fairness': 0.2276, 'utility': 0.6350056550748159, 'total': -0.1413394344925184}\n",
      "--- Step : 1301 \n",
      "  ------- {'fairness': 0.2282, 'utility': 0.6352599593420583, 'total': -0.14185400406579418}\n",
      "--- Step : 1401 \n",
      "  ------- {'fairness': 0.2289, 'utility': 0.6355030192168084, 'total': -0.14245969807831915}\n",
      "--- Step : 1501 \n",
      "  ------- {'fairness': 0.2296, 'utility': 0.6357564756788674, 'total': -0.14306435243211327}\n",
      "--- Step : 1601 \n",
      "  ------- {'fairness': 0.2302, 'utility': 0.6360011935247097, 'total': -0.14357988064752902}\n",
      "--- Step : 1701 \n",
      "  ------- {'fairness': 0.2309, 'utility': 0.6362459101882433, 'total': -0.14418540898117568}\n",
      "--- Step : 1801 \n",
      "  ------- {'fairness': 0.2314, 'utility': 0.6364796526656741, 'total': -0.1446120347334326}\n",
      "--- Step : 1901 \n",
      "  ------- {'fairness': 0.232, 'utility': 0.63669843513735, 'total': -0.14513015648626504}\n",
      "--- Step : 2001 \n",
      "  ------- {'fairness': 0.2325, 'utility': 0.6368970351703512, 'total': -0.14556029648296492}\n",
      "--- Step : 2101 \n",
      "  ------- {'fairness': 0.233, 'utility': 0.6370637546772437, 'total': -0.14599362453227566}\n",
      "--- Step : 2201 \n",
      "  ------- {'fairness': 0.2335, 'utility': 0.6372074463511256, 'total': -0.14642925536488746}\n",
      "--- Step : 2301 \n",
      "  ------- {'fairness': 0.234, 'utility': 0.6373520639902578, 'total': -0.14686479360097426}\n",
      "--- Step : 2401 \n",
      "  ------- {'fairness': 0.2345, 'utility': 0.6375004231293251, 'total': -0.1472999576870675}\n",
      "--- Step : 2501 \n",
      "  ------- {'fairness': 0.2349, 'utility': 0.6376802737245001, 'total': -0.14764197262755002}\n",
      "--- Step : 2601 \n",
      "  ------- {'fairness': 0.2353, 'utility': 0.6378646386799156, 'total': -0.1479835361320085}\n",
      "--- Step : 2701 \n",
      "  ------- {'fairness': 0.2357, 'utility': 0.6380386619147964, 'total': -0.14832613380852036}\n",
      "--- Step : 2801 \n",
      "  ------- {'fairness': 0.2361, 'utility': 0.6381935121341855, 'total': -0.14867064878658148}\n",
      "--- Step : 2901 \n",
      "  ------- {'fairness': 0.2365, 'utility': 0.6383449352318107, 'total': -0.14901550647681894}\n",
      "--- Step : 3001 \n",
      "  ------- {'fairness': 0.2368, 'utility': 0.6384809909704051, 'total': -0.1492719009029595}\n",
      "--- Step : 3101 \n",
      "  ------- {'fairness': 0.2372, 'utility': 0.6385942064772611, 'total': -0.1496205793522739}\n",
      "--- Step : 3201 \n",
      "  ------- {'fairness': 0.2376, 'utility': 0.6386591228307186, 'total': -0.14997408771692816}\n",
      "--- Step : 3301 \n",
      "  ------- {'fairness': 0.2379, 'utility': 0.6387172606590037, 'total': -0.15023827393409964}\n",
      "--- Step : 3401 \n",
      "  ------- {'fairness': 0.2381, 'utility': 0.63880994543255, 'total': -0.15040900545674502}\n",
      "--- Step : 3501 \n",
      "  ------- {'fairness': 0.2383, 'utility': 0.6389250366418586, 'total': -0.1505774963358142}\n",
      "--- Step : 3601 \n",
      "  ------- {'fairness': 0.2385, 'utility': 0.6390328473539443, 'total': -0.1507467152646056}\n",
      "--- Step : 3701 \n",
      "  ------- {'fairness': 0.2387, 'utility': 0.6391363560630857, 'total': -0.15091636439369144}\n",
      "--- Step : 3801 \n",
      "  ------- {'fairness': 0.2389, 'utility': 0.6392270592481352, 'total': -0.1510872940751865}\n",
      "--- Step : 3901 \n",
      "  ------- {'fairness': 0.239, 'utility': 0.639306430830124, 'total': -0.1511693569169876}\n",
      "--- Step : 4001 \n",
      "  ------- {'fairness': 0.2391, 'utility': 0.6393516979482773, 'total': -0.1512548302051723}\n",
      "--- Step : 4101 \n",
      "  ------- {'fairness': 0.2392, 'utility': 0.6393934049178979, 'total': -0.15134065950821024}\n",
      "--- Step : 4201 \n",
      "  ------- {'fairness': 0.2394, 'utility': 0.6394387620058783, 'total': -0.1515161237994122}\n",
      "--- Step : 4301 \n",
      "  ------- {'fairness': 0.2395, 'utility': 0.639484035724784, 'total': -0.1516015964275216}\n",
      "--- Step : 4401 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6395313583176543, 'total': -0.15168686416823457}\n",
      "--- Step : 4501 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6395740547331559, 'total': -0.15177259452668443}\n",
      "--- Step : 4601 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6395593326004824, 'total': -0.15177406673995178}\n",
      "--- Step : 4701 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6395304362835127, 'total': -0.15177695637164873}\n",
      "--- Step : 4801 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6395018067072297, 'total': -0.15177981932927703}\n",
      "--- Step : 4901 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6394561530843963, 'total': -0.1517843846915604}\n",
      "--- Step : 5001 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6394068167659827, 'total': -0.15178931832340176}\n",
      "--- Step : 5101 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.6393574142960581, 'total': -0.1517942585703942}\n",
      "--- Step : 5201 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6393029067462253, 'total': -0.15170970932537747}\n",
      "--- Step : 5301 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6392474187137895, 'total': -0.15171525812862108}\n",
      "--- Step : 5401 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6391909979544919, 'total': -0.1517209002045508}\n",
      "--- Step : 5501 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6391387923459695, 'total': -0.15172612076540307}\n",
      "--- Step : 5601 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.639141991209964, 'total': -0.15172580087900361}\n",
      "--- Step : 5701 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6391825895090688, 'total': -0.15172174104909314}\n",
      "--- Step : 5801 \n",
      "  ------- {'fairness': 0.2396, 'utility': 0.6392212408366869, 'total': -0.15171787591633135}\n",
      "--- Step : 5901 \n",
      "  ------- {'fairness': 0.2397, 'utility': 0.639260430708791, 'total': -0.1518039569291209}\n"
     ]
    }
   ],
   "source": [
    "steps = horizon // update_policy_period\n",
    "\n",
    "results = []\n",
    "for step in range(steps):    \n",
    "    # update policy step\n",
    "    policy = update_policy(policy, belief, utility, l, lr, n_iter) # SDG to update policy\n",
    "    \n",
    "    # evaluation step\n",
    "    step_results = evaluate(true_dirichlet_model, true_model_delta, policy, utility, l)\n",
    "    results += [step_results]\n",
    "    \n",
    "    # update belief step\n",
    "    data_start_index = step * update_policy_period\n",
    "    data_stop_index = min(data_start_index + update_policy_period, horizon)\n",
    "    belief.update_posterior_belief(train_data.iloc[data_start_index : data_stop_index])\n",
    "    \n",
    "    print(f\"--- Step : {data_start_index + 1} \\n  ------- {step_results}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5108256237659907"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6094379124341003"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(true_dirichlet_model, \u001b[43md_2\u001b[49m, policy, utility, l)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_2' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate(true_dirichlet_model, d_2, policy, utility, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[data_start_index : data_stop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_resutls[[\"utility\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load org resutls\n",
    "org = np.loadtxt(org_path_results + \"/results.csv\")\n",
    "org = org[:,1][1:].reshape((4,-1))\n",
    "\n",
    "org_pd = pd.DataFrame( columns= [\"utility\",\"fairness\",\"total\"])\n",
    "org_pd[\"utility\"] = org[0]\n",
    "org_pd[\"fairness\"] = org[2]\n",
    "org_pd[\"total\"] = org[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"utility\"].plot()\n",
    "pd_resutls[\"utility\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(org_pd[\"utility\"], label = \"original code results\")\n",
    "plt.plot(pd_resutls[\"utility\"], label = \"new code results\")\n",
    "plt.title(\"Utility\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(org_pd[\"fairness\"], label = \"original code results\")\n",
    "plt.plot(pd_resutls[\"fairness\"], label = \"new code results\")\n",
    "plt.title(\"Fairness\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pd[\"fairness\"].plot()\n",
    "pd_resutls[\"fairness\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. ProjectPolicyGradient ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
